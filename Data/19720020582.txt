b'General Disclaimer\nOne or more of the Following Statements may affect this Document\n\nThis document has been reproduced from the best copy furnished by the\norganizational source. It is being released in the interest of making available as\nmuch information as possible.\n\nThis document may contain data, which exceeds the sheet parameters. It was\nfurnished in this condition by the organizational source and is the best copy\navailable.\n\nThis document may contain tone-on-tone or color graphs, charts and/or pictures,\nwhich have been reproduced in black and white.\n\nThis document is paginated as submitted by the original source.\n\nPortions of this document are not fully legible due to the historical nature of some\nof the material. However, it is the best reproduction available from the original\nsubmission.\n\nProduced by the NASA Center for Aerospace Information (CASI)\n\n1\t\n\ns\t\n\ni\n\ni\n\nE\n\nC\nLECTRONICS LABORATORY \xe2\x80\xa2 SYRACUSE, N V\n\nov^ - /\t\n-p\n\ny\n\n.-@::J1.fi\n\n\'Yrrrt,\n\njK\n\nFinal Repor t\n\nELECTRONIC SCENE GENERATOR\nV)\n\nC;\n\ntd T\n\nN\n\n1\nN\n\n..a ac\n\nr\nz\n\nEXPANSION SYSTEM\n\na^\no ^^\n\nU 111\n\nv\n0\n\nDecember 1971\n\nC7\n\nEll\n\n0\n\nv\n\npUU\nM 4) N\nyLU\nx\n\nContract No. NAS 9-11065\n\nW\n\nZr^-\n\nGO\n\xe2\x80\xa2r4U\n\nU\n\nN\n\nW\n\nV U\n\nyz^\nC\n\nw\n\n+^\n\nH In d\n\nU ,\xe2\x80\xa2 \xe2\x80\xa2-4\n(<7NW\nW\n\n7\n\n-4\n\nO A\n\nN N\n\n-7:2 .d 4r\n\nPrepared for\n"J\t\n\nMANNFD SPACECRAFT CENT\n1ATIONAL AERONAUTICS AND SPACE A ll^-a \t\n4^^\nHOUSTON, TEXAS\t\n\nr\xe2\x80\x94 CIA c^\n\nw\n\nas\nW\n\nv HEN\n\nw \xe2\x80\xa2\n.^zxr\n\ncn\n\nG E N E R A L\'.^^\' ELECTRIC\n\n^`\n\n10N p,\n\n\t? ,.,t\n\n1\n\n\t\n\n\t\n\xe2\x80\xa2\n\nFinal Report\n3LECTRONIC SCENE GENERATOR\nEXPANSION SYSTEM\nby\n\nW. H. Sharp\nElectronics Laboratory\nGeneral Electric Company\nSyracuse, New York\nDecember 1971\n\nContracto. NAS 9-11065-\n\n^V\n\n\t\n\nPrepared for\nMANNED SPACECRAFT CENTER\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\nHOUSTON, TEXAS\n\nPrepared by\n\nElectronics Laboratory\nGeneral Electric Company\nSyracuse, New York\n\n1\n\n\t\n\xe2\x80\xa2\n\n1 \t\n\nABSTRACT\nThis is the final report submitted in accordance with the provisions of\nContract NAS 9-11065, Electronic Scene Generator Expansion System.\nThP program encompassed the design, fabrication, and installation of\naddit"ons, and modifications to the Electronic Scene Generator located at the\nNASA Manned Spacecraft Center, Houston, Texas. The equipment delivered\non this contract was incorporated into the Electronic Scene Generator to enhance its capabilities by providing:\n1) Additional source computer interfaces\n2) Additional edges thereby allowing more detailed scenes\n3) The ability to share edges to effect economies in complex\nscenes\n4) The ability to use edges without the constraints of a\nconfiguration catalog\n5) The simplified implementation of new environments and\nenvironment modifications.\nThis report contains a summary of the Contract effort and a description\nof the delivered equipment.\n\ni\n\n1\n\n^\n\n\t\ne\n\t\n\n1\n\nTABLE OF CONTENTS\nSection\n\nTitle\n\nPage\n\n1\n\nINTRODUCTION\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n\n1\n\n2\n\nBACKGROUND .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n\n3\n\n3\n\nSCENE GENERATOR EXPANSION SYSTEM . . . . .\t .\t .\t .\t .\t\n3.1\t System Specifications\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n3.2\t Major Technical Changes in Scene Generator\nExpansion System .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n\n4\n4\n4\n\n3.2.1\t\n\n.\t\n\n4\n\n3.2.2\t\n3.2.3\t\n3.2.4\t\n4\n\nGeneral\t\n\nList Priority\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\nEdge Sharing\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\nStart-Stop Implementation\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n\n4\n5\n10\n\nEDGE PROCESSOR UNIT DESCRIPTION . . . . . .\t .\t .\t .\t .\t\n\n12\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n4.1\t\n\nGeneral\t\n\n.\t .\t\n\n12\n\n4.2\t\n4.3\t\n\nImplementation\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\nMechanical Information\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\n\n12\n15\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\n\n15\n\n4.3.2\t\n4.3.3\t\n4.3.4\t\n5\n\n.\t\n\nLogic Cards\t .\t .\t .\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\nCooling Provisions\t .\t .\t .\t .\t .\t .\t .\t . .\t .\t .\t .\t .\t\nPower Generation and Distribution\t . .\t .\t .\t .\t .\t\n\n15\n20\n20\n\nSOFTWARE\t .\t .\t .\t .\t .\t .\t .\t\n5.1\t General\t .\t .\t .\t .\t .\t .\t\n5.2\t Off line Software\t .\t .\t\n5.3\t O:_, Iine Software .\t .\t .\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\nM\'\n\niii\n\n^r\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t .\t .\t .\t\n.\t .\t .\t .\t\n.\t .\t .\t .\t\n.\t .\t .\t .\t\n\n.\n.\n.\n.\n\n.\t\n\n.\t .\t\n\nGeneral\t\n\n.\t\n\n.\n\n.\t\n\n4.3.1\t\n\n.\t\n\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t .\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n.\t\n.\t\n.\t\n.\t\n\n21\n21\n21\n21\n\n1\n\nLIST OF ILLUSTRATIONS\nFigure No,\t\n\nPaEe\n\nTitle\t\n\n1.\n\nExpanded. Scene Generator System . . . . . . . . . . . .\t\n\n2\n\n2.\n\nEdge-Sharing \xe2\x80\x94 Planar Features . . . . . . . . . . . .\t\n\n7\n\n3.\n\nEdge-Sharing \xe2\x80\x94 Objects . . . . . . . . . . . . . . . .\t\n\n7\n\n4.\n\nEdge-generated Texture . . . . . . . . . . . . . . . .\t\n\n8\n\n5.\n\nBasic Instrument Runway\t\n\n. . . . . . . . . . . . . . .\t\n\n8\n\n6.\n\nFace Formation . . . . . . . . . . . . . . . . . . . . 11\n\n7.\n\nEdge Processing Unit (EPU) System Block Diagram . . . . 13\n\n8.\n\nEdge Processor Unit . . . . . . . . . . . . . . . . . . 16\n\n9.\n\nCogar Memory Card 08CO3 . . . . . . . . . . . . . . . 17\n\n10.\n\nMultilayer Card . . . . . . . . . . . . . . . . . . . . 18\n\n11.\n\nHand-wired, General-purpose Card .\t\n\niv\n\n. . . . . . . . . 19\n\ns\n\n1\n\n\t\n^\n\t\n\n1. INTRODUCTION\nThe Electronic Scene Generator (ESG) in the Guidance and Control Division\nat the NASA Manned Spacecraft Center in Houston, Texas, provides scenes for\nout-the-window views for engineering simulation studies, The Scene Generator\nExpansion System delivered to NASA on Contract NAS 9-11065 was incorporated\ninto the ESG to enhance its capabilities by providing:\n1)\n2)\n3)\n\nAdditional source computer interfaces\nAdditional edges, thereby allowing more detailed scenes\nThy, ability to sharw edges to effect economies in complex\nscenes\n\n4)\n5)\n\nThe ability to use edges without the constraints of a configuration\ncatalog\nThe simplified implementation of new environments and\nenvironment modifications.\n\nThe effort on this program was divided into two parallel, independent tasks,\nthe Input Expansion effort and the Scene Generator Expansion effort. The Input\nExpansion effort, conducted as a six-month program, resulted in one item of\ndelivered equipment, the Input Expansion Unit, and its associated software.\nThis effort was completed in December 1970 and documented in the final report\ntitled Expansion of Input Capability for Electronic Scene Generator. For further information on the Input Expansion Unit refer to this document. The Scene\nGenerator Expansion effort, conducted as an eighteen month effort, resulted in\none item of delivered hardware, the Edge Processor Unit (EPU), and its associated software. The EPU replaced the two Object Generator Units supplied on\nContract NAS 9-3916. The expanded Scene Generator System is shown in\nFigure 1. The software development effort on the program was divided into\ntwo parts, the Offline software and the Online software. The Offline software\nused for preprocessing the environment data was generated by Lockheed personnel resident at the NASA Manned Spacecraft Center, Houston, Texas, under\nthe direction of General Electric personnel. The Online programs used for\nreal-time operation of the ESG were generated by General Electric personnel.\nThe EPU and associated software were delivered and installed in the Guidance\nand Control Division at the NASA Manned Spacecraft Center in Houston, Texas,\nin November, 1971.\n\n1\n\n1\n\n1\n\n\t\n\nAT\n\nI\n\t\n\nt............ ,. _J\n\n\'r\'Ef"`IOR\t\nINPI "I\'\tRAYTHEtati\t\n11520CALCI\'LATING\'\t\nINTERFACE\t\n\nUNIT\t\n\nCONIPI"I\'h\'.R\t\n\nI:I)C7I?\n\nPROCESSING\n\nUNIT\n\nFROM\nPROBLEM\nCOMPUTERS\nINPUT\nEXPANSION\t\nI\'NIT\t\n\nTI:^1\nAND\nOUTPUT\nVNIT\n\nAISPLAYS\n\nAND\nMONITORS\n\nSUItI\'ACE\nGENERATING\'\nSUBSY51 EM\nDIGITAL TO\nANALOG\nCONVERSION\nYERSI(,)N\nUNIT\n\nNEW\n\xc2\xae MODIFICATION\nUNCIIANGE D\nr------^\n.. _ _ - _ __.; UNUSED\n\nFig r-^ 1. Expanded Scene Generator System\n\n2\n\n.\t\n\nI\n\n^\n\n\t\n\n\t\ns\n\n1\n\n2. $ACKUROUND\nThe Electronic Scene Generator built for NASA by the Electronics Laboratory of the General Electric Company on Contracts NAS 9-3916 and NAS 9-1375\nis an electronic system that simulates the external visual env ronnient of a space\nvehicle. The equipment generates textured surfaces, three-dimensional objects,\nand certain other special pictorial effects such as horizon dip and curvature, a\nmoving vehicle\'s shadow, and a point-source flashing beacon. The interface capability allows communication with up to five source computers furnishing attitude and position data for multivehicle studies or for several studies run simultaneously.\n\nA.\n\nDigital descriptions of the location, size, shape, and color of objects used\nto simulate the visual environment are stored in the ESG. Inputs to the equipment from the source computers describe the attitude of from one to three observers in, the environment, and perspective transformations are performed at\nthe frame rate of the kinescope displays to present each observer with his correct perspective view of the simulated environment. For further details of this\nsystem, see the Final Deport for Contract NAS 9-3916, Modifications to Interim\nceflight\nVisual Spaceflight Simulator.\n\n3\n\nr ^,\n\n^\n\n\t\ns\n\t\n\n3. SCENE GENERATOR EXPANSION SYSTEM\n3. 1\t\n\nstem S ecifications\n\nThe expansion of the capabilities of the Electronic Scene Generator is\nimplemented primarily by the Edge Processing Unit (EPU). The EPU is\ncapable of generating color video scenes, once every display frame time\n(120th second), containing the following scene content:\nEdges:\t\nedge References: \t\n\n320\n768\n\nFaces:\t\n\n192 active faces per raster line\n256 entries in face list\n\nViews:\t\n5 (faces assignable to views in blocks of 16)\nColor Information: 256 discrete color memory addresses per view\nThe peripheral hardware xn the Electronic Scene Generator (Raytheon 520,\nVector Calculating Unit, Timing and Output Unit, etc. ) is not capable of\nsupporting full utilization of the EPU; the EPU is therefore restricted to\nscenes containing the following content:\nEdges:\t\n\n320\n\nEdge References: 768\nFaces:\t\n192 composed of up to 20 edges per face\nViews:\t\n3 (faces assignable to views in blocks of 16)\nColor Information: 13 discrete color memory addresses per view\n3, 2 Major Technical Changes in Scene Generator Expansion System\n3.2.1 General\n\nThe Scene Generation Expansion System (hereafter called the NASA III\nsystem) is based on essentially the same algorithms used is the system delivered on Contract NAS 9-3916 (called the NASA II system). For details, see\nVolume I, Instruction Manual for Modifications to Interim \'Visual Spaceflight\nSimulator. lit three areas, however, significant changes have been made. The\nfirst of these is the use of list priority rather than matrix priority. Second,\nthe architecture of the NASA III system allows the sharing of edges. Finally,\nthe concept of Start/Stop numbers has been used to reduce the requirement for\nvideo rate hardware. These changes are described in paragraphs 3.2.2, 3.2.3\nand 3.2.4, following.\n3.2.2 List Priority\nThe edge processing techniques used in the Scene Generation Expansion\nSystem are based on a solution of the hidden face problem referred to as List\nPriority. The solution rerynires that the environment be structured so that, for\nany given view of it, the faces may be ranked from highest to lowest priority.\nList priority is not quite as general as priority implemented by the previous\n4\n\n1\n\nr\n\n1\n\n\t\n\n\t\ns\nnnatrix technique, and thorn are soniv situations (rarely onc \xe2\x96\xba )untorod In practical problenm), that cannot be handled by the list approach. On the other hand,\nthe lint approach, which deals with facer;, can often handle situations that a\nmatrix, dealing with complete objects, cannot. One example of this is an object\nwithin an object. If the smaller object is completely within the larger, list\npriority allows the outside faces of the outer abject to have priority over the\ninside abject, as well at) over its own inside faces. The inside object\'s faces\nare given priority over the inside faces of the outer object, and priority is\ncorrect. The matrix solution used previously did not differentiate between the\ninside and outside faces of the larger object and could not solve the problem.\nThe principal advantage to list priority is that image- genera^.tion hardware call\nbe expanded indefinitely without a square-law growth of either hardware or\ncomputing time.\n\nList priority makes use of planes to separate clusters of faces, much\nthe same as the matrix approach. Clusters are defined as groups of faces whose\norder of priority is always the same. A convex object would be a cluster, since\nits outside faces can never conflict with each other, and, if inside facesall\nare\nused, they always have lower priority than outside faces. The rule for\nto be suitable for list priority is that every subset of three clusters\nmust be separable by two planes. Stated in another way, each cluster is to be\nseparated from any other cluster by one plane, and the total number of separating planes will be at most one less than the number of clusters.\nAlthough clusters and separating planes must be chosen by the environment designer, experience with this approach indicates that it is easier and\nless subject to designer\'s errors than the matrix approach,\n3.2. 3 Edge Sharing\nThe capabilities of the Scene Generator Ex p ansion System cannot be compared with the present system solely on the basis of the number of edges. The\nnew edge-processing techniques provide edges that are more powerful and offer\nthe potential for greater scene detail per edge. The relative value of new and\nold edges depends entirely on the geometric arrangement of the environment\nmodel. Therefore, any evaluation of the equivalent capacities of the two systems must consider their differences, and, to be concrete, must reference\nspecific applications. The following paragraphs discuss the mechanisms by\nwhich improvement is attained and illustrate the relative merits of the two\nsystems with examples.\nThe expanded scene generator employs edge-processing hardware capable of 320 edgeR- These edges may be used to form convex planar polygons\n(faces) employir, ,, u to 20 sides. Faces, in turn, may be geometrically arranged in space to Lorm three-dimensional objects subject only to the restriction that they be non-intersecting and amenable to priority-list processing (see\nSection 3. 2.2) .\n\nThe fact that faces and objects can now be formed at the discretion of\nthe environment designer to meet the needs of the model is an important advantage of the new system and contrasts with the former requirement to mare\nthe model from a limited number of basic shapes and to conform to bin-configuration rules necessitated by the physical partitioning of the hardware into 24\nedge groups called bins. Clearly, modeling is simplified and more efficient.\nCompound objects, either convex or concave, can be modeled directly without\nthe duplication of edges and faces that results in the NASA II system when simple\n5\n\n1\n\n1\t\n\n1\n\ns\n\nsolids are combined, The selection of one object type duos not influence the\nchoice of others as it does in the NASA II system with bin constraints; a change\nto one part of a model does not propagate to Esther parts, and one is not faced\nwith the problem of substituting complex shapes for simpler ones b(-cause tho\nlatter are not available,\nThe new edge-processing techniques permit the sharing; of edger, so\nthat a single edge can participate in a number of faces, not only within an object but on other objects as well. Edge sharing makes use of the fRet that the\nmachine representation of an environment edge is infinite in length and not\nlimited by its defining vertex pair. Figures 2 and 3 show how sharing can he\nused. to advantage, to make both plane figure\'s and solids.\nThe planars in Figure 2 are being used for runway threshold markings,\nwhile edges 1 and 2 serve to bound the five faces on the top and bottom, respectively. A total of 12 edges is needed, whereas the same five faces constructed\nwith P4 objects would require 20 edges. Moreover, if the P4 objects could nog\nbe obtained in conjunction with other bin objects, four of the faces would require\nthe use of a 24-edge bin and the total would be 28 edges.\nFigure 3 shows one edge participating in six faces of a group of objects.\nSeven other edges participate in three or more faces and the total edge count is\n32. Implementing the objects with four S12s requires 48 edges, Note that\nseveral edges are saved at the joining faces of the compound obyt.ct.\nThe ability to, share edp,es introduces the requirement for another parameter that helps to define system capability \xe2\x80\xa2-- edge references. The number of\nedge references considers each edge and the number of times it is used in faces.\nIt is found simply by summing the number of edges in every face in the environment. The objects of Figure 3 require 80 edge references, assuming that each\nhas one bottom face. If these objects were to be placed on the ground, the bottom faces would be unnecessary and they would require 72 edge references,\nThe E PCT will provide for 768 edge references, thus allowing; an average sharing\nratio of about 2. 5:1.\nThe amount of sharing needed is a function of the type of environment.\nIsolated planars may allow no sharing, simple solids require about two references per edge, and compound objects use more. An extreme example of\nsharing is shown in Figure 4, where edges are used to construct texture patterns. The photograph shows a plan view of an area approximately 15 by 20\ni.Ailes which uses about 50 edges and 400 references. The sharing ratio for\nthis system was selected to allow the generation of a texture pattern of about\n\'\none-half the complexity shown when used in conjunction with more conventional\nplanar and three-dimensional detail.\n\n.P\nr\'\n\t\nY\n\n6\n\n1\n\t\n\no\n\nEdge I\n4\n\nm\t\nv\t\n\t\n\nLo\n\nv\t\na,\t\n\nin\na,\n\nEdge 2\n\nFigure 2. Edge-Sharing \xe2\x80\x94 Planar Features\n.1\n\n,F\n\nFigure 3. Edge-Sharing \xe2\x80\x94 Objects\n\n7\n\nFigure 4 Edge-generated Texture\n(Photo a 123169-5-A)\n\nFigure 5. Basic Instrument Runway\n(Photo # 123169-5-F)\n\n8\n\n^\n\n\t\ns\n\t\n\n1\n\nAn example will illustrate whet might be achieved with the new system\nand its equivalent complexity in terms of existing capability. The example will\nconsider the environment models for three independent problems; an airport,\na space shuttle, and a section of a space base. Approximately 100 edges are\ndevoted to each model.\nThe airport consists of a 10, 000-ft. runway, a taxiway and ramp area,\na tower, and a hangar. The runway has basic instrument markings, as shown\nfor runway 32 in Figure 5, except that the numerals are omiCted and the centerline extends for only 2000 feet (nine sections). These features would require\n71 edges with the proposed system, rather than 120. The difference is due, in\npart, to the extensive use of quadrilateral faces. Additionally, 26 edges are\ndevoted to background texture generation over a 20-by-20 mile area. These\nedges are not included in the comparison because they have no meaningful\nequivalent. The effectiveness ratio of new edges to old edges is 120/71 or\n1.7;1.\n\nThe space shuttle model includes a fuselage formed with two S18s and\nwings and horizontal stabilizers made with S12s.\t Two S6s and three P8s make\nup the remaining detail.\t A total of 102 edges is required to make this model,\ninstead of 120.\nThe space \'base consists of one central hub modeled with an 524, four\nsymmetrically placed arms (S12s), and four symmetrical outer modules\nmodeled with S18s.\t By virtue of the symmetry involved, this 144-edge scene\ncould be implemented with 116 edges.\n\n;a\n\nTable I summarizes the results of this example. \t The three environments, modeled with the full capability o^ she proposed system, are the equivalent of 384 edges plus the surface texture pF ttern.\n\n`\n\nTABLE I\nCAPABILITY COMPARISON\nENVIRONMENT\t\n\nAirport\t\n\nNASA II EDGES\t\n\n(\t\ni\n\nNEW EDGES \t\n\n120\t\n\n71 (96)\t\n\nEDGE REFERENCES\n\n118 (280)\n\nSpace Shuttle\t\n\n120\t\n\n102\t\n\n256\n\nSpace Base\t\n\n144\t\n\n116\t\n\n210\t\n\n384\t\n\n289 (315)\t\n\nTOTAL\t\nI\t\nj\t\n\n;i\t\t\n{\t\n\n(\t\n\n.y,\n\nt\n\n9\n\xe2\x80\xa2i\n\n)\n\n`\t\nI\n\n584 (746)\n\nincludes edge texture\n\ni\n\n^\n\n\t\ns\n\t\n\nIn addition to the number of edges and the number of edge references,\none ether parameter must be specified to fix the system capability -- the number of fares. The number of faces is the number of separate convex planar\npolygons defined by edges. This does not include the multitude of regions\n(convex or concave) that may be formed by overlaying faces of different priority, such as in ground texture. Faces are one-sided, so that a so-called solid\nobject will normally have no inside faces. If inside faces are desired, they\nare specified as separate faces and require additional edge references, but\nnot edges. An inside face uses the same edges as the outside face, but references them in the reverse order.\nIn summary, the capabilities of the expanded system are;\n320\nEdges;\t\nEdge References; 768\nFaces;\t\n192\n3. 2.4 Start - Stop Implementation\nIn the NASA II system, the intersection of every edge with the raster is\ngenerated at the video rate. In the NASA III system, only the bounding edge\nintersections of the face are generated at the element rate. The bounding element numbers are referred to as Start and Stop numbers, which correspond,\nrespectively, to the lowest and highest element numbers occupied by the face.\nThe Start and Stop numbers are determined by specifying the bounding\nedges of the face as being either Start or Stop edges, and then selecting the\nappropriate edge intercepts that define the extremities of the face. Figure 6\nshows a face bounded by four edges. In this case, edges 1 and 4 are Start\nedges and edges 2 and 3 are Stop edges. On any given raster line (line q for\nexample), the face (if it appears) will be bounded on the left by one of the\nStart edges and on the right by one of the Stop edges. The selection of the\nbounding edges is accomplished by (1) comparing all the Start intersections,\nselecting the largest one, and (2) by comparing all the Stop intersections,\nselecting the smallest one. On line q in Figure 6, for example, the bounding\nStart and Stop edges will be edges 1 and 3. The selected Start and Stop numbers are stored for use by the face generation section during the next raster\nline. If the face does not appear on the present raster line, the largest Start\nnumber will be greater than the smallest Stop number, and the numbers are\nnot stored. This is the case for line k, Figure 6.\nLuring the next active raster line, the two numbers are decremented\nat the video rate (in the EPU the ones complements of the numbers are incremented but the result is the same). The face is active from the time the\nStart count reaches zero until the Stop count reaches zero. The priority network determines which of the current active faces should be displayed.\n\n10\n\n1\n\n1\n\n\t\n\n.-0-\n\n\t\ns\n\n1\n\n.\t\nF.DGI^, I.\t\n\nIF,D(TE 2\n\nEDGI\': 3 ED0 4\n1,,\'\n\nLINE k\n\nA\n\nLINE q\n\nDIRECTION OF RASTER SCAN - \xe2\x96\xba\n\nFigure 6. Face Formation\n\nM\n\n11\n\n0\n\n\t\n1\n\ns\t\n\n-00\n\n4. EDGE PROCESSOR UNIT DESCRIPTION\n4.1 General\nComputations made by the Edge Processor Unit during the active frame\ntime consist of a series of sequential processing steps or cycles. The basic\nprocessing time unit is a raster line-time and the several tasks required to\nform a complete raster line of video are performed in successive line-time\noperations. Three main tasks are performed in generating the video data.\nThey are;\n1) Edge Update - Find for each. raster line the distance in elements\nfrom the left side of the picture to the intersection of each edge\nwith the raster line.\n2) Face Determination - Find for each raster line the edges which\nbound the intersection of each face with the raster line.\n3) Face Generation, Selection, and View Display Assignment - Generate for each raster line the faces intersecting the line and select\nthe highest priority face for each view. Then assign each view to\nthe correct display.\n4.2 Implementation\nThe block diagram for the Edge Processor Unit (EPU) is shown in Figure\n7. Each functional unit is contained on one motherboard. All input data from\nthe Scene Generator Vector Calculator Unit are transferred thA ough the Timing\nand Output Unit and received in the Frame Buffer Unit (FBU). All synchronizing\ntiming signals are sent from the TOU to the General Timing Unit (GTU). All\noutput data from the EPU are transmitted from the Priority View Assignment\nUnit (PVU) to the TOU.\nThe Frame Buffer Unit (FBU) provides the input data interface for the\nEPU. The data for the EPU are transferred serially from the TOU, converted\nto a parallel format, and transferred to the appropriate unit within the EPU.\nThe destination within the EPU is determined by a steering field code from the\nVCU. Four distinct data transfers are accomplished through the FBU. The\nEdge Sequence List, which, is loaded as part of the environment setup, is transferred from the VCU through the FBU to the List Sequencing Unit. During system operation, the edge quantities (A\'s and B\'s) are transferred into the FBU\nduring the early part of vertical blank time and are temporarily stored in buffers\nwithin the FBU. When all 320 A\'s and B\'s have been received, they are transferred to the two Edge Update Units. Also during vertical, blank time, the List\nSequencing Unit is loaded with the Face List. The final transfer through the\nFBU during vertical blank time is the Display Assignment Word, which is\ntransferred through the FBU to the Line Buffer Unit.\n\n12\n\n1\n\n^\t\n\n\t\ns\n\nf\t\n\nI\n\nVC U visa, TOU\n\nFrame Buffer\n\nUnit\n(FBU)\n\nEdge Update\nUnit\n(EUU)\n\nList Sequence\t\nUnit\t\n(LSU)\t\n\nEdge Update\nUnit\n(E UU)\n\nFace\nDetermination\nUnit (FD U)\nLine Buffer\nUnit\n(LBU)\n\nG\n^ eneral Timing\t\nUnit\t\nTOU\t\n(GTU)\n\nFace Generator\nUnit\n(FGU)\n\nPriority and\nView Assignment\nUnit\n(PV U)\n\nFace Generator\nUnit\n(FGU)\n\nDisplays\nvia TOU\n\nFigure 7. Edge Processing Unit (E PU) System Block Diagram\n\n13\n\nr\n\n^\t\n\n\t\ns\n\nJ\t\n\nEach Edge Update Unit (EUU) performs the A plus 13 operation for 160\nedges. The A and D quantities are loaded into the EUU\'s during even field\nvertical blank time. When the computation cycle starts, the 13\'s are added to\nthe A\'s once every line time. The accumulating A\'s are examined for numbers\noff the display, saturated to all zeroes or ones if appropriate, and transferred\nto the Face Determination Unit. Each EUU contains field \'buffer moniories,\nwhich are used to refresh the A quantities during odd field vertical blank time.\nThe List Sequencing Unit (LSU) generates a list of addresses of edges\nevery line time for use in the Face Determination Unit. The addresses refer\nto the locations of the edge quantities in the buffers in the Face Determination\nUnit. The addresses are grouped by face, ordered by faces in priority order,\nand grouped by view in that ascending order. The LSU generates this list every\nline time, using two lists, the Edge Sequence List and the Face List. The\nEdge Sequence List contains the face-grouped addresses. The Face List contains a view-grouped, priority-ordered list of starting addresses in the Edge\nSequence List. The Face List also contains the color code and view assignment of each face. These quantities are buffered temporarily and then transferred to the Line Buffer Unit. Both Edge Sequence List and Face List are\nloaded from the FBU -- the Edge Sequence List during environment setup and\nthe Face List during even field vertical blank time.\nThe Face Determination Unit (FDU) contains two high-speed buffer memories and the fd^e determination logic. The two memories are used in a multiplexed mode to store data from the EUU\'s and to provide data to the face determination logic. On a raster line, one memory is storing data from the EUU\'s\nand the other is providing data to the face determination logic. The data from\nthe EUU\'s are leaded sequentially. The data for the face determination logic\nare unloaded using addresses provided by the LSU. The face determination\nlogic examines edges to find the bounding edges for each face on a raster line.\nThe edge is examined to determine if it is a Start edge or a Stop edge and the\nelement intercept number is compared with the last stored Start or Stop intercept number. If the edge is a Start edge and the intercept number is larger\nthan the stored intercept number, the new edge intercept is stored. If the edge\nis a Stop edge and the intercept number is less than the stored Stop intercept\nnumber, the new intercept number is stored. When all edges in a face hove\nbeen processed, the selected Start and Stop numbers are transferred to the\nLine Buffer Unit. If the Start number is greater than the Stop number, the\ntransfer is disabled and the face is discarded.\nThe Line Buffer Unit (LBU) is loaded with the Display Assignment Word\nduring even field vertical blank time from the FBU. During the active line time,\nthe LBU is loaded with Start and Stop numbers from the FDU and face color and\nview assignment daia from the LSU. During horizontal blank time, the data are\ntransferred to the Face Generator Units. The LBU monitors the view assignment code during the data transfer to the Face Generator Units and insures that\nall view changes occur on a modulo 16 face count. If a view change occurs and\nthe number of faces shifted into the Face Generator Units is not modulo 16, the\nunloading of faces is stopped and dummy Start/Stop numbers are transmitted.\nWhen the modulo 16 count is reached, the reading of faces is restarted. Also\n\n14\n\n1\n\n1\n\n\t\n\n\t\ns\nduring horizontal blank tine, the Display A.,sit nment word is transferred tr y the\nPriority and View Assignment Unit to control the view \'display assignment logic.\nThe two face Generator Units (FGU\'s) are loaded with Start and Stop nunibers from the LBU during horizontal blank time. Each FGU is capable of generating 96 faces during the active raster time. Each face is generated using; a\npair of counters, a Start counter and a Stop counter. The ones complements of\nthe Start and Stop numbers are loaded into the counters and incremented using\na video clock from the TOU. The face active indicator is turned on when the\nStart counter reaches all ones and turf .1d off when the Step counter reaches all\nones. First-level priority is provided by grouping 16 faces of Start and Stop\ncounters. During the active line time, a face active indicator and the address\nof the highest priority face active in each 16-face group are transferred to the\nPriority View Assignment Unit.\nDuring horizontal blank tin\t\nthe Priority View Assignment Unit is loaded\nwith face color, view assignment, and view/display assignment data from the\nLBU. During the active line time, the view assignment code is used to determine the highest active face for a specific view. The address from the FGU\'s\nis used to determine the color word for the highest priority face, The view/\ndisplay assignment word is then used to gate the color word to the appropriate\ndisplay.\nThe General Timing Unit provides horizontal and vertical timing signals\nand digital clock signals to the various units in the E PU. The primary clock\nstandard is a 25-MHz crystal oscillator. The horizontal and vertical counters\nin the General Timing Unit are synchronized by signals from the TOU.\n4.3 Mechanical Information\n4.3.1 General\nThe Edge Processor Unit is contained in a double-bay cabinet. (See\nFigure 8.) The cabinet is similar in appearance to the enclosures provided on\nContract NAS 9-3916. The cabinet contains the digital logic, required power\nsupplies and filtered blower assemblies. Primary power is 220-VAC 60-Iiz 3-0\nAll interconnecting signal and power cables were furnished as part of the Contract.\n4. 3. 2 Logic Cards\nThe digital logic used to implement the E PU is contained on 16 purchased\nmemory cards, 28 multilayer cards, and 66 hand-wired logic cards. The cards\nare inserted into hand-wired motherboards that provide for power distribution,\nfusing, and intercr mection.\nCogar 08CO3 High-Performance memory cards are used for high-speed\nbuffer memory. These cards supply 128 16-bit words with a cycle time of 80\nnanoseconds. A General Electric-designed multilayer card was used to adapt\nthe Cogar edge connector to the E PU format. (See Figure 9.)\n\n15\n\n1\n\n\t\n\n^nr- \xe2\x80\xa2s tour\' n\t\n\nM\t\n\n1\n\n^\n\ni\t\n\n1\n\nI\n\nEdge Processor Unit\n(Photo No. 102771-7 F11)\n\n1\n\nit\n\ni\n\nU\n\nFigure J. Cogar Memory Card 08CO3\n(Photo No. 101171-6 F1)\n\n17\n\n1\n\n4v\t\nMultilayer cards were used whet i n \xe2\x96\xba ultiple cards of one design were\nrequired. The multilayer cards acc i-pt up () 140 dual-inline packages. ( Svi,\nFigure 1U.)\n\ndc)^\t\n\n,\n\n\xe2\x80\xa2 11,110Z 0\n\nw\n\nr\n\nr }\t\nVii?\n\nw\t\n\nr a\n\n^+^K1Q\xe2\x96\xba1R 41r^14i4^\xc2\xb0\n\nIlll1111111UUUUlUUU111U1111^ .\n\nFigure 10. Mu It i l_iyer Card\n(Photo Nu. 102771-6 F8)\nThe remaining logic in the system was implemented on hand-wired\ngeneral-purpose cards. These cards accept up to 64 dual-inline packages.\n(See Figure 11. )\n\n18\n\n1\n\nI\n\t\n\nI^\n\niiiiiiiililllllllllillllll ll1111111\n\ni\n\ni\n\na^\n\nlei\n\nuvV\nAl\n\ny\n\ni\nat 13\n\nY1\n\n44,\t\n\nk,\n\n% + ^ w^ h\t\n\nV w\n\n-M I. z\n.-\'\n\nFigure 11. Hand--wired, General-purpose C\'ard\n( Photo No. 102771-6 F\'G)\nI\'he logic cards are inserted into hand-wired motherboards that provide\nfor power distribution, fusing, and interconnection. The motherboards are\ninterconnected wit \xe2\x96\xba , twisted-pair, 50-ohm coax and 92-ohn. coax. All coax interconnections were made with miniature pull-type coax connectors.\n\n19\n\n1\t\n\n^\n4.3.3 Couli.ng Pruvisions\nCooling air for the digital circuitry is provided by McLean 500 CFM\ncentrifugal blowers at the bottom of the logic card bins and Rotron Feather fans\nat the ton of the bins. Air interlock switches are incorporated into the bottom\nblowers to protect the circuitry if\' the blowers should fail. Temperature sensors are located at the top of the bins to sound an alarm if the exhaust air should\nreach 95oF. Additional cooling air for the power supplies is provided by McLean\n1E 2206 blowers located at the bottom of the cabinet.\n4. 3, 4 Power Generation and Distribution\nMain logic power is provided by two Lambda LB-701 power supplies.\nEach supply is capable of providing 300 amps at 5 volts, One additional bias\nvoltage is provided by a Lambda LMCC-10 power supply. The main logic voltages, plus 5 volts and minus 5.2 volts, are distributed in the cabinet by laminated bus bars.\n\n20\n\n1\n\n^\n\n\t\n\ns\n\n1\n\n5. SOFTWARE\n5.1 General\nThe software effort on the Scene Generator Expansions System program\nwas divided into two separate tasks. The offline software used for processing\nthe environment data into a form suitable for use with the online software was\ngenerated by Lockheed personnel at NASA MSC in Houston, Texas, under the\ndirection of General Electric personnel. The online software used when opevating the system was generated by General Electric personnel.\n5.2 Off line Software\nThe offline software processes the environment data into a form suitable\nfor use by the operating or online software. The environment data are accepted\nby the program, tested for errors, and assembled into the environment data\ntables required in the R520, VCU, and E PU. At the completion of the program,\na complete card deck is punched; this deck is suitable for loading the environment data and online programs into the ESG.\n5. 3 Online Software\nThe online software is divided into two parts, the R520 programs and the\nVCU programs. The algorithms used in the online software are essentially as\ndescribed in Volume I, Instruction Manual for Modifications to Interim Visual\nSpaceflight Simulator. The R520 performs the input processing, the L and P\nvector generation, and the priority calculations. The VCU performs the aspect\ntest on each face, assembles the Face List, and performs the A and B calculations.\n\n21\n\n\xc2\xadV-\n\n'