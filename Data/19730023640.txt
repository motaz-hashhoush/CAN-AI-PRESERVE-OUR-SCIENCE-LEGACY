b'J\xc2\xbb T\n\nD\n\nNASA TECHNICAL\nMEMORANDUM\nMAS A TMX- 64777\n\nPROPOSED RELIABILITY COST-MODEL\n\nBy Dr. Leon M. Delionback\nSystems/Products Office\n\n\xc2\xa3* A O |T\n" \xe2\x80\xa2\xe2\x80\xa2 ^^ t\xc2\xab\n\nC" I\n\xe2\x80\xa2 I\n\nCOPY\nAugust 1, 1973\n\nNASA\n\nGeorge C. Marshall Space Flight Center\nMarshall Space Flight Center, Alabama\n\nMSFC - Form 3190 (Rev June 1971)\n\n1.\n\nREPORT NO.\n\n2.\n\nNASA TM X- 64777\n4.\n\nTECHNICAL REPORT STANDARD TITLE PAGE\nGOVERNMENT ACCESSION NO.\n3. RECIPIENT\'S CATALOG NO.\n\nTITLE AND SUBTITLE\n\n5.\n\nREPORT DATE\n\nAugust 1, 1973\n\nProposed Reliability Cost-Model\n\n6.\n\n7. AUTHOR(S)\n\nPERFORMING ORGANIZATION CODE\n\n8. PERFORMING ORGANIZATION REPORT #\n\nDr. Leon M. Delionback\n9.\n\nPERFORMING ORGANIZATION NAME AND AD DRESS\n\n10.\n\nWORK UNIT NO.\n\nGeorge C. Marshall Space Flig ht Center\nMarshall Space Flight Center, Alabama 35812\n\n11.\n\nCONTRACT OR GRANT NO.\n\n13. TYPE OF REPORV ft PERIOD COVERED\n12.\n\nSPONSORING AGENCY NAME AND ADDRESS\n\nTechnical Memorandum\n\nNational Aeronautics and Space Administration\nWashington, D.C. 20546\n15.\n\nM.\n\nSPONSORING AGENCY CODE\n\nSUPPLEMENTARY NOTES\n\nPrepared by Systems/Products Office,\nScience and Engineering\n16. ABSTRACT\n\nThe research investigations which were involved in this study include: cost analysis/\nallocation, reliability and product assurance, forecasting methodology, systems analysis,\nand model-building. This is a classic example of an interdisciplinary problem, since the\nmodel-building requirements include the need for understanding and communication between\ntechnical disciplines on one hand, and the financial/accounting skill categories on the other.\nThe systems approach is utilized within this context to establish a clearer and more\nobjective relationship between Reliability Assurance and the subcategories (or subelements)\nthat provide, or reenforce, the reliability assurance for a system. Subcategories are further\nsubdivided as illustrated by a tree diagram. The reliability assurance elements can be seen\nto be potential alternative strategies, or approaches, depending on the specific goals/\nobjectives of the trade studies. The scope was limited to the establishment of a proposed\nreliability cost-model format.\nThe model format/approach is dependent upon the use of a series of subsystemoriented CER\'s, and sometimes possible CTR\'s, in devising a suitable cost-effective policy.\n\n17.\n\n18.\n\nKEY WORDS\n\nDISTRIBUTION\n\nSTATEMENT\n\nUnclassified-Unlimited\n\n19.\n\nSECURITY CLASS1F. (of thta\n\nUnclassified\nMSFC - Form 8S92 (Rev December 19 f!)\n\n20.\n\nSECURITY CLASSIF. (of this p\xc2\xabf\xc2\xbb)\n\nUnclassified\n\n21.\n\nNO. OF PAGES\n43\n\n22. PRICE\nNTIS\n\nFor tale by National Technical Information Service, Springfield, Virginia ill51\n\nTABLE OF CONTENTS\nPage\nSECTION I.\n\nINTRODUCTION\n\n..........................\n\n...\n\n1\n\nA. Subsets of Reliability Assurance\n...............\nB. Cost-Estimating Definitions of Reliability\n.........\nC. Variations in Cost Collection Modes\n............\nSECTION H.\n\n1\n3\n5\n\nOBJECTIVES/STATEMENT OF PROBLEM\n\n5\n\nA. Objectives\nB. Statement of Problem\nC. Approach\n\n...........\n\n..............................\n......................\n..............................\n\n5\n6\n7\n\nSECTION HI. ASSUMPTIONS, GROUND RULES, AND CONSTRAINTS . .\n\nA. Assumptions\n............................\nB. Ground Rules and Constraints\n.................\n\n7\n\n7\n8\n\nSECTION IV. DESCRIPTION OF A PROPOSED MODEL FORMAT\n\nA. Background\n.........................\nB. Model Requirements\n.......................\nC. Model Format Description\n...................\nSECTION V.\n\nDISCUSSION\n\n....\n\n...............................\n\nSECTION VI. CONCLUSIONS AND RECOMMENDATIONS\n\nA. Conclusions\nB. Recommendations\n\n14\n...........\n\n.............................\n.........................\n\nAPPENDIX A _ GLOSSARY OF KEY TERMS\n\n...................\n\nAPPENDIX B - RELIABILITY COST-MODEL SYSTEM ANALYSIS\n(APPLICABILITY)\n...............\n.\n..........\n\niii\n\n9\n10\n11\n\n18\n\n18\n20\n\n21\n28\n\nTABLE OF CONTENTS (Concluded)\nPage\nAPPENDIX C - RELIABILITY COST-MODEL SYSTEMS ANALYSIS\n(RELIABILITY)\n\n30\n\nREFERENCES\n\n32\n\nBIBLIOGRAPHY\n\n33\n\niv\n\nLIST OF ILLUSTRATIONS\nFigure\n\nTitle\n\nPage\n\n1.\n\nReliability Assurance tree diagram\n\n2\n\n2.\n\nElectrical subsystem _ CER\n\n4\n\n3.\n\nReliability versus cost figure of merit, master function\n\n13\n\n4.\n\nCost-Model relationships\n\n16\n\n5.\n\nProduct Assurance Venn diagram\n\n20\n\nTECHNICAL MEMORANDUM X- 64777\n\nPROPOSED RELIABILITY COST-MODEL\nSECTION I. INTRODUCTION\nAsa prior condition to the logical development of any cost relationships,\nit was found necessary in the case of reliability to strive for a clearer understanding of the means needed to establish and/or enhance reliability for a\nsystem or subsystem. All of these things, collectively, will provide Reliability\nAssurance. Many of these items may not be directly involved in a reliability\nprogram, although their contributions (or lack of it) will clearly affect\nreliability; e.g., Quality Control.\n\nA. Subsets of Reliability Assurance\nAs noted above, the need was recognized for a better understanding of\nthe various subelements of Reliability Assurance. A Reliability Assurance\ntree diagram, Figure 1, has been constructed to provide better visibility of\nfive categories of Reliability Assurance. An attempt has been made to provide\nan exhaustive set of factors under each category, each of which contributes in\nsome degree to the assurance of reliability. Some of these elements lend themselves more readily to quantification than others in any attempt to establish\nspecific contributions to the overall system reliability, and/or to a specific\nsubsystem. Within this context, the terms "Hard" or "Soft" have been used\nto estimate the degree of difficulty in establishing a direct link with reliability\ncost values. For example, the introduction of "High Reliability" parts into a\ndesign which formerly had utilized commercial grade parts will generally\nprovide a predictable increase in reliability (hard). On the other hand, the\nintroduction of increased spending in the area of manned flight awareness\ncould hardly be expected to provide a discrete increase in the reliability estimate, and for this reason is termed soft. In order to provide further visibility\nconcerning the potential contributions of the subcategories shown in Figure 1,\na systems analysis matrix was used (see Appendix C), to indicate applicability\nof the various subcategories versus hardware subsystems. Also, a systems\nanalysis matrix was used in Appendix D to play the same subcategories of\nReliability Assurance against the various hardware subsystems (hard or soft\nmeasurable effects on Reliability Assurance). In both of these items we can\n\n1\n5\n\n> ^\n<\np 0 x\nS\n\n\xc2\xbb\n\no\ni<\'\n>\n\n(/>\n\nX\n\n\xe2\x80\xa2H\n\xe2\x80\xa2\n\ni \xc2\xa3\xe2\x80\xa2*\n3 3 J2 . .\n\ni\n\no 5 z JH\ni- 3 \xc2\xab o\n^\n\nS\n\ni-\n\nN 5\n\nO\n\nUJ\n\nS \xe2\x80\xa2< oo \xc2\xab\xe2\x80\xa23\n\xc2\xa3 =! "1\n\xe2\x80\xa2-\n\nui 2 3 * (\nS o o >\n< u. 5 t\n\noe\n\n: o ^ .\n< J\n\xe2\x80\xa2\n\niil\n\nS\n,,\n\nui ^ eo\nui 3 <\n\nOS\n<\xe2\x80\xa2\xc2\xbb\nUl\n\n0\n-;\n\xc2\xabi\nU. J"\n\n\xc2\xab \xc2\xb0 -- "\n.\n\ng\n*\nJ5\n\nf\n1\n\nST.\n\na.\nSUPPORTING\nDISCIPLINES\n\nUl\nh-\n\no\nz\n\nui \xc2\xa7\n\n<\n\n0\n<J\n\n<\n\nUl 1- l-\n\nIT z S\n2 s ?\n* \xe2\x80\xa2\xc2\xab a.\n\nl/>\n^ H\n^\n\nP J 5:\n\xc2\xab" 3\nvt\n\nsi!\n\nUl\n\nto\n\nI\n1\n\n</>\n\nU. Ul\n\n<J < z "\xe2\x80\xa2\n< ~i ui O\n\nO\n\na\n\no *> u\n\nC8\nt-i\nbO\n\nrt\n\n\xe2\x80\xa2 FH\n\nT3\n<U\n01\nU\n0)\n\n3\n\xc2\xa3S!2\nizz\n5 \xe2\x80\xa2* ui\n\no\nz\nt</>\nin\ni-\n\nM\nl\n"\n\niS2\n-JS"\n\n\xc2\xa7\nOS\n\nS \xc2\xa3=!;?:\n\np\n3\nco\n\nsf\n\nUl 2 Ul\n\na^\n\nU\n\nWMM\n\nu ui\n\n.2\n\ni-H\n\na\nui\n\n<D\n\nK\n\nSi\nOf. (-\n\nv> .\nv>\n\n"V\nx"\n\nJ\n\nO z!\nO co\n\nz\n\n01\n\nt-l\n\nbO\n\nl- <\n.< >\n\n<<\nu. >\n\nco\n\n\xe2\x80\xa2\niH\n\n"S. <\n\nO\n\n\xe2\x80\xa2\n\no\n\n\xe2\x80\x94 ^\' O\n\nO ui ui o\n\xe2\x80\xa2 z !?\n0-K\n\na2\noZ\n\nUl\nOf\n\ns\n\n"- S\nS S -,*Z >S < I\nI5 . O ui ui\nS55 \xc2\xab/>\n\ni\n\n" J a. t- x ,\n"\xe2\x80\xa2\nQ \xe2\x80\x94? i i\n\ntx. x\n"I S|2\nf\xc2\xab\n-L ui\nx ee.\n\nO w>\n\n_IZI*\n\n<< ! \xc2\xa7 ae\n3\nU. Z\nI U. O\n\nO\n\xe2\x80\xa2\n\nobserve that a desire to increase or decrease reliability is not a simple\nmatter of spending more or less funds, and/or allocation of lesser or greater\nportions of the available resources. The establishment of reliability estimates\nis both complex and heterogenous. Approaches that are effective for electronic/\nelectrical components and subsystems may either not be suitable for mechanical\nsystems, or just simply not available as an alternative. Consequently, approaches for reliability improvement have been categorized in the trade by the\ntype of hardware subsystem.\n\nB. Cost-Estimating Definitions of Reliability\nFor similar reasons the development of cost-estimating relationships\n(CER) may be observed to be structured by hardware subsystem reliability\nversus cost (see Figure 2).\nIn order to complete this milieu for reliability cost sensitivity, another\nparametric aspect should be considered. This parameter might be termed\ndesign configuration type (DCT). A graphical illustration of this type of\nvariability may be seen in Figure 2. One of the curves illustrates the cost\nsensitivity of an EOS type spacecraft to reliability, and the other curve indicates the reliability versus cost factors for a COMSAT-type spacecraft.\nDifferent ground rules, assumptions, and/or variations in technical/mission\nrequirements could account for such differences in variability and cost sensitivity between these two sample design configurations. Further research and\ndata expansion will be necessary in order to include this source of variability\nwith the other factor in structuring a final master function which could be used\nto explain an overall reliability cost-model. A more detailed account of the\ninterrelationships of the cost estimating activities will be given below as a part\nof the proposed model description.\nBased on the information displayed in Figure 1, as well as Appendices\n|_B and C, the primary system elements for which CER\'s can be established for\nreliability assurance will be the hardware subsystems. Typical subsystems\nmay be: Electrical, Mechanical, Attitude/Guidance Control, Structural, etc.\nIf an adequate data base is obtained from aerospace firms such as Boeing,\n[^Lockheed, McDonnell-Douglas, etc., then the next lower_level of CER\'s could\nbe developed to depict the cost variation of reliability for the functional categories shown in Figure 1. The previously discussed aspects of "applicability"\nand "quantifiability" must be considered in this review. At this time it does\nnot appear feasible to include the "Motivation" category as suitable for CER\ndevelopment. For this reason, subsequent illustrative examples will not include motivation as a viable CER candidate.\n\nCOST FACTOR\n\nw\no\n\ng\n\n0)\n\nCD\nO\n\ns\nO\n\nW\nIN\n9)\n\n_bj)\n\nE\n\nC. Variations in Cost Collection Modes\nDuring the course of this study it has been recognized that instead of\nthere being only a single approach to relating cost to reliability in CER\'s,\nthere may be two or more modes which are feasible. Several of these possible\nstrategies, will be discussed below to provide a better understanding of the\ncomplexities involved.\n1.\n\nSubsystem unit cost versus reliability estimate values. This type\nCER relates the subsystem total cost to variations in subsystem\nreliability estimates;\n\n2.\n\nReliability peculiar costs for a subsystem versus variations in the\nreliability estimate;\n\n3.\n\nTotal system unit cost versus reliability estimate values for the\ntotal system; and\n\n4.\n\nTotal program costs per unit versus variations in the reliability\nestimate. This type of cost value includes not only the direct\nreliability-related costs, and hardware costs; but also management,\nburden, and other administrative-type costs.\n\nEach of the above modes explains the cost variability of reliability in a\nslightly different way. Depending on the objectives of a particular model, one,\nall, or additional CER\'s may be desirable.\n\nSECTION 11. OBJECTIVES/STATEMENT OF PROBLEM\n\nA. Objectives\nQuestions have frequently been raised concerning the marginal cost of\nreliability. Stated differently, a question might logically be: "How much will\nit cost to increase the reliability estimate of system X from, say, 95 percent\nto 97 percent, or even 99 percent ?"G As discussed above, it can be readily\nseen that such complex objectives are very difficult to implement. There may\nbe several alternative approaches to reliability improvement, as well as several candidate subsystems which may have the capability to accept part, or all,\nof the allocated increase in reliability performance. The same consideration\nwould also have to be given to an allocated decrease in a reliability estimate\nsince the allocation would have to be distributed among suitable subsystem\ncandidates, in. order to optimize cost-effectiveness within the system as a\n\nwhole. Any change in reliability requirements may be introduced either from\nthe bottom up, or from the top down, depending on how a change in requirements is specified. Consideration must be given to the subsystem that offers\nthe best opportunity for improvement or trade-offs. In certain electrical, or\nelectronic subsystems, the mere substitution of components could effect a\nsignificant change in subsystem or system reliability, with their associated\ncost elements.\nAnother starting point in a Reliability System Analysis could be a condition requiring a reduction in cost. This might involve use of the unique capabilities of the Space Shuttle/Tug for the maintenance and refurbishment of\nspacecraft systems. With the assumption of such capabilities, requirements\nfor high reliabilities and excessively long life cycles could be relaxed, with an\naccompanying reduction in reliability and program costs.\nBriefly stated, the objectives of a Reliability Cost-Model might be one,\nor all, of the following:\n1.\n\nProvide a means to forecast effects on the reliability of the overall\nsystem, based on changes in one or more of the reliability-cost\nrelationships of the several subsystems.\n\n2.\n\nProvide a means to allocate programmed increases or decreases\nin the cost-reliability function (whole system) downward to the\nseveral relevant subsystems.\n\n3.\n\nProvide a system methodology to permit evaluation of the cost\neffectiveness of alternative system configurations and/or program\noperating plans (trade studies, etc.).\n\nB. Statement of Problem\nIn full consideration of previously stated background information, there\nexists a need both in the aerospace industry and in other industries, for a\nmethodology which will permit decision-making for reliability/cost considerations to be made based on quantitative relationships. Such a methodology tool\nhas been termed a "Proposed Reliability Cost-Model", because the development\nof an operational cost model to explain reliability is unquestionably outside of\nthe scope of the meager resource allocated to this effort.\nBased on these considerations a more specific statement of the problem\nfor this study effort would be to generate, or structure, the framework for a\n\nReliability Cost-Model. This smaller and optimistically more-manageable\ngoal for a single investigator still represents a formidable obstacle, since, in\nspite of the fact that the need has been recognized for some time, proposed\nsolutions or methodology are virtually non-existant.\n\nC. Approach\nBased on discussions of the objectives and the statement of the problem,\nstructuring of a Reliability Cost-Model framework will, of necessity, be\ntempered by those considerations. At this point we are more interested in\nestablishing methodology that can be shown to service the practical needs of\ncost modeling and/or iterations of alternative trade-offs of system parameters.\nFeasibility of any proposed model should be demonstrated first, before any\nsubsequent effort is made to construct automated computerized versions of the\nmodel algorithm. This approach to model development might be termed a\n"stepping-stone" approach, with the distinct rationale being that low-cost\napproaches for space programs should also be cost-effective. Hand solutions\nof sample problem applications should be made first to demonstrate feasibility.\nIf the demonstrated methodology shows promise, then more sophisticated\nsolution-methods involving computer programs could be a next logical step.\nThe initial step approach for this study will be based on a non-automated\n| cost-model framework. The general approach will consist of the mathematical\nintegration of a set of subsystem cost-estimating relationships (CER\'s) to form\na single master function which can be used to explain the overall cost variability (of reliability) for the overall system. In other words, the cost variability for reliability of the several subsystems will be embedded mathematically\ninto a single cost figure-of-merit/reliability master function. Further descriptive details of the model-building method will be given in Section IV.\n\nSECTION III.\n\nASSUMPTIONS, GROUND RULES,\nAND CONSTRAINTS\nA. Assumptions\n\nAssumptions are based on previous descriptive information concerning\nthe logic, rationale, and goals for the proposed model framework. They will\ninclude consideration of all these prior aspects and are listed as follows:\n\n1.\n\nCost-Estimating Relationships (CERs) can be formulated based\nboth on historical data obtainable primarily from one or more of\nthe larger aerospace contractors, or from certain internal government sources.\n\n2.\n\nCertain Cost Trade Relationships (CTRs) may also be needed to\nestablish sufficiency for utilization of the cost models.\n\n3.\n\nTo prevent possible misinterpretation of sample information it will\nbe assumed that hardware relative cost values are based on first\nunit costs, with no learning, progress, or improvement aspects\nimplied.\n\n4.\n\nInformation implied or shown as CERs or CTRs should be utilized\nprimarily as planning or forecasting tools, and not in detail cost\nestimating.\n\n5.\n\nInflation and/or changes in productivity should normally not be\nconsidered as sources of variability in the sample cost information.\n\nB. Ground Rules and Constraints\n1.\n\nCost values, CERs, CTRs, and/or other mathematical functions\ndisplayed in this document are for informational uses only, and\nshould not be used for any other purpose. (This is not a working\nmodel.)\n\n2.\n\nThe cost elements utilized in the sample model are either relative\ncost values, or cost figure-of-merit type values which result from\na mathematical embedding process to integrate the cost sensitivities\n(for reliability) of the selected set of subsystems.\n\n3.\n\nNo attempt has been made to isolate, or even to separate, the\n"reliability unique or peculiar" costs from other system cost elements, so far as this initial reliability cost-model format is\nconcerned. (The next lower level of cost elements would presumably involve such information.)\n\n4.\n\nThe prototype model described in Section IV is limited to the subsystem level, based primarily on the lack of sufficient quality and\nquantity of data for the lower levels displayed in Figure 1.\n\nSECTION IV. DESCRIPTION OF A\nPROPOSED MODEL FORMAT\n\nA. Background\nThe approaches utilized in this model building exercise have employed\nsupport from a sizeable group of engineering, management, statistics, mathematics, and econometric disciplines. The unique aspect perhaps being that the\nas-built model configuration does not rely, to any great extent, on any one of\nthese discipline areas as a prime theoretical source. The general approach is\nbased primarily upon a systems engineering methodology, since the principal\naspect being exercised in the proposed model (Reliability) has been termed a\nsystems specialty factor. Systems specialty factors in general specify or\ndefine the degree of engineering confidence or assurance, that a particular\nsystem will perform when compared or referenced to its established requirements (mission, cost, technical, etc.).\nQuite often, in the past, questions have been posed in management\nmeetings which might take form in the following alternative ways:\n1.\n\nIf a reduction in program funding should occur, with a corresponding reduction in reliability assurance allocation, how shall\nthis reduction in resources be dispersed among the several subsystems to minimize impact?\n\n2.\n\nGiven a reduction in resource allocation to a specific subsystem,\nhow shall this reduced support be subdivided among the various\naffected subdisciplines; e.g., design inputs, analysis, testing, etc.?\n\n3.\n\nIf there is an urgent need to upgrade or increase overall program\nreliability, to satisfy a national or international requirement (e.g.,\nincrease reliability of unmanned space launches to reduce possible\nembarrassing launch failure of NATO satellite using U.S. launch\nvehicle such as DELTA), how can reliability of system be increased\nmost economically, and how shall proposed increase be allocated\namong several subsystem candidates ?\n\nThis group of questions is not intended to be exhaustive, and should only\nbe considered as typical. The intent here is to illustrate the fact that such questions are natural in decision-making environments involving top management.\n\nIf such questions are not unexpected, can a quantitative basis be established for\ndecision-making? It is fully realized that historically most decisions of this\ntype have had to be made with little or no precision, or even methodology.\nHopefully, the following information may provide a first step toward the fulfillment of these needs.\n\nB. Model Requirements\nRequirements for the proposed model framework have already been at\nleast partially introduced by the set of questions outlined in the previous\nsection. What should be recognized, however, is that the stated requirements\nmust be considered preliminary until some experience is gained with the\napproaches outlined, and the availability of necessary data has been assured.\n1.\n\n2.\n\nThe model should permit approximate subsystem reliability versus\ncost estimates or forecasts.\n\n3.\n\nThe model should be sufficiently simple in format such that information necessary to iterate the model can be displayed either in\nthe form of a table of parametric cost versus reliability values, or\ncharacteristic curves displaying the same information.\n\n4.\n\nThe model should embody a systems engineering methodology which\nwill integrate the cost versus reliability sensitivities of the set of\nsubsystems which are designated as representative of the overall\nsystem. This information shall also be either displayed in tabular\nform, or by a master functional characteristic curve. The master\nfunction will be comprised of reliability estimates versus cost\nfigure-of-merit values representative of the whole system.\n\n5.\n\n10\n\nThe model should provide a tool for planners and top management\nfor consideration of the interplay between reliability requirements\nand resource allocation.\n\nThe model will be constructed such that the range of useful applications may be specified by the user for each technical system to\nwhich this approach is applied. A typical range could be, for\nexample, between reliability estimates of 90 percent to 97 percent.\n\nC. Model Format Description\nAs previously noted, the intent is not to attempt to provide a detail\nworking model but rather a set of descriptors which indicate the approach.\nThe reader, therefore, should focus his attention on the methodology and not\non the specific numbers and/or estimating relationships, which are included\nprimarily as illustrations. The layman or practitioner wishing to utilize a "\nmodel of this type should establish his own CERs based on his own unique set\nof technical reliability and cost experiences. The examples shown in Figure\n2 illustrate two CERs based on relative, rather than actual, cost values.\nThe curves of Figure 2 represent basically two types of spacecraft design\nconfigurations that could represent a wide range of cost-to-reliability sensitivity. Both of these curves represent data reported by aerospace researchers,\nand indicate possible cost-estimating relationships for a typical electrical subsystem. As might be expected, the relative cost values increase slowly at first,\nfor small increases in reliability. After a certain point has been met, the\nrelative cost values start to increase at a more rapid rate for each additional\nincrease in reliability requirements. This same diminishing return type of\nresponse function is also typical for many other physical and/or socio-economic\nactivities; e.g., learning curves, material quantity discount cost functions,\norganization and/or discipline progress functions, etc.\nThe approach suggested here is based on the utilization of a set of\nsubsystem CERs with each cost-sensitive system; e.g., electrical subsystem,\nmechanical subsystems, etc. The selection of a suitable set is up to the\n\',decision-maker or analyst as long as the overall model constraints and requirements are met, and the following list of special constraints:\n1.\n\nEach of the subsystem CERs used to comprise the system set must\nbe either monotonically increasing, or decreasing, but in the same\ndirection.\n\n2.\n\nFor the benefit of clarity, all functional plots comprising the\nestablished system set (ESS), will be plotted on the same type of\ncoordinates; e.g., Cartesian, log-log, semi-log, etc.\n\n3.\n\nAll diophantine cuts will be linear, and for each model will be\neither parallel to the ordinate, or the abscissa axis.\n\n4.\n\nIf subsystem functions are such that cuts might intersect the\nfunction more than once, the intersection points for the higher\nreliability values will be posted.\n\n11\n\n5.\n\nInitially, cuts will be made at regular intervals; e.g., 10 percent,\n20 percent, 30 percent, etc., but more frequent cuts may be\nneeded for those portions of the CER curves that indicate very\nrapid rate of change.\n\n6.\n\nTo simplify arithmetic computations all values from cutting plane\nsamples will be converted to natural logarithms, and then entered\nin tabular form into a matrix.\n\nFinally, having observed the above constraints, the log values from\nthe matrix table may be plotted to form a characteristic Reliability Assurance\nmaster function as indicated in Figure 3. This function was generated in the\nsame manner as described above. In essence, the framework for a ReliabilityCost Model has been established, thus making it possible to propose various\nre] lability/relative-cost trades.\nMathematically speaking, the model bears resemblance to models\ndescribed elsewhere \xe2\x80\x94 such as the multiplicative model described by Benjamin\n[ l], or the log-normal by Chow [ 2 ] , or the similitude models by Gukhman [4],\net al. There is a common thread through all of the examples cited: the commonality being that a series of parameters (or factors) can be used to explain\nan overall system effect or cumulative resultant, provided the parametric\nvalues are multiplied together, or added geometrically by summing the logarithms of the numbers rather than the discrete numerical values themselves.\nThe application of these concepts may be extended to include variates which\nare either discrete or continuous, dependent or independent. The multiplicative format tends to embed each of the participating variates, one with the\nother. The embedding process tends to minimize unknown or indeterminate\ninteraction or internal influence effects between the various subelements of the .\nESS. So, if we let Q = cost figure-of-merit for the ESS, Y = relative cost of\nvarious factors and,\nQ = Y r Y 2 ... Y n\n\nby taking the natural logarithm of both sides of the equation, the following\nexpression results:\n\n12\n\n(1)\n\nd\n\nw\nco\n\na\n\n1\n\n\xe2\x80\xa2s\n0)\n\n\xc2\xa3?\n\n\xc2\xabM\n-4->\n\nto\no\no\n\nto\nOT\n>\n\n^\n\ns\n\nIH\n-\n\n0)\n\nCO\n\nO\n\no\n\n1I3MW JO 3MH9U - 1SOO\n\n13\n\nor\n1 Q = 1 Y + 1 Y + ... 1 Y ...\nn\nn 1 n 2\nnn\n\n(3)\nv/\n\nIf, for example, the individual values of Y represent functions of subsystems\n(CERs) as we have above, and if we take the geometric sum of these subsystem\nfunctions, then the resulting curve should assume a geometrical shape which\napproximates the shape of the individual elements. For the conditions existing\nin the reliability CERs, the subsystem functions are approximately exponential.\nTherefore, it is not surprising that the master function (see Figure 3) also\nassumes an approximate exponential shape. As such, this master function\nis a characteristic function representing the expected reliability/cost performance for the whole system. There appears to be no definite limit on the number\nof subelements which are included in the ESS. If the master function values\nare normally distributed (log Q) as indicated by Chow, then Q would be loga6\n\nrithmico-normally distributed, based on argument of Central Limit Theorem.\nAlso, a closely related concept is involved in the understanding of the network\n\xe2\x80\x94 the model is also related to the Law of Large Numbers [7]. Agreement\nwith a certain reliability estimate, or failure rate could be made arbitrarily\nclose to some predetermined value by making "n" sufficiently large.\nThe mechanics of the subject model framework does not resemble any\nof these to any significant degree, since what is strived for in the model at\nhand is an artificial population of reliability/economic indicators. A related\napproach was used by the author in structuring a model for learning ts]. This\nmodel does bear a strong methodological similarity, as well as a theoretical\ncommonality based on the aspect of complexity, which is the nemesis of both\nreliability and learnability.\n\nSECTION V. DISCUSSION\nIn the previous section the suggested model approach was described in\nsufficient detail to permit a potential user to assemble his own model. The\nlevel of detail, however, was not sufficient to permit a "cook-book" style\nmimicry of the methodology. This was no oversight, since such procedures\nare not in keeping with the intent of this document.\nIn the past, many questions have been raised concerning the relationship of reliability with other systems engineering specialty factors such as\n\n14\n\nsafety and quality. These disciplines both have many subelements which\neither overlap, or have at least the common bond of purpose. In other words,\nmany of the things that are done in the name of quality, such as inspection,\nand/or traceability also tend to provide a more reliable product. Similarily,\nin the safety area, hazard analysis, or the requirement for fail-safe design\nfeatures, also tends to provide a product which is not only safer, but more\nreliable. Indeed^ there are many instances where it is almost impossible to\nseparately classify a product improvement as being specifically for either\n| quality, safety, or reliability, since, usually, an improvement involves all of\nthem. Recently, the term Product Assurance has been used to include the\neffects of Safety Assurance, Reliability Assurance, and Quality Assurance. A\nfunctional tree diagram (see Figure 4), has been included to indicate the relationships of these three important specialty factors, as well as illustrate the\nmodel-building approach for Reliability Assurance. Although not specifically\nindicated in the diagram, a further expansion of the functional CER could be\nmade at the level indicated by such subcategories as test, design inputs, analysis, etc. Depending on the availability of data, and, of course, on the need,\nthis same approach could be continued to even the next lower level of detail.\nFor example, under the Test category we could track the influence of material\ntesting on the cost of reliability, or the relationship of systems check-out to\nthe cost of reliability improvements. If the same approach is maintained\n1 throughout, it will be possible to assemble a compatible set bf influence factors,\neach of which will explain some factor, or subfactor, or sub-subfactor of the\ncost sensitivities in Reliability Assurance. Eventually, a computerized version\nof the model can be assembled with no extreme difficulty. This would apply not\nonly to the particular problem at hand (Reliability Assurance), but also for the\nhigher level Product Assurance model. Premature attempts to computerize\nthese models before they are definitized and operational, can only lead to a\nwaste of resources.\nRecently, much attention has been given to a reliability-related term\ncalled Man Rating. A particular reference was made to this aspect during a\nmeeting of a House Committee on Science and Astronautics, June 15-17, 1971\n[5]. In this meeting the following statement was made relative to man-rating\ncosts, quote: "For example, the cost of a Titan II, modified for Gemini,\nincluding the addition of redundant flight control systems and man rating,\nincreased from $5 million for a standard vehicle to an average of $23 million".\nA public relations handout [6] entitled "Man-rating the Gemini Launch Vehicle"\ncharacterized man-rating as "... an awesome task, requiring the support and\ncontributions of personnel in many specialties". The company attributed\ninvolvement of personnel in practically all aspects of operations, logistics,\nquality, manufacturing, test, and design as being involved in man rating. The\nfirm also listed a design configuration change in addition to redundancy,\nnamely the Malfunction Detection System (MDS).\n\n15\n\n4\'\n\n?!\n\nM\n\n\xc2\xab\xc2\xa3\n\na s\n\n>=! K\n\n" ill P\n\n\xc2\xab s i-i E\nI? o& i\n\n>\xe2\x80\xa2\n3\n5S\n< uj\n\nCQ\n\nK h-\n\ncc z\nOH\n\nIB\n\n,7 =\n\n1\xc2\xb0\nco z\nco 3\n\n< u.\n\n(J\n\nCC :\n\nglr\n\nY<t\nas\n\nto \xc2\xab2\n\nLli\n\n\xc2\xbb\xe2\x80\x944\n\nCD\n\nQ\nIB C 7\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\nI ^\n\nI\ni\n-> CO\n\ntn\n\no\n\ncc\no.\n\n\xe2\x80\xa28\nI\n\xe2\x80\xa24-J\nW\n\n>\n\nO\n\nO\nubciz\n\n.\xc2\xa7>\nZio\n(S H\n\nS5 =\n\nUJ i\n\nQ z\n\ncona\nr~ ^\nUJ <\nU. CC\nCO\n\nCO\nCO\n\ny\n\xc2\xab\nf\n\no\xc2\xab\n\n35\nUJ CO\n\nS S 5\n\n16\n\nOne of the key aspects stressed in the discussion of the MDS is the\nfeature that, based on the information provided by the special Malfunction\nDisplay Panel, made it possible for crew members to become in reality a part\nof the "loop". They could use such information in deciding whether to abort\nall, or part, of the mission in the interest of personal safety, or to prevent\npossible damage to the equipment. Its contribution to the Increase in cost no\ndoubt was sizeable, but the recognized increase In overall Product Assurance\ncould justify the addition of such a system to the design configuration. As may\nbe observed by reference to the points made above and also to other sources,\nman rating is a rather loose term which is defined in several ways, and can\nmean many different things to different people. (See Glossary for comparison),\nWithout resorting to a detailed cost-effectiveness analysis, it is perhaps\'per\'missible to comment that sometimes quite sizeable increases in the cost of\nReliability and/or Product Assurance might eventually become quite reasonable\nwhen compared with the potential failure of a major space venture.\n\nSECTION VI. CONCLUSIONS AND RECOMMENDATIONS\n\nA. Conclusions\n1.\n\nThe use of CERs as a tool in estimating iterative trade-offs of\nvarious system specialty factor values versus system costs is a\nnecessary approach.\n\n2.\n\nThe necessary CERs can be established, provided sufficient data\nis made available to build these functions.\n\n3.\n\nAssuming the above conclusions can be fulfilled, it should be\npossible to subsequently build system-oriented Reliability CostModels.\n\n4.\n\nSuch models should permit management executives, analysts, et\nal, to forecast the change in reliability estimates by variations in\nthe volume of resources allocated to reliability. Another way of\nsaying this would be: Model users should be able to predict the\nmarginal effect on the reliability of a system from either increases\nor decreases in the allocated resources.\n\n17\n\n5.\n\nAlthough many strategies are available to the decision-maker\nseeking to iterate the reliability of a system (see Figure l), those\napproaches which lend themselves to discrete measurement should\nbe given priority over the soft or indirect methods.\n\n6.\n\nPrevious methodologies for making work breakdown structures\n(WBS) do not readily lend themselves to generation of the needed\ndata to support the subject model. A WBS standard procedure is\nurgently needed.\n\n7.\n\nIrrespective of existing problems, the subject proposed model\nformat does satisfy the intent of the objectives as outlined in\nSection II.\n\n8.\n\nThe relationships which are depicted graphically in Figure 4 indicate\nthe flexibility and universality of the model concepts described\nherein and also in a previously published dissertation on applied\nlearning theory [3].\n\n9.\n\nThe expansion of the model concepts to include the higher level\nsystems specialty factor of Product Assurance appears to be a\nlogical next stop. Prediction models for other systems specialty\nfactors appear to be completely feasible.\n\n10. At present there are no known technical reasons to prevent an\noperational Reliability Cost-Model from being assembled.\n11.\n\n12.\n\n18\n\nProblems in systems engineering have occurred in the past and\nwill presumably continue because of a tendancy to view systems\nspecialty factors in a non-hierarchial and/or synecdochical\nmanner. System elements which are subordinate to other elements\nare frequently treated as equal, or superior, to such items.\nQuite frequently also, an approach is taken whereby the natural\noverlap between Safety, Reliability, and Quality Assurance is\nnot recognized as such (See Figure 5).\nThe modeling concepts outlined herein and in Reference 3 provide\na response to the subject modeling problem, but, more importantly,\nalso show the way to a family of models having a broad and generalized scope of application. Practical applications of these models\nshould be both simplistic and cost-effective, because hand solutions\ncan generally be used efficiently. Computerization is possible, but\nnot essential, for most situations.\n\nQUALITY ASSURANCE\n\nRELIABILITY ASSURANCE\n\n>l^:::?:yvv:\n\nSAFETY ASSURANCE\n\nNOTE; DIAGRAM N.T0S0, DIMENSIONS ARE FOR\nILLUSTRATIVE PURPOSES ONLY,\n\nFigure 5. Product Assurance Venn diagram.\n\nB. Recommendations\n1. A follow-on effort should be initiated to assemble a demonstrational\nReliability Cost-Model based on the information and guidelines\npresented in this document.\n2. Another follow-on project is suggested to define the model-elements\nfor a Product Assurance Cost-Model as suggested in previous\nsections.\n\n19\n\n3.\n\n4.\n\nAlso, an activity should be initiated to formulate an algorithm/\nprocedure for WBS, since relevant cost-experience data cannot be\nrecorded without a logical cost structure.\n\n5.\n\nConsideration should be given to the proposition of a pilot project\ninvolving hardware, which would permit iterations of reliability\ncost-parameters under closely controlled conditions.\n\n6.\n\n20\n\nFurther study should be initiated to define the necessary and\nsufficient criteria for the Completely Generalized Model, as outlined briefly above. The applicability of this proposed model would\nbe extendable to virtually all areas of parameter/factor analysis.\n\nA companion effort should be generated to collect the necessary\ncost data to build CERs for the demonstrational model.\n\nAPPENDIX A\nGLOSSARY OF KEY TERMS\n\n21\n\n1.\n\n2.\n\nComplexity Function (CF) \xe2\x80\x94 This term refers to approximate\nrelations, emperically relating complexity to some other parameter, such as cost or reliability. In general, such functions depict reliability decreasing, and cost increasing as the complexity\nof a system or design increases.\n\n3.\n\nCost Figure-of-Merit (CFOM) \xe2\x80\x94 This term represents a multiplicative parametric value which is created by adding the logarithms\nof the various cuts taken from each of the selected CERs in the\nEstablished System Set (ESS). Since each group of cuts for the ESS\nis made at a specific reliability value, it is therefore possible to\nplot CFOM against reliability and thus create an overall or master\ncost function for the system. An illustrative example of such a\nfunction is shown in Figure 3,\n\n4.\n\n22\n\nCER \xe2\x80\x94 This acronym represents the words Cost Estimating\nRelationship( s). CERs are usually displayed as functional curves\n(see Figure 2), although a tabular format may be utilized. In\neither case, cost is referenced to some system performance/\ndesign parameters, or system specialty factors, such as weight,\npower, volume, thrust, impulse, reliability, durability, maintainability, etc. Such functions are used in making estimates, forecasts, predictions and the like, but are not usually considered\nprecision measures of either. CERs are not recent inovations,\nsince cost estimating relations based primarily on weight have\nexisted for many years. Volume and power were also used to a\nsomewhat lesser extent.\n\nCTR \xe2\x80\x94 This acronym represents the words Cost Trade Relationship^). CTRs are usually displayed as functional curves, although\nthe information may also be presented in a tabular format. As\nimplied, the CTR is used generally as a tool in making trade\nstudies. Such factors as power requirements, R and D cost, weight,\nvolume, etc., are used to generate CTRs such that technical requirements and/or mission objectives can be optimized, or at\nleast logically specified in systems planning exercises. A typical\napproach would be to relate weight, volume, or power for a subsystem versus the performance of the subsystem or system in\norder to select a cost-effective combination of design criteria.\nCTRs are frequently used to provide inputs to the CERs.\n\n5.\n\nDesign Complexity (DC) \xe2\x80\x94 This form of complexity has to do\nwith features or parameters of an engineering design which contribute to its complexity. Examples of such features which tend to\nincrease the measure of design complexity are such aspects as\ntotal number of parts, number of fasteners, or number of subassemblies. Others might be the number of different steps or\nprocesses required to fabricate, assemble, and inspect.\n\n6.\n\nDesign Configuration Type (DCT) \xe2\x80\x94 A Design Configuration Type\nis a term used to designate a category or generic class of system\nconfigurations for which both the technical and cost parameters\ncould be expected to be typical. When estimating costs of large\nsystems, example DCTs would be solid propellant boosters,\nnuclear-powered submarines, army tanks, or jet airliners. Such\nexamples represent rather distinct examples of large system types,\neach of which is made up of a unique set of subsystems and hardware\ncomponents.\n\n7.\n\nEstablished System Set (ESS) \xe2\x80\x94 This term refers to a group or set\nof cost sensitive subsystem CERs which has been selected as\nrepresentative of the overall system (Design Configuration Type,\nDCT). Each cost model will have a characteristic ESS, depending\nnot only on the unique set of subsystems involved, but also on the\ntype of design configuration involved; e.g., electronic, mechanical,\npower supply, etc.\nA typical ESS might be a group of CERs for the following:\nelectrical power, mechanical guidance and control, and environmental control subsystems.\n\n8.\n\nFactor \xe2\x80\x94 This term can be considered a synonym of parameter as\nfar as this research is concerned.\n\n9.\n\nFigure of Merit (FOM) \xe2\x80\x94 This term can be considered a numerical\nperformance rating which is a measure of the relative performance\nof a system or design. Term is usually dimensionless or is considered so in its applications to decision theory.\n\n23\n\n10.\n\nLearning Curve (LC) \xe2\x80\x94 A learning curve is a graphical plot on\neither Cartesian or on double logarithmic paper, which represents\nthe rate of learning progress by humans, usually in performance\nof some task or group of tasks. In the engineering discipline this\nplot is usually made with time as the ordinate parameter, and\nnumber of units complete or simply number of units as the abscissa.\nIn general, these curves will aproximate an exponential-shaped\nfunction, if the progress is normal. This function should be separated from progress and improvement functions by the fact that\nonly human learning progress is to be included in a learning\ncurve; not tooling, design, or other gains in performance, which\nmay be a part of progress or improvement functions.\n\n11.\n\nLog-Linear \xe2\x80\x94 This term is often used to describe learning curves\nwhich are plotted on double-logarithmic paper. In general, such\ncurves will appear as straight lines. This greatly simplifies\ncomputation of the slope, and will, of course, make these curves\neasier to plot.\n\n12.\n\nMan Rating \xe2\x80\x94 Man Rating is defined as the philosophy and plan\nfor marshalling the disciplines necessary to achieve a satisfactory\nprobability of crew survival. It can be seen that achieving a\nsatisfactory level of crew survival requires that careful consideration be given to such launch vehicle items as:\n1.\n2.\n\nAnalysis of launch vehicle modes, followed by design of a\nreliable Malfunction Detection System.\n\n3.\n\nFunctional utilization of the crew as part of the Malfunction\nDetection System.\n\n4.\n\nTradeoffs in checkout philosophy, with emphasis on minimizing the probability of launching a bad vehicle.\n\n5.\n\nTest, countdown, and launch procedures that will maximize\nlaunching a good vehicle.\n\n6.\n\n24\n\nComponent and/or system redundancy, which can improve\nthe reliability of the launch vehicle.\n\nTradeoffs of system complexity versus reliability.\n\nMan Rating requires the very best in engineering, manufacturing,\ntest and quality control, as well as in the supporting procurement,\nlogistics, planning, configuration control, and general management functions. Enforcement of rigid disciplines every step of\nthe way from program inception to liftoff is mandatory.\nMan Rating is a many-sided process of improving the reliability\nof the basic vehicle, by modifying existing systems, by using\nredundant components, adding special systems for crew safety\npurposes, special handling of critical components, meticulous\nselection of qualified people, and by developing procedures in the\nentire design-production-manufacturing-test-launch cycle that\nestablishes, as a goal, flawless performance from the launch\nvehicle.\n13.\n\nMaturation \xe2\x80\x94 This term refers to the sub-set of improvement or\nprogress factors which relate to the segment of progress by individuals or other organisms that results from a time-related\nmaturing or growing-up process. Maturation is not considered a\nnormal part of learning progress.\n\n14.\n\nModel \xe2\x80\x94 A Model is an approximation of reality which is frequently\nused to forecast or predict performance approximations of real\nworld situations. Models may be physical or analytical within\nthis context. Analytical models are sometimes referred to as\nmath models, or as algorithms, which consist of a necessary\nand sufficient set of terms, values, and formuli needed to compute or predict an output value based on a known input or set of\ninput values and recognized constraints or limitations.\n\n/\n15.\n\nMonotonic Function \xe2\x80\x94 This term is used to designate a mathematical function, either theoretical or empirical, which has single\nmaximum and minimum points. If the function is an increasing\nfunction, it would be referred to as a monotonic increasing function and conversely a monotonic decreasing function. Learning\ncurves are normally monotonic-decreasing-functions over time.\n\n16.\n\nParameter \xe2\x80\x94 For purposes of this study, the terms factor, design\nfeature, or parameter may be used interchangeably. A Parameter\nis a term which is used to measure or gauge some feature or\nphysical characteristic of a system or design. This measure is\nusually defined in some unit which is officially accepted, such as\nweight in grams or volume in cubic feet, etc.\n\n25\n\n17.\n\nProduct Assurance (PA) \xe2\x80\x94 Product Assurance is a system\nspecialty factor which combines several of the subfactors such as\nReliability Assurance, Quality Assurance, and Safety Assurance.\nPA includes all activities which directly or indirectly support or\nincrease the likelihood that a product or system will perform its\nintended function in accordance with established criteria, standards, specifications, or other requirements.\n\n18.\n\nQuality Assurance (QA) \xe2\x80\x94 This systems specialty factor includes\nall those activities which may quantify the degree or increase the\nlikelihood that a system or product will be produced and delivered\nsuch that adherence to the established criteria, standards, specifications, or other requirements will be optimum.\nTypical examples of Quality Assurance activities include inspection, qualification and durability tests, subsystem and system\nfunctional checkout, acceptance testing and statistical sampling\nplans.\n\n19.\n\n20.\n\nReliability Assurance (RA) \xe2\x80\x94 This systems specialty factor\nincludes all those activities which quantify or increase the likehood\nthat a product or system will perform it\'s intended function(s)\nwhen called on to do so. This performance must be within the\nestablished criteria, specification, or other requirement limits,\neither at a discrete point in time; e.g., rocket engine ignition, or\nfor specified time intervals as posted in the requirements.\n\n21.\n\n26\n\nReinforcement \xe2\x80\x94 This term frequently appears in psychological\njournals and is used to infer that anything which tends to help a\nperson to recall from memory or to accelerate the learning\nprocess, is considered a reinforcement. Sometimes reinforcements may be considered as positive or negative depending on the\npurpose or objective. One form of reinforcement would be to\nrepeat a rule to a group of army recruits to assure a transfer to\nmemory. A memorized poem may be repeated over several times\nby a student to reinforce the memorization of this passage.\n\nSafety Assurance (SA) \xe2\x80\x94 This systems specialty factor includes\nall those activities which may quantify the degree or increase the\nlikelihood that a person, system, or product will perform the\nintended function(s) in such a manner that no unplanned activity\nor condition will cause damage, destroy, or otherwise incur harm\nto equipment, facilities, or persons.\n\n22.\n\nSystem \xe2\x80\x94 A System is a planned, integrated assembly or grouping as hardware, software, and/or human elements which function,\nas a unit to produce some specific or unique desired effect or\nresult. A subsystem is subordinate to a system, but must meet\nthe same definition criteria.\n\n23.\n\nSystems Engineering (SE) \xe2\x80\x94 The discipline in which engineering\nprinciples are used to plan, group, design, integrate, coordinate,\nspecify, analyze or otherwise bring together all of the elements\nor component parts of a system such that each element operates\nin unison with all other elements of the system to produce a predictable and desired effect or output when operating in a specified\nenvironment.\n\n24.\n\nSystem Specialty Parameters (SSP) \xe2\x80\x94 Expressions of system\nperformance variables or characteristics concerned with the\noverall technical effectiveness of an integrated system. System\nspecialty parameters are used in system modeling, system trade\nstudies, technical performance measurements, and assessments.\nTypical examples of specialty parameters are reliability, availability, maintainability, safety, survivability, etc.\n\n25.\n\nTime Series \xe2\x80\x94 This well-known statistical analysis technique\nemploys an artificial parameter (called Time Series) which is\ncreated from selected subfactors additively or by a multiplicative\nprocess. This macrovariable, when plotted over time, produces\na trend line which is one basis for forecast or predictions of future performance.\n\n26.\n\nWeighting Coefficients \xe2\x80\x94 These values are usually expressed in\nfractional parts and are used to transfer the desired emphasis to\nalternative performance ratings or estimates of value. The sum\nof such weights must always equal 1; if whole numbers are preferred the sum must equal 10. If there is no particular emphasis\ndesired by the decision maker, then each alternative will receive\nan implied weight of one.\n\n27\n\nAPPENDIX B\nRELIABILITY COST-MODEL SYSTEMS ANALYSIS\n(APPLICABILITY)\n\n28\n\nT /\n\n|c\n\n/\n/\n\n/\n\nSYSTEM ELEMENTS\n\nI s< I\n/ C\' / .s?/\nNo.\nA\n\nPARAMETERS\n\n1 DESIGN INPUTS\nffl-REL PARTS\n2\nREDUNDANCY\n3\n4\nOVERDESIGN\n5\nSIMPLIFICATION/IMPROVE.\nSELF - TEST FEATURE\n6\n7\nSELF - HEALING\n8\nFAIL-SAFE\nMAINTAINABILITY\n9\n10\nREPAIRABILITY\n11\nDEPENDABILITY\nFOOL - PROOFING\n12\n13\nDURABILITY\n\nI c3/f- /\n\n1 |c; |\n|j|\nI /\xc2\xa3 /\n\n/\n/\xc2\xa3 js/\ni& \'&/ \'\nI e/ oh.;/\n\xc2\xab?/ I/ I1 \xc2\xa7 |\n| 31 SI fe/\ni/ 8 *\nr\n\na\no.\n\n/I\n\nh\n\niljl<\nJ\n\nLI\n\n1\n\nsj <2i 31\n5/ \xc2\xa3/ Sc\n\xe2\x80\xa2*/ *\nDj\n\n;|\n\nJ/3\n\n)/\n/\n\nU rp\n\nr\n\nf u C\n\nC\n\ntJ <\n\n5/>J/c\n\nY Y N Y N\n\nY\nY\nY\nY\nY\nN\nY\nY\nY\nY\nY\nY\n\nN\nN\nY\nY\nN\nY\nNY\nY\nY\nN\nY\n\nN Y\nN- Y\nY Y\nY Y\nY Y\nN- N\nY Y\nY Y\nN- N\nY Y\nY Y\nY Y\n\nN\nN\nY\nY\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nNY\nY\nY\nN\nN\nY\nY\nY\nY\nY\n\nN\nN\nY\nY\nN\nN\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nN\nN\nY\nNY\nY\nY\n\nN\nY\nY\nN\nN\nY\nY\nY\nY\nN\nY\n\nY\nY\nY\nY\nN.\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nNY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nY\nY\nY\nN\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nY\nY\nN\nY\nY\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\nY\nN\nY\nN\nY\nY\n\nY\nY\nY\nY\nY\nN\nY\nY\n\nY\nY\nY\nY\nY\nN\nY\nY\n\n\xe2\x80\xa21 A\n\n14\n\nB\n\n1\n2\n3\n4\n\n5\n6\n7\n8\n9\n10\n\nC\n\nD\n\nANALYSIS\nFMEA\nFAILURE/DISCREP .\nVALUE\nEFFECTIVENESS\nTRADE-OFFS\nMATH MODEL\nAVAILABILITY\nSOFTWARE/PROCEDURE\nVERIFICATION\nTECHNICAL PERFORM./\nSPECIFICATION COMPARISON\n\n1 TESTING\nQUALIFICATION\n2\nT\\1f WCiT .TYDHyt 1TM T\nLJsL, V lAJirM C/W 1\n3\nACCEPTANCE\n4\nRELIABILITY /PURABILITY\n5\nOPERATIONAL\n6\nSAFETY\n7\n8\nOVERSTRESS\n9\nBURN -IN -TESTS\n10\n1 SUPPORTING DISCIPLINE\nQUALITY CONTROL\n2\n3\nCONFIG. /SPARES - CONTROL\n4\nTRAIN. /PERSONNEL CERT.\n5\ni n;fti . h.M f-u i ,i i x\n6\nPROCESS/OPERAT. CERT.\n7\nHUMAN FACTORS/MAN RATING\n8\nrTTTJ A /I p\n\nE\n\nY Y Y Y Y Y Y Y Y Y Y\n\nY Y Y Y Y Y Y Y Y Y\nY\nY Y Y Y Y Y Y Y Y Y\nY N Y Y Y Y Y Y N Y\nY Y Y Y Y Y Y Y Y Y\nY Y Y Y Y N N Y N Y\nf Y Y\nY Y Y Y Y N N Y N Y\nY N Y Y Y Y Y Y N Y\n\nY\n\nr\n\nY\nY\nY\nY\nY\nY\nY\n\nY Y Y Y Y Y Y Y Y\n\nr\n\nY\nY\n\nr\n\nY Y Y Y Y Y Y Y Y\nY Y Y Y Y Y N Y Y\n\nr\n\nA TST T TT*V\n\n1 MOTIVATION\n/TWIT? Al""TTT A Tj BITT \xc2\xbbl A M 1 L\xc2\xbbl X X\nC*UPl IftAL/ 1 U A l K H 1 TAWTT TT\'V\n2\nINCENT.\nMANNED-FLIGHT AWARENESS\n3\nZERO -DEFECTS\n4\nINDIVIDUAL INCENTIVE\n5\n\nY\nY\nY\nY\nY\nY\nY\nY\n\nY\nY\n\nT\n\n_\n\nf\n\nY Y Y Y Y Y N Y Y\nY Y Y Y Y Y Y Y Y\n\nX*\n\nY Y\n\nY Y Y Y Y Y Y Y Y Y Y\nY Y Y Y Y Y Y Y Y Y Y\nN- N- N- N- N- N- N- N- N- N- N-\n\nNotes: Y = Applicable or Relevant\nN = Not Applicable\nN- = Marginal or Partial\n\n29\n\n/ / / Itfi /\xc2\xbb/\xc2\xa3/ 1 1 1\n\nIllliiJsi/J//\nSYSTEM ELEMENTS\n\nNo.\nA\n\nB\n\nC\n\nE\n\n/Q/S;/ 57 oj/ SI \xc2\xa7/ of/ Q.7 \xc2\xbb# \xc2\xa3i[ o/\n/\xc2\xa3/ W/a?/ O/^/G/oy ^/ 5/ \xc2\xa3\xc2\xab/ ^j\n/ 1\n1 1\n\n1/\n\n1 DESIGN INPUTS\nHI-REL PARTS\n2\nH H H H\n3\nREDUNDANCY\nH S S H\nOVERDESIGN\n4\nH H H H\n&\nSIMPLIFICATION /IMPROVEMENT H H H H\n6\nSELF -TEST FEATURES\nH S S H\n7\nSELF-HEALING\nH S S H\n8\nFAIL-SAFE\nH S S H\n9\nH H H H\nMAINTAINABILITY\n10\nREPAIRABILITY\nH H H H\n11\nDEPENDABILITY\nH H H H\n12\nH S S H\nFOOL-PROOFING\n13\nDURABILITY\nH H H H\nH S S H\n14\nHUMAN-ENGINEERING\n1 ANALYSIS\nFMEA\n2\n3\nFAILURE/DISCREPANCY\nVALUE\n4\n5\nEFFECTIVENESS\nTRADE-OFFS\n6\nMATH MODEL\n7\n8\nAVAILABILITY\nSOFTWARE/PROCEDURE\n9\nVERIFICATION\nTECHNICAL PERFORMANCE/\n10\nSPECIFICATION COMPARISON\n1\n2\n\n3\n4\n5\n6\n7\n8\n9\n10\nD\n\nPARAMETERS\n\nTESTING\nQUALIFICATION\nDEVELOPMENT\nACCEPTANCE\nRELIABILITY /DURABILITY\nOPERATIONAL\nSAFETY\nSCREENING\nOVERSTRESS\nBUHN-IN/TESTS\n\n1 SUPPORTING DISCIPLINES\n2\nQUALITY CONTROL\n3\nSYSTEM SAFETY\n4\nCONFIG. /SPARES CONTROL\nTRAIN. /PERSONNEL CERT.\n5\nTRACEABILITY\n6\n7\nPROCESS/OPERATIONS CEET.\n8\nHUMAN FACTORS/MAN-HATING\n1 MOTIVATION\nCONTRACTUAL/RELIABILITY\n2\nINCENTIVE\nAWARENESS (e.g., MAN-FL.)\n3\n4\nZERO-DEFECTS\nINDIVIDUAL INCENTIVE AWARDS\n5\n\nNotes:\n\nH\nH\nH\n\nH\nH\nH\nH\nH\n\nH\nH\nH\nH\nH\n\nH\nH\nH\nH\nH\nH\nH\nH\nH\nH\nH\nH\nH\n\nH H H\nH H H\n\nH H H\nH H H\nS S S S S S\nH H H H H H\nS S S S S S\nH H H H H H\nH H H H H H\nH H H H H H\n\nH\nH\nH\nH\nH\n\nH\nH\nH\nH\n\nH H S\nH H H\nS S S\nH H H\nS S S\nH H H\nH H H\nH H H\n\nH\n\nH H H H H M H\nH H H" H H\nH H H H. H H H\nH H H \'H H H H\nH H, \xe2\x80\xa2ft H H H H\nH\nH H H H H\nif H H H H H H\nH H H H H H H\nH H H H H H H\n\nH\n\nX\nH\nH\nH,\nH\nH\n\ns\ns\ns\ns\ns\ns\ns\n\nH\nH\nH\n\nH\nH\nH\nH H\nH\nH H\nH\nH H\nH\nH H\nH H H H\nH H H H\nH H H H\nH S H H\nH H H H\nH H H H\n\nH H\n\nH\n\nH\n\nH\nH H\nH H\nH H\nH\n\nH\n\nH\n\nu\n\nLJ / i\n\nH\n\n\xe2\x80\xa2H\'\n\nH\nS\nS\nS\nS\n\nH\nH\nH\nH\nH\nH\nH\nH\nH\n\nH\nH\nH\nH\nH\nH\nH\nH\nH\n\nH\nH\nH\nH\nH\nH\nH\n\nH\n\nH H H H\n\nH H\n\n\xe2\x80\xa2a\n\nH H\nH H\nS S *\nH H\nS S *\nH H\nH H\nH H\n\nH\nH\nH\nH\n\nH H H\nH H H H H\nH H H H H\nH H H H H\nH H H H H\nH H H H H\nH H H H H\n\nH\nH\nH\nH\nH\nH\nH\n\nH H S\nH H S\nH H H\nH H S\nH H S\nH H S\nH H H\n\nS S S S S\n\nS\n\nS S S S S\n\nH H\n\nS\nS\nS\n\ns S\ns s\ns s\n\nS S S S S\nS S S s s\nS S S s s\n\nH\nH\n\nH\nH\nH\nH\n\ns S S\ns S s\ns s s\n\nH = Hard\nS = Soft with respect to measurable affect on reliability estimates\n* = Assumption made: reliability value is held constant\n\n\'31\n\nREFERENCES\n1.\n\nBenjamin, Jack R. and Cornell, AllinC.: Probability, Statistics, and\nDecision for Civil Engineers. McGraw-Hill Book Co. New York, 1970.\n\n2.\n\nChow, Ven Te: The Log-Probability Law and It\'s Engineering Applications. Proceedings American Society of Civil Engineers, vol 80,\nNew York, November 1954.\n\n3.\n\nDelionback, LeonM.: A Design-Oriented Prediction Model for Learning Rates of Individual Mechanical Assembly Tasks. Doctoral Dissertation, Oklahoma State University, Stillwater, Oklahoma, May 1972.\n\n4.\n\nGukhman, A. A.: Introduction to the Theory of Similarity. Academic\nPress, New York, 1965.\n\n5.\n\nLow, George M., Dr.: Mariner 8 Failure, discussed before House\nSub-Committee. NASA Activities Bulletin, vol 2, no. 7, Washington,\nD. C., July 15, 1972.\n\n6.\n\nMan-Rating the Gemini Launch Vehicle. Martin-Marietta, ER-1252115, Kennedy Space Center, Florida.\n\n7.\n\nMeyer, Paul L.: Introductory Probability and Statistical Applications.\nAddison-Wesley, Reading, Massachusetts, 1965\xc2\xbb p. 43.\n\n32\n\nBIBLIOGRAPHY\nAdvanced Spacecraft Subsystem Cost Analysis Study. Final Report Stabilization and Control System, Honeywell Aerospace Division, December, 1969.\nAllen, R. G. D.: Mathematical Analysis for Economists. St. Martin\'s Press.\nNew York, First Edition, 1938.\nArnold, Barry C.: Some Characterizations of the Exponential Distribution by\nGeometric Compounding. SIAM Journal on Applied Mathematics. Ames, Iowa,\nSeptember 21, 1971.\nBaker, B. E.: Operational Considerations and Systems Reliability. NATO,\nAgard Lecture Series no. 47, Reliability of Avonics Systems. Rome and\nLondon, 1971.\nBartholomew, C. S.: Reliability and Program Decision Making. Proceedings\nof Annual Symposium on Reliability. Washington, D. C., 1967.\nBenware, L. T.: Cost Versus Reliability Tradeoff. Proceedings of Annual\nSymposium on Reliability. Washington, D. C., 1967.\nBlanchard, Benjamins., Jr. and Lowrey, Edward E.: Maintainability.\nMcGraw-Hill Book Company, New York, 1969.\nBorchers, C. R. and Churchill, R. E.: System Design Tradeoffs and Economic\nPlanning. IBM Corporation. Owego, New York.\nBrigham, Peter B.: Realistic Reliability for the Cost Conscious Program.\nProceedings of the National Symposium on Reliability. Boston, Ma., 1968.\nBussolini, J. J.: Methods of Specifying and Controlling Design Reliability.\nNATO, Agard Lecture Series no. 47, Reliability of Avionics Systems. Rome\nand London, 1971.\nCarey, Frank R.: System Reliability Cost Trade-Offs Methodology. 10th\nAnnual West Coast Reliability Symposium. Los Angeles, Ca, February, 1969.\nCarter, A..D. S.: Mechanical Reliability. John Wiley and Sons, New York,\n1972.\n\n33\n\nBIBLIOGRAPHY (Continued)\nChestnut, Harold: Systems Engineering Methods. John Wiley and Sons, Inc.,\nNew York, 1967.\nChisholm, Roger K. and Whitaker, Gilbert R., Jr.: Forecasting Methods.\nRichard D. Irwin, Incorporated, Homewood, II., 1971.\nCodier, Ernest O.: Reliability Growth in Real Life. Proceedings of the\nNational Symposium on Reliability. Boston, Ma., 1968.\nColandeive, B. T.: Program Costs versus Reliability. Proceedings of the\nNational Symposium on Reliability. 1964.\nCost-Benefit Analysis. American Elsevier Publishing Company, Inc., NATO\nScientific Affairs Committee, New York, 1971.\nEnglish, J. Morley: Cost Effectiveness. John Wiley and Sons, Inc., New\nYork, 1968.\nFisher, Gene H.: Cost Considerations in Systems Analysis. The Rand\nCorporation and American Elsevier Publishing Co., New York, 1971.\nGoldman, A. S. and Slattery, T. B.: Maintainability: A Major Element of\nSystem Effectiveness. John Wiley and Sons, Inc., New York, 1964.\nGrouchko, Daniel: Operations Research and Reliability. Gordon and Breach,\nScience Publishers, New York, 1971.\nGuide for Reviewers of Studies Containing Cost-Effectiveness Analysis.\nResearch Analysis Corporation, McLean, Va., July 1965.\nHecht, Herbert: Economic Formulation of Reliability Objectives, llth\nAnnual West Coast Reliability Symposium. Beverly Hills, Ca.. May 1970.\nHeiss, Klaus P.: Our R & D Economics and the Space Shuttle. Astronautics\nand Aeronautics. Philadelphia, Pa., October 1971.\nHevesh, Avery H.: Cost of Reliability Improvement. Proceedings of the\nNational Symposium on Reliability. Chicago, 1969.\n\n34\n\nBIBLIOGRAPHY (Continued)\nHinley, J. T. and Shelley, B. F.: Reliability Optimization in the Conceptual\nPhase. Proceedings of Annual Symposium on Reliability. Washington, D. C.,\n1967.\nHunter, Maxwell W., II; Miller, Wayne F. and Gray, Robert M.: The Space\nShuttle Will Cut Payload Costs. Astronautics and Aeronautics, vol 10, no. 6.\nPhiladelphia, Pa., June 1972.\nHymans, SaulH.: Probability Theory. Prentice-Hall, Inc., Englewood Cliffs,\nN. J., 1967.\nIreson, W. Grant: Cost Data-Collection and Use. Symposium on Reliability\nProceedings. San Francisco, Ca., 1966.\nJacks, Herbert G.: The Reliability of Long Life Repairable Equipment. 10th\nAnnual West Coast Reliability Symposium. The Reliability Division. Los\nAngeles, Ca., February 1969.\nKettelle, J. D., Jr.: Least Cost Allocation of Reliability Investment. Journal\nof Operations Research Society, vol 10, no. 2. March-April, 1962.\nKivenson, Gilbert: Durability and Reliability in Engineering Design. Hayden\nBook Company, Inc., New York, 1971.\nLanders, Richard R.: Reliability and Product Assurance. Prentice-Hall,\nIncorporated. Englewood Cliffs, N.J., 1963.\nLeve, Howard L., Dr., and Platte, Maurice M.: Effects of Reliability Variations on System Cost. Symposium on Reliability Proceedings. San Francisco,\nCa., 1966.\nXifson, Melvin W.: Decision and Risk Analysis. Cahners Books, Boston, Ma.,\n1972.\nMisra, Krishna B.: Reliability Optimization of a Series-Parallel System.\nIEEE Transactions on Reliability, vol R-21, no. 4. New York, November,.\n1972.\n\n35\n\nBIBLIOGRAPHY (Continued)\nNeuner, G. E. and Miller, R. N.: Effectiveness Evaluation Using Dynamic\nProgramming. Proceedings of the National Symposium on Reliability. Boston,\nMa., 1968.\nNowlan, F. S.: The Relationship Between Reliability and the Periodicity of\nScheduled Maintainance. 5th Annual West Coast Reliability Symposium. Los\nAngeles, Ca., February, 1964.\nPett, Martin T.: The Effect of Value Engineering on System Reliability. 10th\nAnnual West Coast Reliability Symposium. Missile Systems Division. Los\nAngeles, Ca., February, 1969.\nPieruschka, Erich: Principles of Reliability. Prentice-Hall, Inc., Englewood\nCliffs, N. J., 1963.\nRau, John G.: Optimization and Probability in Systems Engineering. Van\nNostrand Reinhold Company, New York, 1970.\nReliability Assurance Provisions for Government Agencies. NASA, MSFC\nS & E-QUAL 5320. Redstone Arsenal, October, 1972.\nRivett, Patrick: Principles of Model Building. John Wiley and Sons, London,\n1972.\nSalating, Nicholas and Feistman, Myron: Cost Effectiveness via Weighted\nFactor Analysis. Proceedings of the National Symposium on Reliability.\nChicago, 1969.\nSasaki, M.: Slide Methods for Redundant Mission Availability. Proceedings\nof the National Symposium on Reliability. Chicago, 1969.\nScarlett, Neil J.: Reliability Tradeoffs During Concept Formulation. Proceedings of the National Symposium on Reliability. Boston, Ma., 1968.\nSeller, Karl, III: Introduction to Systems Cost-Effectiveness. Wiley-v\nInterscience, New York, 1969.\nStarr, Martin Kenneth: Product Design and Decision Theory.\nInc., Englewood Cliffs, N. J., 1963.\n\n36\n\nPrentice-Hall,\n\nBIBLIOGRAPHY (Concluded)\nTall, M. M.: Relationships Between Program Test and User Support Costs.\nNATO, Agard Lecture Series no. 47, Reliability of Avionics Systems. Rome\nand London, 1971.\nTaylor, Ervin F.: Reliability: What Happens If ... ? Proceedings of the\nNational Symposium on Reliability. Chicago, 1969.\n\xe2\x80\xa2\n\n\'\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\'\n\n\xe2\x80\xa2\n\n-\n\n.-\'\n\n"\n\n;\n\n"\n\n.\n\n>\n\n.\n\n\'\n\n/\n\n\'\n\n\xe2\x80\xa2\n\n:\n\n_\n\n"\n\n-\n\n\'\n\n-\n\n,\n\n^\n\n.\n\n\'\n\n-,\n\n\xe2\x80\xa2\n\n\'\n\nf\n\n_,\n\n" < ,! -\n\nWeiden, van der H.: Status on Reliability in the Netherlands.\' Proceedings of\nthe National Symposium on Reliability. Boston, Ma., 1968.\ni ; Wylie, Jack E.: The Optimization of Systems Reliability. Symposium on\nReiiabiiity Proceedings. San Francisco, Ca., 1966.\nYounger, George O.: A Method for Reliability-Cost Trade-Off Analysis.\nProceedings of Annual Symposium on Reliability. Washington, B.C., 1967.\n\n37\n\nAPPROVAL\nPROPOSED RELIABILITY COST-MODEL\nBy Dr. Leon M. Delionback\ninformation in this report has been reviewed for security classification. Heview of any information concerning Department of Defense or Atomic\nEnergy Commission programs has been made by the MSFC Security Classification Officer. This report, in its entirety, has been determined to be\nunclassified.\nThis document has also been reviewed and approved for technical\naccuracy.\n\nLUI^tE G. RICHARD\nj Director, Systems/Products Office\n\n38\n\n'