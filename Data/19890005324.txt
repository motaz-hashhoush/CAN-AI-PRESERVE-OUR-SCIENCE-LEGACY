b'Aiialysis of FDDI Synchronous Traffic Delays\n4\n\nJanuary, 1988\n\nResearch Institute for Advanced Computer kierlce\nNASA Ames Research Center\n\nRIACS TR 88.3\n\n(hASb-CR-183223)\nANALYSIS CE \xe2\x82\xac E D 1\nSINCHBCNGUS T B A E P l C D E L A Y S\n(kASA)\n\n189-14695\n21 p\nCSCL 098\n\nUnclas\nG3/60\n\nRlACS\nResearch Institute for Advanced Computer Science\n\n0 161942\n\nAnalysis of FDDI Synchronous Traffic Delays\nMarjory 3. Johnson\n\nJanuary, 1988\nResearch Institute for Advanced Computer Science\nNASA Ames Research Center\n\nThe Fiber Distributed Data Interface (FDDI) high-speed token-ring protocol\nprovides support for two classes of service: synchronous service, t o support applications which require deterministic access to the channel, and asynchronous\nservice, to support applications which do not have such stringent response-time\nrequirements. The purpose of this paper is to determine how to set ring parameters to support synchronous traffic most efficiently. Both theoretical results\nand results obtained from a simulation study are presented.\n\nThis work was supported by he National Aeronautics and Space Administration\nunder NASA Contract NAS l?i\n387 to the Universities Space Research Association\n(USRA).\n\nAnalysis of FDDI Synchronous Traffic Delays\nMarjory J . Johnson\nResearch Institute for Advanced Computer Science\nNASA Ames Research Center\nMoffett Field, California 94095\n1. Introduction\n\nThe Fiber Distributed Data Interface (FDDI) is an emerging ANSI standard\nfor a 100 megabit-per-second fiber-optic token ring. FDDI promises to have a\nsubstantial impact on networking products and services of the future. A unique\nfeature of FDDI is its ability to support applications, such as packet voice or\nreal-time control, which require deterministic access to the communications\nchannel, but which can tolerate some jitter. FDDI provides two classes of service: synchronous service, to support the types of applications described above,\nand asynchronous service, to support applications which do not have such\nstringent channel-access requirements.\n\nNASA is studying FDDI\xe2\x80\x99s suitability for use on the Space Station. A possible Space Station application for which the synchronous service class might be\nappropriate is the transmission of periodic samples from an instrument or\nlaboratory experiment on board the Space Station. Samples would need to be\ntransmitted regularly, but a reasonable amount of jitter would be tolerable.\nBased on samples of this type, a scientist could remotely control his experiment\n\n-2-\n\nin real time. The study reported herein was motivated by the need to determine\nhow to set ring parameters to support this type of traffic most efficiently. To\ndate no studies that address this issue have been reported in the literature.\nFDDI is able to provide synchronous service only because token-rotation\ntime is bounded. This bound is a function of a ring parameter, called T-Opr\n\n,\n\nwhich specifies the expected token-rotation time. Each node requires a specified\nfrequency of access to the channel to support its synchronous traffic. T-Opr is\nnegotiated by the nodes during ring initialization to ensure that the most\nstringent synchronous channel-access requirements of all the nodes will be satisfied. It can be proved that the maximum token-rotation time for any ring is\n2x\n\nT-Opr\n\n[3,5]. This would imply that during the negotiation process for\n\nT-Opr , each node should request a value that is half the token-rotation time it\nrequires t o support its synchronous needs. However, it can also be proved that\naverage token-rotation time is less than or equal to T-Opr [ 5 ] . Since ring\noperation is more efficient for larger values of T-Opr , it is desirable, for each\nparticular ring configuration, to determine the largest value that can be assigned\nto T Opt such that the desired frequency of channel access can be guaranteed.\nIn this paper we discuss factors which influence token-rotation time and\nhence which influence channel-access time for synchronous traffic. We derive a\nformula for the maximum token-rotation time for a particular ring configuration, based on the total percentage of ring bandwidth allocated for synchronous\ntraffic. Then we derive a formula for an optimal value for T-Opr, based on\nthis maximum token-rotation time, which guarantees the desired frequency of\nchannel access for the nodes on that ring.\n\nIn practice, even the value for\n\n-3-\n\nT-Opr prescribed by this formula is more restrictive than necessary. Results\nfrom a simulation study suggest that under some relatively non-restrictive\nassumptions regarding the regularity of synchronous traffic, setting\n\nT-Opr\n\nequal to the desired maximum token-rotation time can provide satisfactory performance.\n\n2.\n\nFDDI Access Protocol\nIn this section we present a brief description of the\n\nFDDI media-access-\n\ncontrol protocol. For a more detailed discussion see 14).\n\nFDDI is a timed-token-rotation protocol; timers within each node cooperatively attempt to maintain a specified token-rotation time by using the observed\nnetwork load to regulate the amount of time that an individual node may\ntransmit. Each node has a Token-Rotation Timer (TRT) and a Token-Holding\nTimer (THT), which control that node\xe2\x80\x99s access to the network. A node\xe2\x80\x99s TRT\nprovides a mechanism of accounting for the amount of time that has passed\nsince that node last received the token. The THT assures that initiation of\ntransmission of an asynchronous frame is only allowed if the immediately preceding cycle (i.e., rotation) of the token was less than\n\nT-Opr .\n\nEach node is assigned an amount of time, called its synchronous bandwidth\n\nallocation, for synchronous transmission each time it receives the token. The\ntotal of all synchronous assignments is not to exceed 100 percent of T-Opr.\nSince the average token-rotation time is less than or equal to\n\nT-Opr\n\n(51, then\n\nsynchronous bandwidth assignments are actually a percentage of the total\nbandwidth of the ring. Whereas a node may transmit synchronous frames for its\n\n-4-\n\nallotted time whenever it receives the token, asynchronous transmission is\nallowed only if the load on the ring is light enough to support it. All bandwidth\nthat is not used for synchronous transmission is available for asynchronous\ntransmission. Since a node need not use its entire synchronous bandwidth allocation each time it receives the token, the amount of bandwidth available for\nasynchronous transmission actually varies from cycle to cycle.\n\n3. Theoretical Results\n\nWe wish to select an optimal value for T-Opt that will guarantee the\ndesired frequency of channel access for a particular ring configuration.* Clearly\nthis opt,imal value for T-Opr must be a function of maximum token-rotation\ntime, which in turn is a function of the maximum time that can be spent\ntransmitting both synchronous and asynchronous frames. For simplicity, we\nassume that overhead is negligible, and so we disregard it in the derivation of\nour theoretical results.\n\n3.1. Token-Cycle Length\n\nAverage cycle time is less than or equal to T-Opt [ 5 ] . If the token does\nnot return t o a particular node within a T-Opr time period, then we say that\nthe cycle is a long cycle. There are two possible causes of long cycles: asynchronous overrun and irregular synchronous bandwidth usage.\n\nEach of these\n\nphenomena is discussed below.\n*Note that we are interested in channel-access delays only. Translating synchronous delay requirements at the application level to channel-access requirements at the mediaaccess-control layer is beyond the scope of this paper.\n\n-5-\n\nAsynchronous overrun occurs when a node\xe2\x80\x99s THT expires during transmission of an asynchronous frame. According to the FDDI media-access-control\nprotocol [l],transmission of this frame will be completed before the token is forwarded to the downstream node. The upper bound on asynchronous overrun by\na single node is the time it takes to transmit a frame of maximum size, denoted\nby Frame-t i m e , since the THT might expire right after transmission of the\nframe begins. From [3] this overrun detracts from the amount of time available\nfor asynchronous transmission by downstream nodes during the remainder of a\nparticular token rotation. Hence, Frame-time is the maximum amount of time\nthat can be attributable t o asynchronous overrun during a single token cycle.\nSince transmission of asynchronous frames may be initiated for a T-Opr time\nperiod, the maximum amount of time that asynchronous frames may be\n\nt\ntransmitted during one complete token rotation is T-Opt +Frame - i m e .\nHence, asynchronous overrun may make a cycle long by Frame-time amount of\ntime.\nNow consider the effect of utilization of synchronous bandwidth allocation\non cycle length. Suppose synchronous bandwidth allocation is Sync time units.\n\nAs we noted earlier, the amount of bandwidth available for asynchronous\ntransmission varies from cycle to cycle, depending on the amount of synchronous\ntransmission that occurred in the preceding cycle. If each node uses its full synchronous allocation during each token cycle, then the amount of bandwidth\navailable for asynchronous transmission is effectively\n\nT-Opt -Sync\n\n[2]. How-\n\never, if some portion, say B time units, of the synchronous bandwidth is not\nused during a given token rotation, then the amount of bandwidth available for\n\n-6-\n\nasynchronous transmission increases accordingly. In addition all nodes may still\nuse their full synchronous bandwidth allocation the next time they receive the\ntoken. Depending on the particular transmission sequence, such a situation may\nresult in a token cycle that is long by up to B time units, with asynchronous\nframes being transmitted for up to T-Opt -Sync + B time units and synchronous frames being transmitted for Sync time units.\nThis phenomenon can occur only if one or more nodes uses its synchronous\nbandwidth allocation irregularly. For example, suppose we have a ring with four\nnodes, 1, 2, 3, and 4. Suppose nodes 1, 2, and 4 transmit only asynchronous\nframes and that node 3 transmits only synchronous frames. Suppose node 3\xe2\x80\x99s\nsynchronous bandwidth allocation is B time units.\n\nConsider the following\n\nscenario. Suppose during a particular token cycle beginning with node 1 that\nnode 3 uses none of its synchronous bandwidth allocation. During the token\ncycle beginning with node 1\xe2\x80\x99s next turn, suppose that nodes 1 and 2 transmit\nasynchronous frames for a period of time\n\n2 T-Opt\n\nand that node 3 uses its full\n\nsynchronous bandwidth allocation during this cycle. Then this latter token cycle\n\nis long by at least these B time units.\n\nTheorem\n\n1:\n\nThe\n\nupper\n\nbound\n\non\n\ntoken-cycle\n\ntime\n\nis\n\nT-Opt +Frame -time +Sync, where the total synchronous bandwidth allocation\nfor the ring is Sync time units.\n\nProof: The effects of the two phenomena of asynchronous overrun and irregular\nsynchronous bandwidth usage are additive. For suppose that no synchronous\nframes are transmitted during a particular token rotation beginning with node\n\n-7-\n\nz . Then during the token rotation beginning with node\n\n2\xe2\x80\x99s\n\nnext turn, it is pos-\n\nsible for the maximum asynchronous transmission, T-Opr +Frame -time\n\n, to\n\noccur before the token reaches any of the nodes having a nonzero synchronous\nbandwidth allocation. If all the nodes with a nonzero synchronous bandwidth\nallocation use their total allocation when they receive the token, then the length\nof this cycle will be T-Opr +Frame -time +Sync.\n\n3.2. Computation of\n\nT-Opr\n\nAs a direct consequence of Theorem 1, we can compute an optimal (Le.,\nmaximal) value for T-Opr that guarantees the desired frequency of channel\naccess.\n\nTheorem 2\n\nThe optimal setting for T-Opr that guarantees the desired fre-\n\nquency of channel access, say\n\nT-Opr\n\n=\n\nX time units, for a particular ring configuration is\n\nX -Frame -time -Sync .\n\nProof: By Theorem 1, if\n\ntoken-rotation time is\nnode within\n\nX\n\nT-Opt\n\n=\n\nX -Frame -time -Sync , then the maximum\n\nX . Thus, the token is guaranteed to return to a given\n\ntime units.\n\nIf Sync and Frame-time are both relatively small, then Theorem 2 provides a more efficient setting of T-Opr than that specified by the FDDI standards documents. For example, suppose\n\nX\n\n=\n\n100 time units, Sync = 20 time\n\nunits, and Frame-time = 10 time units. According to Theorem 2, the maximal\nsetting for\n\nT-Opr t o guarantee the desired frequency of channel access is\n\nX -Frame time -Sync =70, whereas the FDDI standards documents suggest\n\n-8-\n\nthat\n\nT Or\np\n\nX -Frame -time\n\nshould\n-Sync\n\nbe\n\n< Sync ,\n\nset\n\nto\n\nX / 2 = 50.\n\nNote\n\nthat.\n\nif\n\nthen it is impossible to assign a value to\n\nT-Opr that will guarantee the desired frequency of channel access, for there is\ntoo much demand for synchronous bandwidth relative to the channel-access\n\np\nrequirements. Setting T-O t so as to guarantee channel access within the\ndesired time interval would result in insufficient channel capacity to support the\namount of synchronous traffic.\n\n4. Simulation Results\n\nIrregular synchronous bandwidth usage is a major cause of long token\ncycles; if synchronous traffic is generated at constant intervals, as in our proposed Space Station application, then token-cycle time will seldom reach the\ntheoretical upper bound.\n\nWe wish to determine a more efficient setting of\n\nT-O r for this type of situation than that provided by Theorem 2. It is clear\np\nthat assigning larger values to T-Opr would increase efficiency of the ring,\n\np\nbecause overhead would be reduced. A natural value to consider for T-O r is\nthe desired frequency of channel access. In fact, this is the upper bound of possi-\n\np\np\nble values you would want t o assign to T-O r , for if T-O r were greater than\nthe desired frequency of channel access, then the average cycle time could also be\ngreater. As a result, the channel-access time for synchronous traffic might often\nexceed the desired upper bound.\nWe conducted a simulation study of the delays experienced by synchronous\nframes when T-Opr is set equal to the desired frequency of channel access, to\ndetermine whether this configuration would provide satisfactory support (both in\n\n-9-\n\nterms of mean delay and in terms of number of delays that exceed T-Opr ) for\nsynchronous traffic.* The delay measured in the simulation is the time from\ngeneration of a frame at the source node to receipt of the frame at the destination node. This includes queueing delay while the frame waits in the transmission queue at the source, transmission time, and the time required for the frame\nto propagate from the source node to the destination node. While there is not a\ndirect correlation between synchronous delay and the time between consecutive\nchannel accesses, as long as synchronous delay does not exceed T-O p t , then the\nring is performing as desired.\nWe modeled a ring with sixteen nodes, as illustrated in figure 1. Nodes 1-3,\n6-11, and 14-16 are synchronous nodes, i.e., they transmit only synchronous\n\nframes, and nodes 4, 5, 12, and 13 are asynchronous nodes, i.e., they transmit\nonly asynchronous frames. We modeled the network under several different\ntraffic loads by varying the number of active synchronous nodes (i.e., those\nnodes actually generating and transmitting synchronous frames during the run)\nand by varying the interarrival rate of asynchronous frames at the asynchronous\nnodes. Asynchronous traffic is evenly distributed among the four asynchronous\nnodes for each simulation run, and the interarrival times of the asynchronous\nframes at each of the nodes are exponentially distributed. Each active synchronous node generates synchronous frames at a constant rate of one frame every\n\n*This study was conducted using LANES (Local Area Network Extensible Simulator),\nwhich was developed by the Data Networks Group at NASA Ames Research Center,\nunder the direction of Terry Grant. William Kessinger, an Industrial Engineering student at Stanford University, made the simulation runs and produced all the figures\npresented herein while he was working as a summer employee at RIACS.\n\n- 10 -\n\n14\n\nA\n\n2\n\n1\n\n16\n\n15\n\n3\n\n7\n4\n\n13\n\nA\n\n-\n\n-\n\nA\n\nA\nS\n\nS\n\nS\n\nS\n\nS\n\nS\n\nFigure 1. Ring Configuration\n\n8000 microseconds. While the interval between any two consecutive synchronous\n\nframes generated a t any individual node is constant, the generation of synchronous frames a t different synchronous nodes is staggered. For each synchronous\nnode, it is desired that any given frame a t that node should be transmitted\nbefore the next one a t that same node is queued for transmission, i.e., the desired\nfrequency of channel access is 8000 microseconds. Since the purpose of our study\nis to examine synchronous delays when T-Opr is set equal to the desired frequency of channel access, then T-Opr is set to 8000 microseconds also.\nFrame size for both synchronous and asynchronous frames is 4040 bytes,\nincluding the header. Hence, approximately 24 frames can be transmitted during\neach 8000 microsecond T-Opt time period. Each active synchronous node is\nallocated synchronous bandwidth to transmit exactly one synchronous frame\neach time it receives the token.\n\n-\n\n11 -\n\nWe modeled the network under three different levels of loading, called levels\n1, 2, and 3. For level-1 loading, only 6 synchronous nodes are active and the\n\naverage number of asynchronous frames generated per T-Opr time period is 12.\nThus, the offered load is approximately 75% of ring capacity. Under level-2 and\nlevel-3 loading, all 12 of the synchronous nodes generate one frame per T-Opr\ntime period. That is, synchronous traffic accounts for half the capacity of the\nring. The average number of asynchronous frames generated per T-Opr time\nperiod for level-2 and level-3 loading are 12 and 16 frames, respectively. Under\nlevel-1 loading, the bulk of the traffic on the network i asynchronous; under\ns\nlevel-2 loading, the offered load is approximately equal t o the capacity of the\nring; under level-3 loading, the ring is overloaded, so that queues at the asynchronous nodes will become infinite.\nUnder level-1 loading, even though ring utilization is approximately 75%,\nboth mean and maximum synchronous delays are considerably less than\n\nT-Opt.\n\nFigure 2 presents a histogram of the delays experienced by a representative node\nduring a single simulation run with level-1 loading.\nUnder level-2 loading, the mean delays experienced by the synchronous\nnodes are all less than 3000 microseconds. Figure 3 presents the 95% confidence\nintervals for these mean delays. Figures 4.a and 4.b are histograms of delays\nexperienced by representative nodes during a single simulation run with level-2\nloading. For this particular run, fewer than 1%of all synchronous frames experience a delay that exceeds 8000 microseconds.\nUnder level-3 loading, the mean delay experienced by each synchronous\n\n- 12 -\n\ne\n\n0\n\nSynchronous Frame Delay (microseconds)\n\nFigure 2. Frequency Distribution of Synchronous Frame Delays\nfor Node 15 under Level-1 Loading (72.6% utilization)\n\n14\n\n1 5 1 6\n\n1\n\n2\n\n3\n\n6\n\n7\n\n8\n\n9\n\n1 0 1 1\n\nNodes\n\nFigure 3. 95% Confidence Intervals for Mean Delays under\nLevel-2 Loading (approx. 96% utilization)\n\n- 13 -\n\ncn\n\na\n\n5\n\nL\nc\nc\n\n0\n\n0\n\n1 0 0 0 2000 3000 4000 5000 6000 7000 8000 9000 10000\n\nSynchronous Frame Delay (microseconds)\n\nFigure 4.a. Frequency Distribution of Synchronous Frame\nDelays for Node 9 under Level-2 Loading\n(96.8% uti kat ion)\n\nSynchronous Frame Delay (microseconds)\n\nFigure 4.b. Frequency Distribution of Synchronous Frame\nDelays for Node 14 under Level-2 Loading\n(96.8% utilization)\n\n- 14 node is still much less than 8000 microseconds. Figure 5 presents the 95% confidence intervals for the mean delays experienced by each of the synchronous\nnodes. Note that these mean delays are larger than the mean delays under\nlevel-2 loading, as we would expect, since the average token cycle will be longer\nin the more heavily loaded situation. Figures 6.a, 6.b, and 6.c are histograms of\nsynchronous delays experienced by represent at ive nodes during a single simulation run with level-3 loading.\nFor this particular run, 80 out of a total of 1718 synchronous frames (less\nthan 5 % ) experience delays that exceed 8000 microseconds. The most instances\nof excessive delay occurred for node 2, with 16 of 144 frames, or 11%,experiencing delays greater then 8000 microseconds. Examination of the individual synchronous delays for this node reveals that these 16 excessive delays occur in 6\nclusters of consecutive frames, with some clusters containing as many as 4\nframes. This clustering phenomenon occurs because the token rotates relatively\nslowly in such a heavily overloaded ring.\n\n(The average token-cycle time is\n\ngreater than 7000 microseconds for this run.)\n\nWhen one synchronous frame\n\nexperiences a delay greater than 8000 microseconds, then a second synchronous\nframe will become queued for transmission before the first one is transmitted.\nSince this second frame must wait for two token arrivals before it will be\ntransmitted and because the cycle time is so large, this second frame may also\nexperience an excessive (i.e.,\n\n> 8000 microseconds)\n\ndelay. This pattern may con-\n\ntinue for several consecutive frames, even though the token visits the node with\nacceptable frequency.\nFor this reason, it might be beneficial t o institute a procedure t o purge a\n\nI\n\n4800-\n\n1\n\nI\n\n1\n\nI\n\n1\n\nI\n\n1\n\n6\n\n7\n\nI\n\nI\n\nI\n\n.\n\nI\n\nI\n\n4600.\n4400.\nv)\n\n4200.\n0\n\n0\nW\n\nWJ\n\n2\n\n4000.\n\n0\n\n3800:\n\n3400\n\n14\n\n1 5 1 6\n\n1\n\n2\n\n3\n\n8\n\n9\n\n1 0 1 1\n\nNodes\nFigure 5. 95% Confidence Intervals for Mean Delays under\nLevel-3 Loading (approx. 99% utilization)\n\n0\n\n1000 2000 3000 4000 5000 6000 7000 8000 9000 10000\n\nSynchronous Frame Delay (microseconds)\n\nFigure 6.a. Frequency Distribution of Synchronous Frame\nDelays for Node 2 under Level-3 Loading\n(99.6 Yo utiI ization)\n\n- 16-\n\n2\n1\ne\n\n0\n\n0\n\n1000 2000 3000 4000 5000 6000 7000 8000 900010000\n\nSynchronous Frame Delay (microseconds)\n\nFigure 6.b. Frequency Distribution of Synchronous Frame\nDelays for Node 6 under Level-3 Loading\n(99.6% utilization)\n\n. . -\n\n0\n\nl o b o 2000 3000\n\n4000 5000 6000 7000 8000 9000 10000\n\nSynchronous Frame Delay (microseconds)\n\nFigure 6.c. Frequency Distribution of Synchronous Frame\nDelays for Node 15 under Level-3 Loading\n(99.6% utilization)\n\n- 17synchronous frame which is pending transmission whenever a new synchronous\nframe becomes queued for transmission at the same node. This would result in\nan occasional lost frame, but it would prevent a series of consecutive frames from\nbeing delivered outside of the time constraints. If this type of purging had been\nused for the simulation run described above, then only 6 synchronous frames\nfrom node 2 (less than 5 % ) would have been lost. Moreover, less than 5% of the\nsynchronous frames generated by any single node would have been lost.\nOf course, it would be unreasonable purposely to overload a ring over a long\nperiod of time. However, level-3 loading might represent a burst of activity that\ntemporarily overloads the network. Our simulation results indicate that even\nwhen the ring is heavily overloaded, if synchronous traffic is generated at constant intervals, then setting\n\nT-Opr equal to the desired frequency of channel\n\naccess yields synchronous delays that are acceptable approximately 95% of the\ntime.\nIt is interesting to note that it is theoretically impossible to set T-Opr\n\nso\n\nas to guarantee the desired frequency of channel access for either level-2 or level3 loading, because in each situation there is too much demand for synchronous\n\nbandwidth relative to the channel-access requirements. That is, using the terminology of Section 3,\n\nX -Frame -time -Sync < Sync . Nevertheless, we obtained\n\nsatisfactory performance in both these situations by setting\ndesired frequency of channel access.\n\nT-Opt equal to the\n\n- 18 5. Conclusions\n\nThe FDDI standards document [l]suggests that T-O r should be set to a\np\nvalue equal to half the desired frequency of channel access in order to support\n\np\nsynchronous traffic. This rule for setting T-O r may be suboptimal for a given\nring, since it is valid for any configuration. In this paper we derive a formula to\ncompute the optimal T-Opr for a particular ring configuration as a function of\nthe synchronous requirements of that ring. If T-O r is set according to this\np\nformula, then the desired frequency of channel access for that particular ring\nconfiguration is guaranteed.\nSimulation results demonstrate that if synchronous traffic is generated at\nconstant intervals and if it is acceptable that a small percentage of synchronous\nframes experience delays that exceed the desired upper bound, then setting\n\nT-O t equal to the desired frequency of channel access produces satisfactory\np\nresults and is more efficient than setting T-Opr according to our theoretical\nformula.\n\n- 19 References\n1.\n\n\xe2\x80\x9cFDDI Token Ring Media Access Control,\xe2\x80\x9d American National Standard,\nX3.139-1987.\n\n2.\n\nM. J. Johnson, \xe2\x80\x9cFairness of Channel Access for Non-Time-Critical Traffic\nUsing the FDDI Token Ring Protocol,\xe2\x80\x9d Proceedings of Seminar on RealTime Local Area Networks, Bandol, France, pp. 145-157, April, 1986.\n\n3.\n\nM. J. Johnson, \xe2\x80\x9cProof that Timing Requirements of the FDDI Token Ring\nProtocol are Satisfied,\xe2\x80\x9d IEEE Transactions on Communications, Vol.\nCOM-35, 620-625, 1987.\npp.\n\n4.\n\nF. E. Ross, \xe2\x80\x9cFDDI - a Tutorial,\xe2\x80\x9d IEEE Communications Magazine, Vol. 24,\nNO. 5, pp. 10-17, 1986.\n\n5.\n\nK. C. Sevcik and M. J. Johnson, \xe2\x80\x9cCycle Time Properties of the FDDI Token\nRing Protocol,\xe2\x80\x9d IEEE Transactions on Software Engineering, Vol. SE-13,\npp. 376-385, 1987.\n\n'