b'XX. Communications Systems Research:\nCommunications Systems Development\nTELECOMMUNICATIONS DIVISION\n\nA. ,OnEstimating the Phase of a Square Wave\nin White Noise, S. Butman\n1 . Introduction\n\nSquare waves are to be used in the JPL sequential\nranging system for locating distant spacecraft such as\nMariner Mars 1969 (SPS 37-53, Vol. 11, Chapter 111-A).\nThe system operates by transmitting and receiving, in\nsuccession, square-wave components whose frequencies\nare successively halved. The first, or highest-frequency,\ncomponent provides the most precise range estimate\nwithin an unknown integer multiple of the component\nwavelength or period. However, each succeeding component removes half of the ambiguity left by its predecessors. The process terminates when the balance of the\nrange ambiguity becomes discerrible from other considerations.\nRange measurements are obtained by estimating the\nphase or time delay of the received noise-corrupted target return relative to a locally generated noiseless replica\nof the square wave. Specifically, the received signal is\ncorrelated with two square-wave replicas spaced onequarter period apart, with analogy to the optimum estimator for the phase of a sine wave (Ref. 1). The two\n200\n\ncorrelator outputs are then combined (in a nonlinear manner) to give the required phase estimate. This is the\noptimum method for determining the range through\ntracking.\nThe purpose here is to determine the functional form\nof the optimum (maximum-likelihood) processing of the\noutputs of the two correlators and the accuracy of the\nresulting estimate. One measure of accuracy is given by\nthe signaI-to-noiseratio (SNR) out of the correlators. The\nsum of the output SNRs is a function of the unknown\nphase of the received signal, ranging from a high equal\nto the theoreticaf maximum to a low of one half of the\ntheoretically maximum SNR, or -3 dB. This amounts\nto an average SNR which is 1.8 dB below the theoretical\nmaximum, where the average is taken with respect to a\nuniform a priori phase distribution between 0 and 2 ~ .\nSuch an a priori distribution is justifiable when there is\nno a priori phase information, as would be the case during acquisition. This raises the question of whether there\nmay not be a better choice of the two correlator functions.\nA general two-correlator estimation scheme is, therefore, considered from the point of view of maximizing\nthe average SNR during acquisition. It is found that the\nJ P l SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nbest two correlators for this purpose are the sine and\ncosine waves, even though the received signal is not sinusoidal. The sum of the SNRs is then phase-independent\nand is only 1.0 dB below the theoretical maximum when\nthe received signal is a square wave. Moreover, the\nprocessing of the above correlator outputs to give the\nmaximum-likelihood phase estimate is also independent\nof the structure of the ranging signal, being of the same\nform for all signals that it is for the sine-wave phase\nestimator.\n\nwhere, as shown in the following sketch, Z ( T ) = R ( T ) ,\nand y\' ( T ) = R [ T - ( T / 4 ) ] ,with R (T) being the autocorrelation function of s ( t ) defined by\n\nR (T) =\n\n+iT\n\ns (t) (t\ns\n\n+\n\n7)\n\ndt\n\n2. Formulation\n\nLet s (t - T ) denote a square wave of unit amplitude\nand period T that has been delayed by an amount\nI , - T / 2 < T L T / 2 , and observed in the presence of additive gaussian white noise n ( t ) of one-sided spectral density N o , in watts/hertz, as\n\nwhere MT is the length of the observation time which,\nfor convenience, is taken to be an integral number of\nperiods. It is assumed that s ( t - T ) is present during the\nentire observation time, starting on or before t = 0 and\nextending to t = MT or beyond. It is also assumed that\n)\nthe a priori probability density p ( ~ is uniform on\n( - T / 2 , T / 2 ] and that the amplitude of the signal or,\nequivalently, the value of No is known exactly.\n\n3. Estimation of T Using the Outputs of Two\nSquare-Wave Correlators Separated by\nOne-Quarter Period\n\nWhen z ( t ) is correlated with the locally generated\nsquare waves s (t) and s [t ( T / 4 ) ] ,the correlator outputs will be\n\n+\n\nAlso,\n\nare zero-mean gaussian random variables of variance\nE [n;] = E [n;] = 2 = No/2MT, where E is the expectation or averaging operator. They are statistically independent because they have zero cross covariance,\nE [nsnv]= 0.\nIn vector notation, we have z = col (x, y), Z ( T ) =\ncol [ X ( T ) , Y ( T ) ] and n = col (ns, where E [nn\'] = 2 I\n,\nnu),\nis the covariance matrix of the noise, I is the twodimensional identity matrix, and the superscript T denotes transpose. Now, z is conditionally normal with\nconditional mean E [ Z I T ] = Z ( T ) and covariance matrix\nE { [z - Z ( T ) ] [z - Z ( T ) ] \' I T } = 2 I. Consequently, the\nconditional probability density p ( Z I T ) = p [ z ] z ( T ]is\n\n(3)\n\nor\nSubstitution of Eq. (1)into Eqs. (2) and (3) imme.diately\nshows that\nx = ?.\n()\n\n+ n,\n\nY=rl(T)+nu\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\np ( x , y 17) = (2rn2)-\'exp\n\n(4)\n\n(5)\n\n(9)\nwhere\n\n11 - 11\n\ndenotes the Euclidian norm.\n20 1\n\nThe a posteriori probability density, as given by Bayes\'\nrule, is\n\nThe following geometry results when the axes are\nrotated 45 deg using the transformation u = 2-lh(x - y),\nv = 2-4(J(x y):\n\n+\n\nwhere p ( T ) = 1/T is the assumed a priori density. It is\nobvious from Eq. (10) that the most probable a posteriori\nestimate $ that maximizes p ( T ~ zover -T/2 < T 4 T/2\n)\nalso maximizes p ( zI T ) and is, therefore, identical to the\nmaximum-likelihood estimate, given z. However, from\nEq. (8) or (9) it is clear that p ( z I T ) is greatest when\nllz - Z(7) /I = { [ x - 2\nI\n)\n.\n(\n;\n[y - G ( T ) ] \' } % is least.\n\n+\n\nGeometrically, this implies that ? must be selected\nsuch that 8= Z($) is the closest point, from the set of\npossible points Z = z ( T ) , T E ( - T/2, T/2] , to the observed\npoint z. To determine 6 analytically would be dBcult,\nsince it would be necessary to minimize I( z - Z I( over\nZ E Z , where Z is the locus of points described parametrically by\n\nwhich can be combined into the simpler, but not analytic,\nconstraint equation\n\n1.1\n\n+lq= 1\n\n(13)\n\nIn vector notation, we have w = U z , where\n\nis the orthogonal matrix defining the rotation, and\nw = col(u, v) denotes a vector in the new coordinates.\nReferriFg to the above sketch, it is easy to see that the\npoint w = W(?)that is nearest to the received point w\nis given by\n\nEquation (13) describes the two-dimensional square of\nside 2% shown below:\n\nwhere satu = u for 1.1 < 1, satu = sgnu for l u l h l ,\nsgnu= 1 for u L 0 , and sgnu = -1 for u<O.\nThe region l u l Z l v l corresponds to the region\nsgn x = -sgn y; similarly, I u I < Iv I corresponds to the\nregion sgnx = sgn y. Therefore,\nA\n\nx = 2-%(&+G)\n\n202\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nbecomes\n% [sgn (x - y)\n\n55 [ s g n ( x\n\n+ sat (x + y)] ,\n\n+ y) + sat(x - y)] ,\n\ns g n x = -sgny\nsgn x = sgn y\n\nThe distribution of the true value of the delay T about\nthe maximum-likelihood estimate ? is given by the\na postmiori probability density p ( T IIC), which is related\nto the conditional probability density ~ ( 9 1 through\n~)\nBayes\' formula:\n\nt 15)\n\n= % [ I + at((xI-~y~)]sgnx\ns\n\nNext, from Eq. (11)we have\n= (1- $) T / 4 , and from\nEq. (12) it is evident that sgn ~ = ~ y^. Also, sgn $=sgn y.\ng n\nTherefore,\n\nc\n\n- = % { 1 - M [ 1 +sat(1x1--Iy1)]sgnx)sgny\n\nT\n\n= Ys[2sgny - sgnxsgny - sat(xsgny - ysgnx)]\n\n(17)\nThe last expression for $\' can be implemented easily\nin either digital or analog fashion. The pieces of analog\nequipment required) in addition to the correlators, are\nthree multipliers, three adders, two hard limiters, and\none soft limiter. The complete mechanization is shown\nin Fig. 1.\n\nsince p ( T ) = 1/T. The conditional probability density\np (C1T ) , on the other hand, determines the distribution of\nthe maximum-likelihood estimate pabout the true value T .\nIt is clear from Bayes\' formula that the plot of p (7 1\n9\nversus T is of the same shape as that of p ($1).\nversus T\n[but not the same shape as that of p ($1 T ) versus $1.\nIt is a straightforward matter to determine p (?IT) analytically. Thus, the probability of obtaining ? = 0 is equal\nt," the probability of decoding w = col (u,v ) as the corner\nw = (2-\'4 2-M). This happens if, and only if, u > 2W\n-\n\nFig. 1 . Range estimator mechanization\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\n203\n\nand v\n\n> 245; hence,\n\n=\n\ncLe-[-\n\nwhere\n\n(u - Z ) Z\n\n+ (v +\n20.2\n\nZ)Z\n\n]du dv\n\nNext, wz determine p (FIT) for - ( T / 4 ) < T < 0. In this\nregion, u = 2-% and 1 < 2-\'h with 6\' = 2-% [1 (8?/T)].\n6\n1\nTherefore,\n\n+\n\nQ (a) = ( 2 ~ ~ ) - % l "( -b2/2a2) d b\nexp\n\n(20)\n\n-\n\nand Pr{ } denotes probability (as opposed to probability density). In the present context, p (2 0 I T ) =\n=\n8 (t) {.^ = o ~ T } ,\nPr\nHowever, u = 2-%and 6 = v if, and only if, u> Iv I = 16\' ;\n1\nhence,\nA\n\nand\n\nSimilarly,\n\nx exp[\n\n-\n\n1 - (8?/T) - 2%V\n402\n\n1\n\nA similar procedure is used for the remaining regions.\nThe end result is\n\n204\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nThe conditional probability density p (PIT) is plotted\nin Fig. 2 for several values of u and T E [0, T/8]. The\nplots for T E [T/8, T/4] are then obtained by reflecting\nthe original set of graphs about the axis $= T/8. Similarly, p (PIT) for T E [T/4,3T/8] is a reflection about\nAT - T/4 of the plot of p (1\n9 T) for T E [T/8, T/4], etc.\n\ne)\n\nThe a posteriori probability density p ( T I\nis plotted\nin Fig. 3 and satisfies the same conditions of symmetry\nas p (PIT ) . However, it should be observed that p ( T I?) has\nno delta functions even though p ($1 T ) does. Since p (?)\nhas delta functions at the same places as p (?I T ) , the delta\n~9 .\nfunctions cancel in p ( T I ?) = p (.*IT ) / T ( )\n4. The General Two-Correlator Problem\n\nThe preceding discussion was concerned with making\nthe best estimate, given the outputs x and y of the two\northogonal square-wave correlators. It is logical to inquire\nnow whether there may not exist a better choice of correlators (assuming, of course, that the correlator outputs\ncan always be processed in an optimum manner).\n\na posteriori average of\n\nThe continual updating of the local zero reference to\nthe latest estimate ? is known as tracking and can be\nimplemented with a phase-locked loop. As the estimate\n9 improves, p ( T [ approaches 6 ( T - ?) and\n\nc)\n\nwhich is the theoretical maximum. Therefore, the use of\nsquare-wave correlators is optimum during tracking.\nHowever, it is still necessary to determine the best two\ncorrelators for acquisition purposes.\n5. Optimum Correlators for Acquisition\n\nSuppose that r ( t ) is correlated with some pair of\nperiodic, orthonormal, but otherwise arbitrary, time functions f ( t ) and h(t).Then, the correlator outputs are\n\nOne measure of the performance of a correlator is the\nSNR:\n\nor\n\nThe sum of the two SNRs is then\n\nf\n\n= b f S (4 + nf\n\nand\nFor the square-wave correlators, Z ( T ) is on the square of\nside 2%and pZ(.) varies from a maximum of l/u2 to a\nminimum of 1/22 with periodicity T/4. The average\nvalue of pZ ( T ) when T is uniform on (-T/2, T/2] is,\ntherefore,\n\n2/32\n\nwhere + f s ( T ) and +hs ( T ) are cross-correlation functions,\nwhile nf and n h are independent zero-mean gaussian random variables of variance u2. Consequently,\n\n(28)\n\nThis average value would be obtained during acquisition, when there is no knowledge of T other than that it\nis equi-probable on (- T/2, T/2]. However, once an estimate ? has been obtained, the receiver can readjust the\nlocal zero reference to C and obtain p X ( r -9) with an\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\n-\n\n= Pf\n\n+El\n\n(34)\n205\n\n2.5\n\n1\n\nI\n\nI\n\n10\n\nI\n\nu = 1/4\n\n2.0\n\n-\n\n1.5\n\nb\n-\n\n%\na\n1.c\n\n05\n.\n\nC\n20\n\nu = 1/8\n\n16\n\n12\n\na\n\n4\n\nC\n\nI\n.\n\n- 1/4\n\n1/4\n\n1\n,\n\n?/T\n\nFig. 2. Conditional probability density p\n\n206\n\n(PITI vs $11 for various values of u\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nI\n\nI\n\nI\n\n1\n6\n\nI\n\nI\n\nI\n\n0\n\n14\n/\n\nu = 14\n/\n\nu = 1\n\n1\n2\n\n? = O\nT/32\n3T/32\n\n<\nT\n-\n\n8\n\nc\n\nT/8\n\nv\n\nQ\n\nT1\n/6\n\n4\n\n- 1/2\n8\n\nC\n\n- 1/4\n\n0\n\n14\n/\n\nI\n\nI\n\nI\n\n-1/2\n\n1\n\n-1/4\n\nI\n7\n64\n\n32\n\ncr = 1 8\n/\n\ncr = 1 2\n/\n\nA\n42\n\n6\n\n-\n\n<r\nI\n\n2 4 ~\n4\n\n3\n;\n\n2\n\nc\n\nv\n\n1(\n\nQ\n\n0\n\n- 1/4\n\n(\n\n0\n\n1\n\n1\n\n-1/4\n\n./T\nFig. 3. A posterioriprobability density p 1~)1\\7) ?/T for various values of (\nvs\nI\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\n207\n\nNow,\n\nSimilarly,\n\n- =\nph\n\n$ (&)\n\nwith equality if, and only if,\n\nlMT\nlNT\n\nh (t) (t - u)h (u)dt du\nR\n\n2am\n\nT\n\n(36)\nHowever, R(t) is an even periodic function of period T\nwith a positive spectrum:\n\nR ( t - u) =\n\n2\n\nsicos\n\n27rk\n\n2 ~ m\n\nf ( t )=usin-t+bcos-t\n\nwhere m i s the subscript of smm.\nConsequently, the optimum choices for f ( t ) and h(t) are\nf ( t )= 2 u c o s ( 2 t~ m\nT\n\n(t - u)\n\nh(t) = 2usin\n\nAlso, f (t) and h (t) are periodic functions of the general\nform\n\n)\n\n+ e)\n\n(37)\n\nk\n\nf ( t )= ~ ( u k s i n - ?2ak d k c o s - t 2xk\n;t+\nT\n\nT\n\n(38)\n\n(\nT\n\n2 ~ m\nt\n\n+8)\n\n(43)\n\n(44)\n\nwhere e is arbitrary and p= s&/u2. In addition, pf (T) is\nnow independent of T ; hence,\n\nk=1\n\nIn the case of a square wave, s& =s: = 8/2, and we\nobtain\nwith\n\np (T) =7= 8/7r2a2\n\n(46)\n\nwhich shows that the theoretical maximum of l/u2 is\nunachievable in the square-wave case.\n\nk=1\n\nFor this choice of correlators, the maximum likelihoodestimate is well-known to be (Ref. 1)\n\n(41)\nk=i\n\nAT\n\nTherefore,\n\nT\n27r\n\n- -arctan (y/x)\n\nT\n+ - (1 - sgn x )\n2\n\n(47)\n\nwhere\n\nu) dt du\n\n1\nx =\n\nY=\n\n(42)\n208\n\ndlT\n\nr (t) (2&/T) dt\ncos\n\n&lMT\n\nr (t) sin (27rt/T) dt\n\nare the correlator outputs.\nJPl SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nTable 1. A posteriori mean-square errors\n\n6. Mean-Square Error\n\nThe probability densities p (T I?) and p (el7 ) contain all\nof the statistical information about the performance of\nthe estimator. Of particular interest, however, is the\na posteriori mean-square error\n\nI\n\nI\n\nsince it gives the scatter of the true value of the delay 7\nabout the maximum-likelihood estimate k It is easy to\nshow that this a posteriori mean-square error approaches\na2/32 as u2goes to zero, provided ?# +-kT/4, k =0, I,2,3.\nThis is because p ( ~ l $ )tends to a gaussian density of\nmean $/T and variance 2/32. At $ = +kT/4, however,\nTI?) is proportional to Q ( 4 * 2 % 1 ~ 1 / T ) . Thus, if\n-3\nu2 0 and x = ( T --?)/T, we can write\n+\n\nlrn\n\n1\n-\n\n1\n\n3/32\n\nI\n\nA porferiori mean-sauare error for indicated u\n1\n-\n\n0.865\n1.300\n1.430\n1.560\n1.390\n\n1\n-\n\n8\n\n16\n\n0.667\n\n0.703\n1.250\n\n1\n-\n\n4\n\n2\n\n0.667\n\n0.905\n0.910\n0.995\n1.WO\n\n0.910\n0.995\n0.995\n1.WO\n\n1.050\n0.910\n\n090\n.0\n\n2.300\n3.700\n\n2.000\n\n8. Analysis o Narrow-Band Signals Through\nf\nthe Band-Pass Soft Limiter, R. C. Tausworthe\n1. Introduction\n\nSeveral authors (Refs. 13)have examined the output\nSNR characteristics of the so-called "soft" limiter, giving\nseveral approximations for the output signal and noise\nterms as functions of the input parameters, The ensuing\narticle illustrates that, under a widely accepted model\nof the soft limiter, the output signal power and signal\nsuppression can be found exactly in terms of the hardlimiter signal-suppression function. The output noise is\ncorrespondingly then well approximated.\n\nx2 Q (402% dx\nx)\n\n-\n\nLrnQ(4-2sx)dx\n\n2. limiter Suppression Factor\n\nIn the discussion below, we shall assume that the following device input\n\nIntegrating by parts and noting that\nQ\' (4 * 2%x ) = (2m2)-% (-32 x2/d)\nexp\nwe obtain\nis a narrow-band waveform consisting of a signal immersed in gaussian noise of variance &:\n\nx (t) = V (t) sin [ m o t\n= u2/48\n\nThe above analytical results have also been verified\nnumerically on a general-purpose digital computer. Numerical values of the a posteriori mean-square error in\nunits o 2/32 are tabulated in Table 1 for 3 = kT/32,\nf\nk=0, *\n,4, and u=2-IC, k = 0 , * * * ,4.\n\n= Vsin4\n\n+ e ( t ) ]+ n ( t )\n\n+n(t)\n\n(1)\n\nwhere\n\nv = V(t)\n(b\n\n= mot\n\n+ 8 (t)\n\nIt has been shown (SPS 37-44, Vol. IV, pp. 303307) that\nthe portion of the limiter output due to input signal is\n\nReference\n1. Viterbi, A. J., Principla of Coherent Communication, pp. 129.\nMcGraw Hl Book Company, Inc., New York, 1988.\nil\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nG(Vsin+) = E [y(x)lVsin+]\n= c,sin+ f c2sin2+\n\n+.\n\n*\n\n.\n\n(2)\n209\n\nin which the coefficient\n\nSuppression is probably computed with least didiculty\nin this case through the approximation given in Eq. (6).\n\n(3)\nrepresents the amplitude of the signal in the kth harmonic zone. For the hard limiter, the ck have been\nevaluated as\n\n3.Soft limiter Model\nWe shall take as the model of the soft limiter the\nfunction plotted in Fig. 4:\n\ny = Lerf[(g)x]\nck = L ( t )\n\n(8)\n\n= Lerf(Bx)\n\nM(G)l:cos+cosk+exp\nv\n\nwhere erf ( x ) is the well-known error function (Ref. 4)\n\n(9)\n\n(4)\nand\nfor odd k, in terms of the parameter v = V ( t ) / u N\nthe modified Bessel functions of the first kind (Ref. 4).\nWith an input SNR of\n\np\n\nthe hard-limiter suppression\n\nfactor a2(p) is defined as the ratio of the fundamental\n\nsignal output power to what it would be if noise were\nabsent. When V ( t ) is a constant amplitude,\n1\n2\n\np =-V2,\n\nso\n(P) =\n\n\' [ () +\ni\n4 pe-" 10\n\nAn excellent approximation for\n\na*\n\n11\n\n(i)]\n\n(5)\n\nand B = K&/2L.\nOur model is thus seen to possess the following characteristics: For values of x much less than 2L/Kig, the\ndevice acts as a linear amplifier with voltage gain K. For\ninputs x much larger than 2L/KrM, signal limiting occurs,\nwith the limit level L. Further, as K + 00 for fixed L, the\ndevice becomes a hard limiter, and as L -+ 00 for fixed K,\nthe device becomes a linear amplifier. The soft limiter\nmodel we have chosen thus degenerates to previously\nanalyzed devices in limiting cases.\nEvaluation of the limiter performance thus now depends only upon finding G (V sin +) and its Fourier co&cients for the assumed characteristic. In the present\ncase G(Vsin$) takes the form\n\n(Ref. 5) is\nG(Vsin+) =\n\n=1\n\nVN(2T)%\n\n+\n+\n\n0.7854p 0.4768p2\n1.024p 0.4768 p2\n\n+\n\n(6)\n\nJim\n-m\n\n{*}\n\nX exp 2ui\n\nIf, however, V ( t ) is time varying, then the input SNR is\np =E($v2)\n\nerf B(Vsin+\n\n+ n)\n\ndn\n\n(10)\n\nAlthough the results to follow are quite general, we shall\nevaluate only the behavior in the fundamental output\nzone:\n\n1\nand\na2( p )\n\n210\n\n=E\n\n[ (+\n\nv~)]\n\n(7)\n\nsin+ erf [B (Vsin+\n\n+ n ) ]d+\n\n(11)\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nThe inner integral can be integrated by parts to give\n\nF=\n\nFI\nl\n\n+\n\ncos2 exp { -B2 (V sin\n\n+ + n)2}d+\n\n(12)\n\nwhich, when inserted back into the expression for C, produces the relation\nc1 = 2 % B L V / T cos2+\nm?x2\n\n-T\n\n{ [(B2 +-205 ) n2\n1\n\nexp -W\n\n+ 2B2Vn sin + + B2V2sin2\n\nin terms of the parameter ratio\n\n(13)\n\nBut the form of c1 is now recognized to involve the same\nintegral as that of the hard limiter, except with a different v. As a consequence, the results for a soft limiter are\nexpressible in terms of the hard limiter suppression factor 2. For example, the device output power P,, considering V ( t )= V as a constant, is\n\nThe inner integral is tabulated (Ref. 4 :\n)\n\n+ + e ) }dt =\n\nexp { - (at2 2bt\n\nand, if V ( t )is time varying, P, is\n\n(14)\nMere substitution thus provides\n\n(15)\nJ P l SPACE PROGRAMS SUMMARY 37-53,\n\nVOL. 111\n\nHere again we can define a signal suppression factor .:\nI\nas the ratio of signal output powers with and without\n21 1\n\nnoise. Because of the last equation above, we see this\ncan be written as\n\nin the simpler, constant-V case. This function appears\nplotted i Fig. 5 for various values of VK/L.\nn\nNote in the limiting case\n\n(19)\n(approachinga hard limiter)\n5\n\n0\n\nVK/L =\n_c_\n\nI\nI\n\n-5\n\n-10\n\n-15\n\n-20\n\n-25\n\n-30\n\n-35\n\n-40\n\n-45\n-30\n\n-25\n\n-20\n\n-15\n\n-10\nINPUT S R dB\nN,\n\n-5\n\n0\n\n5\n\n10\n\nFig. 5. Suppression factor a;and normalized output signal power PJL2 as functions of input SNR\n\n212\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\nthat\n\nwhich can be integrated by parts to produce\na+\n:\n\na\n2\n\nas it should, and as\n\nx\n\n(approaching a linear amplifier)\n\nThis expression is the same as c1 for the signal output\nportion only, except for the substitution u = 2% BV,,. The\ntotal limiter output power is\n\nfor a fixed K, that\n\nPs+ E\n\n[Io (Bp)\n- 4 Zl(T)] (28)\n-\n\n[T]\n\nK2V2\n\n(t)\n\n= K2PSi,\n\n(21)\nPs+n\n\nas it should.\n\n=\n\n1\n\nE (a?)\n\n8\n= -E\n\nTZ\n\n[az\n(B2V&)]\n\n(29)\n\n4. Noise Output Power\n\nPS+\n\n(linearregion)\n\nP\n\nP,,,\n\n8\n-L2a2 [B\xe2\x80\x99E (VZ,)]\n7r2\n\nwhereas, when severe clipping is taking place,\nps-)\n\npt\n\n=\n\ncy2\n\n(PI\n\n(limitingregion)\n\n1 - CY2 (P>\n\n(23)\n\nThus an asymptotically correct approximate expression\nfor the output SNR of the device is\n\n(considering now only the constant-V case). The crossover between these two conditions begins at the point\nwhen the input begins to saturate.\nConsidering that the noise may be decomposed into\nindependent in-phase and quadrature-phase terms\nn ( t ) = n,cos+\n\nin w&c-, c2,\n=\n\n+ n,sin+\n\n(24)\n\n= ug, then it is immediate\nthat (t)takes\n\n(25)\n\nwith the amplitude function\n\nV&(t) = (V\n\npl =\n\n.i[l+(ll-)\xe2\x80\x98P]\n7\nr\ns\n\nthe form\nx (t)= Veq ( t )sin +e,\n\nP\n\nVK\n\n7\nr\ns\n\nn,)2\n\n+ n2,\n\n(26)\n\nPs\n\nPsig\n\n(linear region)\n\n(32)\n\ni.e., r = 1. At the other extreme, it has been shown\n,\n(Ref. 5) that\n\nThe amplitude of d e output fundamental term is\na, =;~*erf(BVeqsin+)sin+d+\n1\n\nVK\n\nFinally, of interest is the ratio rs of the input and\noutput signal-to-noise densities at the fundamental frequency; this function is needed when the limiter output\nfilter is considerably narrower than the bandwidth of the\ninput process. It is clear that in the linear region, the\nSNR is preserved so that\nNt\n-=- No\n\n+\n\n(31)\n\nP\n\n(27)\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\n-_-- (Psi,N o\nNo\nPs\n1\n\xe2\x80\x98\n\n(limitingregion)\n\n(a)\n213\n\nwhere\n\nr (p) is approximately\n\n5. Conclusions\n\nIff\n() = 0.862 p\n\xe2\x80\x99\n\n+\n\nIn the transition region, r, lies somewhere between\n1and r. Thus a simple asymptotic approximation to the\ntrue behavior can be expressed in the form\n\nr, = 1+ aPi, r\n1+ aPi,\n\nDepending on the parameter VK/L, the soft limiter\nperforms in varying degrees between the characteristics\nof a linear ampBer and a hard limiter. The performance\nparameters are furthermore expressible in terms of the\nhard-limiter suppression function under a change of variables. Such parameters include the output signal and\nnoise powers, signal suppression factor, output SNR, and\noutput signal-noise-density ratio.\n\n(35)\n\nin which the parameter a can be chosen to make a good\nfit in the transition region. To match the same type of\ncrossover that we notice between P, and P,,,, we can take\n\nReferences\n1. Galejs, J., \xe2\x80\x9cSignal-to-Noise Ratios i Smooth Limiters,\xe2\x80\x9d IEEE\nn\nTrans. Inf. Theory, vol. IT-1, June 1959, pp. 79-85.\n2. Baum, R. F., \xe2\x80\x9cThe Correlation Function of Smoothly Limited\nGaussian Noise,\xe2\x80\x9d IEEE Trans. Inf. Theory, Vol. IT-3, Sept. 1959,\npp. 193-197.\n\nto provide\n\n3. Deutch, R., Nonlinear Transformations of Random Processes,\nPrentiss Hall, Inc., 1962, pp. 24-25.\n4. \xe2\x80\x9cHandbook of Mathematical Functions,\xe2\x80\x99\xe2\x80\x99 NationaI Bureau of\nStandards, Appl. Math Ser. 55, June 1964.\n\n5. Tausworthe, R. C., Theory and Practical Design of PhaseLocked Receivers, Technical Report 32-819, Jet Propulsion\nLaboratory, Pasadena, Calif., Feb. 16, 1966.\n\n214\n\nJPL SPACE PROGRAMS SUMMARY 37-53, VOL. 111\n\n'