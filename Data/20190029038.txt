b'National Aeronautics and Space Administration\n\nOverview of HECC Pay-for-Use AWS Cloud\nAug. 7, 2019\nNASA Advanced Supercomputing Division\n\nwww.nasa.gov\n\nOutline\n\xe2\x80\xa2 The Whys?\n- Why offer commercial Cloud resources?\n- Why use Cloud through HECC?\n- Why AWS?\n- Why Pay-for-Use and How?\n\n\xe2\x80\xa2 AWS Basic Info\n- Cloud regions\n- Cloud services\n- Sample costs of AWS resources\n\n\xe2\x80\xa2 Integration of AWS into HECC\n- Cost conscious: dynamic on/off of resources\n- Flexible and familiar environment\n- Software stack\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n2\n\nWhy Offer Commercial Cloud Resources?\n\xe2\x80\xa2 Provide access to new hardware resources not currently\n\navailable at HECC, such as newer GPUs or AMD CPUs.\n\xe2\x80\xa2 Provide an alternative environment for applications that do not\n\ncompile or run on HECC on-premises resources (Pleiades,\nElectra, Merope or Endeavour).\n\xe2\x80\xa2 Provide faster turnaround when you do not want to wait in the\n\non-premises queues for a long time.\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n3\n\nWhy Use Cloud Through HECC?\n\xe2\x80\xa2 You do not have to set it up yourself from a barebone IaaS Cloud. HECC\n\nCloud experts provide you a PaaS environment that is ready to use.\nInfrastructure-as-a-Service (IaaS) -> Platform-as-a-Service (PaaS)\n\xe2\x80\xa2 HECC provides an easy and familiar hybrid environment where you can\n\nmove your work between HECC on-premises resources and the HECC\nCloud.\nHECC develops and maintains all the behind-the-scene infrastructure for\naccessing/bursting jobs to the Cloud\n\xe2\x80\xa2 HECC goes through NASA/EMCC, which may get some volume discount.\n\xe2\x80\xa2 HECC Cloud experts may be able to help resolve some of your issues\n\nand/or channel them to the Cloud provider(s).\n\xe2\x80\xa2 HECC follows strict government guidelines to ensure security.\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n4\n\nWhy AWS?\n\xe2\x80\xa2 NASA requirements for dealing with Cloud\n- All federal agencies should use clouds with FedRAMP certification:\n\nThe Federal Risk and Authorization Management Program is a\ngovernment-wide program that provides a standardized approach to\nsecurity assessment, authorization, and continuous monitoring for cloud\nproducts and services.\n- All NASA cloud access is controlled through EMCC: NASA\n\nEnterprise Management of Cloud Computing enables NASA\xe2\x80\x99s cloud\nconsumption to be consistent, safe, and compliant with industry best\npractices and Federal laws and requirements.\n\n\xe2\x80\xa2 Amazon Web Services is FedRAMP-compliant and currently\n\nthe only cloud provider (with the majority of its services)\napproved by EMCC.\n\xe2\x80\xa2 Microsoft Azure will be on the EMCC-approved list soon.\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n5\n\nWhy Pay-for-Use and How?\n\xe2\x80\xa2 Why?\n- Guidance from the HQ HECC Portfolio Manager is that HECC will provide an\n\neasy mechanism for HECC users to access the diverse cloud offerings utilizing\nuser funds and assist users as required to take advantage of the cloud as\nappropriate for their requirements.\n\n\xe2\x80\xa2 How?\n- PI\n\xc3\x98 determine if ITAR/EAR99 environment is needed.\n\xc2\xa7\nNo -> proceed with Public Cloud\n\xc2\xa7\nYes -> wait till Gov Cloud is approved for HECC use\n\xc3\x98 send NASA funding WBS to HECC to establish an ARC WBS billing account\n\xc3\x98 provide a list of users allowed to use this HECC Cloud account\n\xc3\x98 provide an initial desired Cloud configuration (can be adjusted later)\n\n- HECC\n\xc3\x98 set up the account and configure the environment\n\xc3\x98 track usage of all resources (front-end, PBS server, compute, filesystems, storage,\n\nnetwork, support, \xe2\x80\xa6)\n\xc3\x98 charge expenses against PI\xe2\x80\x99s funding and provide usage report and ensure the account\nis not overdrawn\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n6\n\nAWS Basic Info \xe2\x80\x93 Cloud Regions\n\xe2\x80\xa2 Public Cloud Regions (available now)\n- Lower security requirements\n- Used for non-ITAR/EAR99\n- Cheaper\n- Multiple regions; HECC Cloud currently uses AWS US-West(Oregon);\n\nother public regions can be set up upon demand and/or request\n\n\xe2\x80\xa2 Government Cloud Regions (available in the near future)\n- High security requirements\n- Used for ITAR/EAR99\n- More expensive\n- AWS GovCloud (US-West) and (US-East)\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n7\n\nAWS Basic Info \xe2\x80\x93 NASA Approved Services\n\xe2\x80\xa2 EC2: Elastic Compute Cloud\n- Compute resources to run applications on\n- Similar to the various Pleiades compute node types\n\n\xe2\x80\xa2 EBS: Elastic Block Store\n- Block devices that can be mounted on EC2 for faster I/O\n- Similar to the Pleiades filesystems ($HOME, $NOBACKUP)\n\n\xe2\x80\xa2 S3: Simple Storage Service\n- Object storage\n- Similar to NAS storage system Lou\n\n\xe2\x80\xa2 VPC: Virtual Private Cloud\n- Allows access to EC2 over a virtual private network\n- Similar to the HECC Enclave (where the access is controlled/blocked)\n\n\xe2\x80\xa2 IAM: Identity and Access Management\n- Provides authentication and policy-based control to various AWS services\n- Similar to an HECC account\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n8\n\nAWS EC2\n\xe2\x80\xa2 Current Generation of Instance types (July 2019)\n- General Purpose: a1, t2, t3/t3a, m4, m5/m5a\n- Compute optimized: c4, c5/c5d/c5n/c5.metal\n- Memory optimized: x1/x1e, r4, r5/r5a/r5d/r5ad, z1d\n- Accelerated computing: p2, p3/p3dn, g3/g3s\n- Storage optimized: h1, i3/i3en, d2\n\n\xe2\x80\xa2 On-demand instances\n\na: use AMD processors instead of Intel Xeon\nd: with local NVMe SSD on the instance\nn: more memory, higher EBS/network bandwidth\nmetal: use non-virtualized environment\n\n- Full price\n- Price varies with AWS regions, OS, instance types\n\n\xe2\x80\xa2 Spot instances\n- Significant discount (~70% discount is common) except for newly introduced\n\ninstances whose price remains high for some time\n- Price can fluctuate every 5 minutes\n- May take a long time to get them\n- Can be interrupted by EC2 with 2 min of notification\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n9\n\nSome compute instance info\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nc4 and c5 instances come with many different configurations (nxlarge). They are for compute intensive traditional HPC workload.\nAWS web site lists vCPU number, which is double the number of physical CPU cores shown in this table.\nMax EBS bandwidth (dedicated for I/O into EBS volumes) info from\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html\n\xe2\x80\xa2 Max network bandwidth of 25 Gbps of regular c5 instances is much smaller than the 100 Gbps of HECC Skylake/Cascade Lake.\nExpect worse cross-node performance than Pleiades/Electra/NFE. One Nov 26, 2018, c5n with 100 Gbps became available.\n\xe2\x80\xa2 Pricing based on US-West(Oregon) region, basic Linux (Amazon Machine Image) OS.\nOn-demand https://aws.amazon.com/ec2/pricing/on-demand/; More powerful instances more expensive.\nSpot https://aws.amazon.com/ec2/spot/pricing/ (July 26, 2019 record; may change), usually ~1/3 of On-demand\n\xe2\x80\xa2 Cascade c5 instances were made available starting June 18, 2019. Ahead of NAS (Late Aug, 2019) \xe2\x80\x93 1152 nodes\nN A S A\nH i g h\nE n d\n(2.5 GHz, 40 cores, 192 GiB).\nC o m p u t i n g\nC a p a b i l i t y\n\nQuestion? Use the Webex chat facility to ask the Host\n\n10\n\nSome GPU instance info\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\np2 and p3 instances contain GPUs and are ideal for machine learning, HPC, data processing,\nand cryptography.\nPricing data based on July 26, 2019 AWS Pricing page. p3.16xlarge is expensive ($24.48/hour).\nGov price is slightly higher than US-West(Oregon) price.\np3 (with V100) instances were made available starting Oct 25, 2017. Ahead of NAS (June 2019).\nNAS GPU resources:\n- 64 san_gpu nodes: Sandy Bridge CPU and 1 Nvidia K40 GPU card\n- 19 sky_gpu nodes: Skylake CPU + V100 GPUs (17 nodes with 4 V100, 2 with 8 V100 cards)\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n11\n\nSome general/memory optimized instance info\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nm5a is general purpose; used for web servers, app servers, gaming, etc.\nr5a is memory optimized; used for data mining, data analytics, etc.\nPricing data based on July 26, 2019 AWS online pricing page.\nSlightly lower-cost (10%) than comparable Intel-based instances.\nAvailability announced by AMD and AWS on Nov 6, 2018.\nCurrently, there are no AMD processors at NAS.\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n12\n\nSample EBS, S3, and Network Costs\n\xe2\x80\xa2 EBS (US-West) provision \xe2\x80\x93 pay even if you have no data there\n- General Purpose SSD (gp2) Volumes:\n\n$0.10 per GB-month\n- Provisioned IOPS SSD (io1) Volumes:\n$0.125 per GB-month storage,\n$0.065 per provisioned IOPS-month\n- Throughput Optimized HDD (st1) Volumes: $0.045 per GB-month\n- Cold HDD (sc1) Volumes:\n$0.025 per GB-month\n\xe2\x80\xa2 S3 (US-West) \xe2\x80\x93 pay only for what you use\n- Standard storage:\n\nfirst 50 TB/month\nnext 450 TB/month\n- Standard infrequent access: all storage/month\n\n$0.023 per GB\n$0.022 per GB\n$0.0125 per GB\n\n\xe2\x80\xa2 Data transfer out from AWS S3 to Internet\n\nGovCloud pricing info\n- first\n\n10 TB/month\n- next 40 TB/month\n- next 100 TB/month\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\n$0.155 per GB\n$0.115 per GB\n$0.090 per GB\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n13\n\nSample Costs\n\xe2\x80\xa2 EC2 1 instance use for 1 month continuously\n\nc5.18xlarge (Skylake)\np3.16xlarge (GPU)\n\n\xe2\x80\xa2 S3 standard:\n\n~$17,625/month\n\nr5a.24xlarge (AMD)\n\xe2\x80\xa2 EBS gp2:\n\n~$2,200/month\n~3,900/month\n\nprovision 10 TB costs\n\n$1,000/month\n\nuse 10 TB costs\n\n$230/month\n\n\xe2\x80\xa2 10 TB transfer out from AWS to Internet\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\n~$920/month\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n14\n\nIntegration of AWS into HECC\n\nFor security and accounting purposes,\neach project has its own \xe2\x80\x9cisolated\xe2\x80\x9d HECC Cloud environment.\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n15\n\nCost Conscious\n\xe2\x80\xa2 We dynamically turn on/off AWS front-end, servers for you\n- On Pleiades, PFEs, PBS and Lustre servers are up year-round\n- On HECC AWS Cloud, they are turned on only when you need them\n- AWS front-end: cost varies depending on the instance type you choose\n- AWS filesystem server: c5.18xlarge 1 instance 24 hour x 30 days, ~$2,200/month\n\nDepending on filesystems, cheaper servers may be used\n- AWS PBS server: m5.xlarge 1 instance 24 hour x 30 days, ~$140/month\n\n\xe2\x80\xa2 Go with job-time filesystems if you do not need persistent\n\nfilesystems\n- Example: EBS gp2, provision 10 TB costs $1,000/month\n- Persistent: data stays there after batch job ends (you pay $1000/month)\n\nWhen accessed, need a filesystem server to support it (additional cost)\n- Job-time: data is removed when batch job ends (you pay much less)\n#CLOUD \xe2\x80\x93volume_type, -volume_size, -volume_mount directives\nMost job-time filesystem types (except \xe2\x80\x9cshared\xe2\x80\x9d) use the same instances\nfor compute and as filesystem server(s)\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n16\n\nCost Conscious\n\xe2\x80\xa2 Do not transfer data out to internet with an expensive instance\n\n(for example, a GPU p3.16xlarge which costs $24.48/hour)\n- File transfer to internet has a limited bandwidth and can take a long time\n- If you have to transfer data out of a filesystem at end of a job which uses\n\nexpensive compute instances, better to transfer them to S3 inside the job.\nYou can transfer data between S3 and Pleiades afterwards.\nSee a later slide for file transfer options.\n\n\xe2\x80\xa2 Delete data you don\xe2\x80\x99t need in S3\n- pfe% nas_s3_ls, nas_s3_del\n- aws% nas_s3_ls, nas_se_del\n- #CLOUD \xe2\x80\x93volume_list, -volume_delete\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n17\n\nFlexible and Familiar Environment (Front-End)\n\xe2\x80\xa2 Request an AWS dynamic front-end\n- Use /u/scicon/tools/bin/aws_fe [options] from a PFE\n- Highly recommend adding /u/scicon/tools/bin to your $PATH\n- To request 1 node with 2 hours time\npfe% aws_fe \xe2\x80\x93t 2\nThe front end is booting, when the instance is ready an email will be sent to your NAS email\nwith login instructions.\n- To check the status of your front-end request\npfe% aws_fe \xe2\x80\x93l\nFront End Queued\npfe% aws_fe \xe2\x80\x93l\nenv SSH_AUTH_SOCK="" ssh -i ~/.ssh/id_rsa_yours your_nas_username@iii.jjj.kkk.lll\n- To connect to the front-end node\npfe% env SSH_AUTH_SOCK="" ssh -i ~/.ssh/id_rsa_yours your_nas_username@iii.jjj.kkk.lll\n- To properly terminate the front-end node\npfe% aws_fe \xe2\x80\x93k\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n18\n\nFlexible and Familiar Environment (File Transfer)\n\xe2\x80\xa2 Between PFE and an AWS Dynamic Front-End\n- scp from a PFE\npfe% scp -i ~/.ssh/id_rsa_yours ~/file1 iii.jjj.kkk.lll:/nobackup/your_user_name\n- Set up SUP on AWS and use sup/shift from AWS\naws% sup shiftc pfe21.nas.nasa.gov:~/file1 .\n- Set up SSH passthrough on AWS and use scp from AWS\naws% scp pfe21.nas.nasa.gov:~/file1 .\n\n\xe2\x80\xa2 Between a Front-End and your AWS S3 space (nas_s3_xxx)\n- PFE or an AWS front-end\npfe (or aws)% nas_s3_put file1 /\npfe (or aws)% nas_s3_get /file1\n\n\xe2\x80\xa2 Staging files from Pleiades in a PBS job\n- #CLOUD \xe2\x80\x93stagein_file, -stagein_dir,\n- #CLOUD -stageout_file, -stageout_dir, -stageout_file_del, -stageout_dir_del\n\n\xe2\x80\xa2 Transferring data from/to S3 inside a PBS job\n- Persistent filesystem: #CLOUD \xe2\x80\x93get_file, -get_dir, -put_file, -put_dir\n- Job-time filesystem: #CLOUD \xe2\x80\x93volume_get, -volume_put\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n19\n\nFlexible and Familiar Environment (PBS)\n\xe2\x80\xa2 Sample PBS Script\n#PBS \xe2\x80\x93lselect=1:ncpus=2:mpiprocs=2\n#PBS \xe2\x80\x93lwalltime=2:00:00\n#PBS \xe2\x80\x93q cloud@clpbs-01\n\n(if submitting from PFE, specify this queue)\n\n#PBS \xe2\x80\x93W group_list=xxxxx\n#CLOUD \xe2\x80\x93stagein_file=gridfile\n\n(if you need gridfile to be stagedin)\n\n#CLOUD \xe2\x80\x93volume_type=shared\n\n(both nodes will be able to access this shared filesystem)\n\n#CLOUD \xe2\x80\x93volume_size=10G\n\n(requesting 10 GB for this job-time filesystem)\n\n#CLOUD -volume_mount=/shared_data\n#CLOUD \xe2\x80\x93volume_get=/binary\n\n(assume that your S3:/binary folder has a.out)\n\n#CLOUD \xe2\x80\x93volume_put=/results\n\n(everything under /shared_data will be put to this S3 folder)\n\nmodule load intel-mpi/2019.3.062\ncd $PBS_O_WORKDIR\nmpiexec \xe2\x80\x93np 4 ./a.out > output\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n20\n\nFlexible and Familiar Environment (PBS)\n\xe2\x80\xa2 PBS Commands\n- qsub, qstat, and job-deletion can be done from either PFE or an AWS dynamic\n\nfront-end\npfe% qsub \xe2\x80\x93q cloud@clpbs-01 jobscript\npfe% qstat \xe2\x80\x93a @clpbs-01 or\nqstat -a @`aws_pbs_host` (after job moved)\npfe% aws_qdel jobid\nor\naws% qsub jobscript\naws% qstat -a\naws% qdel jobid\n- PBS output/error files are sent back to your $PBS_O_WORKDIR (PFE/AWS)\n- PBS output file contains job cost summary (see next)\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n21\n\nPer-Job Cost Summary\n____________________________________________________________________\nJob Resource Usage Summary for 3552.clpbs-01.nas.nasa.gov\nTotal Runtime : 00:03:03\nJob Stage In Time (free) : 00:00:00\nJob Startup Time : 00:01:03\nTime Spent In PBS Script : 00:02:00\nJob Stage Out Time : 00:00:00\nWalltime Requested : 02:00:00\nExecution Queue : AWS Cloud\nCharged To : cstaff\nJob Finished : Wed Jul 3 10:38:09 2019\nInstance Types (ondemand): 2 m5.xlarge\nEBS Usage : 8577331200 bytes\nS3 Usage : 0 bytes\nCharged Bandwidth Usage : 0 bytes\nNAS overhead charge : 0.000 percent\nJob Costs : $0.00981639861027\n___________________________________________________________________\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n22\n\nFlexible and Familiar Environment (Accounting)\n\xe2\x80\xa2 HECC accounting tools\n- pfe% acct_ytd \xe2\x80\x93caws\n\nor\n\nacct_ytd \xe2\x80\x93ccloud-all\n\nLinear\nFiscal\nYTD\nProject\nProject Host/Group\nYear\nUsed\n% Used\nLimit\nRemain\nUsage Exp Date\n-------- ------------- ------ ---------- ------- ---------- ---------- ------- -----------cstaff\ncloud\n2019\n19675.517\n39.35 50000.000 30324.483\n48.56\n09/30/19\n\n- pfe% acct_query \xe2\x80\x93caws \xe2\x80\x93u username \xe2\x80\x93b 07/01/2019 \xe2\x80\x93e 07/19/2019\n- pfe% acct_query \xe2\x80\x93ccloud-all \xe2\x80\x93b 07/01/2019 \xe2\x80\x93e 07/19/2019\nPrinting information for all the users supplied.\nREPORT FROM 07/01/19 TO 07/19/19\nACCT_QUERY: Generating data ...\nGRAND TOTAL FOR 07/01/19 TO 07/19/19\nCLIENT\nUSER\nPROJECT\nQUEUE\nSBU Hrs/Cloud BU\n------------ ------------------ ------------------ ---------------- ----------aws\naws\n\nstaff1\nstaff1\n\ncstaff\ncstaff\n\naws\nTOTAL FOR\n\nstaff1\n\ncstaff\naws.cstaff\n\ncloud_exec\ndrc\n\n2.337\n0.000\n\nfrontend\n\n5.821\n8.158\n\nTOTAL FOR ALL PROJECTS FOR CLIENT: aws\nTOTAL FOR PROJECT ON ALL CLOUD: cstaff\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\n8.158\n8.158\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n23\n\nSoftware Stack under /nasa at AWS\n\xe2\x80\xa2 Compilers\n- Intel compilers\n- PGI compilers\n\n\xe2\x80\xa2 MPI\n- Intel MPI\n- OpenMPI\n\n\xe2\x80\xa2 GPU related\n- CUDA\n\n\xe2\x80\xa2 Python (can be installed upon request)\n- Intel Distribution for Python 3\n- Cuda Python\n\nInstall other software packages and bring licenses yourself.\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n24\n\nFor More Information\n\xe2\x80\xa2 PI on-boarding or questions/feedbacks\n- Send email to support@nas.nasa.gov\n\xe2\x80\xa2 AWS Cloud KB (ID: 581 to 596)\n\n-\n\nHECC AWS Cloud Overview\nhttp://www.nas.nasa.gov/hecc/support/kb/entry/581\nHECC AWS Cloud File Transfer Overview\nhttp://www.nas.nasa.gov/hecc/support/kb/entry/582\nCloud Billing Units and Job Accounting\nhttp://www.nas.nasa.gov/hecc/support/kb/entry/596\n\nN A S A\nH i g h\nC o m p u t i n g\nC a p a b i l i t y\n\nE n d\n\nQuestion? Use the Webex chat facility to ask the Host\n\n25\n\n'