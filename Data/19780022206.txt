b'General Disclaimer\nOne or more of the Following Statements may affect this Document\n\nThis document has been reproduced from the best copy furnished by the\norganizational source. It is being released in the interest of making available as\nmuch information as possible.\n\nThis document may contain data, which exceeds the sheet parameters. It was\nfurnished in this condition by the organizational source and is the best copy\navailable.\n\nThis document may contain tone-on-tone or color graphs, charts and/or pictures,\nwhich have been reproduced in black and white.\n\nThis document is paginated as submitted by the original source.\n\nPortions of this document are not fully legible due to the historical nature of some\nof the material. However, it is the best reproduction available from the original\nsubmission.\n\nProduced by the NASA Center for Aerospace Information (CASI)\n\n11^V7.^w , ^aw^a^sa^\xe2\x80\x94\n\n^\t\n\n^ s\n\na\n\nr.\ni\n\n\xc2\xae\t\n\n1i\'e\n\n,y\n\n4 \'i\n\n1\n\nHAMPI ON, Vi\n\nEP 79\'9\t\nn\n\nO\t\n\nPr(,f-,\nw ^^\n\nNASA/AMES RESEARCH CENTER, MOFFETT FIELD, CALIFORNIA\n\nStl tZLl11\n\n.\n\n} f s\n\nEXECUTIVE SMOIARx\nI .^\n\nNASA/ESA CV-990\n!3\n\nSPACELAB SIMULATION\n(ASSESS II)\n\nA Joint Endeavor By\nThe National Aeronautics and Space Administration\n\ny.\n\nand the European Space Agency\n\ns\n\nAPPROVED: B. T. Nolan, NASA OA\t\n\n/ f CCI^ti`\nAPPROVED:\t\n\nde Waard, ESA, SPICE\n\nt\n5\n\n3.\n\nY\n\nOr\n\nL\n\nr\t\n\nF\t\n\nAPPROVED: W. 0. Armstrong, NASA, OSF\n\n`\n\n0 .\ni +\n\n_\n\nJuly 1977\n\nTABLE OF CONTENTS\n1.\t\n\nINTRODUCTION\n\n1\n\n2.\t\n\nTHE ASSESS II PROJECT\n\n2\n\n3.\t\n\nBACKGROUND AND ORGANIZATION\nMission Background\n3.1\n\n3\n3\n\ni\n\n3.2\n\nMission Objectives\n\n3\n\n3.3\n3.4\n\nProject Guidelines\nMission Management\n3.4.1\t Mission Steering Group (MSG)\n3.4.2\t Management Structure and Responsibilities\n3.4.3\t Mission Scientist and Investigator Working Group (IWG)\n3.4.4\t Mission Specialist (M/S)\n3.4.5\t Payload Specialist (P/S)\nFlight Payload\n\n4\n5\n5\n5\n5\n5\n7\n7\n\n\'\n\n3.5\n4.\t\n\n\xc2\xa3.\nf\n_\n5.\t\n\n=A\n\nMISSION IMPLEMENTATION\nGeneral\n4.1\nExperiment Selection and Funding\n4.2\nInvestigator Requirements Document ( IRD)\n4.3\nAnalytical Integration\n4.4\nInvestigator Working Group Activities\n4.5\n4.6\nPayload Specialist / Mission Specialist\nSelection and Training Activities\nIntegration of ESA Payload in Europe\n4.7\nSystem Level Payload Integration (Level IV Integration)\n4.8\nLaunch Site Payload Processing (Level III/II%I Integration)\n4.9\n4.10 Mission Control Center and Payload Operations\nControl Center (MCC and POCC)\n4.11 Conduct of the Flight Mission\n4.12 Use cf Central Data System\n4.13 Documentation\n\n10\n10\n10\n10\n12\n12\n\nEVALUATION AND CONCLUSIONS FOR SPACELAB\nIntroduction\n5.1\nPayload Selection. and Funding\n5.2\n5.2.1\t Payload Selection\n5.2.2\t Payload Funding\nManagement Relations\n5.3\nPre-Flight Planing ar.d Payload Integration\n5.4\n5.4.1\t Investigators` Working Group\n5.4.2\t Investigator Requirements Document (IRD)\n5.4.3\t Analytical Integration\n5.4.4\t Integration of ESA Payload in Europe\n5.4.5\t System level Payload Integration (Level IV)\n5.4.6\t Launch Site Payload Processing (Levels III, II, I)\n5.4.7\t Safety\nPayload Flight Crew\n5.5\nFlight/Ground Operations Interactions\n5.6\nExperiment Hardware Considerations\n5.7\nData Handling\n5.8\nDocumentation\n5.9\n\n24\n24\n25\n25\n26\n27\n29\n29\n29\n31\n31\n31\n32\n34\n35\n39\n40\n41\n42\n\nList of Acronyms\n\n44\n\nReference 1\t\n\n`^\n\n12\n13\n13\n17\n17\n18\n\n20\n21\n\n44\n\na _?\n\n1.\t\n\nINTRODUCTION\n\nThis Executive Summary represents an initial report and briefly\ncovers the highlights of the ASSESS * 7I Project.\t The report is in three\nmain sections.\t The first parts cover factually, without analysis, the\nbackground, project organization, and project implementation. \t These first\nparts are intended to serve as background for the last section which\npresents r esults and brief evaluations of major issues and activities of\nparticular interest in Spacelab planning.\n\n{i\n\nInformation for this report was obtained from the records of a team\n,\nof observers, a general mission debriefing, interviews with p articipants,\nP\t\nP\t\n8 ^\t\n8\t\nand the mission documentation.\t NASA and ESA personnel joined in preparation\nof this report immediately following the close of the mission.\n\n2.\t\n\nTHE ASSESS PROJECT\n\nThe ASSESS II project was a detailed simulation of Spacelab operations\nusing the NASA / Ames Research Center CV-990 aircraft laboratory ( Fig. 1) to\nrepresent the Shuttle carrier and Spacelab pressurized module/pallet\ncombination to carry a complex payload of experiments in a manner similar\nto that planned for the Spacelab era.\t The project was carried out for the\nbenefit of Spacelab planning to identify and analyze cost-effective techniques\nfor addressing management and operational acitivities. \t It was a cooperative\nproject between NASA and ESA with payload and flight responsibilities\nassigned to those organizations which have -Waen given those responsibilities\nfor early Spacelabs.\nThe project covered a period of approximately eighteen months from\ninitial approval to flight, and studied the full range of Spacelab-type\nactivities including.\nManagement interactions\nExperiment selection\nHardware development\nPayload integration and checkout\nMission Specialist (M/S) and Payload Specialist (P/S)\nselection and training\n- Mission Control Center/Payload Operations Control Center\ninteractions with ground and flight problems\n- Real time interaction during flight between Principal\nInvestigators (PIs) and the Mission Specialist/Payload\nSpecialist flight crew\n- Retrieval of scientific data and analysis\n\n-\n\n*\t\n\nASSESS is an acronym for Airborne Science/Spacelab Experiments System\nSimulation.\t A list of other acronyms and abbreviations is given on\npage 44.\n\n\t\t\t\n\ne .\n\nr.l\n\nM+\n\n-%\t\n\na.\n\n2\n\n\t\n\nDRIGINAL PAGE It\nZ)x POOR QUALITT\n\n>I\n\n"y \'^\n\n,y\t\n\n\t\n\ni\t\n\nGl\nL\n\n7\n\nH\n\nd\n00\nC\n>\t\n\neE\n\nC\n\na\nb\n\nLs.\n\nOD\n\nw\n\nw\n\n>\t\nU\n\ni\n\nO\na,\na\n\nd\n\nrl\n\n:J\n\nV\n\nw\nco\n\n.y\n\n1\n\nY\n\ni \xe2\x99\xa6\nIt y\n\ni +.\n\n!i\n\n3. BACKGROUND AND ORGANIZATION\n3.1\t\n\nMission Background\n\nThe ASSESS Program was initiated by the AirborneSeience Office (ASO) at\nNASA/ARC to identify simplified low-cost techniques used by ASO \t in\nintegrating and carrying experiments aboard airborne laboratories which\neight be applied effectively to Spacelab. \t Several ASSESS missions to\nsimulate Spacelab operations were conducted prior to ASSESS II including\none NASA/ESA joint mission aboard the CV-990 in 1975. \t [Ref. 11\n\n=\n\nA decision was reached in late 1975 to conduct ASSESS II as a joint\nmission sponsored by NASA Office of Applications (OA) and Office of Space\nFlight (OSF) together with ESA. \t Operational costs were shared. \t Experiments\nfrom the U.S. were totally funded by NASA, while in Europe the basic\nexperiments were funded nationally with ESA providing funds to interface\nthe experiments into the ASSESS Mission.\t It was agreed to involve planned\nSpacelab management elements to test and evaluate interface activities.\nMSFC was assigned responsibility for the payload and appointed a Mission\nManager, KSC was given responsibility for Launch Site Payload Processing,\nand JSC was assigned Flight Operations--all working closely with ARC where\nthe aircraft was stationed and where the final integration and flight\nphase would be conducted. \t In Europe, their payload responsibility was\nassigned to ESA/SPICE.\nThe mission received final approval in March 1976, and "launch"\noccurred 14 months later on May 16, 1977.\n\n3.2\t\n\nMission Objectives\na)\t\n\nScience related\n- Evaluate experiment selection procedures\n- Evaluate participation of PI in mission planning and\nimplementation, and utilization of an Investigators\'\nWorking Group (IWG) chaired by a Mission Scientist\n- Maximize science data\n\nb)\t\n\nManagement\n- Study proposed NASA and ESA/SPICE Spacelab payload\nmanagement concepts and interface relationships\n- Evaluate Mission Manager, Mission Specialist, and\nPayload Specialist roles in mission planning\nand implementation\n\nc)\t\n\nAnalytical Engineering and Mission Planning\n- Evaluate the methods and effectiveness of performing\nanalytical system engineering, mission flight\ninterface definition, and interface control\n\nd)\t\n\nPayload Specialist Selection and Training\n- Evaluate methodology of Payload Specialist selection\nand training\n- Determine practicability of a PI as a Payload Specialist\n\n_\n\nF\n\n`\n\n3\n\ne) Mission Specialist Selection and Training\n- Evaluate the Mission Specialist responsibilities concerning:\n1)\n2)\n\nrequirements for managing and operating the\nexperiment support equipment\nin-flight coordination and integration of the\npayload operations\n\nf) Ground Operations\n- Identify ground operations and testing requirements for\nefficient experiment integration and checkout\n- Evaluate Mission Specialist, Payload Specialist, and PI\ninvolvement in experiment ground operations\n- D.iderscand and gain an appreciation of integration\nactivities pertinent to Spacelab payloads\ng) Mission Planning and Flight Operations\n- Assess methods and degree of real time experiment/mission\nplanning for Spacelab missions\n- Evaluate concept of proxy operation and maintenance of\nexperiments by P/S during flight operations\n- Evaluate POCC concept and operating procedures\nh) Documentation\n- Develop and evaluate minimum cost documentation approach\nconsistent with Spacelab payload requirements\n\n3.3 Project Guidelines\nMajor\n\nASSESS II\n\nproject guidelines were as follows:\n\n- Maximum Spacelab reality within funding limits and the limitations\ninherent with aircraft operation\n- Ten-day mission with payload crew confined to the aircraft and\ncontiguous living quarters with one aircraft flight planned\nfor each 24-hour period. The total of the aircraft flights\nand confined periods betwe,!n flights to represent a single\nSpacelab mission\n- Payload crew to consist of two European Payload Specialists to\noperate the ESA experiments, two U.S. Payload Specialists to\noperate the NASA experiments, and one Mission Specialist.\nNo cross-training between :NASA and ESA experiments except for\nthe ESA medical experiment involving all Payload Specialists\n- Communications with the ASSESS Spacelab crew to conform to actual\nSpacelab communications procedures as far as practicable.\nCommunication to be established between the ground and the\naircraft throughout flight periods\n- Centralized experiment control panels to be provided in the aircraft\n- The aircraft flight crew (pilot, copilot, navigator) not to be\nincluded in the simulation exercise\n- A few unconstrained personnel (called ghosts) to participate in the\nflights to assure continuous operation of basic aircraft systems\nthat were not designed for operation from the centralized control\npanels\n4\n\n\t\n\n1\t\n\n3.4 Mission Management\n3.4.1 Mission Steering Groue (MSG)\nAn MSG was established at the beginning of the project with representatives\nfrom every major participating organization. The MSG was unique to ASSESS,\nand is not planned for Spacelab. The participating NASA Headquarters\nprogram offices were represented along with MSFC, JSC, KSC, ARC, aad ESA\nHeadquarters and ESA/SPICE. The MSG was cochaired by representatives from\nNASA/OA and ESA/SPICE. Four meetings were held.\nFunctions of the MSG were to provide overall guidance to the simulation\nin order to achieve maximum benefit for Spacelab planning. Accordingly, the\n,\n% G established the mission gu+dellnes and provided an overall managesent\nforum for resolution of inter-center/agency responsibilities.\n\n3.4.2 Management Structure and Responsibilities\nFigure 2 shows the management structure, which with the exception of\nthe MSG, corresponds closely to that planned for early Spacelab missions.\n\n3.4.3 Mission Scientist and Investigator Working Group (IWG)\nA Mission Scientist, along with a Deputy Mission Scientist, were\nappointed by MSFC. ESA also appointed a Mission Scientist from ESTEC.\nAn Investigators\' Working Group (IWG) was established early in the\nASSESS II Project, and was made up of a PI from each experiment. The\nMission Scientist from MSFC chaired the IWG with the ESA Mission Scientist\nas cochairman. Functions of the IWG were to provide a forum for PI\ndiscussion and to make recommendations concerning science plans and\npriorities for the mission. NASA and ESA IWG members provided\nrecommendations to their respective managements for Payload Specialist\nselection. Two meetings were held.\n\n3.4.4 Mission Specialist (M/S)\nThe Mission Specialist, from the scientist astronaut group at JSC,\nwas recommended to the Mission Manager and approved by the Program Manager.\nA second Scientist Astronaut from JSC was appointed to serve as backup.\nThe Mission Specialist was responsible administratively to JSC, but\nfunctionally reported directly to the ASSESS II Mission Manager at MSFC.\nThe role of the Mission Specialist for ASSESS II was established as follows:\n\n`\t\n\n- To act as the in-flight alter ego of the Mission Manag,.r and to\nbe generally responsible for coordination and conduct of\ncombined payload operations during flight\n- To be the single interface between the Payload Specialists and\nSTS flight crew (pilot/copilot)\n- To be responsible for all aircraft experiment-support systems\nsuch as power distribution, central data system, etc.\n5\n\nW\n\nQ\nN\nQ\nZ\n\nv\n\na\n\nW\n\nm\n\nO\n0\n\nQ\n\nQ\nZ\n\ny\n\na\n\nw\n\nQ\n\nz\n\nU\nQ\n\nir\nW\n\ny\n\nW\nZ w\naV\n\nO\n\nULL\nO\n\nH\nH\nW\nH\n\nW\n\nQ\n\n~\n\nm\n:\nZ\n\xe2\x80\x94\n\nW\n\n2\n\nW\nQ\ny\nW\n\nD ji\n\na\n0\n\nN\ncc\nZW\n\na\nZ_\nY\ncc\n\nO\ny\n\nN\nW\nZ\n\n\t\n\nN\nZ\n\nw\n\nX\n\nW\n\n=ac\n\nN^\n\ncc\nW\n\nO\nCC\nQ 0\nC7\n\nCC:)\n\na\n\n7 UA\nW A\nA\nX\nW\n\nCC\n\nQ hwZ\n-----^^_ -- Q UA\n\n-\n\nW}\n\ny0\n\nQ\nCL\n\n90\n\nU z\nQ\n\nZ^\n\nU Q ^j\ny\n\nHZ\n\n740\nQ\nZ OC\nui\nO cc\n\nY ^0\n\nV\t\nv^\n\n^= H\n\n\xe2\x80\xa2 ^\t\n\ns\n\nrI\n\nF\n\nN\n\n<\n\nOu y\n\nt/f 0\n\nWa\n\nrc\n\nN W\n\nQO\nQ\ncc\n\n^\nQ\nZ<\n\na\nO\n\ncc\nCL\n\nH\n\nZ\nO\n\nO Na\n\nLL W\nto H H\n\nac s \xe2\x80\x94\n\nZ\nU F- O\nw\nCL.\nO\n\n^\n\nh WW\n\nd\ny\n\nW\n\nZ\n\na\n\nz\nO\n\nfU\nZ\nW\n\nw\nF-\n\nU\nW\n\nW\n^\n\nti\n\nw\n2\nN\nZ\n\nU\n\n^\n\nZ\n\na\n\na^\n\nu\n\n7\nL\nN\nAi\ny\n\nN\n\n41\nC\n\nv\n\na\n\nQD\n\nH\nH\n\nW\n\nw\n\nco\n\n7\n\nN\n\nOl\n\nN\n\nW\n\nY\n\nd\n\ncn\nm\n\nU\nN\nU\nW\n\nV1\n\nO\n\nW\nH\n\n0\nCL\nCL\n\nD\n\nU\n\ny\ncc\nd\n\ns\n\n\t\n\nt\ni tr\n\nUpon approval of the NASA Program Manager, to be trained to act\nas a Payload Specialist and operate experiments during the\nflight mission\n- To work with the POCC, MCC, Payload Specialists, and Flight\nCommander (Pilot) to solve in-flight problems caused by\nequipment failures and/or flight conditions leading to\nchanges of science priorities\n\n3.4.5 Payload Specialists (PJS)\nNASA selected two P/Ss from JPL. Thirty-three P/S nominations were\nsubmitted, 31 of them from JPL. To reduce training and travel costs, NASA\nassigned the Assistant Mission Manager from MSFC as tae single backup P/S,\nwho thus served a dual role and dividel his time between mission m.&iagement\nactivities and P/S training. ESA selected four P/Ss: one from the University\nof Southampton, one from the ESA Space Science Department, and two from DFVLR.\nA dozen candidates applied. The ESA plan was to appoint two as prime P/Ss\nand two as backup. In reality, ESA decided, with NASA Program Manager\nconcurrence, to change one of the P/Ss during the mission flight period so\nthat three of the ESA P/Ss participated as payload flight crew members.\n\nE\t\n\n\' \xc2\xbb\t\n\nThe Payload bpecialists reported administratively to JPL and ESA\nrespectively. Prior to arrival at Ames, they reported managerially to\nthe MSFC Mission Manager and to the ESA Payload Manager respectively.\nAfter arrival at Ames, they were integrated into the mission management\nteam. In addition to their flight role, they actively participated in\nthe ground operation and test phase.\n\n3.5 Flight Payload\nExperiments selected for the ASSESS II payload are given in the\ntable on the next page.\nSome elements of the payload were considered to be experiment support\ndevices analogous to Spacelab experiment support systems to be operated by\nthe STS organization. These included aircraft provided systems such as\nthe experiment power distribution system, the ADDAS data handling system,\na water vapor overburden radiometer, and two gyrostabilized mirrors.\nv\n\nQ =.\t\n\'`\t\n\nMost equipment was mounted in or on standard CV-990 equipment racks.\nExperiment control functions, except for the IR telescope, were centralized\nin five Spacelab-like racks which were grouped in the forward area of the\naircraft for operation by the Payload Specialists. Figure 3 shows the\npayload in the aircraft including these control racks.\n\nEXPERIMENTS FOR ASSESS II MISSIGN\n\nINSTRUMENTATION\n\nMEASUREMENT\n\nObservatoiie de Paris, Meudon\nFrance; Max Planck Institut,\nGarching, Germany;University\nof Groningen, Netherlands\n\n30-cm open port telescope\nwith TV tracking. IR\nPhotometer and FabryPerot Tilting Filter\nSpeci^rometer\n\nIR line spectroscopy\nand\nIR galactic cold cloud\ntemperatures\n\nUniversity of Southampton,\nEngland\n\nImege intensified\nintegrating TV cameranear IR\n\nOH Airglow -;lave\nstructure\n\nDFVLR-Oberpfaffenhofen,\nInstitut L Physik der\nAtmosphare, Germany\n\nLIDAR (Light Emitting\nDetection and Ranr,Ing)\n\nConcentration of\n\nDFVLR-Bad Godesberg,\nInstitut f. Flugmedizin,\nGermany, and NASA/Ames\n\nPhysiological sensors\n\nP/S med 4 . cal reaction\nto time and stress\nchanges\n\nObservatorio de Capodimonte/\nInstituta de Physica,\nFirenze, Italy\n\nMichelson Interferometer\n-sub mm\n\nChromospheric\ntemperature\n\nESA/ESTEC\n\nEMI measuring equipment\n\nEMI characteristics\nof aircraft systems\nand payload\n\nNASA/JPL\n\nTwo synthetic aperture\nradars - X band and L\nband\n\nRadar terrain mapL\nfor earth resources\nfeajibility study\n\nNASA/JPL\n\nMicrowave limb sounder\n-167 GHz\n\nSpectral lines of\ntrace gases in\natmosphere\n\nNASA /JP\'.\t\n\nLaser Absorption\nSpectrometer \xe2\x80\xa210.6 }gym\n\nAtuvispheric ozone\nconcentration\n\nNASt.,\'[.aRC\t\n\nInfrared heterodyne\nradiometer -10.6 um\n\nAtmospheric ozone\nconcentration\n\nNASA/GSFC\t\n\nSwept and fixed band\nradio receiver.i\nVHF & UHF\n\nMonitoring of\nselected communication\nband usage\n\nORGANIZATION\nESA Experiments\n\n-1 um\n\nscattering aerosols\nin atmosphere\n\nNASA Experiments\n\n8\n\n^I\nP,\n\nA\n\nL. .\n\nFigure 3. Payload with Spacelab-rype Racks in CV-990 Aircraft\n9\n\n4. MISSION IMPLEMENTATION\n4.1 General\nFigure 4, on page 11, shows the overall project schedule. Experiment\npreparation, integration planning, Payload and Mission Specialist selection\nand training at PI facilities, flight plannin,, and other associated\nactivities took place over the first 10 months leading to integration\nof the European experiments at ESA/SPICE in Germany beginning in January\n1977. System Level Payload Integration at ARC started in March, and\nrequired about a month. Launch Site Payload Processing on the aircraft\nalso required a month, and ended in mid-May. The simulated Spacelab\nflight began on May 16, 1977, 14 months after final project approval.\n\n4.2 Experiment Selection and Funding\nEuropean experiments were selected by ESA in April 1976, following\nan Announcement of Opportunity. Funding of these experiments was handled\non a national basis with ESA adding necessary funds to support the activities\npeculiar to the ASSESS II Spacelab simulation.\nNASA/OA decided initially to select experiments from their ongoing\nexperiment program, and a baseline group comprised of five experiments\nwas approved in May 1976. Because of shortness of time, OA emphasized the\nselection of experiment prototypes destined for the Spacelab era that\nhad previously flown on the CV-990 aircraft. It was also recognized that\none or two experiments might have to be dropped from the baseline because\nof development or funding problems. Iterations within NASA/OA delayed\nfull solidification of the NASA payload for several months. Funding was\nfinally distributed in December 1977, except for one experiment (from\nGSFC) which, because of special approval requirements, was not authorized\nand funded until February 4, 1977, the last day Program Management agreed\nto accept the experiment with any chance of success.\n\n4.3 Investigator Requirements Document (IRD)\nThe IRD form was prepared by the MSFC Mission Management staff with\na plan to cover, in a single document, all experiment interfaces for the\nproject from hardware and data interactions through POCC and flight\nrequirements. One IRD form was sent from MSFC to each experimenter,\nfollowed by visits of system engineers from ESA and NASA to each experimenter\nin June and November, 1976. During these visits, the PIs were aEsisted\nin filling in the requested information by the visiting engineers. At\nthe close of these visits, the IRDs had been filled in to the extent\npossible at that time. No further effort was made to complete the IRDs\nafe-r November 1976. Open items still remaining following the second\nrolmd of visits were individually har p ed directly between the Pis and\ncognizant project management personnel.\n\n10\n\n\t\t\t\t\t\t\t\n\nn\nr\no^\n\nQ\xc2\xb0\n\nfa\n\nz\n\n_\n\n`U\t\nJ\t\n\nW\t\n\n\xc2\xb0\t\n^\tQ o\t\n\nw\tC7\t\nU W\t\n\nw W\t\n\nJ\xc2\xb0 W\n\t\n\na U W Z = 2 J O ZE- ta\ni)\t\n\n( C a Z\n\nZ Q w J Z 0 J y\t\n~\t\n>\xc2\xb0 X w z Q z H \t\nJ Z w ^- O tJ w U Q\nj\n\ntq d\t\n\nawF z\n\xc2\xb0\t\n\nr\t\n\nz^\nD\nQ\t\n\nw\na\nQ\n\nQ\n\nco\nW\nLL\n\nZ\nQ\n\nZ\n\nO\nN\t\nQ\n\n^ 7\ntS1 \'\'\n\nG\nQ\n^\nLL\n\n\tO\n\nU. 0 Z\n\nr\n\nz\no\n\nC\nJ z 0 Q\n\nW dS Q\n\nF-\t\n\nI\n\nI\n\nZ\n\nrn ^ Q Q\nQ a\n\n\xc2\xb0\n\nto Q a O\nC7\n\ntQi^\t\n\n-^\t\n\nW\n\na y\n\nU f\' W\n\na ZH V\nQ tnO p Z cc QQ\t\nC5a w FZ\ny H\nV mV a oC ,Q\np 0^ Q Qy z QY to Q Vw Q\n0 cc\nOw Q\nUJ\nQ z0 U (D\n\xc2\xb0\n\xc2\xb0 QJ\n0 2 oC\nQ ^ W w a: CC O O^ OJ uuizt^i > Z\t\nQ in 0 U U >\'\t\n-i\t\nU.\ng CL\t\na\t\n`\na w zz^ w U. 0\n\nW\n\ncri\n\nc!)\n\n7:\ncn\n\nv)\nf\n\n7\nL\n\nx\ni\n\n4.4 Analytical Integration\nTwo formal analytical integration efforts were conducted at MSFC\nin July and December, 1976, utilizing information from the IRDs. The\nfirst session was organized into three basic groups to address Giound\nOperations, Flight Operations, and Payload Configuration. Many details\nwere not available at that time, which permitted only gross planning in\nseveral areas. The initial look at flight operations did establish that\nit was possible to meet nearly all experiment objectives.\nThe second analytical integration at MSFC updated flight plans,\narrangements for the POCK, and the aircraft configuration. Continuing\nchanges in experiment configuration and coordination of data interfaces\nwere handled by telephone a:zd letter directly with ARC. Flight planning\nwas iterated among MSFC, JSC, and ARC throughout the pre-flight period.\n4.5 Investigator Working Group Activities\nTwo meetings of the Investigator Working Group (IWG) were convened\nimmediately following each formal analytical integration activity in July\nand December, 1976. The IWG identified complementary science objectives\nand negotiated science scheduling and target allocations for flight\nplanning. Analytical engineering results, mission plans, and schedules\nwere presented to the IWG for discussion and iteration. The IWG also\nmade recommendations regarding P/S selection.\n4.6 Payload Specialist/Mission Specialist Selection and Training Activities\nEuropean P/S candidates were submitted by the participating PI organizations, DFVLR, and ESA. Screening tests were conducted on candidates for\nESA by the DFVLR Institute of Aviation Medicine and the Lufthansa Medical\nOffice for Flight Personnel. These tests were based on criteria for airline\nflight engineers. Using the results, ESA management, with recommendation\nfrom the European IWG members, selected four P/Ss to participate in\nASSESS Il--two to be later designated as prime, and two as backup.\nIn the U.S., the single P/S nominations from GSFC and LaRC were\nwithdrawn, leaving 31 from JPL, wheie laboratory-wide advertisement had\nbeen conducted. JPL narrowed their nominations to two candidates who\nme* the payload operator requriements issued by MSFC. The Assistant\nMission 11unager from MSFC was designated to serve as the sole backup\nP/S for U.S. experiments to save training and travel costs. These\nthree were accepted by the IWG and mission management.\nP/S training generally consisted of about one week of classroom-type\ntraining with each PI plus an additional two weeks of hands-on training\nwith the experiment equipment at the PI laboratory. For secondary experiment\nassignments, they received only about one week of hands-on training at the\nit laboratory. This hands-on training varied, since the schedule uf single\nvisits to the PI laboratories found the experimenter equipment in widely\nvarying degrees of completion. The M/S did not visit the PI laboratories,\nbut he did observe and train on aircraft experiment support systems on\nearlier CV-990 flights. Also, the U.S. P/Ss and the M/S participated in\nsome of the analytical integration process at MSFC.\n"\t\n\n12\n\nFurther valuable training occurred during P/S and M/S participation\nin the payload integration process.\t The ESA P/Ss and the M/S (pact-time)\nparticipated at SPICE in Europe in the ESA/SPICE integration and\nsimulated mission operation of the European installed instruments. \t All\nP/Ss and the M/S participated (both interface and payload operation) in\nSystem Level Payload Integration and Launch Site Payload Processing at\nARC.\t During this period, the NASA P/Ss received their training on the\nmedical equipment.\n\nt\n!\n\nT\n4\'-_\n\n4.7\t\n\nIntegration of ESA Payload in Europe\n\nESA brought all European experiments together at ESA/SPICE\n(Porz-Wahn, Germany) for centralized integration of their portion of\nthe payload.\t Activities at this centralized site during the period from\nJanuary 15 to March 15, 1977, included:\n-\n\n_\n\nCompletion of experiment development and integration\nESA acceptance testing\nEMI characterization and corrective action where necessary\nFlightworthiness verification\nDevelopment and integration of experiment software\nExperiment integration on system level\nInterexperiment compatibility testing\nMission Simulations\nTraining of flight and ground support personnel\n\nAs part of the ESA integration activities, a CV-990 mockup was\nconstructed (Fig. 5) with DFVLR support. Features of this mockup\nincluded flight crew living quarters and power and data handling\nsupport systems. In addition, a remote POCC was provided.\nThe integration activities were performed under ESA management by\nPI teams and the P/Ss, supported by DFVLR technicians.\t Further support\nwas provided by an ARC safety engineer and a contract data processing\nengineer.\t ESA management involved in this integration were also very\nactive in the later phases of the project at ARC. \t Experiment hardware\nwas upgraded where necessary to meet flight standards, European payload\nlevel P/S training was completed, and operational timelines and procedures\nwere exercised and consolidated.\t In addition, the interaction between\nthe payload flight crew and the PIs on the "ground" was developed and\npracticed during simulated flights.\nr~\n4.8\t\n\n\'-\n\nSystem Level Payload Integration (Level IV Integration)\n\nSystem Level Payload Integration was the initial payload activity\nat ARC and accomplished total hardware and software integration with the\n"Spacelab" interface elements.\t This was the first time the entire payload\ncame together.\t Both NASA and ESA provided compatibility and mission\nsimulation testing and payload crew integrated training.\t The integration\nwas performed using a combined NASA/ESA checkout team under the direction\nof the MSFC Ground Operations Manager with full participation of the PIs\nalong with the P/Ss and the M/S. \t This approach was analogous to the MSFC plan\nfor system level payload integration of the Spacelab I payload.\n13\n\n\t\n\n`\t\n\n_\t\n\nSystem Level Payload Integration was performed on the hangar floor\n(independent from the aircraft) using a Payload Checkout Unit (PCU) to\nsimulate the onboard interfaces with experiments. Figure 6 shows a\nphotograph of the integration layout. The experiments and associated\ncabling were arranged approximately like the planned flight configuration.\nThe PCU fed simulated carrier housekeeping signals to the experiments and\nalso interfaced data outputs planned for data handling on the aircraft.\nPrincipal activities included:\n- Experiment preparation by the experimenter\n- Physical/electrical integration with the PCU\n- Experiment checkouts, calibrations, alignments,\nand software verification\n- Experiment/PCU functional and compatibility tests\n- A Simulated Mission Sequence Test\n- Flightworthiness verification\nPrior to experiment connection to the PCU for initiation of checkout,\neach PI listed his instrument status with identification of all known\nproblems.\nU. S. experiments were sequentially integrated upon delivery during\na 10-day period. European experiments, which had been through an integration\nand operation sequence at ESA/SPICE, were delivered together and were\nintegrated as a group within a short period (4 days). Combined NASA and\nESA experiment integration and testing required an additionl 13-g weeks.\nExperimenters and their staffs, along with the P/Ss and ARC technicians,\nperformed hardware and cable installation of the experiments. Integration\nactivities were conducted using MSFC system checkout procedures which\nincorporated individual PI generated experiment test sequences. MSFC\nimposed a uniform work control system for all integration activities of\nthe payload checkout team which had the following features: identification\nof problems, authorization and scheduling of all test and problem solving\nactivities, certification of all tests and problem corrections, and a\ncomplete log of open and closed items. After an experiment was integrated\nwith the PCU, the PI worked on his experiment as required using the work\ncontrol system. The PIs were requested to keep a log book to record\nactivities and changes in their hardware.\nThe schedule was closely tracked using daily meetings to identify\nopen items and to schedule all activities. Single shift operation was\nplanned, but extensive calibrations (not previously requested by the PIs\nfor system integration) combined with experiment and data interface\nproblems, necessitated daily overtime and weekend operations.\nAt the end of this integration task, MSFC, supported by each\nexperimenter and ESA management, certified the payload to KSC with\nidentification of equipment status and all open items.\n\n14\n\na\n\n+ r\n\n}\n\n/I\n\nO Y P\xe2\x96\xbaL Q AGE ^\n^\niL aV ALITY\n\nst\n\n-0 \\ {\n\n15\n\nI\n\n\xe2\x80\xa2\t ^\n\nd\n\nW\nU\nH\nN\n\nL\n\nW\nQ\n\n(b\n\nU\nO\nz\nO\nO,\n\nV\nV4\n\nO\n\n.b\nO\n\nco\na\n\nd\n\nW\n\ncn\n\nQ)\n\n00\n\nH\na\n\nw\n\nK.,\n\ni\n\ni\n\nFigure 6\nPayload Integration and Checkout Area at Ames\nPAGE\n\n16\t\n\n1S\n\nDrk ^R gU U.iTY\n\nF.\n4.9 Launch Site Payload Processing (Level III/II/I Integration)\nLaunch Site Payload Processing was managed by KSC and involved\ninstallation and checkout of the payload in the aircraft, preparatory\nfor flight. Activities included: experiment installation,\nexperiment/aircraft interface verification, experiment testing and\ncalibration, compatibility test, mission sequence test, an all-up\nIntegrated Mission Simulation, and final preparation for launch. The\nentire process was completed during a four-week period by a team composed\nof KSC, ARC, MSFC, the M/S, P/Ss, and experimenter personnel.\nExperiment installation was completed during the first two weeks and\ninvolved a number of changes due to incomplete analytical integration\ninformation and several changes in PI requirements. These changes were for\nincreased testing and calibration on board the aircraft which were beyond the\nrequirements initially identified in the IRDs, and they were approved to\nmaximize the science return. A single-shift schedule, similar to the Level IV\nintegration plan, was planned for launch site processing, but daily and weekend\novertime work was required to maintain the schedule and meet the flight date.\n\n}\t\n!.r\t\nt\t\n3\t\n\nSignificant features of the activity on board the aircraft were the\nconsiderable amount of experimental testing found to be necessary to insure\nachievement of payload objectives and the large number of hardware and\nsoftware problems encountered during experiment operations.\n;U1 onboard activities were conducted under a uniform work control\nsystem in tditch all tasks were planned, scheduled, and documented. The P/Ss\nrepresented the PI and were responsible for experiment integration, testing,\ntroubleshooting and repair, with the PI being called in when necessary. The\nresponsibility for any work internal to an experiment remained with the\nexperimenter. A formal stowage list was prepared, including a flight data\nfile, tools, test equipment, materials, and spare parts. All items were\nplaced aboard the aircraft similar to preparation for space flight.\nAn Integrated Mission Simulation was carried out on May 5 and 6 as\na final checkout and training exercise. This was a full-up dress rehearsal\ncovering a continuous 31-hour period and involved the payload crew (in\nconfinement), the PIs, the MCC/POCC staffs, and managen.snt personnel.\nAt the coc.pletioh of launch site processing, a Flight Readiness Review\nwas held at which KSC certified to the Mission Manager that all payload\nrequirements had been completed ready for launch.\n\n4.10 Mission Control Center and Payload Operations Control Center (MCC and POCC)\n\n`\t\n\nAn MCC was established at Ames and was operated by JSC, with support\nfrom ARC, to manage aircraft flight operations. An MCC Flight Operations\nDirector from JSC was in charge of flight planning activity and real-time\ncommunications with the aircraft flight crew relative to implementation of\nthe flight plans or any changes dictated by flight constraints of payload\nrequirements. The MCC and its operation were a very abbreviated\nrepresentation of that planned at JSC for the more complex arrangement\nfor interaction with Shuttle.\n17\n\ni\n\n\t\n\nThe POCC at Ames was organized and operated by MSFC is a manner\nsimilar to their plans for Spacelab 1. They staffed the PCCC with a\nPayload Operations Director, a Payload Activity Planner, and an operations\nCoordinator, along with the Mission Scientist and a representative from\neach experiment. Voice communications were provided to maintain contact\nthroughout the flight mission asioig all elements of the POCC. with the\npayload crew, and the MCC. The only additional communication links were\na video downlink and a text uplink similar to the system planned for early\nSpacelab flights and operated by the MCC. in the POCC, the Mission\nScientist coordinated the PI science requirements and science communications\nwith POCC management and the payload flight crew. Additional separate\nfacilities were provided close to the POCC operations area for PI conferences\nand data analysis.\n\n`\t\n\nPOCC operations consisted of:\n- Updated payload Planning on a daily basis\n- Briefing of the payload flight crew for each day\'s activities\n- Communications with the payload crew to address problem areas\nand coordinate decisions with the payload crew\n- Daily operations debriefing\n- Quick-look scientific data analysis by the ?Is\n.9\n4.11 Conduct of the Flight Mission\nNine aircraft flights (data-take periods), totaling 53 flight hours\nin nine successive days, were carried out to represent a single Spacelab\nmission. The M/S and four P/Ss were fully confined to the aircraft and\nliving quarters throughout the entire period. Preestablished timelines\nfor P/S preparation and operation of experiments were used as baselines\nfor pre-data-take periods and data-taking operat:.oas of the payload.\nDaily briefings and debriefings were conducted before and after data-take\nperiods from the MCC for flight operations and from the POCC for payload\noperations. As the flight proceeded, payload problems and flight\nconditions necessitated real time changes from the preplanned experiment\nobjectives tracks and changes of plans for given experiment observation\nperiods. Communication was possible with the paylaod crew during data-take\nas well as the ground based periods. Communication was generally poor\nover the HF radio system during aircraft flights. The M/S coordinated\ncommunications to and from the payload crew. Communication blackout\nperiods were scheduled into the overall timeline to represent Spacelab\ncommunications blackout periods.\n\nz\t\n\nGenerally most experiments produced good data, but many real-time\nproblems occurred and were addressed by onboard and ground based\npersonnel, which resulted in varying degrees of correction and several\nalterations of flight plans. Approximate flight data-take time and the\nmajor problems for each experiment were as follows:\nty\n\n18\n\ni\n\n-\t\n\nIR Astronomy - 45 hours \t\n\n- Misalignment of optics caused large\noffset signal - P/S minimized at\nexpense of sensitivity, but did\nnot eliminate.\n- Pump failure - P/S timeshared pump\nfrom another experiment and\nlater repaired it.\n- Computer program problems (occasional).\nP/S switched to manual mode.\n\nr\n\nAirglow - 35 hours\t\n\n- One camera out of alignment\nelectronically. P/S attempted\nadjustment at length without\nsuccess.\n- Tape recorder jammed - P/S oiled\npart and restarted.\n\nIHR - 46 hours\t\n\n- Reference channel weak throughout\nmission. Not fixed - degraded data.\n- Optics left in wrong position for one\ndata-take period. Finally reset\n(10% data time lost).\n\nLAS - 46 hours\t\n\nf\n\na_\n\n- Low sensitivity throughout mission.\nP/S realigned and effected some\nimprovement.\n\nLIDAR - 46 hours\t\n\n- Blown fuse prevented signal detection.\nData lost for one data-take period.\nP/S replaced fuse. ( 10% data time\nlost). Data link to ADDAS occasionally\nmalfunctioned. Corrective procedure\nemployed by P/S.\n\n- One of the tape recorders failed Medical - 53 hours\t\nP/S replaced it with onboard spare (data also taken throughout\t\nlittle data loss.\nnon-flight periods) \t\n\n^Y\n4\n\n19\n\nL\n\nSAR - 41 hours\t\n\n- Inoperative optical recorders (2)\n(basic grounding problem) - lost all\ndata first four data-take periods.\nExperiment declared failure for the\nmission. PI than fixed the recorders\n(outside mission constraints) for\nlast five data-take periods (45%\ndata time lost).\n\nAELS - 53 hours\t\n\n- Persistent EMI throughout mission on\none receiver - P/S could not identify\nfix. PI fixed after constrained\nmission. Noise generator failed\noccasionally - reduced calibration\naccuracy. (P/S restored operation).\nSecondary chart recorder failed reconnected to spare channels of\nM.S recorder.\n\nMLS - 46 hours\t\n\n- Automatic mode chosen by PI for P/S\noperation caused low signal output.\nPI recognized problem - P/S not asked\nto change made as he was not trained\nin manual mode. PI improved after\nconstrained mission.\n\nCapodimonte - 46 hours\t\n\n- Amplifier failed - P/S replaced with\nspare. Operated with degraded\ndata for one data :ake period.\n\nEMI - 53 hours\t\n\n- Loose electrical connector. Fixed by\nnon-flight personnel after first\ndata-take period. No data lost.\n\n4.12 Use of Central Data System\nEight of the ten instruments were designed to interface with the central\ndata handling system (ADDAS).\nThe experiment/ ADDAS interface data handling Sophistication varied\nfrom simple use of ADDAS only to obtain housekeeping data (which was\nrecorded by ADDAS for the entire mission), to onboard interaction with\nADDAS for experiment calibration, and, in some cases, limited data\nreduction using the ADDAS system. Some experiments had their own\nmicroprocessors. Three experiments had flown before on the CV-990. so\nthat their data system interfacing problems were reduced.\n\n20\n\nTwo of the ESA experiments encountered significant problems in interfacing\nand operating with the ADDAS system. One problem was due to a complex timing\ninconsistency which, in fact, was not.completely solved until the third\ndata-take period. The other problem was due to an experiment hardware\ninterface design incompatibility that required inordinate effort through\nexperiment testing, Level IV integration, and launch site processing, but\nwas fully solved just before flight. Both experiments correctly functioned\nafter problem resolution, and no significant degradation in science return\nwas experienced.\nBoth experiment software development and integration were, in general,\nperformed by specialized ADDAS data system engineers working very closely\nwith PIs for definition of requirements and experiment interfaces.\n\ni\n\nData tapes from ADDAS plus some selected records directly from experiments\nwere carried off the aircraft daily to simulate the Spacelab payload data downlink.\nLimited processing facilities were provided in conjunction with the PCCC, along\nwith some PI furnished data processing equipment, to permit the PI to evaluate\nthe condition of the experiment and request any changes in flight plan or\nexperiment operation resulting from quick-look results.\n\n4.13 Documentation\n\ni\nt\nt\ni\nt\n\nA special objective of the ASSESS II mission was to simplify procedures\nand minimize the amount of paper work necessary to accomplish the mission,\nconsistent with plans for Spacelab. These criteria led to significant\ndiscussion in the Mission Steering Group and a Baseline Documentation and\nInformation Flow for ASSESS II issued by the MSG about 10 months before\nflight. That plan is shown in Figure 7.\nThe actual documents issued by the various participants and used in the\nmission are given below. Top level inter-agency agreements between NASA and\nESA Headquarters documents are not included since they were ASSESS unique and\nnot applicable to Spacelab. Also, the ESA documentation used for the ESA\npayload integration and checkout in Europe is not included. The documentation\nis divided into three classes as follows:\nCLASS A Reference documents - not mission unique\nCLASS B Mission management documents - interfacing documents\nwhich would be reissued for each mission\nCLASS C Mission implementation documents - internal working\ndocuments within a given organization\n\nMSFC Documents\nCLASS A)\n-\n\nT\n\nI1\n\nPOCC Requirements\nPOCC Operations Handbook\nPOCC Operations Implementation Procedures\nGround Operations Reference Document\n21\n\nlw\xe2\x80\x94:\n\nCA\n\nN\n\nY\n\nY/\n\n^a\nUJ\n\na\n\nQ\n\ncl^^\n\nQ W\n\n&I\n\n_N\n\nm= m= w M M= M= M= w= M= M\n\nH\nH\nW\nE\n\nO\nw\n\n3\n0\n0\n\nc\n\nL\nJ\nw\n\nG\nc\n\nG\n\nL\n\n4J\n\nJ\nE\n\nJ\nC\n\nO\nC\n\nU\n\nL6\n\n^J\n\nv:\n\nQ\n\na\n\nx\n\n^Z\nO\n\nV Z\nLL Q\nN\n\nW\n\nmmmmmmmmm\n\nJ\n\na\n0\n\ni\n\nCLASS B)\n\ni\n\ni\n\ni\n\n- Investigator Requirements Documents (one per experisent)\n- Payload Level IV and Launch Site Ground Operations\nRequirements Document\n- Payload Flight Definition Requirements Document\n- Payload Operator requirements and Preliminary\nTraining Plan\n- Payload Specialists Training Implementation Document\n- Level IV Integration Implementation Document\n- Payload Mission Rules\n- Payload Configuration Drawing\n- Experiment Installation Sketches (Mechanical)\n- Experiment Installation Cable Interconnect\nCLASS C)\n\ni\n\n-\n\nData Requirements Document\nPayload Flight Data File\nDetailed Payload Crew Activity Plans\nPayload Stowage List\n\nLevel IV Detailed Documents\nr\n-\n\nInvestigator Log (oue per experiment)\nDiagrams and Procedures\nPayload Procedures\nProblem Reports\nTest Preparation Sheets\nDiscrepancy Report Tags\n\nPOCC Documentation for each Flight\n- Director\'s Log\n- Payload Planner\'s Log\nCommunicator\'s Log\nFinal Flight Plans\nScience Plan Chart\n= POCC Operations Timeline\n- Payload Crew Timelines\n- Data Slice Requests (one per experiment as required)\n- Data Terminal Time Assignment\nRecord of Data Offloaded from Aircraft\n- As Flown Data Logs (postflight)\n- Science Summary Report (postflight)\nt\n\nL\n\nKSC Documents\n`\t\n\nCLASS A)\n- Launch Site Integration Implementation Plan (Part A)\n\n23\n\nCLASS B)\n- Launch Site Integration Implementation Plan (Part B)\n- Operation and Malatenance Instruction\nCLASS C)\n-\n\nProblem Report\nDiscrepancy Report Tag\nEngineering Change Notice\nLaunch Site Requirements Change Notice\nTest Preparation Sheet\n\nJSC Documents\nCLASS A)\n- STS Rules\n- MCC Console Handbook\nCLASS B)\n-\n\nMission Implementation Plan\nIntegrated Summary Crew Activity Plan\nCV-990 Daily Might Plans\nFlight Support Work Schedules\nIntegrated Mission Simulation Plan\nData Retrieval Log\n\nCLASS C)\n- MCC Console Log\n\n5. EVALUATION AND CONCLUSIONS FOR SPACELAB\n\n5.1 Introduction\nThe ASSESS II mission was very successful as a simulation of Spacelab\ninterfaces and activities. Management interfaces were exercised among\nexperimenters and the ESA and NASA organizations to be tnvolved in Spacelab.\nThe gamut of activities to bring experimenters througL development,\nintegration into a payload, and through flight operation and data retrieval\nwith active PI participation and an operating POCC and MCC was thoroughly\nexperienced. An M/S and Y/Ss were selected and trained, and performed\nsatisfactorily in flight. The entire exercise was regarded by all\nparticipants as excellent and valuable training for future Spacelab\noperations. Some anticipated Spacelab activities were exercised extensively;\nothers less so due mainly to funding limitations, particularly in the U.S.,\nand aircraft system constraints. Also, it is important to point out that\nall parties were working to extremely tight schedules that forced some\npreliminary work to be done in parallel and some data to be late. No one\nhad the option of adding additional manpower or funding to overcome the data\nand schedule problems.\n24\n\nIt is not the purpose of this report to address scientific results,\nbut a very general evaluation of the quality and quantity of scientific\ndata is given for completeness. The data obtained from the experiments\nwas of satisfactory quality in the majority of cases, and the ratio of\ndata achieved to data expected was also good. The fact that the payload\nwas interdisciplinary dictated that flight periods had to be prioritized\nbecause flight conditions were not conducive to data retrieval from all\nexperiments at the same time. A first look at the results is summarized\nbelow:\n\nj\t\n\nLIDAR (Germany) - Good quality data in majority of the data periods.\nIRA (France, Germany, The Netherlands) - New maps of several prime sources\nwith good data on main targets.\nLAS (U.S.) - Ozone detections were made only near end of mission.\nIRR (U.S.) - Data not yet evaluated, but appears satisfactory.\nAIRGLOW (England) - Good looking sky pictures for most data periods.\nMLS (U.S.) - Data in all data periods, but sensitivity very low.\nAEES (U.S.) - Data during all data periods, but partly masked by\nfrequent electromagnetic interference in some receiver frequencies.\nSAR (U.S.) - Ground mapping with L-band system during later data periods\nafter PI was allowed to violate simulation rules and correct a\ncritical physical integration error.\nCAPO (Italy) - Solar and atmospheric data satisfactorily taken during\nmost of data periods.\nMEDICAL - (Germany) - Excellent data throughout mission.\nEMI (ESA) - An engineering experiment that identified good approaches to\neliminate or ree.-,ce EMI and also proved extremely valuable as\ntroubleshooting apparatus.\n\n\'\t\n\nThe follow. -g conclusions for Spacelab were synthesized from the\nproject and are i _lowed % q each case by a brief analysis.\n5.2 Payload Selection and Fun^^ng\n5.2.1 Payload Selection\n\n(a)\n\nCompatibility of payload scientific discipline requirements simplifies\npayload planning and mission implementation.\n\nFor ASSESS II, a variety of s--.ientific objectives required a wide\nvariety of targets and tines of observation, involving both day and night\nobservation perioO,. With this mix of L. . periments, there was no possibility\nof operating all experiments efficiently at all times. Flight planning was\nseriously complicated by the mix of objectives, and experiment operations\nwere necessarily compromised. Although or Spacel pb it may be necessary\nin many cases to carry interdisciplinary payload , similar scientific\nobjectives will permit more simplified flight pianning, increase efficiency\nof experiment operations, reduce scope of crew training, and should be\nexpected to yield more usable data for an overall mission.\n\nY^\n\n25\n\n(b) Payload complement can be formed by selecting from ongoing experiment\ndevelopment programs or existing instrumentation.\n\nOA avoided the use of an Announcement of Opportunity for generating\nits payload complement for ASSESS II because of the limited time available\nand lack of funding to support proposals. Instead, in June 1976, OA\nidentified payload candidates among various disciplines that were planned\nfor future Spacelab missions and for which early prototype tests were\nbeing conducted with the CV-990. The five OA experiments flown on ASSESS II\nwere selected by this method. In view of planned Spacelab/Shuttle launch\nrates in the mid 1980s, this selection method could be used with "discipline"\nAnnouncements of Opportunity used to secure proposals without regard to a\nspecific mission (e.g., Spacelab I, etc.). Although ESA used an Announcement\nof Opportunity, all the experimentF they selected were in some stage of\ndevelopment, which also supports the conclusion.\n\n5.2.2 Pffload Funding\nThe following conclusions arise particularly from experience with\nthe NASA experiments on ASSESS II.\n\n(a)\n\nTimely authorization and funding of the payload is mandatory to avoid\nserious impact on mission definition and resultant compromise of\nscientific return. Analysis of payload funding schedules is of equal\nimportance to payload analytical integration.\n\nDelay in distribution of funds, and authorization for one U.S.\nexperiment, delayed configuration, interface definition, data processing\nsoftware, and construction of experiment support hardware. These difficulties\nwere reflected throughout the whole chain of participating organizations.\nThe resultant extremely tight schedule for the one experiment necessitated\npremium time costs, caused equipment failures, and lost scientific data.\n\n(b)\n\nFunding deficiencies and multiple funding channels must be avoided to\nprevent compromising payload elements.\n\nThe selection of five experiments comprising the baseline OA payload\nwes made by the NASA HQ OA "discipline" program offices having management\ncognizance. Funding for hardware was available for all but one experiment,\nbut was not adequate for integration and data analysis. Reprogramming from\nother funding sources caused delays in getting funds distributed. There\nwas no central control authority established in NASA Headquarters (and,\ntherefore, none at the mission management level) to work these problems.\nMultiple authorities over funding resulted in on-again-off-again\ndecisions. One experiment was dropped for lack of funding, only to\nreappear later when reprogramming actions were taken.\n\n26\n\nr\nt\nE\nE\nE\n\nFunding allocations should cover all required integration and mission\noperations support in addition to hardware development and data anlysis.\n\nInsufficient effort was made to budget for integration and support\nactivities by experimenters. The analytical integration effort, in\nparticular, was insufficiently supported, with resultant detriment to\nmission planning, integration, and checkout. Several experimenters\nwere limited by travel fund restrictions to a lower level of personal\nsupport than was necessary to do a minima\' proper job.\n\n5.3 Management Relations\n(a\n\nThe Mission Steering Group (MSG) proved an effective forum for solving\ninterface problems and exchanging views and philosophies on the conduct\nof the mission. ESA suggests that a similar multiorganizational group\nbe used to oversee all joint Spacelab missions.\n\nThe Mission Steering Group was established for ASSESS II specifically\nto guide the mission and establish ground rules for the simulation in order\nto maximize results for Spacelab. As the mission progressed, the MSG, with\nkey representatives from all of the participating organizations, became a\nforum for addressing basic mission problems. ESA, particularly, believes\nsuch a body would serve a useful purpose in the same manner for Spacelab\nmissions in which they are involved; NASA feels that such a body conflicts\nwith its direct management responsibility, particularly the Mission Manager\nrole, and does not agree that this approach is appropriate or required\nfor Spacelab.\n\n(b) Mission Manager concept appears sound, but adequate :staffing is essential\nand further development of the concept is necessary to insure efficient\ncoverage of all program aspects.\n\nImplementation of the ASSESS II project under an MSFC Mission Manager\nworked well and could be implemented at any organization given responsibility\nfor a payload. However, the Mission Manager must have adequate resources to\nfully organize the payload, identify and track all payload interfaces, conduct\nmeaningful analytical integration, identify payload requirements to STS, and\nplan and staff the POCC during flight operations.\n\nF\n\nThe engineering support provided was not adequate to properly handle\nthe Investigator Requirements Documents and the analytical integration of\nphysical, electrical, and data experiment interfaces. The result substantially\naltered an initial objective to implement the procedures proposed for Spacelab,\nand caused these areas of effort to be handled on an informal basis between\nthe experimenters and ARC. However, there is reason to believe that additional\nanalytical integration effort plus more effort to maintain current understandings\nof the experiment interfaces as the mission progresses toward flight would\neliminate these difficulties.\n\n27\n\nThe ESA/SPICE Mission Manager served as the single interface to the\nMSFC Mission Manager for the European experiments and also managed integration\nand operation of the ESA portion of the pa^, load in Europe. KSC representatives\nin particular observed that the single interface of the ESA/SPICE Manager\nfor the European experiments worked very smoothly and efficiently.\n\n(c)\n\nManagement must clearly inform all participants early in the mission as to\nroles and responsibilities.\n\nIt is essential that an early, deliberate effort be made by program\nand mission management to inform all prime participants as to various roles\nand responsibilities and the management paths required to obtain optimal\nresults, particularly for such complex management arrangements as existed\nfor ASSESS II and are planned for some Spacelab missions. The STS role, and\nits relationship to other implementing centers, was not clearly defined by\nNASA Headquarters at the outset of ASSESS II. Interviews with many\nparticipants late in the ASSESS project revealed that they had only\nsketchy ideas as to the responsibilities of various organizations and\nof their relationships with them.\nASSESS II was an initial trial for the Mission Manager concept for\nSpacelab and, in spite of early attempts to inform participants as to\nvarious roles and responsibilities, some modes of operation developed as\nthe mission progressed. Some Payload Specialists and the Mission Specialist\nbecame involved well after the beginning. The Mission Manager at MSFC was\nchanged in January 1977 to put all Office of Applications missions into one\noffice. Continuity of effort and early complete identification of all\nparticipants\' responsibilities are required for full understanding and\nmost effective operation.\n(d)\n\nParticipation by the PIs throughout the mission planning and implementation\nphases can enhance overall mission understanding (by both management and\nuser) and thereby improve science return. PIs must recognize their\nleadership position concerning their experiments.\n\nIn ASSESS II, each PI and/or his staff participated directly in IRD\nactivity, IWG meetings, System Level Payload Integration, and the real time\nflight operations through the POCC. In addition, access to his equipment\nwas relatively easy during Launch Site Payload Processing if he had such a\nneed. The PIs were pleased with their degree of involvement. The only\nconcerns expressed by them were a lack of feedback from the IRD submittals\nso they would know what commitments had been made, and a desire for an\nopportunity for greater science exchange during IWG actions.\nThe degree of responsibility by the PI for integrated tests, P/S\ntraining and operational procedures, and support of all mission operations\nwith a sufficient and effective PI support team must be realized and\nfully supported by the PI.\n\n28\n\n5.4\n\nPre-Flight Planning and Payload Integration\n5.4.1\n\n(a)\n\nInvestigators\' Working Group (IWG)\n\nThe IWG can be a satisfactory forum for scientific inputs and a valuable\nchannel for management / PI information flow.\nOn ASSESS II, the IWG concept was not fully exercised. The IWG met\ntwice during ASSESS II, but the meetings, especially the second, were not\nwell attended due mainly to lack of travel funds for Pis. This problem\nmade transatlantic travel out of the question, and even meetings of the\nEuropean half-IWG, or the O.S. half-IWG difficult. Within this severe\nconstraint, the IWG had the following beneficial results: - Evolution\nof a cooperative experiment between two PIs; inputs to Payload Specialist\nselection; transfer of information about the aircraft and the data handling\nsystem; and contributions to mission planning. With more extensive use of\nthe IWG, all of these functions can be better exercised for Spacelab. In\naddition, early IWG meetings with management can be used to inform the Pis\nof mission plans, and iterate the integration requirements. The IWG, under\ncharimanship of_the Mission Scientist, can be an effective body for nominating\npayload specialits.\n\nF-V\t\n\n(b)\n\nF11\n\nThe Mission Scientist (and any IWG cochairman or vice-chairman) needs to\nhave clearly defined responsibilities, full support by the PIs, and be\nprovided with a management overview.\nThe Mission Scientist served a key role in planning and execution of\nscience activity and provided focus of science requirements and science\ntradeoffs to the Mission Manager. His effectiveness in performing this role\nwas variable depending upon the degree to which all other participants\nrecognized the requirement for his analysis of all science considerations.\nHe worked with planners for flight operations to present the science case\nto mission management. This mode of operation was very effective. During\nflight operations, the NASA and ESA Mission Scientists were very successful\nin coordinating and managing PI activities. The \'mission Scientist must be\nstrong in his own right to promote and defend payload needs in the face of\nproject implementation processes.\n\n5.4.2 Investigator Requirements Document (IRD)\n\n(a)\n\n^r\n\nA single requirements document interfacing with each PI is desirable and\nFace-to-face discussions with the participation of disciplinary\nfeasible.\t\nexperts are necessary to clarify interfaces. These discussions must start\nearly in the mission, and must continue to be iterated to insure proper\ninformation transfer.\n\n29\n\nf.\n\nA single document for each experimenter to identify all requirements\nwas used with limited success on ASSESS II. However, the concept appears\nvery sound. The question and answer format was good, but the overall\norganization of the questions needs very careful study and arrangement to\neliminate redundancy and achieve tadmum clarity with brevity. Initial\nattempts to have the PIs fill out the document unilaterally were not\nsatisfactory. Face-to-face meetings with the experimenters were necessary\nto clarify the need for interface information and obtain total understanding.\nWhen experimenters understood the requirements, in every case they very\naggressively worked to produce needed information. The IRD, in most cases,\nserved very well to focus PI attention on interface areas much earlier than\nwould otherwise be the case.\nOnly a very small interfacing group (perhaps 3 or b) is needed to\ndeal with each experimenter, but it-is absolutely mandatory that experts\nwho fully know the Spacelab systems (electrical, mechanical, data system,\netc.) work with the experimenters. The IRD mist be a living document since\nmuch of the information will develop with time and the resultant document\nforms the basic source of experimenter input for integration and flight\noperations.\nIn ASSESS II, the IRD effort started well, even though the format\nneeded much improvement, but the initial effort about a year before flight\nleft many unanswered questions. After a second effort by MSFC and the PIs\nto complete all elements of the IRD, schedule pressure and unavailability\nof manpower necessitated gathering the balance of the required interface\ninformation on an informal basis. However, even with the limited application\nof the IRD on ASSESS II, there is general agreement that the basic concept\nis sound.\n\nt\t\n\n(b) The IRDs must be kept current so that they properly reflect changes in\nexperiments as they are developed, but there must be a cut-off date beyond\nwhich all aspects of the experiments are fixed.\n\n!\t\n\nDuring ASSESS II, most experiments delivered to ARC for system\npayload integration had at least some configuration change from that\nworked out with the PI during the IRD baselining activity. Sbme PIs\nhad added components, others had removed components, and some had changed\ncomponent positions. This necessitated juggling hardware arrangements\nand recalculation of weights and overturning moments to insure safety.\nFor the aircraft program extra effort permitted satisfactory recovery,\nbut for Spacelab not only will the payload configuration have to be\ntracked closely, but the much larger number of components for many\nSpacelab experiments, coupled with the severe schedule and cost restrictions\nto handle many configuration changes, dictates a need to freeze the\nexperiment configurations at an appropriate time.\n\n30\n\nrl\n1\n1-\n\n5.4.3 Analytical Integration\n\t\n\n(a)\n\nThe analytical integration of a Spacelab payload must be accomplished in\na timely, complete fashion so that all participants can receive complete\npayload definition and requirements early enough to plan the payload\nprocessing activities.\n\nH\nIn ASSESS II, since the formal analytical integration effort was not\nfully completed, extensive real time effort was required by ARC to work with\nthe PI and solidify final physical, electrical, and data interfaces. Hardware\ninstallation sketches were used by KSC in lieu of formal documentation. As a\nculmination of the compressed mission schedule, manpower, and late PI test\nrequirements input, the final Launch Site Integration Requirements were\ndelivered to KSC one week before statt of Launch Site Payload Processing. As\nIn several other activities, this allowed little time for review, and several\nchanges were required to bring the payload to flight readiness.\n5.4.4 Integration of BSA Payload in Europe\nFor Spacelab payloads involving ESA experiments, testing, integration, and\noperation of those experiments under ESA management at a centralized\nEuropean site is extremely beneficial.\n\nThe ESA sponsored integration, test, and operational activity at\nESA/SPICE was extremely beneficial. In most cases, the experimenters needed\ndeep support to get their equipment assembled and working properly. Individual\nassistance was supplied and many problems were identified and solved during\nthe ESA/SPICE integration and operational activity. With support of a NASA\nsafety representative, all safety issues were addressed, thus avoiding major\ndifficulty later. Valuable training was accomplished. The ESA integration\nactivity insured that die ESA complement arrived in the U.S. as a tested\nset of experiments, thus reducing their integration time with the balance\nof the payload.\n\n^j\n\n5.4.5 System Level Payload Integration (Level IV)\n\ni\n\n(a)\n\nThe value of off-line System Level Payload Integration activities (Level IV)\nis directly related to the fidelity of the test facility and the completeness\nof the tests performed.\n\nj\n\nFor ASSESS II, the off-line System Level Payload Integration activity\n(Level IV) was performed on the hangar floor. It was a minimum cost\narrangement. This first - time integration of the entire payload uncovered\nmany problems- -most were solved and some were passed on to launch site\nprocessing where those plus many additional problems were addressed.\n31\n\nThe ability to address all problems in an off-line system simulator is strongly\nproportional to the investement in simulator equipment to achieve high fidelity.\nWithout the exact cabling configuration (both data and power) and duplicates of\nthe flight support system, the most troublesome EMI type of problems cannot be\nidentified.\n\n(b)\n\nOff-line System Level Payload Integration activities (Level IV) are very\neffective in crew training.\n\nFor ASSESS II, although the ESA P/Ss had participated and trained during\nthe ESA integration activity, the off-line System Level Payload Integration and\noperation at ARC was the first time all P/Ss had an opportunity to operate\nexperiments as a complete payload. The P/Ss were given basic responsibilities\nduring this phase, side by side with the experimenters, who also participated\ndirectly in this ;\'l ase of integration. This was excellent training for the P/Ss,\nand it is highly recommended that P/Ss be given this same opportunity and\nassignment for Spacelab.\n\n5.4.6 Launch Site Payload Processing (Levels III, II, I)\n\n(a) For launch site integration, timely detailed technical definition of\npayload carrier interfaces is essential.\n\nThe Launch Site Ground operations Requirements Document was delivered to\nKSC one week before start of Launch Site Payload Processing. Several payload\ninterfaces were not completely defined. As a result, KSC had essentially no\nlead time to prepare for their work. Although present Spacelab guidelines\nlimit KSC responsibility to interface verification, some severe experiment\nproblems occurred which had to be addressed. For the Capodimonte experiment,\none undefined signal interface had to be revised. An incorrect power\nconnection on the SAR caused complete failure of the experiment from a\nSpacelab point of view, and was fixed during flight operations by permitting\nthe PI to break the simulation rules and go aboard the aircraft to solve the\nproblem.\n\n(b) Effective launch site payload processing can be performed using a single\ndirect payload manager interface to the KSC payload processing management.\nA payload test team approach, using the M/S, P/Ss,and PIs when necessary,\nunder the Jurisdiction of KSC to directly support and participate in the\nKSC launch site processing operations was very successful and Is recommended\nfor Spacelab.\n\nFor ASSESS II, the KSC launch site Manager, the MSFC Ground Operations\nManager, who had handled the Level IV Integration, and the ESA Payload Manager\nworked closely together as a team, utilizing the M/S and the P/Ss full time.\nThe Mission Manager was the single basic interface with KSC for the payload.\n32\n\n\xe2\x96\xba t\n\nAlthough KSC maintained strict control of the schedule and operation, they\nwere very receptive to participation by the experimenters to handle experiment\nproblems, rather than creating procedures for use by others. This team\napproach is recommended for Spacelab integration at KSC.\n\ny_\n(c) To minimize experiment systems failure, time should be scheduled to conduct\nexperiment functional tests on the integrated vehicle. Failure to perform\nthese tests implies,at least on priority experiments, technical risk that\nmay not be commensurate with mission investment.\n\nThere is no fully satisfactory substitute for test of the payload\ncomponents in the actual flight configuration. While a high-fidelity\noff-line test device does allow very significant debugging of the system\ninterfaces and the payload experiments, there will always be at least\nminor configuration variations from the flight system that can produce\nserious anomalies in payload operation. In ASSESS II, each experiment\nwas checked out on the aircraft after final integration. 1. number of\nproblems were found and solved. For Spacelab, the KSC integration is\nbaselined only to insure interface and EMI compatibility. It is\nrecommended that a full operational check of at least priority experiments\nbe included to insure proper data producing capability.\n\n(c) ,Past experience should be applied to insure that experiment tests are\nconducted that will indicate possible experiment hardware weaknesses\n, or susceptibilities.\n\nA great deal of experience exists at both NASA and ESA Centers\nfor checkout of experiments to be flown in space. The participation of\nthe implementation Centers in the design review and test planning phases\nof the experiments can assist the PI\'s rate of success through experience\ntransfer. The ground rule now being considered for Spacelab puts prime\nresponsibility upon the PI to insure satisfactory operation of his experiment\nwhile the STS responsibility is limited to safety and interface compatibility.\nFor ASSESS II, at the discretion of the experimenters, experiments were\nnot thoroughly tested in all cases before flight. One prim experiment\nfailed; others had operational problems. A positive approach to marry the\nknowledge of experienced personnel with the experimenters\' responsibility\nto perform critical experiment tests is recommended.\n\n33\n\n(e)\n\nAn all-up Integrated Mission Simulation is valuable and is recommended, at\n(least for the early Spacelab missions. Inclusion of instrument operation\nIto verify operational interfaces during the simulation enhances the probability\nof experiment success.\n\nA generally effective end-to-end Integrated Mission Simulation was\nconducted in ASSESS II with the payload flight crew carrying out experiment\noperation supported by full MCC/POCC participation. Many problems were\nidentified, some with hardware, and some with operations. This level of\nsimulation offers the greatest possible degree of training for the total\noperations team (MCC, POCC, and payload crew), and should be included\nduring the final integration period for Spacelab, especially for early\nmissions.\n\ny\ni\n\n(f)\n\nFacilities and dssociated equipment along with some schedule time should be\nmade available at the launch site to allow for some experiment testing, solve\nlast minute experiment problems, and allow for calibration requirements.\n\nExperience has sham that some experiment problems will show up at\nKSC when the payload is integrated with the actual flight system. Also,\nsome experiment calibrations must be performed with the flight system\nhardware to obtain acceptable flight data. Both of these cases were\nevident in ASSESS II.\nMost hardware problems can be quickly and effectively solved at the\nlaunch site, but some electrical and job shop capability close at hand is\nnecessary along with simple procedures to use this capability. Airborne\npayload integration at Ames has been highly successful, particularly\nbecause of these strong capabilities. They were extensively used for\nASSESS II and are recommended for KSC.\n\n5.4.7 Safety\n\n(a)\n\nSafety considerations for ASSESS I1 were applied with a low level of\nformality, but the experience did not contribute materially to understanding\nthe required lc ,+el of detail necessary for Spacelab.\n\nSafety considerations for the basic aircraft system and the payloads\nat Ames were handled by the Airworthiness Assurance Office. General safety\ninspections were handled on a daily basis during integration and ground\noperations by the Inspection Branch with simple squawk sheets which\nincorporate provision for signoff on the same sheet upon corrective action.\nFinal all-up mission safety approval is issued in writing by the\nAirworthiness and Flight Review Safety Board after formal meeting(@) with\nreview of all safety related items and operational procedures. All flight\npersonnel are required to participate in safety briefings. The Aircraft\nCommander is the final safety authority during flight. Many safety\n34\n\nf\n\nconsiderations for Spacelab were not required for ASSESS II; e.g., outgassing,\nflammability, stress corrosion, and detailed hazard analyses.\n\nf\n\n5.5 Payload Flight Crew\n\n(a)\n\nThe M/S role in ASSESS II and the management arrangement was very successful\nand is recommended for Spacelab.\n\nt\n\n^_\n\n\t\n\nAfter much controversy and delay, the arrangement for a Scientist\nAstronaut to serve as M/S for ASSESS II was worked out. There is no evidence\nthat this arrangement would not work equally well for Spacelab. The M/S\nremained administratively under JSC, but was assigned functionally to the\nMission Manager at MSFC. In addition to his ground based duties, he served\non the flights as the alter ego of the Mission Manager. As the mission\nprogressed, it became apparent to everyone that he operated very effectively\nas leader of the P / Ss, which came about naturally based on his background,\ntraining experience, and personality. The P / Ss were all well satisfied\nwith this arrangement.\n( b) The M / S functions for ASSESS II were unique to that position and served a\nvital need.\n\nOn ASSESS II, a prime function of the M/S was to bridge the gap\nbetween the experiments and the payload support systems (central data\nsystem, power supply and distribution system, and some special payload\nsupport devices such as gyrostabilized mirrors and a water vapor\nradiometer). Long term training is required to handle such systems,\nespecially the data system, and, in fact, the six-month period for\ntraining for the ASSESS II M/S was wholly insufficient for him to\ntotally handle the data system (a ghost operator was used). In addition\nto this basic function, it was natural for him to serve as the communications\nand operations coordinator during flight to maintain ground contact primarily\nbecause the aircraft had a single payload communication station at his\nconsole. The M/S handling of most communications unloaded the P/Ss, who\nwere overburdened with direct experiment operation duties. Also, the M/S\nfrequently served to support the P/Ss in operating functions. This ream\n\napproach was very smooth and successful.\nDuring integration and operation of the payload for Level IV and\nfor Launch Site Payload Processing, the M / S was very valuable as an\noperations and training coordinator for the payload flight crew.\n\n35\n\ns._\n\n(c) The participation of M/S and P/S (time of selection, training schedule,\netc.) should be included as an integral part of the mission planning so\nthat their involvement begins at the optimum time comimensurate with their\nassignments. In particular, P/S involvement should commence at a stage\n\nthat would al l ow their inputs to the control and operations aspects of\nthe experiment design.\n\nASSESS II P/Ss were selected eight months before flight. By the time\nthey got to most of the He for training, much of the hardware design was\nsolidified. As in ASSESS I, the P/Ss all made strong observations that\ntheir early input to design would have been very helpful toward making\nexperiment operation more conducive to successful operation of the hardware\nand obtaining science data.\n\n(d) Effective verbal communication skills should be an important criterion for\nP/S selection.\n\nDuring ASSESS II, it was noticeable that some P/Ss were significantly\nless adept at giving and receiving information than others, with a tendency\nto communicate less effectively under stress. This affected the success of\nmaking repairs and collecting data. This aspect of competence must not be\nneglected when making P/S selection for Spacelab.\n\n(e) Prior to final selection, P/S candidates should be subjected to some type of\nstress, including timeline activity.\n\nObservations indicated that the ability of P/Ss to operate under\nstress of multiple activity varied considerably. In Europe, psychological\ntests were used that clearly eliminated some P/S candidates and raised\nconcerns about others. These concerns were borne out on ASSESS II during\nthe integration and flight periods.\n\n(f) Any PI candidate for P/S must be fully cognizant of the workload time\ncommitment and demonstrate his ability to s upport both r o le s.\n\nOn ASSESS II, one P/S was also a PI. Some interference was noted when\nhe interrupted his ASSESS II activity to take care of urgent PI management\nresponsibilities. Very careful consideration should be given to any PI who\nproposes to be a P/S on Spacelab to assure his genuine willingness to forego\nhis basic PI duties, or have them handled by others, and that he thoroughly\nunderstands the time required away from his home base for meetings, training,\nand operational duties associated with the Spacelab payload.\n\n36\n\n(g)\n\nThe use of backup P/S from the Mission Management team it feasible, b,%\n\npracticability depends upon the balance of duties required for a specific\nmission.\n. rn\n\xe2\x80\xa2\t\n\nn\n\nFor ASSESS II, the U. S. Assistant Mission Manager was selected to be\nbackup P/S for U.S. experiments. This plan for a single backup for both U.S.\nP/Ss was adopted particularly to save travel funds, and the individual was\nconsidered to be well acquainted with the U.S. experiments. Ilia management\nduties were severely diluted, but he handled P/S training and generally\nrepresented the payload crew to management during the pre-flight phases in\naddition to undergoing his own limited training. The question arises as\nto whether capable candidates will be willing to accept only a backup\nassignment for Spacelab, with historically a very low probability of Flight\nassignment, unless there is some accompanying responsible assignment (which\ndilutes both jobs), or some strong liklihood that a backup P/S assignment\nis a step toward prime assignment on another mission.\n\ns\n\n(h)\n\nr\xe2\x80\xa2\n\nEach crew candidate should be subjected to sufficiently realistic functional\nand environmental simulation of his roles early in the training period to\npermit self-evaluation of his desire to proceed.\n\nSome substantial physical difficulties were experienced with the\nmedical experiment by one P/S during the 72-hour collection of P/S preflight\nbaseline medical data at ARC. The problem was sufficiently severe that,\ndue to potential loss of medical data and/or degradation of his overall\neffectiveness, consideration was given to replacing him for the flight\nmission. However, in the actual mission, the medical data was collected\nand there was no detectable degredation of P/S performance due to the\nmedical experiment.\n\nP!S training must be tailored to the individual P/S selected and the\ncomplexity and degree of P/S understanding of any given experiment.\nPIs must devote adequate time and effort to maximize the training\neffectiveness.\n\nOn ASSESS II, P/Ss training was somewhat varied. Initial training\nwas scheduled on a time basis per experiment without regard to P/S capability\nof initial, understanding of experiments, but some adjustments were made as\ntraining progressed. Discussions with P/Ss after the mission indicated\nthat training, in some cases, had been overdone for some experiments and\ninadequate for others. Mission management judgment should be blended with\nP/S desires to schedule training time consistent with the background and\ncapability of each P/S for every experiment and its priority.\n\n37\n\nNASA should consider means to provide independent travel fund support for\n\'P/Ss from Centers where this factor can prevent nomination.\n\nThe problem of selecting a P/S from a NASA Center raises the problem\nof devoting extensive travel funds to a single individual and organization\nwith a center for benefit of others on Spacelab. The travel fund problem\nis so severe within NASA, under the present system, that any NASA organization\nis extremely reluctant to expend travel funds except for local benefit. For\nASSESS II, the travel fund problem was very severe. Where payloads came from\nseveral organizations, special travel fund arrangements may be necessary to\nattract the best P/Ss.\n\n(k)\n\n\'\t\n\nP/S participation in development of experiment operation procedures contributes\nsignificantly to their training and operational understanding, and supports\ntheir responsibility as the onboard PI representative.\n\nFor ESA experiments, the P/Ss were given the responsibility to develop\noperational flight procedures for their assigned experiments. This proved\nto be a very effective method to assure their complete understanding of\nexperiment operation, and caused a very deep interaction with the PI to\niterate various modes of operation. The further hands-on operational\nresponsibility assigned to the P/S during LeNel IV and launch site\nintegrat7lons was an excellent combination to maximize P/S training for\nflight. NASA chose to have the PIs maintain responsibility for all\nprocedure generation with review and iteration with the P/Ss. No difference\nin P/S operational success could be detected due to this different approach.\n\n(1) Flight operations workload planning must allow for a P/S adaptation period,\nwith attendant lower effectiveness for the first several days of the mission.\n\nEven without the effects of zero-g, for ASSESS II the P/Ss readily\nstated that they required from one to three aircraft flights before they\nhad reached a high degree of effectiveness in experiment operation. The\nP/S who had many details to consider but was concerned with only one\noperational goal developed operational effectiveness more rapidly than those\nfaced with a multiplA city of operational goals (single vs multiple experiment\noperations). Even the M/S, with his considerable flight experience, felt\nthat he was not handling his several duties with full efficiency until about\nthe third flight. Increased experiment/system level training can minimize,\nbut not eliminate, the initial lower effectiveness.\n\n38\n\n5.6 Flight/Ground Operations Interactions\n\n1\nr\ni\ni\n\n(a)\n\nAdequate resources and time must be provided for training of POCC personnel,\nespecially PI science tr.ams.\n\nThe POCC for ASSESS II was fully manned as planned for Spacelab.\nSome POCC training occurred for ESA personnel during the ESA integration\nand operation activity in Europe, but very little operational training took\nplace at Ames before the start of flight operations. Total plans for\ntraining at ARC could not be exercised due to minimum schedule time, total\nlaunch team workload, and the minimum on site PI support teams. Initial\noperations were inefficient, but improved with time. Whereas experienced\nmanagement personnel may man key positions for Spacelab, which eliminates\ntheir training needs, most PIs will be untrained. PI participation in\nflight communications was very poor in many cases during ASSESS II,\nespecially during the early flight period. Leadership of the PI group\nin the POCC by the Mission Scientist was very good, but some training for\nthat arrangement is recommended.\n\nTne TV text uplink is a beneficial mission operations tool. Facsimile\ncapacity for transmission of troubleshooting information is desirable\nand should be incorporated into the Spacelab concept at an early date.\n\nThe TV text uplink and its Polaroid readout in the aircraft proved its\nutility by being used increasingly as the ASSESS II mission progressed. The\nability to send simple messages to P/Ss and the M/S, with a record for\nreference, was found to be far less interruptive of work than extensive\nvoice communication. Inability of the link to handle facsimile precluded\nsending wiring diagrams that were needed for troubleshooting.\n\nPeriodic data samples from the Spacelab to the POCC during the mission\nare essential for PI experiment surveillance and to provide operations\ninstructions back to the Spacecraft.\n\ni\nData slices were passed to the POCC each day, and gro.md-based\nfacilities were available through the POCC to d-termine the effectiveness\nof experiment operation. This system was highly successful, and is\nrecommended for Spacelab. Some probl:ms occurred with data interfaces to\nthe experiments, but in every case a work-around was implemented so that\nnearly all data was retrieved.\n\n39\n\n(d)\n\nIf backup P/Ss are to be used effectively in the POCC, they must be trained\non all experiments. Also, on joint missions, Mission Scientists must be\nfamiliar with all experiments.\n\nDuring ASSESS I_I, in-flight communication between the POCC and the M/S\nprimarily concerned experiment operation and experiment troubleshooting.\nCommunication is much more efficient if both sender and receiver are conversant\nto a reasonable level of detail with all aspects of the payload. For ASSESS II,\nthe backup P/Ss served as the maiu POCC communicators and their payload\ntraining, along with close familarity with the flight crew, made this very\neffective.\nThe Mission Scientist must be conversant with the payload to a\nconsiderable level of detail so that he can make decisions on the best\nuse of flight time. It is therefore imperative t-at he understand the\nscience and operation of all experiments.\n\n5.7 Experiment Hardware Considerations\ns:\n(a) Automation of routine tasks is recommended in reducing P/S workload and\noperating errors; however manual bypass capability is also desirable.\n\nExperiments that contained automation of routine tasks and did not\nrequire extensive adjustments or setup of controls by the P/S appeared to\nhave a higher data-take success ratio than those with extensive manual\nsetup and control. Two examples from ASSESS II illustrate this point.\nThe infrared telescope experiment was highly automated with computer\ncontrol. However, when the computer occasionally failed, adequate manual\noperation by the P/S was possible. One U.S. experiment was also highly\nautomated with computer control, but not in such a way that the P/S could\neasily bypass it. The PI recognized early in the mission that the data\nwas badly degraded, but gave no instructions to the P/S because there were\nno suitable manual control provisions.\n\n(g)\n\nUse of off-the-shelf hardware should be considered where modifications or\ntesting to meet the Spacelab constraints is cost effective.\n\nAs in ASSESS I, the majority of the components that made up the\nASSESS II experiments were off-the-shelf items. Statistically they\nperformed as well as specially constructed components.. The primary reason\nfor resorting to special construction was the need for s unique functional\ncapability. Reliability, low power cono umyiLon, etc., were definitely\nsecondary considerations.\n\n40\n\n(c)\nMr,\n\ntI\n\nPayload integration and operations management personnel, as well as the\npayload flight crew, should have available a complete set of simplified\nschematics. These should clearly show all interface connections and\ncontrols for ready reference during integration and operation when problems\noccur.\n\nDuring ASSESS II, except for Spacelab rack interfaces, PIs provided\nintra-experiment and control diagrams in varying degrees of detail. Other\ninterface diagrams were hastily developed just prior to Launch Site Payload\nProcessing by the Systems Level Payload Integration team in cooperation with\nmembers of the various PI teams. Over all, the level of detail in the\ndiagrams was not sufficient to permit integration management personnel to\nefficiently pursue and solve problems. Even though it is recognized that\nintra-experiment hardware is a PI responsibility, unless some reasonable\ninner visibility is immediately available, internal components can cause\nsevere interface problems without a capability to quickly trace the\nproblem to the source.\n\na.\n\n5.8 Data Handling\n(a)\n\nFace-to-face interactive discussions betw\xc2\xb0en responsible representatives\nof the experiment and the central data system with a resulting bilateral\ninterface agreement, including verification, procedures, are necessary to\nfully define and establish the data handling interface.\n\nInterface resolution between experiments and the central data system\nis traditionally one of the most difficult areas. Usually experiment\ninterface identification comes late in the process of experiment hardware\npreparation, which compounds the problem. A reasonable understanding by\nthe experimenter of central data processor interface limitations may also\naffect the experiment design, and should come early enough to prevent the\nneed for redesign. All of this dictates that experts from each side of\nthe interface start face-to-face discussions early and continue that type\nof interaction until a firm interface is fully defined and agreed to by\nboth parties. Attempts to define this interface without extensive discussion\nand understanding will almost guarantee problems except for the simplest\ntype of data interface.\n\nLi\nF\'\n\nFor ASSESS II, the key data system experts were unfortunately not\nbroug:it into IRD discussions. This area turned out to be the most severe\nproblem area with persistent difficulty in several cases. For Spacelab,\nproper early expenditures of travel funds and manpower in this area will\nalmost certainly be cost effective and save later severe problems.\n\nqq }\n\n41\n\n(b) Hardware and software interfaces should Le standardized wherever possible\nbetween the experiment and the central data system to simplify integration\nand checkout and enhance operating reliability.\n\nIn the.ADDAS system, all analog data is generally received through\na single analog to digital converter that is sampled by standardized\nsoftware. Thus, any analog signal that conforms to the limitations of\nthe converter can be quickly and surely added to the data collection\nsystem. Limiting C`.gital interfaces to a format and procedure for which\nthe central computer is designed likewise reduces the need for special\nprogramming which s costly, prone to error, and generally makes\ninefficient use of all resources.\n\n(c) Successful soft-fare debugging can be accomplished only if enough time is\nexperiments being stimulated simultaneously in the\nprovided wi\'Ch\t\nplanned flight configuration.\n\nAlthough individual experiments to the central data system interfaces\nshould be well verified by the time the total integration phase commences,\ninteraction between experiment software modules can only be reliably tested\nin a full system environment, and sufficient time must be allowed to identify\nand solve total system problems which are almost guaranteed to show up. The\nASSESS II schedule did not provide sufficient debugging time with all\nexperiments operating, and consequently some severe data processing problems\noccurred during flight. Software debugging should be expected to continue\nwell into payload integration, and with the real possibility that this type\nof problem is likely to show up during flight, it is recommended that the\nuplink be capable of handling data processing computer programs.\n\n5.9 Documentation\n\n(a)\n\nThe fidelity of document generation and late issuance during ASSESS II\nresulted in lack of agreement among the participants on any immediate\n(general conclusion for Spacelab on this subject. A separabeanalysis of\ndocumentation will be undertaken.\n\nIdentification and review of documentation on ASSESS II was difficult\nbecause very little documentation was generated until late in the project.\nThe early IRDs were not completed. Lack of complete analytical integration\ndid not produce the ingredients necessary for timely issuance of documents\nwhich required that data. Thus, although the ground and flight operations\nrequirements documents were finally issued, they came too late for review\nor strong application, and the resulting ground and flight plans were\nconsequently generated very late, mostly on the basis of informal inputs.\n\n42\n\ni_\n\n(b) For joint NASA/ESA missions, both sides should have an opportunity to\nreview all basic mission documents. Some form of mission implementation\nagreement should be developed and jointly agreed to by both parties.\nThis should identify those documents which commit each other\'s resources\nor significantly impact mission objectives and should be concurred in by\nboth parties.\n\n\t\ni\n\nDnring the progress of the ASSESS II mission, ESA management felt\nthey were being committed without recourse to certain lines of action by\nNASA issued documentation. No formal means was developed during the\nprogram for NASA/ESA discussion of such documents before their issue.\nESA feels that they must be able to discuss jointly those areas where\ncommitments of manpower are to be made before detailed policies are set\nby NASA issued documents.\n\n{\n\n43\n\nAbbreviations_ and Acronyms\nADDAS\nARC\nASO\nDFVLR\nEMI\nESA\nESTEC\nGHz\nGSE\nGSFC\nHF\nIR\nIRD\nIWG\nJPL\nJSC\nKSC\nLaRC\nMCC\nMSFC\nM/S\nMSG\num\nNASA\nOA\nOH\nOSF\nPCU\nPI\nPOCC\nP/S\nSPICE\nSTS\nUHF\nVHF\n\nAirborne Digital Data Acquisition System\nAmes Research Center\nAirborne Science Office\nDeutsche Forschungs-und Versuchsanstalt fur Luft-und\nRaumfahrt (the German Natioual Space Agency)\nElectromagnetic Interference\nEuropean Space Agency\nEuropean Space Technology Center\nGigahertz\nGround Support Equipment\nGoddard Space Flight Center\nHigh Frequency\nInfrared\nInvestigator Requirements Document\nInvestigators\' Working Group\nJet Propulsion Laboratory\nJohnson Space Center\nKennedy Space Center\nLangley Research Center\nMission Control Center\nMarshall Space Flight Center\nMission Specialist\nMission Steering Group\nMicrometer\nNational Aeronautics and Space Administration\nOffice of Applications\nHydroxyl\nOffice of Space Flight\nPayload Checkout Unit\nPrincipal Investigator\nPayload Operations Control Center\nPayload Specialist\nSpacelab Payload Integration and Coordination in Europe\nSpace Transportation System\nUltra High Frequency\nVery High Frequency\n\nExperiment Designations\nAirborne Electromagnetic Emission Survey\nAEES\t\nAirglow University of Southampton\nCAPO\t\nshort for Capodimonte\nIHR\t\nInfrared Heterodyne Radiometer\nEMI\t\nEMI experiment\nInfrared Astronomy\nIRA\t\nLaser Absorption Spectrometer\nLAS\t\nMedical Medical Experiment\nSAR\t\nSynthetic Aperture Radar\nMLS\t\nMicrowave Limb Sounder\nReference 1: NASA/ESA CV-990 Spacelab Simulation - Executive Summary July 1975. NASA TM X-62,457 and ESA-SL-75-1.\n44\n\n'