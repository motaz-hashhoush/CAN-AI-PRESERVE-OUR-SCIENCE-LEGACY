b'Detecting Distributed SQL Injection Attacks in a\nEucalyptus Cloud Environment\nAlan Kebert, Bikramjit Banerjee, Juan Solano\n\nWanda Solano\n\nSchool of Computing\nThe University of Southern Mississippi\nHattiesburg, MS 39402, USA\nAlan.Kebert@eagles.usm.edu\n\nNational Center for Critical Information\nProcessing and Storage\nNational Aeronautics and Space Administration\nStennis Space Center, MS 39529, USA\nWanda.m.solano@nasa.gov\n\nAbstract\xe2\x80\x94The cloud computing environment offers malicious\nusers the ability to spawn multiple instances of cloud nodes that\nare similar to virtual machines, except that they can have\nseparate external IP addresses. In this paper we demonstrate\nhow this ability can be exploited by an attacker to distribute\nhis/her attack, in particular SQL injection attacks, in such a way\nthat an intrusion detection system (IDS) could fail to identify this\nattack. To demonstrate this, we set up a small private cloud,\nestablished a vulnerable website in one instance, and placed an\nIDS within the cloud to monitor the network traffic. We found\nthat an attacker could quite easily defeat the IDS by periodically\naltering its IP address. To detect such an attacker, we propose to\nuse multi-agent plan recognition, where the multiple source IPs\nare considered as different agents who are mounting a\ncollaborative attack. We show that such a formulation of this\nproblem yields a more sophisticated approach to detecting SQL\ninjection attacks within a cloud computing environment.\nKeywords\xe2\x80\x94cloud computing; Distributed Attack; Eucalyptus;\nSNORT; Havij; OSSIM; MAPR\n\nI.\n\nINTRODUCTION\n\nCloud computing offers new opportunities for software\ndistribution, resource allocation, convenience, and information\nsecurity for users, but it also creates new opportunities for\nmalicious users to penetrate security layers and damage,\ndestroy or steal data of other users. One advantage that a cloud\ncomputing environment offers to malicious users is the ability\nto spawn multiple instances of cloud nodes that are similar to\nvirtual machines, except that they can have separate external\nIP addresses. In this paper we demonstrate how this ability can\nbe exploited by an attacker to distribute his/her attack, in\nparticular SQL injection attacks, in such a way that an\nintrusion detection system (IDS) could fail to identify this\nattack. To demonstrate this, we set up a small private cloud\nusing the Eucalyptus [10] cloud environment, established a\nvulnerable website in one instance, and placed an IDS (open\nsource OSSIM [11]) within the cloud to monitor the network\ntraffic. We found that an attacker, using a freely available\nSQL injection tool (Havij) could quite easily defeat OSSIM by\nperiodically altering its IP address, i.e., by hopping from one\ninstance to another in the cloud.\n\nTo detect such an attacker, we propose to use multi-agent\nplan recognition [1][2][4][5], where the multiple source IPs\nare considered as different agents who are mounting a\ncollaborative attack. We show that such a formulation of this\nproblem yields a more sophisticated approach to detecting\nSQL injection attacks within a cloud computing environment.\nII.\n\nRELATED WORK\n\nIn the past, very little work has been done to study security\nissues and strategies in a cloud computing environment.\n\xe2\x80\x9cDigital Forensics for Eucalyptus\xe2\x80\x9d [9] considered security\nvulnerabilities in a Eucalyptus cloud, and our work can be\nconsidered as an extension or a continuation of that work,\nsince we not only address exploitation of some vulnerabilities\nof Eucalyptus cloud, but also how to detect a resulting attack,\nwhere existing IDS fail.\nSQL injection continues to be a threat and is discussed in\ndepth in "A classification of SQL-injection attacks and\ncountermeasures\xe2\x80\x9d [3]. Although multiple methods exist to\nprevent or detect SQL injection attempts, these methods tend\nto focus on single actions. It can be difficult to differentiate a\nsingle action of an attack from normal traffic, so Security\ninformation and event management programs (SIEMs) try to\ncorrelate multiple activities with the plan of an attacker [6].\nSIEM directives typically look for a pattern of activity from a\nsingle user to increase the reliability of an alert, but do not\nconsider whether the actions of multiple agents have\ncollectively achieved a malicious goal.\nMulti-agent plan recognition [1][2][4][5] (MAPR) has been\nformalized and studied recently in abstract and theoretical\nsettings, and to the best of our knowledge it has not been\napplied to any realistic cyber-security problem. Hence in this\nrespect our work constitutes the first practical application of\nMAPR.\nIII.\n\nDESCRIPTION OF SETTING\n\nIn this section we describe how the various components of\nour system are setup, and how they operate. In succession, we\n\nwill describe the Eucalyptus cloud setup that we used, the\nHavij SQL injection tool and the network traffic sniffer Snort,\nwhich is used as a sensor by the security event manager\nOSSIM to generate its alerts. Finally we describe how a\nsimple strategy of switching source IP address can defeat\nOSSIM.\nA. Eucalyptus Cloud\n\non a given string whose runtime will be reported to Havij.\nBased on this runtime, Havij can detect the binary outcome of\nthe comparison. Fig. 2 shows a partial example of this process.\nThe statements containing \xe2\x80\x9cif (Length\xe2\x80\x9d are part of a single\nbinary search to determine the length (in this example 5) of the\nname of the database. The subsequent statements containing \xe2\x80\x9cif\n(ascii(substring\xe2\x80\x9d attempt to find the 5 characters one by one.\nThe\nlast\nstatement\nof\nthe\nform\n\xe2\x80\x9cif\n(ascii(substring((database()),x,1))=y,BENCHMARK\xe2\x80\xa6\xe2\x80\x9d that\ncontains =y, marks the end of the process of finding the xth\ncharacter. In this example, the 1st character has been\ndetermined to be \xe2\x80\x9cd\xe2\x80\x9d, the ascii character with code 100. The\nsearch for the 2nd character starts next, but is not completed in\nFig. 2.\n\nFig. 1. The Eucalyptus Cloud Environment\n\nThe cloud environment on which this work is based is\nshown in Fig. 1. It contains three nodes, the head node \xe2\x80\x93 the\nmanager of all communication with the external world \xe2\x80\x93 and\ntwo other nodes that offer various computational and storage\nresources to users. The communication between the head node\nand the other nodes are via an ethernet switch. An IDS\n(OSSIM) sniffs all packets passing through this switch. This\ngives OSSIM a vantage point to monitor any external attack\non resources within the secondary nodes. In particular, we\nestablish a vulnerable website within a VM in node 1. Fig. 1\nalso shows users outside the cloud accessing the cloud\nresources through the head node. Our attack computers were\nlocated outside the Eucalyptus cloud, but still able to\ncompromise the database inside the cloud node.\nB. Havij\nIn order to demonstrate an attack we used a program called\nHavij. Havij is a freely available SQL injection tool. SQL\ninjection is the process of inserting arbitrary SQL code into a\nform whose input is queried against a SQL database. The form\nexpects a user input, such as a username field on a login page,\nbut if the text is not carefully sanitized a malicious user may\nplace SQL commands into the field and cause the database to\nexecute unintended commands. Havij facilitates this sort of\nactivity by discovering the important field names needed for\nmany SQL commands: database names, table names, and the\ncolumns of the tables. Havij can also reveal the contents of an\nunsecured database. It does this by first issuing a series of ifstatements that test the length of field names, and then test the\nnumerical value of the ascii characters representing individual\ncharacters of field names. Havij cannot ask the SQL database\nfor the values directly, so it uses these comparisons to perform\na binary search against a table of ascii numerical values. Each\ncomparison will usually return zero immediately if false, but if\ntrue then an expensive MD5 benchmarking will be performed\n\nFig. 2. Sample of (partial) tcpdump of a Havij attack formatted to be\nreadable\n\nSometimes, perhaps due to delays in processing by the\ndatabase, Havij receives non-zero runtimes for false statements\nthat cause the binary search to go out of range or return a\nwrong length or character. This is usually inconsequential, as\nthe search may be run again and comparing two searches\nallows the operator to fill in missing or wrong characters. In\norder to describe the database, Havij first runs these searches\nfor length of the database name. Next it will perform binary\nsearch for that number of characters to determine the database\nname. Once it has the database name it can issue statements to\ndetermine the number of tables in the database. From there it\nwill find each table name in a similar manner to the way it\nfinds the database name, targeting the length of table names\nand then each character of the table names. It may then do this\nfor column names in each table, and then for data contained in\nthe table. Once the structure of the database is known, a hacker\nmay execute arbitrary commands by filling in the appropriate\nvalues.\nFig. 3 shows an attack where Havij has determined the\nlength of the database\xe2\x80\x99s name to be 5, and then conducted 5\nseparate binary searches for the characters in the database\xe2\x80\x99s\nname, discovering the name \xe2\x80\x9cdummy\xe2\x80\x9d. Fig. 4 shows an\nadvanced stage of this attack where Havij has discovered the\n\nname of a table (\xe2\x80\x9cusers\xe2\x80\x9d) in the database \xe2\x80\x9cdummy\xe2\x80\x9d, and used it\nto discover the three field names \xe2\x80\x9cuser\xe2\x80\x9d, \xe2\x80\x9cemail\xe2\x80\x9d and\n\xe2\x80\x9cpassword\xe2\x80\x9d. This attack can be manually continued through\nHavij, by selecting the columns in Fig. 4, and clicking\n\xe2\x80\x9cGetData\xe2\x80\x9d, to reveal the contents of the table, potentially\ncompromising sensitive data.\n\nFig. 4. Havij after identifying each column in the users table.\n\nFig. 3. Havij after finding the name of our database \xe2\x80\x9cdummy.\xe2\x80\x9d\n\nC. Snort\nWe decided to use the popular packet sniffer Snort to detect\nthese attacks. Snort compares the content of packets against a\nlibrary of rules, and upon finding a packet whose contents\nmatch a rule, may raise an alert, log the packet, drop the\npacket, or perform some user defined function.\nWith\nappropriate rules, Snort easily detects the Havij attack, but the\nfunctionality of Snort is greatly diminished by the large volume\nof alerts it raises. For example: our Snort rule library checks\nthe packet content for the \xe2\x80\x9cBENCHMARK\xe2\x80\x9d command Havij\nuses to check the results of its binary search. This causes Snort\nto alert hundreds of times for one Havij attack. This problem is\nworse if valid traffic can contain suspicious content. For\nexample, the character \xe2\x80\x9c \xe2\x80\x98 \xe2\x80\x9c is often needed in SQL injection\ncommands to end the query that is intended to run and allow\nthe arbitrary commands to be inserted, but \xe2\x80\x9c \xe2\x80\x98 \xe2\x80\x9c may also be\npart of valid names like \xe2\x80\x9cO\xe2\x80\x99Reilly.\xe2\x80\x9d A snort rule that checks\nfor \xe2\x80\x9c \xe2\x80\x98 \xe2\x80\x9c in the packet will alert on the name \xe2\x80\x9cO\xe2\x80\x99Reilly\xe2\x80\x9d unless\nadditional conditions are added to the rule. Each additional\ncondition to reduce false positives makes the rule easier to\ndefeat. This results in a tradeoff between reducing false\npositives and decreasing detection rate. Since Snort only\nconsiders one packet at a time, it is very difficult to avoid false\npositives. This is where SIEMs come in.\n\nD. SIEM/OSSIM\nSIEM stands for Security Information and Event\nManagement. A SIEM uses tools like snort to detect various\nthings, but interprets the results at a higher level before making\nalerts to the operator. We used the open source SIEM OSSIM\nfor this project. OSSIM uses what its creators call a\ncorrelation engine to reduce false positives. The correlation\nengine relies on user created correlation directives to determine\nwhen to raise an alert. A correlation directive takes data from\none or more sensors, like Snort, and tries to match them to\npatterns of malicious activity by organizing the data into\ncorrelation levels. The first level is always a single occurrence\nof a suspicious activity. Instead of alerting the operator\nimmediately, the correlation directive moves to level two\nwhich will have a set of conditions and a timeout. If the\nconditions of level two are met before the timeout, the directive\nwill elevate to level three and begin trying to meet a new set of\nconditions with a new timeout. The user defines how reliable\neach level is in indicating an attack, and this value along with\nthe user assigned value of the assets that the SIEM is\nmonitoring determines when an alert is actually raised. While\nthe Havij attack generates hundreds of lower levels alerts, the\ncorrelation engine raises only one alarm. Fig. 5 shows the\ndirective accumulating multiple snort activations while the far\nright column displays the correlation level of 3 where the\nsingle alert is raised.\n\nFig. 5. Snort activations and correlation level 3\n\nThis directive generates an alert at level three. It is\nactivated by Snort detecting the BENCHMARK command in\nthe packet content. Upon initial detection of the command and\nelevation to level two, it looks for fifty activations in 6 seconds\nbetween the same source and destination IPs that activated\nlevel one. If it sees fifty activations before the timeout, an alert\nwill be raised and it will elevate to level 3 where it attempts to\ncollect 1000 activations in the next 10 seconds between the\nsame source and destination IPs. This directive easily picks up\non a Havij attack, which generates hundreds of BENCHMARK\ncommands within a few seconds in order to perform the binary\nsearches. The details of the directive appear in Fig. 6.\n\nIP would change, and these changes cycle within a set of 6\ndistinct IP addresses. This is a realistic simulation of a\ndistributed attack, especially in a cloud computing\nenvironment, where a user can launch multiple instances with\ndistinct IP addresses. By contrast, multiple VMs on a single\nmachine do not acquire distinct external IP addresses (but they\ndo acquire distinct internal addresses). After distributing the\nattack across the 6 distinct IP addresses, the script was still able\nto detect each attack, but since activations for any single IP\naddress never exceeded the conditions, each distinct source IP\nremained at level two and raised no alarm. This is shown in the\nmiddle part of Fig. 7. However, the total number of packets\nsent by any single IP address is not under 50 (as shown in the\nbottom part of Fig. 7 for a single source), indicating that it is\nthe temporal staggering of the packets that defeats level 2 of\nthe directive, not a straightforward distribution of the packets\namong multiple sources which would make each source count\nfall under the threshold of 50 packets. In general, for any\ndirective expecting x activations within time t before raising an\nalarm, n activations must be spread over more than (n/x) IP\naddresses such that an IP address is not reused before t, where\nlowering x makes it harder to slip past but more likely to raise\nfalse alarms.\n\nFig. 6. The OSSIM correlation directive fired upon Havij attack.\n\nE. Simulating a Directive\nUnfortunately, we had difficulty getting our setup of\nOSSIM to perform consistently. Due to limited resources and\ntime, we chose to simulate this directive with a python script\nand a tcpdump file. Tcpdump is a utility that captures traffic\nacross a network in a widely used format. We used tcpdump to\ncapture traffic from an attack. We then used a script to create a\nlog of all the packets that contained the BENCHMARK\ncommand to simulate the snort activations. Using this data,\nour script counted up the number of activations before the\ntimeout for each IP, elevating to level three in the same way\nthat the OSSIM correlation would. An alert was then raised if\nenough activations were found. This is shown in the top part\nof Fig. 7.\nNext, to simulate a distributed attack, we modified the IP\naddresses in the attack traffic so that after every 20 packets the\n\nFig. 7. Top: The attack from a single IP source, that raises an alert from the\ncorrelation angine. Middle: Attack spread across 6 source IP addresses.\nEvents are detected but level 2 is not passed for any source, so no alert is\nraised by the correlation engine. Bottom: A single IP source sends more than\n50 packets (210 packets) in all, showing that level 2 was defeated by temporal\nstaggering of the packets.\n\nIV.\n\nMULTI-AGENT PLAN RECOGNITION\n\nMulti-agent plan recognition (MAPR) refers to the problem\nof explaining the observed behavior trace of multiple agents\nby identifying the (dynamic) team-structures and the team\n\nplans (based on a given plan library) being executed, as well\nas predicting their future behavior [1][2].\nTeam\t\r \xc2\xa01;\t\r \xc2\xa0Goal:\t\r \xc2\xa0TAR\nArm\t\r \xc2\xa01\n\nTeam\t\r \xc2\xa0 2;\t\r \xc2\xa0Goal:\t\r \xc2\xa0AXE\n\nArm\t\r \xc2\xa02\n\nA\n\nR\n\nT\n\nX\n\nArm\t\r \xc2\xa03\n\nArm\t\r \xc2\xa04\n\nA\nT\n\nE\n\nR\nX\n\nE\n\n(Partial)\t\r \xc2\xa0Goal\n\nT\n\nA\n\nA\n\nfail to yield a complete partition hypothesis. In this example,\nagents 1 and 4 would be executing illegal plans individually,\nor building separate stacks as a team, neither of which yields a\nvalid partition hypothesis. Fig. 10 shows a (non-unique) plan\nfrom the library, for start state in Fig. 8 and goal ``TAR\'\', in\nthe form of a plan graph. This is a graph based on the partially\nordered set of steps needed to achieve a goal from a start state,\nwith added constraints for multi-agency: role constraints\n(which steps need to be performed by the same agent) and\nconcurrency constraints (which steps need to be executed\nsimultaneously; not needed in this illustration). The above\nillustration is adopted from a previous paper by the authors\n[2].\n\nX\n\nR\n\n.\t\r \xc2\xa0.\t\r \xc2\xa0.\t\r \xc2\xa0.\t\r \xc2\xa0\n\nE\n\n.\t\r \xc2\xa0.\t\r \xc2\xa0.\t\r \xc2\xa0.\t\r \xc2\xa0\n\nFig. 8. Multi-agent blocks world example.\n\nFig. 10. A plan graph for the blocks world example.\n\nV.\nFig. 9. Trace of activities of 4 robotic arms, shown in Fig. 8\n\nWe first illustrate MAPR in a multi-agent blocks word\ndomain, shown in Fig. 8, Fig. 9, and Fig. 10, using standard\nPDDL operators. In Fig. 8 we see two teams of robotic arms\nassemble (i.e., spell out) the goal words ``TAR\'\' and ``AXE\'\'\nfrom separate stacks, starting from the (not necessarily) same\ninitial configuration. Fig. 9 shows the trace of 6 steps of\nactivities of the 4 robotic arms available to the (remote)\nrecognizer, who is not aware of the team-structure (i.e., the\nmapping of agent-id to stack-id). This assumption partly\nmodels the realistic incomplete information under which the\nrecognizer must operate. While arms 1 and 2 appear to jointly\nassemble ``TAR\'\', and arms 3 and 4 appear to jointly assemble\n``AXE\'\', arms 2 and 3 seem to assemble ``TAX\'\' as well,\ncreating ambiguity for the recognizer. The key insight is to\npartition the trace into non-overlapping team plans, such that\ninvalid teams (such as the supposed team of agents 2 and 3)\n\nAPPLICATION OF MAPR FOR DETECTION OF HAVIJ\nATTACK\n\nThe SQL injection attack of Havij follows a pattern that can\nyield the abstract plan graph shown in Fig. 11.\nFind length\n(=L, say)\n\nBinary Search\n1\n\nBinary Search\n2\n\n\xe2\x80\xa6..\n\nBinary Search\nL\n\nFig. 11. Abstract plan graph corresponding to Havij attack\n\nHere a binary search first finds the length of a certain field,\nsay L. Then L binary searches are done in succession,\nfollowed by a return to the top (abstract) action. Suppose the\nith binary search returns a character that is used to fill the ith\n\ncharacter of a string s. Then the string s[1:L] will be a part of\nthe query used in the next search, e.g., after the name of a\ndatabase is found this way, the queries to detect the names of\ntables in that database will include the name of the database\nalready found. A string that differs by only a few characters\nfrom the database name used later should still be accepted\nbecause of the occasional false positives in the benchmark\ncommand. This pattern repeats to find the names of tables in\nthe database using the database name, and then again to find\nthe column names in a table using that table\xe2\x80\x99s name.\nA solution to the problem of limiting false positives while\nstill detecting an attack that is spread across multiple agents is\nto use plan recognition. Rather than relying on a single IP\ngenerating sufficient suspicious activity to raise an alert, a\nplan recognition algorithm searches input from all users to see\nif steps in a plan have been completed. For this pattern an\nalgorithm would find the length command and then identify\nthe search result by finding the last \xe2\x80\x9c=\xe2\x80\x9d or equivalent symbol.\nIt would then look for that number of binary searches using\nthe ascii and substring commands. If it sees these actions it is\nreasonable to assume that a field name has been found\nwhether spread across multiple agents or not.\nACKNOWLEDGMENT\nThe authors thank the NASA Office of Chief Technologist\nat NASA Stennis Space Center for support under the 2012\nCenter Innovation Fund.\n\nREFERENCES\n[1]\n\nB. Banerjee, L. Kraemer, and J. Lyle. Multi-Agent Plan Recognition:\nFormalization and Algorithms. In Proceedings of AAAI-10, pp. 1059\xe2\x80\x93\n1064, Atlanta, GA, 2010.\n[2] B. Banerjee and L. Kraemer. Branch and Price for Multi-Agent Plan\nRecognition. In Proceedings of the 25th AAAI Conference on Artificial\nIntelligence (AAAI-11), pp. 601\xe2\x80\x93607, San Francisco, CA, 2011.\n[3] Halfond, W. G., Jeremy Viegas, and Alessandro Orso. "A classification\nof SQL-injection attacks and countermeasures." In Proceedings of the\nIEEE International Symposium on Secure Software Engineering, pp. 6581. IEEE, 2006.\n[4] Hankz. H. Zhuo and Lei Li. Multi-agent plan recognition with partial\nteam traces and plan libraries. In Proceedings of the 22nd International\nJoint Conference on Artificial Intelligence (IJCAI-11), pages 484\xe2\x80\x93489,\n2011.\n[5] Hankz. H. Zhuo, Qiang Yang, and Subbarao Kambhampati. Actionmodel based multi-agent plan recognition. In Proceedings of NIPS 2012,\n2012.\n[6] Karg, . OSSIM, "Correlation engine explained.." Last modified\n2004/02/01.\nAccessed\nMarch\n5,\n2013.\nhttp://www.alienvault.com/docs/correlation_engine_explained_rpc_dco\nm_example.pdf.\n[7] Nicolett, Mark, and Kelly M. Kavanagh. "Magic Quadrant for Security\nInformation and Event Management." Gartner RAS Core Reasearch\nNote (May 2009) (2011).\n[8] Roesch, Martin. "Snort-lightweight intrusion detection for networks." In\nProceedings of the 13th USENIX conference on System administration,\npp. 229-238. 1999.\n[9] Zafarullah, Z.; Anwar, F.; Anwar, Z., "Digital Forensics for\nEucalyptus," Frontiers of Information Technology (FIT), 2011 , vol.,\nno.,\npp.110,116,\n19-21\nDec.\n2011\ndoi: 10.1109/FIT.2011.28\n[10] Nurmi, Daniel, Rich Wolski, Chris Grzegorczyk, Graziano Obertelli,\nSunil Soman, Lamia Youseff, and Dmitrii Zagorodnov. "The eucalyptus\nopen-source cloud-computing system." In Cluster Computing and the\nGrid, 2009. CCGRID\'09. 9th IEEE/ACM International Symposium on,\npp. 124-131. IEEE, 2009.\n[11] Karg, D., and J. Casal. Ossim: Open source security information\nmanagement.\nTech.\nreport,\nOSSIM,\n2008.\n\n'