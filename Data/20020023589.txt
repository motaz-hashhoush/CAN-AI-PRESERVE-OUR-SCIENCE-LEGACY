b'[_______I\n\nAIAA 2002-0539\n\nError-Based\nDesign Space Windowing\n\nMelih Papila, Nilay U. Papila, Wei Shyy,\nRaphael T. Haftka and Norman Fitz-Coy\nDepartment\n\nof Aerospace\n\n& Engineering\nUniversity\n\nEngineering,\n\nScience\n\nof Florida,\n\nGainesville,\n\n40th AIAA\n\nAerospace\n\n14-17 January\nFor permission\n\nMechanics\n\nFL\n\nSciences\n\nMeeting\n\n2002 / Reno,\n\nand Exhibit\n\nNevada\n\nto copy or republish, contact the American Institute of Aeronautics and Astronautics,\n1801 Alexander Bell Drive, Suite 500, Reston, Virginia 20191-4344.\n\nERROR-BASED\nMelih\n\nPapila"\n\nSPACE\n\n(papila@aero.ufl.edu)\n\nWei Shyy _ (_,_wss_aero.ufl.edu)\nNorman\n\nDepartment\n\nDESIGN\n\nof Aerospace\nUniversity\n\nNilay\n\nFitz-Coy\n\nEngineering,\nof Florida,\n\nMechanics\nGainesville,\n\nWindowing\nof design space is considered in order to\nreduce\nthe bias errors due to low-order\npolynomial\nresponse surfaces (RS). Standard design space windowing\n(DSW) uses a region of interest by setting a requirement\non\nresponse\nlevel and checks it by a global RS predictions\nover the design\nspace.\nThis approach, however,\nis\nvulnerable\nsince RS modeling errors may lead to the wrong\nregion\nto zoom on.\nThe approach\nis modified\nby\nintroducing an eigenvalue error measure based on point-topoint mean squared\nerror criterion.\nTwo examples\nare\npresented\nto demonstrate\nthe benefit of the error-based\nDSW.\n1. INTRODUCTION\nThe popularity of response surface (RS) techniques in\ndesign optimization\nstudies has brought attention to ways\nof increasing\nthe\naccuracy\nof RS\napproximations.\nAdequacy and accuracy of RS are mainly affected by the\nfollowing three factors:\n\xe2\x80\xa2\nUse of finite number of data points due to cost of\ndata generation\n\xe2\x80\xa2\nNoise in the data\n\xe2\x80\xa2\nInadequacy\nof the fitting model\nWe are mainly\nfocused\nin this paper\non model\ninadequacy\nor bias error\ndue to use of low-order\npolynomials\nsuch as quadratic RS.\nAn obvious way for reducing bias error is to use higher\norder polynomials\nor more complex\nfunctions\nin RS.\nCubic or even higher order polynomials\nwere applied, for\ninstance, by Venter et al. [1] and by Papila (N) et al. [2].\n\nAeronautics\n\n\xc2\xa9 2000\n\nby authors.\n\nand Astronautics,\n\n" Student Member\n, Fellow AIAA\n\xc2\xa7 Member AIAA\n\nAIAA\n\nPublished\nIne\n\nby the American\n\nwith permission.\n\nInstitute\n\nU. Papila"\n\n(nilay@aero.ufl.edu)\n\nRaphael\nT. Haftka\n\xc2\xa7 (nfc@aero.ufl.edu)\n\nABSTRACT\n\nCopyright\n\nWINDOWING\n\nof\n\n* (haftka@ufl.cdt_)\n\n& Engineering\n\nScience\n\nFL 32611\n\nPapila\nand\nHaftka\n[3-4]\nalso\nachieved\nsubstantial\nimprovement\nin accuracy by using cubic polynomials\nin\nRS approximation\nfor HSCT\nwing bending\nmaterial\nweight.\nA high-order\nfitting model, however, requires a large\nnumber of data points, which is usually prohibitive in high\ndimensional problems.\nDesign\nof experiments\n(DOE)\noffers minimum-bias\ncriterion\nfor reducing\nmodeling\n(bias) error when loworder models are used.\nVenter and Haftka [5] developed\nan algorithm implementing\nminimum-bias\nbased criterion,\nnecessary for an irregularly\nshaped design space where no\nclosed form solution exist for minimum-bias\ndesign.\nDecreasing\nbias error is also possible by reducing the\nsize of the fitting region by the use of reasonable-designspace (RDS) approach.\nThe approach starts by identifying\nconstraints specific to the problem of interest provided that\nthey are easy and inexpensive\nto evaluate.\nThese\nconstraints are then used to eliminate unreasonable\ndesigns\nfrom the original\ndesign space.\nFor instance,\nsimple\ngeometric\nconstraints\nwhere\napplicable\nmay prevent\ncombinations\nof design variables resulting in unreasonable\ngeometry configurations\n[4, 6-8].\nFinally, tools of DOE\nsuch as D-optimality\nselect data points within the region of\ninterest where response is evaluated.\nIt is also possible\nto identify\nregion or regions of\ninterest by windowing\nthe design space simply based on\nthe observed or predicted response levels over the design\nspace [2]. The windowing\napproach\nshares the sprit of\nRDS approach in that it reduces bias errors by reducing the\nsize of the design domain.\nHowever,\nwindowing\nneeds\ndata generation\nand a global\nRS beforehand\nunlike\ntraditional RDS approach.\nIn this paper, we aim to focus on improving\nthe RS\naccuracy\nparticularly\nin the regions\ncritical to design\noptimization.\nWe limit ourselves\nto quadratic\nRS\napproximation\nand concentrate\non effective use of design\nspace windowing\n(DSW) approach relying on a global RS.\nStandard\nDSW uses a requirement\nset on the response\nlevel and checks it by using a global RS predictions\nover\n\nAIAA\n\nThe standard\ncondition.\n\nthe whole design space.\nThis approach,\nhowever,\nis\nvulnerable since poor accuracy in the global RS may lead\nus to zoom on the wrong region.\nAt this point, we modify the approach and call it as\nerror-based\nDSW by introducing\na bias error measure.\nThe error measure is based on an eigenvalue\nproblem\nobtained by point-wise\nmean squared\nerror criterion.\nThe eigenvalue problem was derived by Papila and Haflka\n[9] and used as a tool to map qualitatively the RS bias error\nby the associated eigenvalues.\nIn the proposed approach,\nregions with high eigenvalues\ncorresponding to potential\nlarge bias error are excluded from consideration.\nThe\nfollowing\nsection\npresents\nmore\ndetailed\ndescription of the mean squared error criterion and use of\neigenvalues\nin the DSW approach.\nSection 3 describes\nexample\nproblems\nused to demonstrate\nthe approach.\nSection 4 presents the results and discussion followed by\nconcluding\nremarks in Section 5.\nThe derivation\nof\neigenvalue\nproblem along with the background\nfor RS\nmethodology can be found in the Appendix.\n\n._RSI\n\nwhere\n\nSquared\n\nError\n\nwas found\nstudied.\n\neigenvalues\n\n_\n\nand the absolute\nof 2D polynomials\n\n_\n\nDSW\n\nby the global\n\nbound\n\nto define\n\nmodifies\n\nthe\n\nRS (RSI)\nthe region\n\nstandard\n\nDSW\n\n_\n\nYint\n\nand\nof\nby\n\nere-st\n\nand\n\n(2)\n< mean(_\'-_)\n\nwhere\n\nresiduals\nthat were\n\nfield.\n\n2.2 Design Space Windowing\n\nis the response\n\n}RSI\n\nWe also use FCCD as our original DOE, quadratic RS\nas our fitting model and calculate the eigenvalues\nas if the\ntrue function is a cubic. Figure 1 presents the FCCD points\nand relevant\n\nas the reasonability\n\nadding another condition based on the eigenvalues\n[9] that\ncharacterize\nthe modeling\nerror.\nIn order to set a\nprecaution\nfor the possible misleading\ninformation\ndue to\ninaccuracy\nof the global\nRS (RSI),\nour reasonability\nconditions in error-based DSW can be written as follows.\n\nCriterion-Eigenvalues\n\nfor the examples\n\nEq. (l)\n\n(1)\n\n)3RsI is the prediction\n\nYinterest\n\nAn approach for estimating\nRS approximation\nbias\nerrors due to fitting model inadequacy is presented in Ref.\n[9].\nThe mean squared error predictor\n(MSEP) for an\ninadequate model is studied point-to-point\nyielding an\neigenvalue\nproblem where the maximum eigenvalue\nat\neach point provides a relative estimate of maximum bias\nerror.\nWith the calculation of the maximum eigenvalues\nover the design space, regions of possible high bias error\nare identified.\nThe derivation presented in Ref. [9] can\nalso be found in this paper as an Appendix. As can be seen\nfrom the derivation the eigenvalue\nerror measure strongly\ndepends on the DOE used, but not on the response data.\nPapila and Haftka\n[9] used face-centered\ncentral\ncomposite\ndesign (FCCD) and demonstrated the use of\neigenvalue\nestimate of bias error for problems where the\ntrue function is a cubic while the fitting model is quadratic.\nIn particular, positive correlation between the square-root\nof maximum\n\nuses\n\n>- Yinterest\n\ninterest.\nError-based\n\n2. APPROACH\n2.1 Mean\n\nDSW\n\n2002-0539\n\nApproach\n\nWe adopted two types of DSW approaches based on\ndifferent reasonability\nconditions while windowing for the\ndesign region or regions of interest.\nFor simplicity, we\nconsider\nproblems\nwhere we are interested\nin the high\nresponse regions.\n\n2\n\nmean(_f_, c )\n\nis the mean\n\nover\n\nthe design\n\nspace.\n\nDesign points with eigenvalues\nless than their mean over\nthe design space are more likely to be accurately predicted\nby the global RS (RS 1).\nFigure 2 presents the generalized\nflowcharts\nfor the\nstandard and error-based\nDSW approaches.\nThe following\ndescriptions\ngive the details of our implementation\nin the\nflowcharts.\nStandard\nDSW Approach (Figure 2a):\nStep 1: We start with a standard DOE, face-centered\ncentral composite\ndesign\n(FCCD)\nfor Data set l and\nconstruct a global RS approximation\n(RS 1).\nStep 2: We use the global RS (RS1) to predict the\nresponse values on design points of a fine grid netting the\nwhole design space.\nStep 3: We identify design region or regions of interest\nbased on the predictions\nin Step 2. We build a pool of\nsupposedly\nreasonable\ndesigns by simply disregarding\nthe\ndesigns violating the condition in Eq. (l). This is done for\neach identified region in case of multiple disjoint regions\nof interest.\nStep 4: Among the designs located in the pool of Step\n3, the number of data points is reduced to a desirable\namount by using D-optimality.\nWe include design points\nof Data set 1 where data itself is in the region of interest\n(Y_Yinterest)"\n\nThis\n\nreduces\n\nthe\n\nnumber\n\nof\n\nadditional\n\nevaluations for creating Data set 2. We then construct new\nRS (RS2) approximation\nto be used over the associated\nregion only. (In case of multiple regions separate RS2 s\nare constructed)\nError-based\nDSW Approach\n(Figure 2b):\nStep 1: Same as Step 1 of standard approach\nStep 2: We use the global RS (RSI) to predict the\nresponse\nvalues and calculate\nthe eigenvalues\non design\npoints of a fine grid netting the whole design space.\n\nAIAA\n\nStep 3: We identify\ncombining\n\neigenvalue\n\ndesign\n\nregion or regions\n\ninformation\n\n()xD-_-_G) with\n\nstandard DSW approach by Eq. (2).\nStep 4: Same as Step 4 of standard\ndenoting RS in refined regions as RS3.\n\nquartic\n3\n\nof interest\nthe\n\napproach\n\nexcept\n\nTurbine\n\n+0.000486xlx\n\n_ +0.486381x_x\n\nwhere xland\n\nDesign\n\n\xe2\x80\xa2 rms-error\n\nFigure\n\nPredictor: V\n\nas coded\n\naerodynamic design software called Meanline Flow Path\nGenerator\n[I0, 16] that allows rapid analyses of turbine\nflow fields. Using the overall turbine and stage input, the\nMeanline code first generates a candidate turbine flow path\nand displays a plot of the elevation view. The code then\nruns a 1-D quick aerodynamic analysis, calculating gas\nconditions,\nvelocity\ntriangles,\nand required number of\nairfoils,\npredicted\nefficiency\nand power output.\nIn\nturbomachinery design problems, high efficiency and low\nweight systems are sought.\nFor this design problem, the\ncompromise between these two criteria can be quantified\nby a single response\nthat is payload of the RLV.\nTherefore, the output or response\nof interest from the\nMeanline code is the change in payload compared to a\nfixed baseline design (i.e. dpay). We are mostly interested\nin positive dpay designs (i.e., dpay>O).\nin Two-Dimension\n\nWe wanted to mimic the efficiency data of supersonic\nturbine blade shape optimization\nproblem [10] in terms of\nthe range of response values as varying between 0 and 1.\nSince we are mainly interested in high efficiency regions in\nturbomachinery\ndesigns,\nwe will consider y>0.7 as the\nregion of interest for this problem.\nA quartic function\nin 2-D is devised with variables\nranging between -1 and +1 (as coded variables).\nThe\n\n3\n\ntins-error:\n\n1.\n\nAND DISCUSSION\nroot-mean-\n\n--Yi )2\n"N\n\n[M-N\n\n\xe2\x80\xa2 Testing\n\nPolynomial\n\n(-1,+l)asshownin\n\nin Two-\n\n(3)\n\n2\n\n,/_(Y,\n\nvariables xl and x2 in (-1,1), respectively [15]. The design\ndomain of the coded variables is a square as shown in\nFigure 1.\nThe\nnumerical\nsimulations\nare based\non\nthe\n\n3.2 Quartic\n\n2\n\nWe assess the accuracy of RS using mainly\nsquared (rms) error calculations.\n\n21,977\n\n). They are normalized\n\nx2rangein\n\nin Eq.\n\n2\n\n+0.000486x_x\n\n4. RESULTS\n\n\xe2\x80\xa2 Testing\n\n_<40,814\n\n0 and 1 is given\n\n+0.000486xtx\n\n+0.012646x_\n\nIn our previous efforts [2, 10-14], we have studied the\npreliminary and detailed design optimization of supersonic\nturbines for reusable launch vehicle (RLV). A two-variable\nversion\nof the two-stage\nturbine design\nproblem\nis\nconsidered in this study.\nThe design variables are the\nmean diameter, D, and RPM (5.081 <_D(in) < 15.243 and\n_<RPM\n\nbetween\n\n-0.242704x_\n\nWe investigate\ntwo different\ntest problems\nto help\nassess the performance\nof the strategies explained above:\n(1) Two\ndimensional\npreliminary\nsupersonic\nturbine\ndesign, and (2) A quartic polynomial\nin two dimensions.\nThe main reason for choosing 2D problems is that we want\nto visualize easily the response surface, prediction\nerror\nand eigenvalue field distributions.\nSupersonic\n\nranges\n\ny = 0.742 +0.000486x_\n\n3. TEST PROBLEMS\n\n3.1 Preliminary.\nDimension\n\npolynomial\n\n2002-0539\n\n2\n\nV\n\nM--- N\n\nwhere N, rib, M number of data set points, number of\ncoefficients\nin RS and number of design points in the\ndesign space grid, respectively.\nI_,(y,-_i)\nrms-error\n\nK is the number\n\nin y >\n\nYint\n\ncrest\n\nof the testing\n\n:\n\ni\n\nK\n\n2\nwhere\n\ndata in y > Yinterest region\n\nexcluding the data points of the associated RS.\nFace-centered\ncentral\ncomposite\ndesign\n(FCCD)\nas\nshown in Figure 1a is used for fitting a quadratic global RS\n(RS1). We use 21 by 21 grid over the design space for the\nevaluation\nand assessment\nof the methods\nare used.\nTherefore,\nN = 9, nb= 6 and M=441.\nK is problem\ndependent as reported on the tables.\nThe\n\neigenvalue\n\ndistribution\n\n( 2xf_-G is a function\n)\n\nof\n\nDOE, the fitting model and assumed true model [9]. We\nuse FCCD as our DOE, quadratic RS as our fitting model\nand calculate the eigenvalues\nas if the true function is a\ncubic.\n\nTherefore\n\nproblems\n(i) Results\n\nas shown\n\ndistribution\nin Figure\n\nfor Turbine\n\nof _\n\nis identical\n\nfor both\n\nlb.\n\nDesign\n\nThe Meanline results (exact function for turbine design\nproblem) are shown as a contour plot in Figure 3a. Three\nquadratic RS models were studied. The details of these RS\nmodels are given below.\n\xe2\x80\xa2\nRS 1: Quadratic\nRS based on 9 design selected by\nstandard\nFCCD\n(Figure\nla).\nIts prediction\nerror\ncontours are given in Figure 3b.\n\xe2\x80\xa2\nRS 2: Quadratic\nRS based on 9 reasonable\ndesigns\nusing standard DSW condition.\nFour of the points\nare original FCCD points, which satisfy Apay>O. The\nother five designs are selected\nfrom the designs of\n\nAIAA\n\n\xe2\x80\xa2\n\npositive RS 1 predictions\nof the dpay calculated in 21\nby 21 grid over the design space.\nDesign points are\nshown in Figure 4a.\nRS 3: Quadratic\nRS based on 9 reasonable\ndesigns\nusing error-based\nDSW conditions.\nFour of them\nare FCCD points, which satisfy Apay>O. The other\nfive designs are selected from the designs where RS 1\npredicts\npositive\nApay\nand eigenvalue\ncondition\nsatisfied.\nDesign points are shown in Figure 4b.Table\n1 summarizes\nthe statistics\nof the three RS of the\nturbine problem.\nIt appears that rms-error predictor of\nRS1 is conservative\nas the testing rms-error\nis less\nthan the half of the predictor.\nTesting rms-error\nin\nregion of interest is 63.5, slightly higher than overall\ntesting rms-error.\nBoth approximations\nof windowing\napproaches,\nRS2 and RS3, resulted in smaller testing\nrms-error in region of interest than RS 1 as expected.\nThere is factor of about 2.8 and 4.2 in the magnitudes\nfor RS2 and RS3, respectively,\ncompared to RS1. This\nindicates that error-based\nDSW approach improved on\nthe standard\none.\nThe substantial\nincrease in the\n\noverall testing rms-error\nand max. error reflects the\nfact DSW approach approximations\nRS2 and RS3 are\nnot accurate outside of the region of interest. This can\nalso be observed on the RS2 and RS3 prediction error\ncontours,\nFigure\n5a and Figure\n5b, respectively.\nComparison\nof error contours given in Figure 3b and\nFigure 5 demonstrate\nthe benefit from the windowing\napproaches\nwhere we are most interested.\nIn spite of\nthe fact that maximum\nerror in region of interest by\nRS3 is higher than RS2 (Table 1), more uniform lowerror distribution\nin Figure 5b compared to Figure 5a\nand reduction in testing rms-error in the same region\nshows us that we benefit from eigenvalue\ninformation\nduring windowing.\nIn order to check if the eigenvalues (bias error measure)\nhelped us to select design points with more accurate RS 1\npredictions,\nwe compare error at selected points in Table 2\nand Table 3. The tables report the error measure\n\n_\n\nand\n\nRS1 prediction\nerrors at the RS2 and RS3 design points,\nrespectively.\nExcluding\nfour common\ndesign\npoints\ncoming from the original FCCD, average error (average\nerror of the boldface rows) decreases from 66.4 in Table 2\nto 45.7 in Table 3. This confirms the usefulness\nof the\neigenvalues\n\nfor this example.\n\n(ii) Results\n\nfor Quartic\n\nconnected regions as a single region of interest around one\ndiagonal\nof the domain.\nWe first present the single\ncontinuous\nregion\nconsideration;\nwindowing\nas single\nregion.\nThen present results of windowing\nas multiple\nregions.\n(a) Windowing\nas single region\nFour quadratic RS models were studied for the overall\ndesign domain. The details of these RS models are given\nbelow.\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nRS 1: Quadratic\nRS based on 9 designs selected by\nstandard\nFCCD\n(Figure\n1).\nIts prediction\nerror\ncontours are given in Figure 6b\nRS 2: Quadratic\nRS based on 9 reasonable\ndesigns\nusing standard\nDSW condition.\nFour of the data\npoints are FCCD points, which satisfy y>0.7.\nThe\nother five designs are selected\nfrom the designs of\npositive RS 1 predictions\nof the y calculated\nin 21 by\n21 grid over the design space. Design points and error\ncontours\nare shown\nin Figure\n7a and Figure\n8a,\nrespectively.\nRS 3: Quadratic\nRS based on 9 reasonable\ndesigns\nusing error-based\nDSW conditions.\nFour of the data\npoints are FCCD points, which satisfy y>0.7.\nThe\nother five designs are selected from the designs where\nRS 1 predicts y higher than 0.7 and eigenvalue\ncondition satisfied.\nDesign points and error contours\nare shown in Figure 7b and Figure 8b, respesctively.\nRS 4: Quadratic\nRS based on RS 1 and RS 3 design\npoints (13 designs in total). Design points are shown\nin Figure 9a.\nTable 4 summarizes\nthe statistics\nof the four RS.\n\nUnlike turbine problem, rms-error predictor of RS I (equal\nto zero) suggesting perfect fit gives a sense of security that\nis proved to be wrong by the nonzero testing rms-error.\nTesting rms-error in region of interest is even higher and\nequal to 0.051. Both approximations\nof DSW approaches,\nRS2 and RS3, resulted in higher testing rms-error in region\nof interest\nthan RS1.\nThey\nare 0.073\nand 0.063,\nrespectively.\nThis\nindicates\nthat\nerror-based\nDSW\napproach\nimproved\non the standard one for the single\nwindowing,\nbut neither DSW helped to increase accuracy\ncompared to RS 1 with single windowing.\nFigure 8a and b\nalso compares visually the two DSW approaches\nin terms\nof error distribution.\nIt shows that error-based\nDSW\nresulted smaller errors at remote locations of the quadrants\nforming the region of interest.\nTable\n\nPolynomial\n\nContour plot for quartic example response\ngiven in\nFigure 6a shows that we can consider two separate regions\nof interest:\nupper-right\nand lower-left\nquadrants\nof the\nsquare design domain.\nThis observation\nand the logic\nbehind the windowing\nprocedure\nlead us to evaluate each\nregion separately.\nThe regions, on the other hand, are not\ncompletely\nremote and disjoint.\nTherefore,\nwe also want\nto see the effect of employing the DSW approaches\non the\n\n4\n\n2002-0539\n\n5 and Table\n\n6 show\n\nerror\n\nmeasure\n\n_\n\nand\n\nRS1 prediction errors at the RS2 and RS3 design points,\nrespectively.\nExcluding\nfive common\ndesign\npoints\ncoming from the original FCCD average error (average\nerror of the boldface rows) decreases from 0.0916 in Table\n2 to 0.0868 in Table 3.\nThe best performance\namong the four RS was obtained\nby RS4 (Figure 9). Although its rms-error predictor is the\nlargest we obtained\nsmallest\noverall testing tins-error,\n\nAIAA\n\xe2\x80\xa2\n\ntesting rms-error\nand maximum\nerror in the region of\ninterest.\nIn other words, adding new data points selected\nby DSW to the original FCCD improved the accuracy.\n(b) Windowing\nas multiple regions\nWe report results only on the upper-right\nquadrant\nsince the results of lower-left quadrant are mirror image of\nthe upper right.\nFor the statistics and design points we\nconsider 11 by 11 grid points in the quadrant.\nTwo RS\nwere constructed\nas described below\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nRS 5: Quadratic\nRS based on 9 reasonable\ndesigns\nusing standard\nDSW condition.\nThree of them are\nFCCD points,\nwhich\nsatisfy y>0.7.\nThe rest is\nselected\nfrom the designs\nof RS 1 predictions\nexceeding\n0.7. Design points for RS 5 are shown\nFigure 10a.\nRS 6: Quadratic\nRS based on 9 reasonable\ndesigns\nusing error-based\nDSW condition.\nThree of them\nare FCCD points, which satisfy y>0.7.\nThe rest of is\nselected from the designs where RS 1 predicts y higher\nthan 0.7 and eigenvalue\ncondition\nsatisfied.\nDesign\npoints for RS 5 are shown Figure 10b.\nTable 7 summarizes\nthe statistics\nof the two RSs.\n\nOverall testing rms-error and testing rms-error in region of\ninterest is lower by standard DSW than error-based\nDSW\n(overall: 0.042 and 0.046, respectively,\nand in the region of\ninterest: 0.026 and 0.030, respectively).\nIn other words,\nstandard DSW did a better job compared\nto error-based\napproach\nin this example.\nOne possible reason is that\nintroducing\nthe\nerror-based\ncondition\nmay\nincrease\nirregularity\nof the domain of interest.\nWe also calculated\nthe RS 1 testing rms-error\nin region of interest over this\nparticular\nquadrant\nas 0.061\nthat shows\nboth DSW\napproaches\nhelped us to lower by half. Figure 11 presents\nthe error contour for RS5 and RS6. The location of high\nerrors seemed to be shifted by the error-based DSW.\nTable 8 and Table 9 present eigenvalue\nbased error\nmeasure\n\n_\n\nand RSI\n\nprediction\n\nerrors\n\nat the RS5 and\n\nRS6 design points, respectively.\nAlthough we did not see\nbenefit from the error-based\nDSW in terms of statistics,\nthese tables\nshow that eigenvalues\ncondition\nin fact\nselected points with lower errors.\nExcluding five common\ndesign points average error (average error of the boldface\nrows) decreases from 0.0943 to to 0.0658.\n5. CONCLUDING\n\nREMARKS\n\nIn this paper we focused on the model inadequacy or\nbias error due to use of low-order polynomials\nsuch as\nquadratic RS and increased accuracy by design space\nwindowing\n(DSW\'). We set a requirement on the response\nbased on a global RS and zoom with a local RS on that\nregion.\nSince the modeling errors may lead us to the\nwrong region to zoom on, we integrated an eigenvalue\nerror measure into the procedure and called it error-based\nDSW.\nTwo examples were studied to demonstrate\nthe\nbenefit from error-based DSW:\n\n5\n\n\xe2\x80\xa2\n\n2002-0539\n\nIn two-dimensional\ntwo-stage\nturbine problem\none\nregion\nof interest\nwas\nidentified.\nBoth\nDSW\napproaches\nimproved\non the global\nRS accuracy.\nStatistics\nshowed that accuracy obtained\nafter errorbased\nDSW\nincreased\nin the region\nof interest\ncompared to standard DSW\nIn quartic polynomial\nexample\ntwo regions\nwere\nidentified.\nIn each region DSW approaches\noffered\nsubstantial\nimprovement\nin accuracy\ncompared\nto\nglobal RS. The error-based\nDSW, however, did not\nbring\nimprovement\nover\nthe\nstandard\napproach\npossibly due to increased irregularity\nof the region of\ninterest caused by the eigenvalue condition.\nFor both examples,\nthe average\nerrors at the data\npoints are lower after the selection\nby error-based\nDSW.\nThis is an indication\nthat modified\napproach\nemploying\neigenvalues\ndisregarded\ndesign\npoints\nwhere reasonability\nbased on RS 1 prediction\nmay be\nmisleading.\n6. ACKNOWLEDGEMENT\n\nThis work has been partially\nsupported\nby NASA\nMarshall Space Flight Center, Mr. Kevin Tucker project\nmonitor and by NASA Grant # NAG 1-2177.\n7. REFERENCES\n1. Venter, G., Ha_ka,\nR. T., and Starnes, J. J. H.,\n"Construction\nof Response\nSurface Approximations\nfor\nDesign\nOptimization,"\n6 th AIAA/USAF/NASA/ISSMO\nSymposium\non\nMultidisciplinary\nAnalysis\nand\nOptimization,\nBellevue, Washington,\n1996.\n2. Papila, N., Shyy, W., Griffin, L., Huber, F., and\nTran,\nK.,\n"Preliminary\nDesign\nOptimization\nfor a\nSupersonic\nTurbine\nfor\nRocket\nPropulsion,"\nAIAA/SAE/ASME/ASEE\n36th\nJoint\nPropulsion\nConference,\nAIAA Paper 2000-3242,\nJune 2000.\n3. Papila, M. and Haftka,\nR. T., "Uncertainty\nand\nWing Structural\nWeight\nApproximations,"\nProceedings,\n40th\nAIAA/ASME/ASCE/ASC\nStructures,\nStructural\nDynamics,\nand Material\nConference,\nPaper AIAA-991312, pp. 988-1002, St. Louis, MO, April 1999.\n4. Papila, M. and Haftka, R. T., "Response\nSurface\nApproximations:\nNoise,\nError\nRepair\nand Modeling\nErrors," AIAA Journal, 38(12), pp. 2336-2343,\n2000.\n5. Venter, G., and Haftka R.T., "Minimum-Bias\nBased\nExperimental\nDesign for Constructing\nResponse\nSurfaces\nin\nStructural\nOptimization"\nProceedings,the\n38th\nAIAA/ASME/ASCE/AHS/ASC\nStructures,\nStructural\nDynamics,\nand Materials\nConference,\nPaper AIAA-971053, Part 2, pp. 1225-1238, Kissimmee, Florida, April 710, 1997.\n6. Kaufman,\nM., Balabanov,\nV., Burgee,\nS. L.,\n"Variable-Complexity\nResponse\nSurface Approximations\nfor\nWing\nStructural\nWeight\nin\nHSCT\nDesign,"\nComputational\nMechanics,\n18, pp. 112-126, 1996.\n\nAIAA\n\n7. Roux,\nW.J.,\nStander,\nN., and Haftka,\nR.T.,\n"Response\nSurface\nApproximations\nfor\nStructural\nOptimization,"\nInternational\nJournal\nfor\nNumerical\nMethods in Engineering,\n42, pp. 517-534, 1998.\n8. Balabanov,\nV. O., Giunta, A. A., Golovidov,\nO.,\nGrossman,\nB., Mason, W.H., Watson,\nL.T., and Hafika,\nR.T., "Reasonable\nDesign Space Approach\nto Response\nSurface Approximation,\n" Journal\nof Aircraft\nVol. 36,\nNo.l, 1999, pp. 308-315.\n9. Papila, M. and Haftka, R. T., "Uncertainty\nand\nResponse\nSurface\nApproximations,"\n42nd\nAIAA/ASME/ASCE/ASC\nStructures,\nStructural\nDynamics,\nand Material\nConference,\nPaper AIAA-011680, Seattle, WA, April 2001.\n10. Papila, N., Shyy, W., Griffin, L., and Dorney, D.J.,\n"Shape\nOptimization\nof Supersonic\nTurbines\nUsing\nResponse\nSurface and Neural Network Methods, " AIAA\n39th Aerospace\nSciences\nMeeting\n& Exhibit,\nReno,\nNeveda, AIAA Paper 2001-1065, January 2001.\n11. Shyy, W., Papila, N., Tucker, P. K., Vaidyanathan,\nR., and Griffin L., "Global Design Optimization\nfor Fluid\nMachinery\nApplications,"\nProceeding\nof the Second\nInternational\nSymposium\non Fluid Machinery\nand Fluid\nEngineering,\nOctober, Beijing, China, 2000, pp. 1-10.\n12. Shyy, W., Papila,\nN., Vaidyanathan,\nR., and\nTucker,\nP.K.,\n"Global\nDesign\nOptimization\nfor\nAerodynamics\nand\nRocket\nPropulsion\nComponents,"\nProgress in Aerospace Sciences, Vol. 37, 2001, pp.59-118.\n13. Vaidyanathan,\nR., Papila, N., Shyy, W., Tucker,\nP.K., Griffin, L. W., Fitz-Coy,\nN., and Haftka,\nR.T,\n"Neural\nNetwork-based\nand Response\nSurface-based\n\nTable 1: Statistics\n\nof the\n\nRSquare Adj\nrms-error Predictor\n\n-432.831\n\nMean\n\nOptimization\nStrategies\nfor Rocket\nEngine Component\nDesign," 8th AIAA/USAF/NASA/ISSMO\nSymposium\non\nMultidisciplinary\nAnalysis and Optimization,\nLong Beach,\nCalifornia, September 2000.\n14. Griffin, L. W., Dorney, D. J., Huber, F., Shyy, W.,\nPapila, N., and Tran, K., "Detailed Aerodynamic\nDesign\nOptimization\nof\nan\nRLV\nTurbine,"\nAIAA/SAE/ASME/ASEE\n37th\nJoint\nPropulsion\nConference and Exhibit, Salt Lake City, Utah, AIAA Paper\n2001-3397, June 2001.\n15. Myers, R. H., and Montgomery,\nD. C., Response\nSurface Methodology\n-Process\nand Product Optimization\nUsing Designed Experiments,\nNew York: John Wiley &\nSons, Inc., 1995, pp.208-279.\n16. Huber, Frank, "Turbine Aerodynamic\nDesign Tool\nDevelopment",\npresented\nat the Space Transportation\nFluids Workshop, Marshall Space Flight Center, AL, April\n2001.\n17. Hafika,\nR.T.,\nScott,\nE.P.,\nand Cruz,\nJ.R.,\n"Optimization\nand Experiments:\nA Survey,"\nApplied\nMechanics Reviews, Vol. 51, No. 7, 1998, pp. 435-448.\n18. Khuri, A. I. and Comell, J. A., Response Surfaces:\nDesigns\nand Analyses,\n2nd edition, New York, Marcel\nDekker Inc., 1996, pp. 207-247.\n19. Seber, G. A. F., Linear Regression\nAnalysis, New\nYork, Wiley, 1977.\n\nlobal fits for turbine design problem\nRS 2\nRS 3\nRS 1\n(Standard DSW)\n(Error-based\nDSW)\n(FCCD)\n0.998\n0.998\n0.984\n151.947\n\n19.053\n\n22.103\n\n513.476\n\n502.470\n\n4/9\n\n9/9\n\n9/9\n\nrms-error\n\n60.583\n\n171.830\n\n133.616\n\n#of the testing data, (M-N)\n\n432\n\n432\n\n432\n\n63.546\n\n22.645\n\n15.106\n\nObservations\nTesting\nTesting\n\nin Apay >0 / Observations,\n\ntins-error\n\nin Apay >0\n\n#of the testing data in Apay >0, K\n\nN\n\n193\n\n188\n563.886\n\n188\n\nMean of the testing data in Apay >0\n\n505.870\n\nMax. Error in Apay >0\nMax. Error\n\n160.897\n\n45.356\n\n96.660\n\n160.897\n\n885.188\n\n692.394\n\n6\n\n2002-0539\n\n554.938\n\nAIAA\n\nTable 2:RS1\n\nerror at RS 2 data points for turbine\nStandard\nD\n\nDSW.\n\ndesign\n\nAverage\n\nRPM\n\nerror\n\nproblem.\n\nBold face rows are design points selected\n\nof the boldface\n\nrror\n\n1\n\n212.66\n\n0\n\n62.51\n\n0.715\n\n15.75\n\n4.58\n\n0.497\n\n11.17\n\n0\n\n806.18\n\n677.3I\n\n0.832\n\n128.87\n\n0.3\n\n0\n\n983.04\n\n928.90\n\n0.792\n\n54.14\n\n-0.5\n\n18.71\n\n16.22\n\n0.654\n\n2.49\n\n-0.6\n\n130.77\n\n40.51\n\n0.662\n\n90.26\n\n630.5\n\n565.97\n\n0.832\n\n64.53\n\n749.29\n\n714.34\n\n0.815\n\n34.95\n\n1074.38\n\n1173.87\n\n0.762\n\n99.49\n\n0.6\n\n0.2\n\nerror at RS 3 data points\nerror-based\n\nfor turbine\n\nDSW. Average\n\nD\n\nRPM\n\n-0.3\n0\n\ndesign problem.\n\nerror\n\n150.15\n\nBold face rows are design points\n\nof the boldface\n\nrows decreases\n\nselected\n\nto 45.7\n\nrror\n\n0.5\n\nApay\n108.41\n\n33.52\n\n0.634\n\n74.89\n\n0\n\n15.75\n\n4.58\n\n0.497\n\n11.17\n\n0\n\n1\n\n806.18\n\n677.31\n\n0.832\n\n128.87\n\n0.3\n\n-0.3\n\n4.6\n\n14.34\n\n0.568\n\n9.74\n\n0.5\n\n0.4\n\n728.89\n\n703.76\n\n0.645\n\n25.13\n\n0.7\n\n1\n\n1068.91\n\n1127.53\n\n0.613\n\n58.62\n\n0.9\n\n-0.6\n\n84.61\n\n24.46\n\n0.599\n\n60.15\n\nl\n\n0\n\n630.5\n\n565.97\n\n0.832\n\n64.53\n\n1074.38\n\n1173.87\n\n0.762\n\n99.49\n\nTable 4: Statistics\n\nof the RS fits for t\nRS 1\n(FCCD)\n\nR\'S2\n\n_RSquare Adj\n\n1.000\n\n(Standard\nDSW)\n0.990\n\n_ms-error\n\n0.000\n\n0.015\n\nPredictor\n\n0.5800\n\nRS 3\n(Error-based\nDSW)\n0.847\n\n.\n\nRS 4\n(RS 1 + RS 3\ndesign points)\n0.880\n\n0.056\n\n0.115\n\n0.829\n\n0.653\n\n7/9\n\n7/9\n\n7/9\n\n0.08\n\n0.260\n\n0.259\n\n0.075\n\n432\n\n432\n\n432\n\n428\n\n0.051\n\n0.073\n\n0.063\n\n0.039\n\n200\n\n198\n\n198\n\n198\n\nMean of the testing data in y >0.7\n\n0.789\n\n0.794\n\n0.765\n\n0.776\n\nMax Error in y>0.7\n\n0.161\n\n0.149\n\n0.159\n\n0.109\n\nMax. Error\n\n0.192\n\n0.778\n\n0.750\n\n0.217\n\nFesting\n\nin y >0.7 / Observations,\n\nrms-error\n\n_of the testing data, (M-N)\nFesting\n_ofthe\n\nrms-error\n\nin y >0.7\n\ntesting data in y >0.7, K\n\nN\n\n7\n\n75164\n\n,nomial\n\n5/9\n\nMean\n9bservations\n\nby\n\nrows is 66.4\n\nApay\n\n-0.5\n\nTable 3:RS1\n\n2002-0539\n\nby\n\nAIAA\n\nTable 5: RS 1 error at RS 2 design\nStandard\n\npoints for quartic\nDSW. Average\n\nerror\n\npolynomial.\n\nBold face rows are design points\n\nof the boldface\nRS\n\n0.9731\n\n0.762\n\n0.0003\n\n0\n\n0.7296\n\n0.7292\n\n0.831\n\n0.0003\n\n-0.5\n\n-1\n\n0.5582\n\n0.7358\n\n0.715\n\n0.1775\n\n0\n\n0\n\n0.7417\n\n0.7417\n\n0.497\n\n0.0000\n\n0.1\n\n0\n\n0.7417\n\n0.7430\n\n0.499\n\n0.0013\n\n0.5\n\n1\n\n0.5621\n\n0.7494\n\n0.715\n\n0.1873\n\n1\n\n-0.1\n\n0.7037\n\n0.7040\n\n0.827\n\n0.0003\n\n1\n\n0\n\n0.7549\n\n0.7552\n\n0.831\n\n0.0003\n\n1\n\n1\n\n1.0000\n\n0.9997\n\n0.762\n\n0.0003\n\n-1\n\nTable 6: RS 1 error at RS 3 design points for quartic polynomial. . Bold face rows are design points\nerror-based DSW. Average error of the boldface rows is 0.0868\n_-\n\n0.9731\n\n0.762\n\n0.9509\n\n0.9509\n\n0.613\n\n0.0000\n\n0.7296\n\n0.7292\n\n0.831\n\n0.0003\n\n-1\n\n0.6615\n\n0.8307\n\n0.613\n\n0.1692\n\n0\n\n0\n\n0.7417\n\n0.7417\n\n0.497\n\n0.0000\n\n0.7\n\n1\n\n0.6714\n\n0.8495\n\n0.613\n\n0.1781\n\n-1\n\n-0.7\n\n-1\n\n0\n\n-0.7\n\n0\n\n0.7549\n\n0.7552\n\n0.831\n\n0.0003\n\n0.7\n\n0.9773\n\n0.9773\n\n0.613\n\n0.0000\n\nl\n\n1.0000\n\n0.9997\n\n0.762\n\n0.0003\n\npolynomial in upper-right\n0.061 b), RS 1\n\nRS fits forqua_ic\n\nquadrant\nRS 5\n\n(Standard DSW)\n0.905\n\nRSquare Adj\ntins-error Predictor\n\nwhere testing rms-error\nRS 6\n(Error-based\n0.840\n\n0.043\n\n0.049\n\n0.755\n\n0.778\n\n7/9\n\n7/9\n\nrms-error\n\n0.042\n\n0.046\n\n#of the testing data, (M-N)\n\n112\n\n112\n\n0.026\n\n0.030\n\n74\n\n74\n\nMean of the testing data in y >0.7\n\n0.790\n\n0.796\n\nMax Error in y>0.7\n\n0.060\n\n0.054\n\nMean\n\nresting\n\nresting\n\nby\n\n0.0003\n\n-1\n\ny\n0.9728\n\nYRSl\n\nselected\n\nError\n\nx2\n-1\n\nXI\n\nObservations\n\nby\n\nError\n\n1\n\n-1\n\nX2\n\n-1\n\nofthe\n\nselected\n\nrows is 0.0916\n\nY\n0.9728\n\nXI\n\nTable 7:Statistics\n\n2002-0539\n\nin y >0.7 / Observations,\n\nrms-error\n\nin y >0.7\n\n#of the testing data in y >0.7, K\n\nFor the comparison,\n\ntest points\n\nN\n\nare the designs of the relevant\n\nquadrant.\n\nDSW)\n\nin y >0.7 is\n\nAIAA\n\nTable 8: RS 1 error at RS 5 design points\nb_, Standard\n\nfor quartic\n\nDSW. Avera[[e\n\npolynomial\n\nin upper-right\n\nerror of the boldface\n\nquadrant.\n\n2002-0539\n\nBold face rows selected\n\nrows is 0.0943\nRSI\n\nError\n\n0\n\n0\n\nY\n0.7417\n\n0.4969\n\n0.742\n\n0.0000\n\n0\n\n0.4\n\n0.7029\n\n0.5708\n\n0.703\n\n0.0001\n\n0.3\n\n0.8\n\n0.5975\n\n0.7042\n\n0.707\n\n0.1099\n0.0049\n\nXl\n\nX2\n\n0.5\n\n0\n\n0.7434\n\n0.6175\n\n0.748\n\n0.5\n\n1\n\n0.5621\n\n0.7148\n\n0.749\n\n0.1873\n\n0.6\n\n0.4\n\n0.7481\n\n0.6615\n\n0.828\n\n0.0798\n\n1\n\n0\n\n0.7549\n\n0.8315\n\n0.755\n\n0.0003\n\n1\n\n0.5\n\n0.9380\n\n0.7148\n\n0.938\n\n0.0001\n\n1\n\n1\n\n1.0000\n\n0.7617\n\n1.000\n\n0.0003\n\nTable 9: RS I error at RS 6 design points for quartic\nby error-based DSW. Average\n\n0\n\n0\n\npolynomial in upper-right\nquadrant. Bold face rows selected\nerror of the boldface rows is 0.0658\nRSI\n\nError\n\n0.4969\n\nY\n0.7417\n\nX2\n\nXI\n\n0.742\n\n0.0000\n\n0\n\n0.4\n\n0.7029\n\n0.5708\n\n0.703\n\n0.0001\n\n0.1\n\n0.5\n\n0.6814\n\n0.6193\n\n0.707\n\n0.0255\n\n0.5\n\n0\n\n0.7434\n\n0.6175\n\n0.748\n\n0.0049\n\n0.5\n\n0.3\n\n0.7400\n\n0.6341\n\n0.800\n\n0.0597\n\n0.7\n\n1\n\n0.6714\n\n0.6128\n\n0.849\n\n0.1781\n\n1\n\n0\n\n0.7549\n\n0.8315\n\n0.755\n\n0.0003\n\n!\n\n0.7\n\n0.9773\n\n0.6128\n\n0.977\n\n0.0000\n\n1\n\n1\n\n1.0000\n\n0.7617\n\n1.000\n\n0.0003\n\n_cu_\n\nI\n\n0797\n0829\n0365\n137_\n0701\n0 669\n0837\n0605\n0573\n0541\n0509\n0477\n04\'r_\n\n\xc2\xa3\n-1-1\n\n0.5\n\n-0.5\n\n0\n\n0,5\n\nx_\n\n(a) FCCD\nFigure\n\n1: Design\n\nspace for two-variable\n\n(b) _-_-c con tours\nexamples:\n\nFCCD\n\n9\n\ndesign points and _f_-\'c con tours (Mean\n\n_-_--c =0.0646)\n\nAIAA\n\n2002-0539\n\nGlobal RS\nGlobal RS\nModel\n\nI\n\nI\n\nPrediction\n\n[\nII\n\nby RS at\nmanypoints\n\n:1\n\ni;)\n\nI\n\n,\n\nEigenvaluesat\n\n...........[-1-,\n.................. .............. 15:---:1r\n7\n\n,, ,.z__________.__\n/I\ni \'\n\nModel\n......\n/\n\nt.\n\nIIy\n\n,\n\nGrid points\n\nI It of design\nI I _x space\n\nI \\1\nr\n\nPrediction\n\ni\n[\n]\n\nbyRS at\n\nil\n\n]l\n\nL_\n\nII t_l\n\nmanypomts\ny )\n\nmanypoints\n\nI L.] "_\n__1\nI\n\n(\n\n_/ Grid points\n\n[\nI\n\n( _G\n\n/\n\nof design\n\n/\n\nI1_\n\n)\n\nI U\\\n\nspace\n\\l\n\n_\n\n.....L__L---J-"_\n\nl\n\n\'\n\n,\n\n---i\n.==\n....................\n\nI\n\nI\n\nI\n\nI\n\nII.....................................\n\nI\n\n\',_._\n\ni: _\n\n#\n\nReasonable\n\nExo..,i,de\n\n)\n\n! _.._._::t:::\n\n#\n\n"F\n\nDesign Points _\nk.\nPool\nk,.\n_ __ ,_ .......\n[ ........\n__=__=______\n.....\n\n\',\n\nf"\n\n_o_-,y\n\ni\'_]--_\n\'\\\n\n)\n\n#\n\nDesign Points\n\n" ........\n\n--........\n\ni\nif Y >Yinterest\n\n]::\'xe\' n d e\n\n_s\n\nReasonable\n\n__ _,\n\n1\n\ni\n\nn a_G ]/////_\'-_\n\n/\n\n1:"\n\n(x\n_\n\n]........\n\n_ ........\n\n--\n\n--- - .....\n\n\\\nDOE")y\n\n/I\n\n/x"-" I fromData Set 1\nif Y>Yinterest\n\nI\n\nLl-----M-\xc2\xb0-d-eI.........................\n\nfRefined\nRS\n_L______t_Y_\n........................\n(b) Error-based DSW approach\n\n(a) Standard DSW approach\n\nFigure 2: Standard and error-based design space windowing approach for searching regions of high response designs\n\n10\n\nAIAA\n\npafloac_._\ni\n....\n\n_:i\n\nen_r_l\n\n756 680\n1050453\n462 907\n169 134\n-124639\n-418 412\n\n9333\n8000\n66.67\n5333\n4000\n10667\n2667\n1333\n0.00\n\n0\n\n-0,5\n\n(b) Abso]ut\xc2\xa2\n\n. ij_L\n\nof RS !\n\n(xz:D\n\nand x2: RPM)\n\n0_-I i tl_i e_.i L.i...<L I-: I..m\n:__...I_...L_L_\nt\n\' -I _.._\n\nE_t\n\n,r o\n\n[liii[IT\n\ntttigi- i/\n\n_J_L_\n\nproblem\n\n1\n\n-j i i]._=J..I._.IL.L;_L\nL.LJ it\xc2\xa3]..\n-]..]: [..J._i_i_L] L...!.i..].. J_J.LLLJ_\n\niL\'L\n\n+\n\ndesign\n\n..... ]_.LI. 1\nL\n\n.....\nL.L.L.\n..........\n+\n\nfor turbine\n\n0.5\n\nx_\nerror\n\n::7\n\n.L0..i.....\n\n0.5\n\nand RS 1 errors\n\n146.67\n1600(]\n13333\n12000\n\ni\n\n"1-1\n\n3: Apay contours\n\n2002-0539\n\n_ I ..... !0\n_ I ] ]_i. LA ,. _\nJ_\nILL/\'\n\n-l...i._ix\n\nLt:i\n\n.\'\n\n\xe2\x80\xa2 -\'\n\nlit\n\n: I ! !i\n\ni"..l _t..__\n! li\nt\n\nL._L_--_-\xc2\xb1e\' L Ll.L.[_\n\nL L..L._ iAi!.[il]_Z\xc2\xa3\n_ Jh\nL!\n_.i{\n_\n\ni\n\nI I!....\n\n.,.._\no.i! I i, l_i_.....\nLII\n\n0\n\n-0.5\n\n03\n\n.1._/i\n\n1\n\ni I._5t I i I_i\n\nxt\n(a) RS 2 (Standard\nFigure\n\n4: Design\n\n! i/isl\n\nI i l\n\nx_\nspace\n\n(b) RS 3 (Error-based\n\nDSW)\nfor RS models\n\nfor turbine\n\ndesign\n\nproblem\n\n(xl:D\n\nDSW)\nand x2: RPM)\n\n146,67\n160,00\n133.33\n\n13333\n12006\n10667\n\n12000\n_:_\n\n93.33\n80.00\n56.67\n53.33\n\ni\n\n6667\n53.33\n26.67\n\n26.67\n40.00\n13,3\'3\n090\n\n4).5\n\n,-0.5\n\n0\n\n0 5\n\n1\n\n"t-1\n\n-0,5\n\nx,\n\n5: Error\n\n03\n\n1\n\nXl\n\n(a) RS 2 (Standard\nFigure\n\n0\n\ncontours\n\nDSW)\nafter\n\n(b) RS 3 (Error-based\nDSW\n\nin turbine\n\nII\n\ndesign\n\nproblem\n\nDSW)\n\n(x_" D and xz: RPM)\n\nAIAA\n\n2002-0539\n\n1\n\n0.75\n\n0,75\n\nerr_rns,\n\no_,5\n0,5\n\n0.9104\n\n0.5\n\n0.8284\n0.7463\n0.6642\n0.5821\n0,5OOO\n\n0.25\n\n_\n0.25\n\nx"o\n\n0.1710\n0.0886\n0.0075\n\n0.1000\n00833\n0 D_7\n0 0500\n01167\n0.0333\n\no.41_\n\n-0.25\n\n0,1833\n01667\n02000\n0.1500\n01333\n\n0.3358\n02537\n-0,2\n\n0.0167\n\n-0.5\n\n-0.5\n\n-0.75\n\n-1.1\n\n0\n\n-O.5\n\n0.5\n\n1\n\n"1-1\n\n-0.5\n\n0\n\nx1\n(a) True\n\nfunction\n\n_)\n\nFiglire 6: Contours\n\n1\n\n0.5\n\nx,\n\n_\'],L_LL_.LL_L.LLJ.\n\nI. "\n\nfor y and RS ] errors\n\nAbsolute\n\nin quartic\n\nerror\n\nof RS l\n\npolynomial\n\n1\n\n-7-T7\n\ni....l....L.l.._.!._i..LI \'-[1 ] L]\nL.i\n\n__.\n_.L.I.._I\n\n05\n\n0.5\n\nJ ;.i\n\nLi]LI_M i\nIi:\n\n._L..\nLt.\n\n......... liiLL_.i\nFI\n\n......\n\nill]:\n\n,\n\n,\n\n,rl\n\n,|\n\nL.LI L_\nLL.I._.LL\n,\'__LL.L\nLL 1 .!__t._]_I._JL L\nI_1 L _ .J__I_L_-._\xc2\xb1\n\n.l\nIL\n\nr_\n\nbbl\n\n,,,,,\nI\n\n-05\n\nJ !\n\nL kJ .L_L.]_.t_._L\n1\n-q\n\n- _:..,... L_t.LJ_\xc2\xb1.LI_i_I\nt i_.L_L...Li\nL_\ni k_\n_ _.l,,! 11 I ii t I]\n\n....\n"_.i.1\n\ni\n\n!\n\n!L.IA LL-_.i...I .......\n! !!..Ljilti2_LL\n\nI....._.\n-&5\n\n:\n\n::I:Z_I\n\n7,7!_\n\n-i\n\n.LL21_.I\n\n....\n\n-........]7] LLLLL] ...... _t2_\ni\nL\nJ__ !.II.[..!Ii_L_\n_ _.L.I ....\n-7 ] _ _ I..._].LJ.._.i_.LJ_ _ ; L I..\n_..\ni_ Ti iilI/lit l I i l\n! L2_\n_]I\n:_,;l[\nI"\n\n//i\nw\n\n-0.5\n\nt i\n\ni\n0\n\n[ i i / 1\n0.5\n\nx_\n\n(a) RS 2 (Standard DSW)\nFigure\n\n7: Design\n\nspace\n\n(b) RS 3 (Error-based DSW)\n\nof global\n\nRS models\n\nfor quartic\n\npolynomial\n\n0.7\n\n.....\n\nw\'_ar_\n02000\n01_3\n01_7\n01_0\n\n0.5\n\n01833\n02000\n01667\nO _500\n0 1333\n0116"/\n01000\n00833\n\n025\n\nooe_\n\nx" o\n\no o5oo\n0 0333\noo_B7\n\n01_3\n0.1167\n01OOO\n0._3\n0 _7\n00_\n\n-025\n\n00_3\n00167\nO.0000\n\n0 oo00\n\n-0.75\n\n-0.5\n\n0\n\n0.5\n\n1\n\n-1-1\n\n*0.5\n\n0\n\n0.5\n\nx_\n\n(a) RS 2 (Standard DSW)\nFigure\n\n8: Error\n\ncontours\n\n(b) RS 3 (Error-Xbased DSW)\nafter\n\n12\n\nDSW\n\nin quartic\n\npolynomial\n\nAIAA\n\n2002-0539\n\n0.75\n\nI\n\n0.5\n\n0.1833\n0.1667\n0.150(]\n0.1333\n0.1167\n0,1000\n0.0833\n0.0667\n0.0500\n0.0333\n0,0167\n00000\n\n025\n\n_o\n-0,25\n\n-0.5\n\n-0.75\ni\n-1-1\n\n-0.5\n\n0\n\n0.5\n\nxt\n(b) Error contours\n\n(a) Data points\nFigure 9:RS4\n\nfor quartic\n\npolynomial\n\n(RS I+RS 3 design points)\n\n.... i\ni\n:),\n\no.s- j_\n\n05\n\nI\n\n-_\n\ni!ill\nif\'\n\no-\n\n,\n\n_\n\n_ i\n\ni\n\n\xe2\x80\xa2\n" ]\n\nl:\n-o.5-\n\n\'ii_[\n\nIi\n\n_]\n\nI\n\n!\n\n\'.0\n\nii\n\ni!\ni l\n\n[\n\ni]\n\nI .......\n\n):\n\n]q\n\ni\n\ni\n- t-\n\n!I!i:!i\n\n-0.5 -[--\xe2\x80\xa2\nk\nz\n\n:,tii!:i_\n0.5\n\nFigure\n\n.1.t\n\n\'\n\n(a) RS 5 (Standard DSW)\n(b) RS 6 (Error-based\nDSW)\nl 0: Design space of local RS models for quartic polynomial in upper-right\nquadrant\n\n1\n\n1 -\n\n03\n\n0.8\n\n0.6\n\neror_s_gcub\n\n0.6\n\n0.2\n\ni\n-0.2\n\n-0.4\n\n0.1833\n0.1667\n0.1500\n0.1333\n0.1167\n0.1060\n0.0833\n0.0667\n02000\n0.0500\n\n-0.2\n\n0.0333\n0,0167\n0.0000\n\n0.4\n\n-0.4\n\n04\n\nN\n\n0.183,3\n0.201_\n0.1667\nOJSO0\n\n0,2\n\ni\n\n0.1167\n0.1000\n00833\n0\xe2\x80\xa20667\n0.0500\n0.1333\n0.0333\n0.0167"\n00000\n\n-0,6\n\n-0,6\n\n-0.8\n\n-0.8\nillll\n-1_1\n\n"\n\n-0.5\n\n0,5\n\n0\n\n-11\n\n1\n\nI\n-0.5\n\nr\n\ni\n\n_\n\ni\n\nI\n0\n\ni\n\ni\n\n,\n\ni\n\nI\n0.5\n\nxl\n\nxl\n(a) RS 5 (Standard DSW)\nFigure 11: Error contours for quartic\n\n13\n\n(b) RS 6 (Error-based\nDSW)\npolynomial in upper-right\nquadrant\n\n?\n\nI\n1\n\n,\n\nAIAA\n\n2002-0539\n\nAPPENDIX\nResponse\n\nSurface\n\nMethodology\n\nResponse surface approximations\nfit numerical or physical experimental\ndata with an analytical model that is\nusually a low-order polynomial.\nThe response at design point x" is denoted as y [ = y(x)] and given by Eq. (4)\n\ny(x) = r/(x) + e\nwhere\n\nr/(x)\n\nis the true mean response\n\nmeasurement\n\nerror\n\nperforming\ne.\n\nand\n\nnoise\n\nthe experiment\n\nRandom\n\nstandard\n\n(4)\n\nerrors\n\npoint x and e represents\nfor in q.\n\nmany times at x, the average\n\ne are assumed\n\ndeviation\n\nat design\n\nnot accounted\n\n_r, which\n\ngiven in terms of coefficients\n\nto be uncorrelated\n\nIn other\n\nof the observations\nand normally\n\nis the same at all points.\nfli s and shape functions\n\nother random\n\nwords\n\nwill tend to r/ despite\n\ndistributed\n\nIn RS technique\nfi (x)\n\nsources\n\nif the experimenter\n\nrandom\n\nvariable\n\nthe true mean response\n\nof variation\n\nsuch as\n\nhas the luxury\nthe random\n\nof\n\nerrors\n\nwith zero mean and\nis assumed\n\nto be\n\n(i= 1, rib) as in Eq. (5).\n\nglb\n\nr/(x) = ]F_.flifi (x) = fT[5\n\n(5)\n\ni=1\n\nwhere\n\nf\'r ={ft(x\n\nrepresentation.\n\n)\n\nf2(x)\n\n..-\n\nf.b(x\n\nThe n b shape functions\n\nthe best approximation\n\n)} and\n\nI_={/3,\n\nf12\n\njr/ are usually\n\nto y when noise is absent.\n\n"\'"\n\nfln_}T\n\nmonomials\n\nand\n\nand T denotes\n\nfli are unknown\n\nWith noise the fitted approximation\n\ntranspose\n\nfor the matrix\n\ncoefficients,\n\nrepresenting\n\nis given as\n\nnb\n\n)3(x) = Ebifi(x)\n\n= frb\n\n(6)\n\ni=1\n\nwhere\n\nb_s (vector\n\nb) are estimates\n\nbetween the datay\ne = y - ._(x)\nThe residual\n\nfor a point x and the estimate\n\n[_) obtained\n\ndefined\n\nfrom a least squares\n\nfit. The difference\n\n(residual)\n\nin Eq. (6) is given as\n(7)\n\nI\n\n(8)\n\nX 1 is the matrix\n\ninstance,\n\n(vector\n\nfor the N data points can now be written in matrix form,\n\ne =y-Xlb\nwhere\n\nof the fli\n\nwhose terms\n\nfor a quadratic\n\nin the row associated\n\nmodel in two-variables\n\nwith the point x are formed\n\nwith N data points\n\nby monomials\n\nfi (x) *.\n\nFor\n\nX ! is given as\n\nx,,\n\nx_,\n\nx 2,\n\nx,,x21\n\nx_,\n\nXl2\n\nX22\n\nX?2\n\nX12X22\n\nX22\n\n\xe2\x80\xa2\n\n:\n\n:\n\n;\n\n:\n\nXl=\n\nx2J\n\nxl I\n\n-\n\nexpressed\n\nvector\n\nx\'jx2J\n\n:\n\n-\n\n(9)\n\n:\n\nbj\n\nin Eq. (8) is solved\n\nfor minimum\n\nresidual\n\nvector\n\nin a least-square\n\nsense,\n\nand can be\n\nas\n\nb, = (xTxt)\'I\n\nX_y\n\n(10)\n\nWhen the model is exact (no bias error), unbiased estimates\ns\n\nx2.i\n\nx, N x,Nx2\n\nXIN\n\nThe coefficient\n\nx2j\n\nof the noise o" in the data is given as\n\n.l yTy - b_Xlry\n\n(11)\n\nWith finite number of data, errors in the data cause errors in the coefficients,\nand that in turn causes a prediction\nerror of the RS approximation\nthat depends on location.\nBecause Eq. (5) is only an approximation\nto the true mean\n\n" Bold face is used for vector and matrix\n\nrepresentations,\n\ne.g. x = Ix I\n\nx2 ]3" for two-variable\n\ncase where superscript\n\nT stands for transpose operation\n" The subscript "1" used forpl,b\n_ and X_ refers to the set of monomials included in the model. Later, a subscript\n"2" will be used for the set of monomials needed to complete the model in order to obtain the true response.\n\n14\n\nAIAA\n\nresponse\n\nfunction,\n\ns will contain\n\nquality of the approximation\nR_, = 1\n\nnot only noise\n\nis often measured\n\nerror,\n\nbut also error due to the approximation.\n\nby the adjusted\n\ncoefficient\n\nof multiple\n\n2002-0539\n\nBesides\n\ndetermination\n\ns2\n\nN\n\ns, the\n\nR2 .\n(12)\n\n___(y j _ y)2/(N\n\n- 1)\n\nj=l\n\nwhere\n\nfi is the average\n\nD-Optimal\n\nvalue of the response\n\ndata.\n\nDesign\n\nA D-optimal\ndesign minimizes\ndeterminant of the moment matrix,\n\nthe generalized\nM [ 15].\n\nvariance\n\nof the estimates,\n\nwhich\n\nis equivalent\n\nto maximizing\n\n-IxTx\ntMl--N\xc2\xb0b\n\nthe\n\n(13)\n\nThe D-optimal\ndesign approach makes use of the knowledge of the properties of polynomial model in selecting the\ndesign points. This criterion tends to emphasize the terms of the polynomial model with the highest sensitivity [17].\nMean Squared\n\nError\n\nAs a measure\n(14) is used\nMSEP(x)\nwhere\n\nq(x)\n\nCriterion\n\n[9]\n\nof the error in the approximation,\n\n= E_(x)\n\nthe mean squared\n\nMSEP\n\ndefined\n\n- r/(x)] 2\n\nand _(x)\n\nas in Eq.\n\n(14)\n\nare the tree mean response\n\nand the prediction\n\nby definition an expected value that would be reached\nEquation (14) may be rewritten as\nMSEP = E_(x)\n\nerror of prediction\n\nif the number\n\nby the fitted model,\n\nrespectively\n\nof data used in approximation\n\n- E33(x)] 2 + [E)3(x) - q(x)] 2\n\nat x. MSEP is\nwere unlimited.\n\n(1 5)\n\nThe first term in Eq. (15) represents the variance error due to random noise and the second term represents bias\nerror due to inadequate\nmodeling.\nThis error expression is usually averaged via integration\nover the design space\nand the integral is minimized by choosing the experimental\ndesigns (DOE) that control the effect of one or both\ntypes of error-noise and bias-J18 and 5]. It is reported in [18], "the averaging MSEP over the design region in fact\nmask a poor performance\nby the RS approximation\nat certain locations of the design region "\'. Papila and Haftka [9]\ninstead attempted point-wise characterization\nof the error and to determine the design regions where RS prediction\nmay suffer due to either or both types of error. Therefore Eq. (I 5) is used to investigate the variation of MSEP from\npoint-to-point.\nThe expectation\nof the predicted response at a given design point x can be expressed as\nEj3(x) = fTE(bl)\nwhere\n\n(16)\n\nfl "*is the vector of shape functions\n\nThe mean and the variation\nE(b,)\n\nf/ [see Eq. (5)] calculated\n\nfor the coefficient\n\nestimates\n\nat point x.\n\nare given as\n\n= (XTX,)\'XTE(y)\n\n(17)\n\nVar(hl ) = o-2 (xTx1) -1\nwhere\n\ncr is the standard\n\nthe prediction\nE[_(I)-\n\n(18)\n\ndeviation\n\nof the noise error.\n\nThe first part of the mean squared\n\nerror in Eq. (15) is equal to\n\nvariance at x.\nE)3(x)] z = Var[y(x)]\n= frVar(bl\n\n)fl\n\n(19)\n\n_- -\'\nf?(x,%)-\'f,\nThe second part of Eq. (15) is the squared\n\n\xe2\x80\xa2 Subscripts\n1,\n\n1 and 2 assign matrices\n\nerror due to the inadequacy\n\nand vectors\n\nof the model used\n\nfor the fitting model and the missing\n\n15\n\nterms,\n\nrespectively.\n\nAIAA\n[E_(x) - r/(x)] 2 = (Bias_(x)_\nTherefore\n\nmean squared\n\nMSEP = Var[_(x)]\n\n+ (Bias_(x)])\n\nsince variance\n\nmean square\n\n(20)\n\nerror of prediction\n\nThe form of the prediction\nmodeling,\n\n2\nin Eq. (15) can be rewritten\n\nas\n\n2\n\n(21)\n\nvariance,\n\nVar[_(x)],\n\nin Eq (19) does not change\n\nby random\n\nis only caused\n\ns 2 is not an unbiased\n\nnoise.\n\nestimate\n\nHowever,\n\neven in the presence\n\nwhen bias error is present,\n\nof inadequate\n\nthe residual\n\nP=\n\n(22)\n\nX| (xITx1)-Ix1T\n\n(23)\n\nThe accuracy of this estimate depends on factors such as the available data or number\nadequacy of the fitting model that determines whether the estimate is unbiased or biased.\nThe true mean response at x can be written as\n\nof points\n\nr](X) = f7111 + f2Tp2\nwhere\n\nfrom the assumed model.\n\nSince one usually does not know the true response,\n\nassumed to be a higher order polynomial\nwhen monomials\nfitting model in two-variables\nwhen true function is cubic\n\n_12\n\n_13\n\nill,\n\n/_15\n\nThe mean of the true response\nE(y) = Xt11 t +X2112\nwhere\n\nare used as shape functions.\n\nFor instance,\n\nfor a quadratic\n\nis given as\n(26)\n\nX 2 is similar to X l , but due to the terms (shape\n\nfunctions)\n\npresent\n\nin the true response\n\nthat are not included\n\nof Eq. (26), Eq. (17) becomes\n(27)\n\nis called the alias matrix.\n\nSubstitution\n\nof Eq. (27) into Eq. (16) yields\n\nE)_(x) = f? (1_1+ A112)\n(Bias_\'(x)])2\n\n(28)\n\n={fX0_t +A112)-f|x11\'\'f2r[I2]_\n= [IT[ATf, _ f2][fTA\n\n(29)\n\n_ f2 1112\nT\n\nThe MSEP at a given point can now be estimated\nMSEP(x)\n\nas by using s 2 instead of 0-2\n\n= s2f? (X ITx 1)-1 fl + 111M112\n\n(30)\n\nwhere M = [A Tf_ _ f2 ] [fT A - f_ I\nNote that MSEP is an expectation\nassociated\n\ns 2 . Using\n\nE(y)\n\n(31)\n\nby definition\n\n[Eq. (14)], and Eq. (30) is its estimate by the data available and\n\nfrom Eq. (26), the expected\n\nvalue of biased\n\nerror mean square\n\ns 2 given by Seber [19]\n\nT T\nE(s 2) = 0-2 + 112\nX2 (IN -- P)X2112\nN-p\nI\nsince\n\n(I N -P)\n\ndefinite\n\nmatrix,\n\nis an idempotent\n\nmatrix,\n\nso E(s 2) > 0-2 provided\n\n(32)\nthat is a matrix\nthat\n\npresent, s 2 is a biased estimate of o -2 .\nIf this expected value, E(s2), is substituted\nestimate\n\nMSEP\n\nit is often\n\n(25)\n\n/_16]\n\nin the fitting model. After substitution\nE(b_) = 111+A112\nwhere A = (XlXX_)-_X/X2\n\nand also the\n\n(24)\n\nf2 are terms missing\n\n111T [_11\n----\n\nerror\n\nof 0-2. Using Eqs. (10) and (11) we get\n\nS 2 = YT( I N -- P)Y\nN-n\nb\nwhere\n\n2002-0539\n\ncan be expressed\n\nwhose\n\n(I N -P)Xzl32\n\nin prediction\n\nas\n\n16\n\nsquare\n\n_ 0.\n\nvariance\n\nis equal\n\nEquation\n\nto itself.\n\n(32) means\n\ncontribution\n\nIt is also positive\n\nsemi-\n\nthat when bias errors\n\nin Eq. (30) expected\n\nare\n\nvalue for the\n\nAIAA2002-0539\n\nT\n\nE[MSEP(x)]=f!\n\nT\n-i\n(XIXi)f,[O"\n\n2\n\nL\n\n=\nwhere\n\nT\n\n(33)\n\nf, +P GP2\n\nK = xT(xz\n\n(34)\n\n-- XIA)\n\nG = fT(xTxl)-lfl\nN-pl\n\n(35)\n\nK + M\n\nThe aim of the method\nfrom the fitting model\ncan estimate\n\nTK P2\nP2\n+--l+[_zM[32\nN-PlJ\n\nis to identify\n\nare known,\n\npoints\n\nthe size of [$z, it is possible\n\nof the mean squared\n\nwhere the bias error is large.\n\nbut there is not enough\n\nerror predictor\n\nto formulate\n\ndata to calculate\n\na constrained\n\nthat may be experienced\n\nIt is assumed\n\nthe corresponding\n\nmaximization\n\nproblem\n\nat any given design\n\nthat the terms missing\ncoefficients\n\npz. If one\n\nfor the largest magnitude\n\npoint for the worst possible\n\n132 of\n\nthat magnitude.\nmax E[ MSEP(x)]\nP2\n\n(36)\n\nsuch\n,ha,IlP 2--c\nll\nThe Lagrangian\n\nfor this optimization\n\nL(ll 2 , 2) = E[MSEP(x)]\nDifferentiating\n\nV=[\n\n\xc2\xa2)_21\n_)\n\n(37)\n\nwith respect to _2\n\nft] + v(pTG[_2)\n\xe2\x80\xa2..\n\nwhere\n\ncan be written as\n\n+ 2(ll2Tliz - c)\n\nthe Lagrangian\n\nVl a2fT (xTx1)-_\n\nproblem\n\nb\n\nb_22\n\n+ 2V([52TP2 - c) = 0\n\n------_ -\n\n. Equation\n\n(38)\n\n(38) yields the following\n\neigenvalue\n\nproblem\n\nat a design\n\npoint\n\n_2p2\n\nx j;\nGp_+2pz=0or\n\nGP2- ;t P2 =0\nfor which\n\n(39)\n\nthe maximum\n\neigenvalue\n\n2Gma\xc3\x97 characterizes\n\nthe maximum\n\npossible\n\nmean\n\nsquared\n\nand bias\n\nerror\n\nassociated\nwith the assumed\ntrue model that includes\nshape functions\nmissing\nin the fitting model.\nThe\ncorresponding\neigenvector defines the coefficients of the missing shape functions that results in the largest bias error\nwhen fitted only with the assumed model.\nThe eigenvectors\nand the function experiencing\nthe worst possible bias\nerror may be different point-to-point\nalthough the magnitude of the missing coefficient vector is constrained.\nSo the\neigenvalue\ncalculated\ndoes not reflect the true function corresponding\nto the data (as the data is insufficient\nto\ncalculate\n\n_z ). It reflects\n\nall the possible\n\ninstead,\n\ncombinations\n\nthe assumed\n\nsuch that [_[_2 = c ) causing\n\nAs can be seen from the derivation\nthe response\nfitting model\ndemonstrates\ny = l+x\n\ndata. This independence\npredicts the true function\nsuch a case.\n\nthe eigenvalue\n\nwith the shape function\n\nthe largest\n\nerror measure\n\ncoefficients\n\nthe FCCD\n\ncentral\n\n_z (among\n\nerror.\nstrongly\n\ndepends\n\nfrom the response data may be misleading\nvery well at the data points.\nThe following\n\non the DOE used, but not on\nespecially\n2D cubic\n\nfor the cases where\npolynomial\nexample\n\n3 +x 3\n\nFace-centered\npresents\n\nform of true function\n\n(40)\ncomposite\n\npoints and relevant\n\ndesign\n_\n\n(FCCD)\nfield.\n\nin 2D was used for constructing\n\nThe maximum\n\na quadratic\n\nvalues are at the data points\n\nRS.\n\nFigure\n\non the boundary,\n\n1\nbut\n\nTable A1 indicates a perfect with the nine data points. The testing rms-error (using 21 by 21 grid points except the\nnine data points) and the maximum error, however, shows that the fit is actually quite poor. Figure A1 presents the\ntrue function and the error field. Comparing\nFigure Alb and Figure lb indicates that eigenvalue\nerror measure did\nnot predict the high-error regions in this particular example, unlike for the examples studied and reported in [9]. It is\nexpected that the benefit of the error measure will be increased further if the response data can also be used in the\nderivation.\n\n17\n\nAIAA\n\nTable AI" Statistics\n\nof the quadratic\n\nRS for cubic polynomial\n\ngiven in Eq. (40).\n\nRSquare\n\nRSquare Adj\n\nRS is given is _ -- 1 + x I + x 2\n\n! .000\n1.000\n\nrms-error\n\n0,000\n\nPredictor\n\nMean\n\n1.000\n\nObservations,\n\nTestin_\n\nN ,,\n\nrms-error\n\n9\n0.385\n\n(21 x 21 _rid)\n\n0.768\n\nMax. Error\n\n3._100\n2.067\n2.333\n2.000\n1.667\n1.333\n\ncmo"\nu\n08OO\n0 733\n0667\nO6OO\n0533\n0_7\n04OO\nO333\n0267\n02OO\n0133\n0OO7\nO(X)O\n\n05\n\n0.25\n\n1.ooo\n\n_"\n\n0.687\n0.333\n0,000\n_333\n_.667\n-I._\n\n-0.5\n\n-0.75\n\n"-1\n0\n\n05\n\n1\n\n-0.5\n\n0\n\n0,5\nX1\n\nXz\n\n(a) True function\n(b) Absolute error of RS 1\nFigure AI: Contours and RS errors for cubic problem in Eq. (40)\n\n18\n\n2002-0539\n\n'