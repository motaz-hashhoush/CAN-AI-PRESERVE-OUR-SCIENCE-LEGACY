b'HUMAN FACTORS in HUMAN-SYSTEMS INTEGRATION\nHuman Research Program - Space Human Factors & Habitability\nSpace Human Factors Engineering Project\n\nDavid. J. Fitts (PI),\nAnik\xc3\xb3 S\xc3\xa1ndor, Ph.D., Harry L. Litaker, Jr., Barry Tillman\n\nABSTRACT\nAny large organization whose mission is to design and develop systems for humans, evaluate systems for humans, and train humans needs a well-developed integration and process plan to\ndeal with the challenges that arise from managing multiple subsystems. Human capabilities, skills, and needs must be considered early in the design and development process, and must be\ncontinuously considered throughout the development lifecycle. This integration of human needs within system design is typically formalized through a Human-Systems Integration (HSI)\nprogram. By having an HSI program, an institution or organization can reduce lifecycle costs and increase the efficiency, usability, and quality of its products because human needs have been\nconsidered from the beginning.\n\nBENCHMARKING HSI PRACTICES\nINTRODUCTION\nHuman-Systems Integration (HSI) emphasizes human considerations as the top\npriority in systems design to optimize the fully integrated system\xe2\x80\x99s (i.e., human and\nmachine\xe2\x80\x99s) performance and often to reduce lifecycle costs. HSI at NASA is a\nmultidisciplinary field of study composed of several user-related areas, including:\nHuman Factors Engineering (HFE), System Safety, Health Hazards, Manpower &\nPersonnel, Training, and Habitability.\n\nFUTURE RESEARCH DIRECTIONS\nDirected research must specifically investigate lifecycle costing and identify the\ncontributions that HSI can make in this arena for the Agency. For example, in the DoD,\nHSI was advocated on the basis of cost savings, not on the promise alone of producing\nsuperior user-interfaces. It is essential that DoD and NASA work together to develop\nmetrics that can be used during development that provide indications of operational\nefficiencies and inefficiencies, preferably using lifecycle cost as one of the desired\noutput metrics. Our research should pursue identification of a forward plan for\nintegration of lifecycle costing into the Agency for the sake of demonstrating HSI\xe2\x80\x99s\nusefulness in this area.\n\nHUMAN PERFORMANCE METRICS\nHuman-in-the-loop evaluation\nA human-in-the-loop evaluation is any evaluation that includes a human, whether in an active or\npassive capacity in the participant role. The active human-in -the -loop means that the human\xe2\x80\x99s\nactions are being evaluated in some capacity. The passive human-in-the-loop means that the\nhuman is providing passive data (waste, or other physiological outputs). The human as\nparticipant means that the human is providing the data in which case human performance can be\ncaptured. Using standardized metrics helps to use data collected across evaluations.\nFrom an HSI point of view, for humans to be truly included as a \xe2\x80\x9csystem\xe2\x80\x9d, designers and\nevaluators must be able to quantify their performance. To attain this, human performance\nmetrics have to be defined and also standardized within an organization so that data can be\nshared across systems.\n\nHuman performance metrics\nHuman factors metrics depend on context, phase, and cost. Performance measures can be used\nin formative or summative evaluations, and these are determined by the research goal. Human\nfactors performance measures can be usage or predictive metrics and these define the method\nused.\n\nThe Human Factors Engineering processes have to be inserted into the NASA project\nlifecycle to ensure a Human Centered Design process. Below is a flowchart that\nillustrates possible insertion points:\n\nRESEARCH METHODS\nOne purpose of the project is to benchmark DoD and other organizations\xe2\x80\x99 HSI\npractices. This is being accomplished by organizing meetings with DoD\nrepresentatives who use MANPRINT (Manpower and Personnel Integration),\nSEAPRINT (Systems Engineering, Acquisition and Personnel Integration), and\nAIRPRINT (Airman Performance Integration), meeting with other organizations (e.g.,\nindustry), studying their processes, reviewing their documents, and meeting with\ncontractors who implement these HSI requirements. The purpose of these activities is\nto learn how the requirements are implemented in the final products. Agency and\nJohnson Space Center (JSC) programmatic and Systems Engineering documented\nprocesses and practices will also be reviewed, and a gap analysis will be developed to\nidentify where HSI should be a part of the process.\nINTERVIEWS AND DISCUSSIONS\nInterviews and discussions will be conducted with personnel involved in HSI practices\nin other organizations to learn about their processes. An interview questionnaire has\nbeen put together covering the different topics.\n\nHuman performance measures database\nA database is being developed that will contain all the metrics with recommendations for users.\nThe purpose of the Human Performance Metrics database is to address the need for standard\nmetrics to be collected whenever humans are included in testing. It is always advantageous to\ncollect human performance measures no matter how small the number of participants per test.\nThis data can become part of an archive of data which may be later combined with other\narchives to be correlated, and compared.\n\n'