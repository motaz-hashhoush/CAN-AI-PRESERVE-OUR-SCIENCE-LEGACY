b'NASA Contractor Report 178334\n\nICASE INTERIM REPORT 2\nPISCES 2 USER\'S MANUAL\n\nTerrence W. Pratt\n\nNASA Contract No. NAS 1-1 8 107\nJuly 1987\n(EASA-CB-178334)\nP I S C E S 2 UEEKS 8ANUAL\n(hASA)\n44 p A v a i l : E l I S f3f A G 3 1 B E A01\nCSCL 098\n\n~8 7-2 6 554\n\n63/61\n\nUnclas\n00879C6\n\nINSTITUTE FOR COMPUTER APPLICATIONS I SCIENCE A N D ENGINEERING\nN\nNASA Langley Research Center, Hampton, Virginia 23665\nOperated by the Universities Space Research Association\n\nNabonal Aeronautics and\nSpace Admnistrafion\n\nLn0kY-w\n\nHampton,Wgnm 23665\n\nICASE INTERIM REPORTS\nICASE has introduced a new report series to be called ICASE Interim Reports.\nThe series will complement the more familiar blue ICASE reports that have been\ndistributed for many years. The blue reports are intended as preprints of\nresearch that has been submitted for publication in either rcfcrced journals or\nconference proceedings. In general, the green Interim Report will not be submitted for publication, at least not in its printed form. It will bc used for research\nthat has reached a certain level of m t r t but needs additional refinement, for\nauiy\ntechnical reviews or position statements, for bibliographies, and for computer\nsoftware. The Interim Reports will receive the same distribution as the ICASE\nReports. They will be available upon request in the future, and they may be\nreferenced in other publications.\n\nRobert G. Voigt\nDirector\n\ni\n\nTABLE OF CONTENTS\nIntroduction\nPISCES 2\nAcknowledgements\nPart I : Pisces Fortran and the Preprocessor\nThe Preprocessor\n\n2\n\nPisces Fortran\nSyntax descriptions\nRestrictions\nUse of upper and lower case\nSignificant spaces\nFortran inpuVoutput\nDATA statements\nOverall Program Structure\nPFSUB subroutines and PFCALL statements\nEND DECLARATIONS statement\n\n4\n4\n4\n\nClusters, Slots, and Task Controllers\nCluster numbers and cluster number functions\nTask controllers\n\n5\n5\n5\n\nTask Definition, Initiation, and Termination\nTASKTYPE definitions\nINITIATE statements and task scheduling\nTERMINATE statement\nTaskid\'s and Task Communication Topology\nTASKID declarations\nEstablishing a communication topology\nPredefined TASKID variables and functions\n\n8\n9\n9\n10\n\nMessage Send and Accept\nSEND statement\nACCEPT statement\nHANDLER and SIGNAL declarations\nHANDLER subroutines\n\n10\n10\n11\n14\n14\n\nArgument Lists\n\n16\n\nForces\nFORCESPLIT statement\n\n18\n19\n\nShared Variables\nSHARED declarations block\n\n20\n20\n\nSynchronization: Barriers and Ciia Regions\nrtcl\nBARRIER statement\nLOCK declarations\nCRITICAL statements\n\n21\n21\n\nParallel Loops and Segments\nPRESCHEDULED DO loops\nSELFSCHEDULEDDO loops\nPARSEG statement\n\n23\n23\n\nTable of Predefined Variables, Functions and Subroutines\n\n26\n\nExample Programs\nExample 1: Matrix multiply; using tasks and message passing\nExample 2: Normalize a matrix; using a force\n\n27\n27\n30\n\n22\n22\n\n24\n\n25\n\nPart 2: The ConfigurationEnvironment\n\n33\n33\n33\n34\n36\n36\n37\n\nWhat is a Configuration File?\nWhat is a Loadfile?\nEntering the Configuration Environment\nConfiguration Options\nTerminating a Configuration Editing Session\nRunning a Pisces Fortran Program\nThe FLEX "Static Variables" Bug\nPart 3: The Run-timeEnvironment\n\n38\n38\n39\n39\n39\n39\n\nInitialization of a Run\nRun-time Menu Options\nTrace Output Display during Execution\nTrace Output Interpretation\nStorage Management\nTypes of free space\nLocal free space lists\nG o a free space lists\nlbl\nGlobal free block\nReading the system state dump\n\n40\n\n40\n40\n40\n\niV\n\n.\n\nINTRODUCI\'ION\nPISCES (Parallel Implementation of Scientific Computing Environments) is a "virtual" computer\nsystem intended for the solution of large scale problems in scientific and engineering computation. It is\nl.?sed on the use of MIMD parallel cornputation to achieve high computation rates. The "virtual" system\nincludes a programming environment and programming language that can be implemented on a variety of\nunderlying operating systems and machine architectures. Because the software provides an abstract "virtual machine" to the user, the precise details of the hardware and lower levels of operating system\no\no\nsoftware are of concern t the user primarily when "tuning" a program t improve its performance.\nPISCES 2\nPISCES 2 is the version of the PISCES environment and language for the Flexible FLEW2 computer system. This manual describes the PISCES 2 system as it is currently implemented at NASA Langley Research Center. The system consists of t r e major components:\nhe\n1. Pkces Fortran and the Preprocessor. The applications programmer writes programs in a version\nof Fortran 77 that includes extensions for parallel computation. These extensions include tasktype\ndefinitions, task initiation and termination, message passing among tasks, "forces" consisting of several\nparallel tasks executing the same program text, shared variables, and other constructs.\nA preprocessor converts a Pisces Fortran program into a standard Fortran 77 program. The parallel\nprogramming constructs of Pisces Fortran are converted into mofe complex sets of ordinary Fortran statements and declarations, together with calls on procedures in a Pisces run-time library that implement the\nrun-time actions necessary for the parallel constructs. Part 1 of this manual describes the Pisces Fortran\nextensions and use of the preprocessor.\n2. The Conjiguration Environment. When the user has created and successfully compiled a Pisces\nFortran program, the command "pisces" brings up the PISCES configuration environment. This envimnment provides a series of menus that allow the user to build or edit a configuration for a particular run. A\nmenu also drives the creation of an appropriate loadfile for the r n The configuration includes an execuu.\ntion time limit, trace settings for execution monitoring, and related information, in addition to a mapping\nfrom the virtual machine to the actual FLEX hardware. Part 2 of this manual describes the PISCES\nconfigurationenvironment.\n3. The Execution Environment. If the user requests program execution from the configuration\nenvironment, the loadfile is downloaded to the appropriate set of FLEX PE\'s, and control transfers to the\nPISCES execution environment, a program that runs on the "main" FLEX PE. This program displays a\nmenu with various options for controlling and monitoring the execution of the Pisces Fortran program.\nPart 3 of this manual describes the PISCES execution environment.\n\nAcknowledgements\nAlthough the details of the PISCES design and implementation are entirely the author\'s, design\nideas have come from many souTces. Harry Jordan of the University of Colorado is responsible for the\nconcept of a "force" and the associated declarations and statements. Piyush Mehrotra of Purdue Univerh\nsity is responsible for developing t e basic concepts of "windows" as a mechanism for remote access to\ndata. Other staff members and visitors at ICASE, esp. Merrell Patrick, Loyce Adams, Tom Crockett, and\nBob Voigt, have contributed numerous suggestions. Nancy Fitzgerald and Jeff Taylor, together with the\nauthor, constructed the earlier PISCES 1 implementationfor an Apollo workstation network and the DEC\nVAX under Unix.\nThis work w s supported in part by NASA G a t 1467-1 and Virginia CIT Grant INF-86-01 t the University\na\nrn\no\nof Virginia and in part by NASA Contract No. NASI-18107 while the author w s in residence. at the Institute\na\nfor Computer Applications in Science and Engineering (ICASE),NASA Langley Research Center, Hampton, VA\n23665.\n\nPISCES USER\'S MANUAL:PART 1\n\nPISCES FORTRAN AND THE PREPROCESSOR\nThis part details the syntactic and semantic extensions to Fortran 77 for the "Pisces Fortran" programming language, as implemented on the FLEX/32.\n\nThe Preprocessor\nA preprocessor is used to translate Pisces Fortran into standard Fortran 77, which is then compiled\nby the standard UNIX Fortran compiler (f77). A small library of additional run-time routines are needed\nto support calls inserted by the preprocessor into the Fortran code. The FLEX Concurrent Fortran (cf77)\npreprocessor is NOT used by Pisces.\nA Pisces Fortran program may be created in one or more Unix files. Standard Fortran 77 routines\nmay be included along with routines that use the Pisces Fortran extensions described below. Ordinary\nFortran routines may be compiled using the Unix Fortran compiler, ff77 (on the FLEX). Routines that\nuse Pisces Fortran extensions must be preprocessed. Files containing Pisces Fortran routines, or containing a mixture of Pisces Fortran and Fortran 77 routines, must have names that end in ".pf\'.\nThe preprocessor is named "pfpp" (Pisces Fortran preprocessor). To use the preprocessor to\ntranslate and compile a file <filename>.pf, at the Unix prompt, type:\n\npfpp <filename>\n\nNOTE:Don\'t include the ".pf\' in the name.\n\nThe preprocessor will find the file cfilename>.pf in your local directory, preprocess it to produce a file\nnamed <filename>.f, and then use ff77 to compile this file to produce an object file named <filename>.o.\nAll files are left in your local directory. If your program uses shared variables, there will also be a file\n\nnamed <filename>.sh.o left in your directory.\nYou can look at the translation from Pisces Fortran to ordinary Fortran in the file <filename>.f.\nPisces Fortran statements have been turned into comment lines that begin with "****" and are immediately followed by the Fortran 77 lines generated by the preprocessor for that statement.\nIf you wish to compile a Pisces Fortran program using special options on the Fortran 77 compiler\ncall (such as code optimization), you can delete the <filename>.o file produced by the preprocessor and\ncall ff77 with your options and the <filename>.f produced by the preprocessor. Currently the preprocessor calls ff77 with the Unix command:\nff77 -c <filename>.f\n\nPisces Fortran\nThe new Fortran statements and declarations for parallel processing in Pisces Fortran are described\nbelow, beginning with the constructs associated with tasks and message passing, and ending with the constructs associated with "forces".\n\n2\n\nSYNTAX DESCRIPTIONS\nThe syntax of the extensions is described using a slightly modified BNF notation. The extensions to\nstandard BNF notation are:\n(1) \'7\nindicates an optional element,\n(2) "( ...)" indicates repetition of an element zero or more times, and\n(3) a quoted element must appear exactly as written.\n...]*I\n\nRESTRICTIONS\nThe Pisces Fortran preprocessor must generate various Fortran identifiers and statement numbers.\nIn order to avoid conflict with user chosen names, the following are resewed for use by Pisces:\n1. A l names that begin with "ppp...".\nl\n2. Statement numbers greater than 73000.\nUSE OF WPER AND LOWER CASE\nl\nFortran is a single-case language (Le., a l letters are converted to a single case on input, except in\nquoted strings). In keeping with Unix Fortran style, lower-case is standard for programming in Pisces\nFortran.\nSIGNIFICANT SPACES\nPisces Fortran syntax does NOT follow the Fortran convention of allowing spaces to be left out\nwithin statements; spaces are \'significant\' in Pisces Fortran extensions. In general, the parts of a Pisces\nFortran statement must be separated by at least one space unless the next character is a special character.\nFor ewzmple:\npfcall subl(a)\n\n-- valid\n\npfcallsubl(a)\n\n-- invalid\n\nFORTRAN INPUT/OuTpuT\nOrdinary Fortran 77 UO statements may be used in Pisces Fortran. To READ or WRITE from a file\nother than the standard input and output files:\n1. Execute the statement:\ncall setcpu (1) -- on lrcflx (use file system attached to PE 1)\nor\ncall setcpu (2)\n-- on csmflx (use file system attached to PE 2)\nbefore the file is opened.\n2. OPEN the file, using the standard Fortran OPEN statement (not the Concurrent Ftn OPEN) with\nthe full Unix path as the filename. For example:\nopen (unit=9, file=\'/usr/u2/twp/datafile\')\n\n3\n\nDATA STATEMENTS\nDue to a peculiar bug in the FLEX software, use of Fortran DATA statements to initialize variables\nin Pisces Fortran is not recommended. See the discussion of the FLEX \'static variables\' problem in P r\nat\n2 of this manual.\n\nOVERALL PROGRAM STRUCTURE\nA program is written as a set of program units of the following types:\nTaslctype definitions.\nPF subroutines (Ftn77 routines that contain Pisces Fortran extensions).\nHandlers (subroutines for processing messages).\nFortran 77 subroutines and functions.\nThere is no PROGRAM unit (main program) in a Pisces Fortran program. These program units may be\nstored in Unix files in any convenient arrangement.\nPFSUB subroutines and PFCALL statements.\nIn general, the Pisces Fortran statements and declarations described b l w may be included in any\neo\nFortran 77 subroutine. Replace the w r "subroutine" in the header by "pfsub:\nod\n\npfsub <name> (<formal arguments>)\nand then instead of the usual Fortran "call" statement, use a "pfcall"\npfcall <name> (<actual arguments>)\nA Fortran FUNCTION subprogram cannot use Pisces Fortran extensions (including PFCALL\'s). Each\nPFSUB subroutine must, of course, be preprocessed by "pfpp".\nEND DECLARATIONS Statement\n\nEvery program unit that uses Pisces Fortran extensions (TASKTYPE, PFSUB, HANDLER units)\nmust have an "end declarations" statement included between the last declaration and the first executable\nstatement. For example:\npfsub sub1 (argl, arg2)\n\ninteger a, b, c\nend declarations\nif (argl .eq. 1)then\n\n-- last declaration\n\n-- first executable statement\n\n4\n\nCLUSTERS, SLOTS, AND TASK CONTROLLERS\n\nl\nI\n\n-\n\nThe PISCES virtual machine is organized into one or more "clusters" of processing resources. The\no\nprecise set of resources assigned to each cluster varies from machine to machine, from cluster t cluster,\nand cn the FLEX even from run to run (because the programmer controls this assignment on the FLEX to\nsoine extent, see Part 2 below.) On the FLEX, a cluster consists of one "primary" PE and a set of "secondary" PE\'s.\nin\nWithin a cluster, each task IUI~S a particular numbered "slot". The slot is chosen by the system at\nthe time the task is initiated. While a task is running, the pair <cluster number/slot numben uniquely\nidentifies it within the system.\nThe programmer chooses the number of clusters and slots to use before each run of the program, as\npart of the "configuration" chosen for that run (seeP r 2 of this manual.) A maximum of 18 clusters may\nat\nbe used on the FLEX (because 18 PE\'s are available). A cluster may have as many slots as desired. Limiting the number of slots in a cluster limits the number of tasks that may be simultaneously competing for\nuse of the FLEX PE assigned to the cluster.\nCLUSTER NUMBERS AND CLUSTER NUMBER FUNCI\'IONS\nClusters are identified by "cluster numbers", small positive integers. On the FLEX the programmer\nchooses how many clusters to use for a particular run, and assigns them numbers in the range 1-25.\nWithin a Pisces Fortran program. three functions may be used to retrieve the cluster numbers being\nused for clusters in the current run of the program. These functions allow a program to be written without\nknowledge of the precise set of cluster numbers to be used:\ninteger function pppcrnino: returns the smallest cluster number in the configuration being used\ninteger function pppcmaxo: retums the largest cluster number in t e configuration being used\nh\ninteger function pppcnxt(cc1uster-numben):returns the next larger cluster number (modulo # clusters)\nafter <cluster-numben, in the configuration being used\nFunctions pppcmin, pppcmax, and pppcnxt are predefined and do not need to be declared as type\nINTEGER in the user program.\n\nTASK CONTROLLERS\nWithin each PISCES cluster, a system-defined task called a task controller is used to control and\nmonitor the operation of the cluster. A task controller for each cluster is initiated automatically on system\nstartup (at the beginning of a run on the FLEX). The task controller initiates each user task that runs in\nthat cluster. This initiation is done in response t "initiate" messages from other user tasks or the user at\no\nthe terminal, as explained below.\n\nTASK DEFINITION, INITIATION, AND TERMINATION\nAt the top-level, every Pisces Fortran program is structured as a set of one or more tasks that carry\nout the computational work. The programmer defines a set of "tasktypes" in the program. A task of a\nparticular tasktype may be created by executing an INITIATE statement. A task terminates by executing\na TERMINATE statement. These tasks communicate by passing messages, as discussed in the next section; there are no shared variables among tasks.\n\nTASKTYPE Definitions\nPurpose:\nProvide a name and argument list for a tasktype definition (program Unit).\nSyntax:\nTASKTYPE-heading= "tasktype" tasktype-name ["(It argument-list ")"I\n\ntasktype-name = -- any valid Fortran subroutine name\nargument-list = -- see below\nSemantics:\nA task is the largest unit of program execution in Pisces Fortran. A task represents one execution of\na particular tasktype. During execution of a Pisces Fortran program, many tasks of the same tasktype\nmay be running in parallel in different clusters or in the same cluster. The INITIATE statement is used to\ninitiate execution of a new task in a given cluster (see below). The programmer writes tasktype\ndefinitions, and then uses the INITIATE statement to control the number of tasks and their placement in\nclusters.\nA tasktype definition has the same general form as a Fortran subroutine except that "TASKTYPE"\nreplaces "SUBROUTINE" in the heading. The last statement executed in a tasktype definition is a TERMINATE statement (replacing the Fortran RETURN).\nThe arguments for an execution of a task are taken from the message that caused the task to be initiated (see the INITIATE statement below). The INITIATE message contains a sequence of values\n(integers, reds, characters, vectors, etc.). The list of arguments given in the TASKTYPE header specifies\nthe local and COMMON variables that are to receive these values at t e time the task is initiated. The\nh\nargument-list in the TASKTYPE heading must match the argument-list in any INITIATE statement naming that tasktype, in terms of number of values and their types. See the section on argument lists below\nfor details.\n\nFLEX Implementation:\nThe preprocessor converts a tasktype definition into a Fortran subroutine. Initiating a task of a\ngiven tasktype on a given cluster causes the corresponding Fortran subroutine to be executed as a "process" on the FLEX processor that serves as the primary processor for the cluster. Pisces maintains a block\nof data about each running task, called the "taskblock, which indicates the tasktype, inqueue. and various\nother information about the task. Process initiation is done with the FLEX CCcrp and CCrunp calls.\nExample:\ntasktype solver (a, b, c)\ninteger a, b\nreal c\ncommon /blkl/ a, c\n\n...\n\nterminate\nend\n\n6\n\nINITIATEStatements and Task Scheduling\nPurpose:\nInitiate execution of a new task of a particular tasktype. The new task may be scheduled for execution in a particular cluster, or t cluster may be left unspecified (and the Pisces system will schedule it).\nk\nSyntax:\nINITIATE-statement =\n"on" cluster-spec "initiate" tasktype-name I"("argument-list ")*\']\n\ncluster-spec = "any" I "other" I "same" I "cluster(" cluster-number *\')\'\'\nargument-list =\n\n-- see below\n\ncluster-number =\n\n-- standard Fortran integer-valuedexpression\n\nSemantics:\nAn INITIATE statement specifies that a task of a specified type is to be initiated on a specified cluster. The arguments to be passed to the new task are specified using t e syntax described in the Argument\nh\nLists section below. The number and type of the arguments specified in the INITIATE statement argument list must match the argument list specification given in the TASKTYPE heading for the tasktype\nbeing initiated.\nScheduling tasks. Each task is scheduled to be run in a particular cluster when it is initiated. The\ncluster may be specified in one of several ways:\n1. CLUSTER(n). The programmer may specify the number of t e cluster where the task is to be\nh\ninitiated, by an integer or integer-valued expression.\n2. ANY. Specifying the cluster as %ny" means the task may be initiated in any (system-chosen)\ncluster.\n3. OTHER. Specifying the cluster as "other" means the task may be initiated in any system-chosen\ncluster, other than the cluster running the task executing the INITIATE statement.\n4. SAME. Specifying the cluster as "same" means the task must be initiated in the same cluster as\nthe task executing the INITIATE statement.\nThere is no priority scheduling of tasks within a cluster. All tasks share the FLEX PE assigned to\nthat cluster, using the FLEX MMOS-defined time-slicing algorithm.\nWhen an INITIATE statement is executed, an "initiate" message is created and forwarded to the\ntask-controller of the designated cluster. If no cluster is explicitly specified, a system scheduler in the\ncluster of the initiating task determines the appropriate cluster and forwards the initiate message to the\ntask-controller of that cluster. This task-controller determines when the task is actually initiated. At the\ntime of initiation, the arguments designated in the INITIATE statement are passed to the new task. These\narguments are a sequence of values, as described in the Argument Lists section below.\n\nFLEX Implementation:\nThe FLEX implementation follows the semantics described above: execution of an INITIATE stateo\nment causes an "initt" message to be sent t the task-conmller of the designated (or system-chosen) cluster. The task-controller finds an available slot, sets up the taskblock for the task, and initiates the task as a\nFLEX process. If there is no slot available, the task controller waits until a slot is freed by the terminao\ntion of another task in the cluster. This activity is all local within the PE assigned t the cluster.\n\n7\n\nThe current scheduling algorithms for ANY or OTHER scheduling are trivial: the task is initiated in\nthe \'hext" cluster in sequence, as defined by a call to pppcnxt (this cluster). No load balancing is\nattempted.\nExumples:\non cluster(2) initiate solver ( ~ 2 . 5 0pivot)\n,\non any initiate printa (vakl ,vals2)\nTERMINATE Statement\n\nPurpose:\nServes to terminate execution of a task.\nSyntax:\nTERMINATE-statement = "terminate"\nSemantics:\nThe TERMINATE statement is the last statement executed by a task. The task terminates immediately unless the task has split into a "force". If the task is a force, then TERMINATE terminates a secondary force member immediately when executed by the secondary force member. The primary force\nl\nmember waits to terminate until al secondary force members have terminated.\nOrphan messages. A message that remains in a task\'s inqueue when it terminates, or that arrives\nafter a task has terminated, is called an "orphan message". Orphan messages found when a task terminates are reported to the user terminal.\n\nFLEX Implementation.\nAt termination of a task, all storage used by the task is returned to the free storage lists in the global\nheap. The FLEX process representing the task is then killed by issuing a Cckillp call.\nTASKID\'S AND TASK COMMUNICATIONTOPOLOGY\nWhen a task is initiated, it is given a unique "taskid" of the form:\n<cluster-number, slot-number, unique-number, force-member-id>\nwhere the cluster-number and slot-number designate the particular cluster and slot in which the task is\nrunning. The unique-number differentiates the task from other tasks that have run previously or may run\nsubsequently in the same slot. The force-member-id is always 0 for an ordinary task and non-zero for a\nsecondary member of a t s that has split into a force.\nak\nA taskid is a datu value that can be stored in a variable, passed as an argument in a message,\ntransmitted to a subroutine as an argument, printed, etc. Variables and arrays that store taskid\'s must be\ndeclared as type TASKID.\n\nFour functions may be applied to a taskid to retrieve its four parts:\ninteger function pppgclu (taskid). Returns the cluster number part of the taskid.\n\n8\n\nintegerfunction pppgslo (taskid). Returns the slot number part of the taskid.\ninteger function pppguni (taskid). Returns the unique number part of the taskid.\ninteger function pppgfor (taskid). Returns the force-member-id part of t e taskid.\nh\nThese functions are predefined in Pisces Fo~tran do not need t be declared as type INTEGER\nand\no\nby the user.\n\nTASKID Declarations\nPurpose:\nDeclare variables and arrays that are to store taskid\'s.\nSyntax:\nTASKID-declaration= "taskid" variable-list\n\nvariable-list =\n\n-- list of Fortran variables and arrays, as in a REAL\nor INTEGER declaration\n\nSemantics:\nThe declared variables and arrays may be used to store taskid\'s.\n\nFLEX Implementation:\nA taskid is represented as a 32-bit integer, w t 8 bits for each of the four components of the taskid.\nih\nA TASKID declaration is translated into an INTEGER declaration in Fortran.\nExample:\ntaskid a, b, ~(10,201,\nd(100)\n\nEstablishing a Communication Topology\nTaskid\'s are the basis for establishing the communication topology of a Pisces program (which\ntasks can send messages to which other tasks). The rule is: a task may only send a message to another\ntask if it knows the taskid of the other t s Alternatively a task may "broadcast" a message to all other\nak\no\ntasks, or t all tasks within a particular cluster.\nWhen a task begins execution, it only knows its own taskid and the taskid of its parent task (the task\nthat executed the INITIATE statement). Thus, without any other action by a task, the initial communication topology is a directed me: children can send messages directly to their parent task only (but parents\ncannot send messages to their children.)\nFrom this initial starting point, the Pisces program generates the appropriate communication topology dynamically, by sending and broadcasting messages that contain taskid\'s, until each task knows the\ntaskid\'s of every other task with which it must communicate.\nExample:\nSuppose task A initiates ten subtasks, each of which must communicate with all the others. To\nestablish this topology each task would send a message containing it\'s own taskid to the parent task, A.\nTask A stores each received taskid in a TASKID vector. When all ten taskid\'s have been received, task A\nbroadcasts the contents of the TASKID vector. Each of the child tasks accepts this message and stores\nthe received taskid\'s in its own TASKID vector. The 11 tasks have now established a "complete connection" topology, with each able to send messages to each of the others.\n9\n\nPredefined TASKID Variables and Functions.\nTaskid values may be obtained in several ways:\nPPPSELF variable. The TASKID variable "pppself\' is predefined in every Pisces program ui. It\nnt\ncontains the taskid of the task within which it is referenced. For example, executing the assignment:\n\nmyid = pppself\nstores the taskid of the task executing the statement into variable myid (which must be declared to be of\ntype TASKID).\nPPPGPAR function. The predefined TASKID function pppgpar (taskid) returns the taskid of the\nparent task of the argument task. For example:\nmyparent = pppgpar (pppself)\nstores in variable "myparent" the taskid of the parent of the task executing the statement.\nPPPGJOB function. The "job" taskid is the taskid of the top-level task that was initiated directly by\nthe user at the terminal. The predefined TASKID function pppgjob (taskid) returns the job taskid for the\nargument task.\nPPPGSEN function. The "sender" taskid is the taskid of the sender of the last message received by\na task. Thus when task A accepts a message that came from task B, B\'s taskid is stored as the "sender"\ntaskid for A until A accepts another message. The predefined TASKID function pppgsen (taskid) returns\nthe sender\'s taskid for the argument task.\nNote: These functions may be applied by one task to a stored taskid of another task, but they will\nh\nnot return correct results if the other task has terminated at the time of t e call.\nMESSAGE SEND AND ACCEPT\nTasks, once initiated, communicate by sending and receiving messages. Sending and receiving are\nperformed asynchronously. The sender does not wait for the receiver to acknowledge receipt of a message at the time a SEND statement is executed. Instead, the message is inserted in the receiver\'s\n"inqueue", where it waits until the receiver executes an appropriate ACCEPT statement to allow the message to be processed. If the message arrives after the receiver has already terminated, the message\nbecomes an "orphan".\nThe receiver can choose to treat any type of message as a SIGNAL, which means that no processing\nis done when the message is accepted, the message is simply counted and removed from the receiver\'s\ninqueue. Alternatively the receiver may process any type of message with a HANDLER,which is a subroutine that performs the processing required at the time the message is accepted.\nThe receiver of a message may never accept the message at all, in which case the message becomes\nan "orphan" when the receiving task terminates.\n\nSEND Statement\nPurpose:\nSend a message from one task to another.\nSyntax:\n\n10\n\nSEND-statement = "to" task-spec "send message-type ["(" argument-list ")"I\ntask-spec = task-id-expressionI"parent" I "sew 1 "sender"\nI "all" [\'\'cluster(\'\' integer-expression")"I\ntask-id-expression =\n\n-- a variable or function reference whose result is of type TASKID\n\nSemantics:\n\nA SEND statement specifies that a message is to be sent to a designated task or group of tasks. The\nargument-list is treated as described in the Argument Lists section below. The arguments are evaluated\nwhen the SEND statement is executed, a message is created containing copies of the argument values,\nand that message is forwarded to the task or task group specified in the task-spec. The message waits in\nthe in-queue of the receiving task until that task executes an ACCEPT statement that allows the message\nto be pmessed. The sending task continues execution immediately after the message is created and sent;\nit does not wait for a response.\nThe task-spec in the SEND statement specifies the task or group of tasks that are to receive a copy\nof the message. Ordinarily the recipient is specified directly by giving its task-id, which may be stored in\na variable of type TASKID or be the result of a function such as pppgjob. Various special tags are used to\nspecify tasks whose task-id\'s are known to the Pisces system: "parent" (same as the result of the function\ncall pppgpar (pppself)), "self\' (same as "pppself\'), or "sender" (same as the xsult of the function call\nPPPgsen @PPself)).\nTo broadcast a message to all tasks associated with the same job (excluding system-defined tasks),\n"all" is specified, or *\'all clustefln)" to broadcast to all user tasks in a particular cluster.\nMessages are guaranteed to arrive reliably in the receiver\'s inqueue. If task A sends several messages to the same recipient B, then A\'s messages will appear in B\'s inqueue in the order in which A executed the SEND statements.\nFLEX Implementation:\nA message is represented by a header and a linked list of packets. The header contains the sender\'s\ntaskid, the message type, the length of the argument list, and a pointer to the list of packets. The packets\ncontain the argument values.\nWhen task A sends a message to task B, task A allocates and fills a header and as many packets as\nare needed to contain the arguments. The header and packets are always in the FLEX common memory.\nThese are linked together and then appended (linked) to the inqueue of the receiving task (also in common memory.)\n\nExamples:\nto parent send tennin (myindx, emf)\nto sender send badval (x)\nto tidl send newmw (rowmax, mwidx, pppvl (b, 1,100))\nto all send converge (myid, eps)\n\nACCEPT Statement\nPurpose:\nSpecify that a certain number of messages of certain types are to be "accepted" and deleted from the\ntask\'s inqueue.\nSyntax: The ACCEPT statement is multiple-line statement. Each of the lines that begin "accept", "delay",\n11\n\nand "end accept" must appear on a separate line. Also each of the message-type\'s must appear on a\nseparate line.\nACm-statement =\n"accept" "all" or integer-expression "of\'\nmessage-type\n\nmessage-type\n["delay" real-expression "then"\n[statement-sequence]]\n"end accept"\nor\nst\n\naccept"\nmessage-type ["all" or integer-expression]\n\nmessage-type ["all"or integer-expression]\n["delay" real-expression "then"\n[statement-sequence]]\n"end accept"\nI\n\nmessage-type = -- as appears in a SEND statement\nstatement-sequence =\n\n-- any Fortran statement sequence\n\nSemantics:\n\n1\n\nI\n\nI\n\nAn ACCEPT statement allows receipt of a specified number of messages of specified types. The\ntypes of messages are listed in the ACCEPT statement.\nThe number of messages accepted when an ACCEPT statement is executed is specified in one of\ntwo ways:\n1. If an " O F clause appears in the first line of the ACCEFT statement, then the OF clause count\ngovern the number of messages accepted. The task will continue t process messages of any of the listed\no\ntypes until the OF clause count is satisfied (or until the "timeout" of the ACCEPT occurs, see below). If\nthe OF clause specifies a count of "all",then all messages of the listed types that have been received are\nprocessed, and the task continues execution without waiting further.\n2. If no OF clause appears in the first line, then a count may be specified for each individual message type listed. If no message count follows a message type, then one message of that type is accepted.\nIf the message count is "all", then all messages of that type in the in-queue of the task are accepted. If the\nmessage count is an integer expression, then the expression is evaluated on entry to the ACCEPT statement, and the resulting number of messages of that type are accepted. A negative or zero count means no\nmessages of that type are accepted.\nThe task executing the ACCEPT declares each message-type as a SIGNAL or HANDLER. Each\nmessage accepted that is declared of a HANDLER type causes execution of one activation of the handler\nsubroutine with that name. These activations are executed in sequence, depending on the order that the\naccepted messages appear in the task\'s inqueue. Each message accepted that names a SIGNAL is simply\ncounted; a signal message invokes no other processing.\n\n12\n\nIf the designated number of messages have not been received when the ACCEPT statement is executed, then all the received messages are accepted and processed, and the receiving task waits for the\nremaining messages to arrive. If "all" is specified for any message-type, then any messages of that type\nx\nh\nthat a e in the inqueue when t e ACCEPT is executed will be processed (messages that anive during execution of the accept may not be processed, depending on the timing of the message anival).\nTimeout. An ACCEPT statement will always terminate, either when a l the specified messages have\nl\nbeen processed, or, if not all messages have anived, after a specified maximum wait for the remaining\nmessages. The maximum delay is specified as a system default, or it may be given explicitly in the\nACCEFT statement, as the value of a (real-valued) expression which gives the maximum delay in\nseconds.\nThe value of this delay expression has the following meaning: all messages which have already\narrived in the inqueue of the receiving task (and which the ACCEPT statement allows t be accepted) are\no\nprocessed. When all messages which can be accepted have been processed, the delay timing begins. If\nan acceptable message is received before the maximum delay has elapsed, this message is processed, and\nthe delay timing begins anew. If the maximum delay elapses with no acceptable message received, then\nthe specified "timeout" statement sequence is executed, or a system-generated timeout message is\ndisplayed.\n\nFLEX Implementation:\nThe FLEX implementation of ACCEPT uses a single scan down the inqueue of the task. The type\nof each message in the inqueue is compared against each of the message types listed in the ACCEFT. If a\nmatch is found, the appropriate counters are decremented, and if the message-type has been declared a\nHANDLER,then the handler subroutine is called. If the end of the inqueue is reached before all the\ncounts have been satisfied, the clock time is recorded and the task relinquishes the PE (a CCnextp call).\nWhen the task reawakens it checks the inqueue following the old end. If new messages have been\nreceived, it checks each new message against the ACCEFT list, and accepts any that can be accepted. If\nnone are accepted, then the delay since the recorded clock time is determined, and the ACCEFT times out\nif the specified delay has been exceeded; otherwise the task again goes to sleep and the cycle repeats.\nThis timeout algorithm guarantees that the ts will wait for the desired messages at least as long as\nak\nthe specified delay value, but it may wait longer.\nExumples:\naccept all of\nnextmw\nend accept\naccept 1 of\nenque\ndeque\nendaccept\naccept\ntennin (all)\nconverge\ndelay 25.0 then\nto parent send error1\nendaccept\n\n13\n\nHANDLER and SIGNAL Declarations\n\nPurpose:\nDeclare the type of processing required within a task for a particular message type that the task\nacmpts.\nSyntax:\nHANDLER-declaration= "handler" message-type, { ,message-type}\n\nSIGNAL-declaration= "signal" message-type, { ,message-type)\nSemantics:\nEach message-type that appears in an ACCEFf statement must be d e d d as either HANDLER or\nSIGNAL in the program unit that contains the ACCEPT. Message-types declared as SIGNAL are simply\ncounted and deleted fmm the inqueue of t e task when they are accepted. Message-types declared as\nh\nHANDLER are processed by calling a HANDLER subroutine of the same name as the message-type (see\nHANDLER subroutines below).\n\nFLEX Implementation:\nHANDLER declarations are translated into Fortran EXTERNAL declarations by the preprocessor,\nto force the necessary run-time linkages between the task and its handler subroutines. SIGNAL declarations are deleted from the Fortran code, but both declarations are used to guide correct translation of subsequent ACCEPT statements in the program unit.\nExamples:\nhandler newrow, solve\nsignal converge\n\nHANDLER Subroutines\nPurpose:\nA HANDLER is a Fortran subroutine for processing ("handling") messages of a certain type.\nSyntax:\nHANDLER-header= "handler"message-type\n\n[\'I("\n\nargument-list ")"I\n\nmessage-type = -- any F r r n name\nota\nargument-list =\n\n-- see the Argument Lists section below\n\nSemantics:\nA handler is written as an ordinary Fortran subroutine, with "SUBROUTINE" replaced by\n"HANDLER in the heading. A handler is always part of some tasktype definition, in the same way that\nan ordinary subroutine is part of some main program definition in ordinary F o m .\nThe name of a handler is always the same as the name of the message type that it processes. A\nhandler is not CALL\'ed in the usual way. It is executed when a task (of the tasktype associated with the\nhandler) executes an ACCEPT statement to accept a message of the handler\'s type.\n\n14\n\nThe handler does not have Fortran subroutine arguments. Instead the handler receives the arguments contained in the message that it is invoked to process. The "argument-list" in the handler heading\no\nlists the variables in the handler that are t receive these incoming values from the message. These\nargument-list variables may be COMMON variables or local variables in the handler. When the handler\nbegins its execution, the incoming argument values have already been stored in the specified argumentlist variables. The handler may then process these values in whatever way is appropriate. The argumentlist in the handler heading must match the corresponding argument-list in the SEND statement that sent\nthe message received by the handler, in terns of correspondingnumbers and types of values transmitted.\nOften the purpose of a handler is simply to store the incoming argument values in COMMON\nblocks that are accessible to the task associated with the handler. Because the handler is not CALL\'d by\nits associated task, the nonnal Fort~an\nsubroutine argument list is not available as a means for the handler\nto send message values back to its associated task. Thus COMMON blocks must be used to store any\nvalues from the message that must be sent back to the handler\'s associated task.\nA handler may use any of the new statements and declarations defined below, except that a handler\no\nmay not do an ACCEFT (Le., a handler may not invoke another handler t process a second message\nwhile it is still processing a first one).\n\nFLEX Implementation:\nA HANDLER definition is translated into a Fortran subroutine with two arguments, the "self\' taskid\nof the invoking task and a pointer to the message to be processed. Fortran calls on handler subroutines\nare generated by the preprocessor during translation of ACCEFT statements. The "arg-list" in the handler\nheading is translated into a sequence of calls on the argument unpacking functions (seethe discussion of\narg-lists below). These calls are inserted by the preprocessor at the END DECLARATIONS position in\nthe handler body, before the first executable statement of the handler body.\n\nEmple:\nhandler newval (row, value)\ncol,\ninteger mw, col\ncommon /blk2/solution (100,200)\nend declarations\nsolution (row, col) = value\n\nreturn\nend\nwhich stores the incoming value in the designated spot in the result matrix. An equivalent, but simpler,\nversion is:\nhandler newval (row, col, solution (row,\ncol))\ninteger row, col\ncommon /blk2/solution (100,200)\nend declarations\nreturn\nend\n\n15\n\nARGUMENT LISTS\nThere are four different places where an argument list may appear in a Pisces Fortran program:\nSEND statements.\nINITIATE statements.\nTASKTYPE headers.\nHANDLER subroutine headers.\nThe tern "argument-list" in Pisces Fortran refers to:\n1. The list of variables and arrays that contain values to be copied into a message when a SEND or\nINITIATE statement is executed ( h n of this list as the variables from which to gather the values to be\ntik\nsent). This list may also include literal values.\n2. The list of variables and arrays that are to receive the values contained in a SEND or INITIATE\nmessage when it is processed by the receiving task (think of this list as the variables into which to scatter\nthe values received in the message.\nSyntax:\nThe syntax for argument lists is the same in any of these four constructs. Because the Pisces Fortran\npreprocessor does not build a table.of type and dimension information for variables and arrays, the pmgrammer must provide this information as part of each argument list element. The specifications below\ncan be combined into argument lists of any length by listing the specifications in sequence separated by\ncommas.\n\nREAL, INTEGER, and LOGICAL Variables. A simple variable of one of these types occupies one\nword of storage. To specify in an argument list, just list the variable name. For example, to send REAL\nvariables X and Y,you might write:\n\nto ...send unessage-type> (XIY)\nCOMPLEX and DOUBLE PRECISION Variables. A simple variable of one of these types occupies\ntwo words of storage. To specify in an argument list, write:\n\n"ppp2(" variable-name [, variable-name}\'*)"\nFor example, to send COMPLEX variables cmin and cmax, you might write:\nto ... send anessage-type> (ppp2 (cmin, cmax))\nCHARACTER Variables. A simple variable of one of these types occupies one byte of storage for each\ncharacter position in the variable. To specify in an argument list, write:\n\n"pppch(,,variable-name, first-char-posn, last-char-posn "Y,\nwhere the first and last character positions are specified by integer-valued expressions. For example, to\nsend the first 10 characters of a CHARACTER variable charl, you might write:\nto ... send anessage-type> (pppch (charl, 1.10))\n\n16\n\nREAL, INTEGER or LOGICAL Vectors. A vector (one-dimensional array) of one of these types\noccupies one word of storage for each element. To specify in an argument list, write:\n\n\'*pppvl(,,variable-name,first-element, last-element [, stride] ")"\nwhere the subscripts of the first and last elements in the vector are specified by integer-valued expressions. The stride, if included, is an integer-valued expression that specifies the "stride" between vector\nelements to be included (the increment to be added to one subscript to get to the next subscript). If omitted the stride is assumed to be 1. For example to send the 5th through 20th elements of a REAL vector\nsolnvect, you might write:\nto ... send anessage-type> (pppvl (solnvect, 5,20))\nCOMPLEX or DOUBLE PRECISION Vectors. These vector elements occupy two words of storage.\nUse the same specification as for one word vectors, but replace "pppvl" by "pppv2". For example, to\nsend the 5th through 20th elements of a COMPLEX vector compvect, you might write:\n\nto ... send unessage-type> (pppv2 (compvect, 5.20))\nREAL, INTEGER, or LOGICAL Matrices or Parts of Matrices. Elements of these matrices occupy\none word of storage. You may specify an entire matrix or any rectangular subportion such as a row,\ncolumn, or block of rows or columns. To specify a portion of a matrix, write:\n"pppml(" matrix-name, #rows,#columns, first-row-subscript, last-row-subscript,\nfirst-column-subscript, last-column-subscript")"\nwhere integer-valued expressions may be used to specify each item except the matrix-name. The ##rows\nand #columns should be the declared dimensions of the matrix. The first and last TOW subscript expressions specify the range of rows to be included and the first and last column subscripts specify the range of\ncolumns to be included. For example, to send the 2nd row of a 10x20 matrix, tablel, you might write:\n\nMatrix values are sent and received in "column-major order" (normal Fortran order in which all values\nfrom the first column come first, then values from the second column,etc.)\nCOMPLEX and DOUBLE PRECISION Matrices or Parts of Matrices. Use the same specification\nas for REAL matrices, but replace "pppml" by "pppmT to indicate that each matrix element occupies\ntwo words of storage.\nCHARACTER Vectors. To send all or part of a vector of character strings, write:\n"pppvch(" vector-name. first-element, last-element, declared-element-length")"\nwhere each item except the vector-name is specified by an integer-valued expression. The first and last\nelement designations specify which elements to include. The declared-string-length specifies the number\nof characters declared to be in each element. For example, to send the 5th through 20th character strings\nin a vector declared as: CHARACI\'ER stringtab (100)*25, you might write:\n\nto ...send message-type> (pppvch (stringtab, 5,20,25))\n\n17\n\nSemantics:\nThe meaning of argument specifications depends on whether the argument list appears in a\nSENDDNITIATEstatement or in a TASKTYPE/HANDLER heading.\nSENDIINITIATE. The value of each specified argument is copied into the argument list being\nformed for the message to be sent. For a SEND,the message is sent directly to the receiver. For an I I\nNTIATE, the message is sent to the task controller of the cluster, which passes the argument list on to the\nnew task after its initiation.\nTASKZYPE/HMDLER. Each specified argument is assigned a new value taken from the message\nargument list. Values are copied from the message into receiving variables and arrays in the order\nspecified in the argument list.\n\nFLEX Implementation:\nEach argument specification is translated into a sequence of calls on argument packing functions\nwhich fetch values from the specified argument variables and arrays and copy them into the packets of the\nmessage argument list. On the receiving end, the same functions copy values from the packets into the\nreceiving variables and arrays.\nOnly values are sent and received; no type or size information is included in the message (other than\nthe overall length of the message). Thus it is the programmer\'s responsibility to insure that sender and\nreceiver agree as to the number and type of values in the message. Note that the same SEND or INITIATE statement may generate a message of different length each time it is executed. An attempt to\nunpack more values than are received in a message, or unpacking fewer values than were received will\ngenerate a run-time error message.\nFORCES\nA "force" in Pisces Fortran is simply an ordinary task that has "split" into several "force members"\nthat are running on different PE\'s and each executing the same tasktype definition. Forces are an altemative form of parallel execution, subordinate to the concept of task discussed in the preceding sections.\nForces have several distinguishing characteristics:\n1. From the "outside", a task that has split into a force appears still to be a single task -- it has a\nunique taskid, inqueue, etc. It may send and accept messages from other tasks. There is no way that\nanother task can tell whether a given task has split into a force. Thus the "force" or "not a force" distinction is entirely an internal question about a task.\n2. Every task begins execution in the same way, as an ordinary task. A task splits into a force when\nit executes a FORCESPLIT statement (see below). After execution of a FORCESPLIT the task is composed of a set of force "members" running in parallel on separate PE\'s. No two members of the same\nforce ever share the same PE.\n3. Members of a force are identified by a taskid with the same cluster-number, slot-number, and\nunique-number, but with a unique force-member-id. The original task continues execution after a FORCESPLIT as force-member O. The "secondary" force members that begin execution at the FORCESPLIT\nare given force-membernumbers 1-k. A force member can always obtain its force-member-id number by\nexecuting the predefined function pppgfor (pppself).\n4. The number (k above) of force members for a particular tasktype is not determined when the\nPisces Fortran program is written, but when the configuration for a particular run of the program is set up\n(see P r 2 of this manual). Thus the program itself is independent of the number of force members. The\nat\nprogram should run the same if a particular force has only one member or if it has 18 members (the maximum size of a force on the FLEX). The size of a force affects only the speed of execution of the force,\n18\n\nnot the results of that execution.\n5. Forces may use s h m d variables, baniers, parallel loops, and other program constructs that are\nnot available to ordinary tasks. These constructs are described below.\nFORCESPLIT Statement\nPurpose:\nCauses an ordinary task to split into a force.\nSyntax:\nFORCESPLIT-statement = "forcesplit"\nA tasktype definition may contain only one FORCESPLIT statement, which cannot be part of any other\nstatement (e.g., an IF or DO). The FORCESPLIT statement must appear in the main tasktype definition,\nnot in a subroutine.\nSemantics:\nWhen an ordinary task executes a FORCESPLIT, it "splits" i t k identical copies running on\nno\nseparate FLEX PE\'s. Each of the copies begins execution at the point of the FORCESPLIT. These\ncopies are called the force "members".\nThe number k of copies is determined by the number of "secondary" PE\'s that have been assigned\nto the cluster within which the task is executing at the time of the FORCESPLIT. This number is determined by the configuration chosen for a run of the program (see Part 2 of this manual), and may vary\namong clusters. Thus the number of force members depends on the cluster within which a task is initiated. For example, if cluster 1 has been assigned 4 secondary PE\'s and cluster 2 has been assigned 16\nsecondary PE\'s, then executing a task A (that executes a FORCESPLIT) in cluster 1 will cause a split into\n5 force members (primary plus 4 secondary members). If executed in cluster 2 the same task will split\ninto 17 force members (primary plus 16 secondarymembers.)\nEach force member is assigned a force-member-id that uniquely identifies it. The original task continues execution after the FORCESPLIT as force member 0. The other force members receive id\'s in\nsequence from 1-k, where k is the size of the force. Each force member can access the variable pppself to\nobtain its selfid, which contains the same cluster-number, slot-number and unique-number as other\nmembers of the same force, but contains the unique force-member-id of that force member.\n\nFLEX Implementation:\nEach force member is a separate FLEX process executing on one of the PE\'s assigned to the cluster.\nAt the time a FORCESPLIT is executed by a task of tasktype A, a FLEX process of type A is initiated on\neach of the secondary PE\'s assigned to the cluster where the original task is executing. The preprocessor\nhas inserted a branch at the beginning of each tasktype definition that checks the force-member-id at the\nstart of execution and branches to the FORCESPLIT statement if the force-member-id is not 0.\nIn the taskblock for a task, a flag is set indicating that the task has split into a force. The MMOS\nprocess id\'s assigned to each force member are retained in the taskblock while the force is executing. A l\nl\nforce members share the same taskblock and inqueue. Thus force members are not treated as separate\nPisces tasks, although they are executed as separate h4MOS processes.\nExample:\n\n19\n\ntasktype solver (a, b, c)\n\n...\n...\n-- these statements are executed only by the primary force member\nforcesplit\n... -- these statements are executed by all force members\n\nend declarations\n\nterminate\nend\nSHARED VARIABLES\nMembers of the same force communicate with each other by using shared variables. Shared variables are grouped into Fortran COMMON blocks and the entire COMMON block is placed in the FLEX\ncommon memory. Access to shared variables by separate force members must be synchronized by use of\nBARRIER or CRITICAL statements.\nSHARED Declarations Block\nPurpose:\nDeclare one or more Fortran COMMON blocks and related declarations t a are t be placed into\nht\no\nthe FLEX common memory.\nSyntax:\nSHARED-block =\n"shared"\n<FortranCOMMON and other declarations>\n"end shared"\nwhere the Fortran COMMON and declarations may be any declarations that may appear in a Fortran\nBLOCK DATA program unit (type declarations, PARAMETER\'S,etc.). Use of DATA statements to initialize shared variables is not recommended due to a FLEX software bug. See the discussion of the\nat\nFLEX \'static variables\' problem in P r 2 of this manual.\nSemantics:\nThe COMMON blocks that are specified in the SHARED block are allocated in the FLEX common\nmemory.\nFLEX Implementation:\nThe entire set of declarations is translated into a Fortran BLOCK DATA unit, which is written to a\nfile with the suffix ".sh.f\'. This file is then compiled into a ".sh.o" file. The FLEX cf77 processor that\nu\nbuilds a loadfile for a r n uses this file to determine what COMMON blocks are to be allocated in the\nFLEX common memory.\nExample:\n\n20\n\nshared\nparameter (M=lO, N=20)\nreal a1(M, N), a2(200)\ncommon /blkl/al, a2,eps\ncommon /globaVid, next, soln\nend shared\nSYNCHRONIZATION:BARRIERS AND CRITICAL REGIONS\n\nBarriers and critical regions provide the means for force members to synchronize their activities,\nand, in particular, to synchronize their access to s h a d variables. LOCK variables are used with CRITICAL statements to form critical regions.\n\nBARRIER Statement\nPurpose:\nProvide a banier synchronization point for all members of a force.\nSyntax:\nBARRIER-statement =\nbarrier"\n<Pisces Fortran statement sequence>\n"end barrier"\nSemantics:\nA BARRIER statement is only meaningll after a FORCESPLIT has been executed by a task. A l\nl\nforce members pause and wait when they execute the BARRIER statement. When al force members\nl\nhave arrived at the banier, the primary force member (force-member-id = 0) executes the <statement\nsequence> within the barrier, and then all force members continue their execution. For a secondary force\nmember, the barrier seIves simply as a point at which execution pauses; secondary force members take no\naction during execution of a BARRIER statement.\nDeadlock or other synchronization errors may occur if BARRIER statements occur within conditional (IF) statements or other constructs that may cause some force members to skip execution of a particular BARRIER.\n\nFLEX Implementation:\nBarriers are implemented using two counters, two locks, and two flags in the taskblock of the force\ntask; there is no use of MMOS "events". Each force member "checks in" on amval at the barrier. When\nall members have arrived, the primary executes the <statement sequence> in the barrier. Each force\nh\nmember then "checks out" of t e bamer.\nExample:\nbamer\nread (2,*) a, b, c\nend barrier\n\n-- read values into s h a d variables\n\n21\n\nLOCK Declarations\nPurpose:\n\nDeclare variables and arrays to serve as "locks" for synchronizing access to shared variables.\nSyntax:\n\nLOCK-declaration = "lock" variable-list\nVariable-list = -- list of Fortran variables and arrays as in a REAL declaration\nThe LOCK declaration may only appear within a SHARED block (Le., LOCK variables must be shared\nvariables.)\nSemantics:\n\nEach variable and array element declared as type LOCK may be used as a lock on entry to a CRITICAL statement (see below). The program must set the initial state of each lock variable to "unlocked" by\nexecuting a pppunlk (<variable>) call before the lock is used.\nFLEX Implementation:\nThe LOCK declaration is translated into a Fortran LOGICAL declaration. On the FLEX any variable or array element may be used as a lock. The LOCK declaration is a convenience declaration, but not\nrequired. For example, it is possible to use every other element of a vector as a lock for the preceding\nelement.\nExample:\n\nlock queueptrs, solnlock\n\nCRITICAL Statements\nPurpose:\nSynchronize access to shared variables by force members.\nSyntax:\n\nCRITICAL-statement=\n"critical" lock-var\n<statement sequence>\n"end critical"\nlock-var = -- name of a LOCK variable or array element\nThe <statement sequence> may include any Fortran or Pisces Fortran statements, including nested CRITICAL statements.\nSemantics:\n\nWhen a force member arrives at a CRITICAL statement, it attempts to lock the designated lockvariable (ppplock function). The ppplock call does not return until the lock has been successfully locked.\nThe force member then executes the <statement sequence> and the lock is unlocked. While one force\nmember holds the lock, no other force member may enter the same CRITICAL statement (or any other\nCRlTICAL statement that names the same lock-variable.)\n\n22\n\nI\n\nFLEX Implementation:\nSpinlocks art: cumntly used to implement locks. A bit within the lock variable is set to indicate\nthat the lock variable is "locked". A test-and-set instruction on the FLEX PE is used to set the lock. The\nbit is set to zero to indicate the lock is "unlocked". If the bit is already set when a "lock" operation is\nattempted, the force member loops u t l the lock is unlocked (busy waiting). Since force members are\nni\nguaranteed to run on different PE\'s, this busy waiting cannot keep another force member from unlocking\nthe lock.\nExample:\ncritical mylockl\n<statements to change values in shared variables and arrays>\nend critical\n\nPARALLEL LOOPS AND SEGMENTS\n\nForce members may cooperate to execute the iterations of loops in parallel. There are two basic\nways of splitting up the iterations of a loop among force members, called "prescheduling" and "selfscheduling". The loop body is an ordinary Fortran DO loop body.\n1. Prescheduled loops. When a prescheduled loop is executed by a force of K memben, each\nmember executes 1/K of the loop iterations (approximately). If the loop iterations have index values 1 to\nN, then force member 0 executes, in sequence, iterations 1, K+1,2*K+1, and so forth. Force member 1\ntakes iterations 2, K+2,2*K+2, and so forth.\n2. Selfscheduled loops. When a selfscheduled loop is executed by a force of K members, each\nmember executes the "next" iteration that has not been executed by some other force member, until all\niterations have been completed. In the extreme, if one force member is running far ahead of the others,\nthat force member may reach a selfscheduled loop and execute all the iterations before any other force\nil\nimembers amve. In general, which iterations a particular force member executes wl depend on the t m\ning of the arrival of that force member at the selfscheduled loop, and the speed with which it is able to\nexecute each iteration assigned to it.\nPRESCHEDULED DO Loops\nPurpose:\nProvide parallel execution of loop iterations by a force, using the "prescheduling" technique for\ndividing the iterations.\nSyntax:\nPRESCHEDULED-DO-lWp =\n"presched do" <usual Fm DO loop heading>\n<loop body>\nwhere the end of the loop body is indicated by a statement number that appears in the loop heading, as\nwith an ordinary Fortran DO loop.\nSemantics:\nThe loop iterations are executed by the force members using the prescheduling method described\nabove to divide the iterations. Each force member does approximately 1/K of the iterations. The programmer is responsible to determine that the loop iterations can safely be executed in parallel. There is\n23\n\nno synchnization of force members on entry to or exit from a prescheduled loop -- one force member\nmay have finished its share of t e iterations and gone on before another force member arrives at the loop.\nh\n\nFLEX Implementation:\nThe preprocessor inserts a new initial value and stride for the loop index variable into the DO loop\nheading, based on the force-member-id of the executing force member and the size of the force. Thus\nwhen the loop is executed, each force member executes its iterations and skips those not assigned to it.\nThere is essentially no run-time cost associated with using a prescheduled loop (over an ordinary Fortran\nDO loop).\nExample:\n\npresched do 10 i = 1,500\na(i) = Mi) + 2 * c(i)\n10\ncontinue\nIf the force executing this statement has 10 members, then each member executes 50 iterations.\nSELFSCHEDULEDDO Loops\nPurpose:\nAllow force members to execute loop iterations in parallel, using "selfscheduling" to divide the\niterations among force members.\nSyntax:\n\nSELFSCHEDULED-DO-statement\n=\n"selfsched do" <Ftn DO loop heading>\n<loopbody>\n"end selfdo"\nwhere the <Ftn DO loop heading> does not include a <statement numben for the end of the loop.\nSemantics:\nEach force member requests the next unassigned value of the loop index and then executes the loop\nbody with that index value. After execution of the loop body, the force member requests the next unassigned value of the loop index. Each force member continues to request loop index values until all iterations are executed.\n\nFLEX Implementation:\nThe initial loop index value, final value, and stride are computed and stored in the taskblock of the\ntask. Each force member "checks in" to the loop, and then loops, requesting an index value and executing\nan iteration, until all iterations are complete. To get the next index value. the index is locked, incremented, and unlocked. On loop termination, each force member checks out of the loop. No force\nmember can enter the next selfscheduled loop until all have left the previous one.\nExample:\nselfscheddoi= 1,100\na(i) = Mi) + 2 * c(i)\nend selfdo\n\n24\n\nPARSEG Statement\nPurpose:\nProvide for parallel execution of arbitrary program segments by force members.\nSyntax:\nPARSEG-statement =\nparseg"\n<statement-sequence-1>\n"nextseg\n<statement-sequence-2>\n"nextseg"\n"\n\n\'I\n\n...\n\n"endseg"\nwhere as many segments as desired may be included. Each segment is a sequence of ordinary Fortran or\nPisces Fortran statements.\nSemantics:\nExecution of the <statement-sequence>\'s is divided among force members in a "prescheduled"\nmanner. That is, if there are K force members, force member 0 executes, in sequence, sequence 1,\nsequence K+1, sequence 2*K+1, and so forth. Force member 1 takes sequences 2, K+2, 2*K+2, etc.\nThere is no synchronizationof force members on entry or exit to a PARSEG statement. The programmer\no\nis responsible t insure that the segments can correctly be executed in parallel.\n\nFLEX Implementation:\nThe preprocessor generates an appropriate computed GOT0 to send each force member in turn to\nits assigned segments. There is essentially no run-time overhead associated with parallel execution of a\n\nPARSEG.\nExample:\n\nPaw3\n\ni = nextmw\ncall rowsolver (i, vect, 1, 100)\n\nnextseg\n\ncall printout (matrix, eps, solnvect)\nnextseg\nto task27 send tryagain\n\nnextseg\n10\nendseg\n\ndo 10 k = 1,100\nbal(i) = 0.0\ncontinue\n\n25\n\nTABLE OF PREDEFINED VARIABLES, FUNCTIONS AND SUBROUTINES\n\nSerf taskid variable.\npppself: taskid of a task, when referenced within the tasktype definition or a subroutine (pfsub).\nCluster numberfunctions.\ninteger function pppcmin(): return the smallest cluster number in the configurationbeing used.\n\ninteger function pppcmaxo: returns the largest cluster number in t e configuration being used.\nh\ninteger function pppcnxt(<cluster-numben):return t e next larger cluster number (modulo # clusters)\nh\nafter <cluster-numben, in the configuration being used.\nTaskid componentfunctions.\ninteger function pppgclu (taskid): returns the cluster number part of the taskid.\n\ninteger function pppgslo (taskid): returns the slot number part of the taskid.\ninteger function pppguni (taskid): returns the unique number part of the taskid.\ninteger function pppgfor (taskid): retums the force-member-id part of the taskid.\nLock and unlock subroutines.\nsubroutine pppunlk (variable): set the variable to the "unlocked" state.\n\nsubroutine ppplock (variable): wait until the variable is in the "unlocked" state\nand then set the variable to the "locked" state.\nTaskidfunctions.\ntaskid function pppgpar (taskid): returns the taskid of the parent task of the argument taskid.\n\ntaskid function pppgjob (taskid): returns the taskid of the \'job\' task (top-level task)\nfor the argument taskid.\ntaskid function pppgsen (taskid): returns the taskid of the sender of the last message accepted\nby the argument taskid.\nTask termination subroutine.\nsubmutine pppkill (taskid): terminate execution of the specified task, including a l l force members.\n\n26\n\nreal v e c t l o , v e c t 2 0 , sum\ninteger mw,col, length\nenddeclarations\n\n*\n* Form the inner product\n*\n10\n\nsum = 0.0\ndo 10 i = 1,length\nsum = sum + vectl(i)*v&(i)\ncontinue\n\n*\n* Send message with result to parent\n*\n\nto parent send newval (row, col, sum)\nterminate\nend\n\n29\n\nEXAMPLE 2: N r a i e a Matrix; Using a Force.\nomlz\n\n*\n* This program normalizes a square matrix by its largest element.\n* It represents a Pisces Fortran version of the Force demo program\n* in the FORCE USER\'S MANUAL (Jordan, Benton, Arenstorf, U. Colo.,\n* Oct. 1986).\n* Printing of the result matrix has been suppressed, and additional\n* intermediate printouts have been added.\n* The use of asynchronousvariable ALLMAX in the original version has\n* been replaced by an equivalent shared variable \'allmax\' and lock\n* variable \'maxlock\' in the Pisces version.\n*\n......................................................................\ntasktype demo\n*\n* Parameter N represents the matrix size. User modifiable.\n*\nshared\nparameter (N=lO)\ncommon x(N, N), allmax, maxlock\nlock maxlock\nreal allmax, x\nend shared\nreal pmax. tem\nend declarations\n\n*\n* Only the primary task begins execution here\n* Initialize shared variables before forcesplit\n*\nprint *, \'Begin force demo...\'\n*\n\nallmax = 0\ncall pppunlk (maxlock)\nforcesplit\n\n*\n* Force is running now; secondary force members start here\n*\nid = pppgfor (pppself)\nprint *, \'Begin forcemember \',id\n\n*\n* Generate test matrix\n*\n\npfcaU intmat (x, N)\n\n*\n* Search matrix for its greatest element\n*\npmax = 0\n\n*\n* Each force member findsmax of its share of\'&\n*\n\nmbs;>ooi;?d in pmax\n\n30\n\n"\n*\n\npesched do 100 i = 1, N\nprint *, \'Loop 1: Member \',id, \' takes TOW \', i\ndo 200 j = 1, N\ntem = abs(x(ij))\nif (tem .gt.pmax) pmax = tem\n200\ncontinue\n100 continue\n\n*\n* Force members communicate to place global max in allmax\n*\n&\n\ncritical maxlock\nprint *, \'In critical section, member = \', id,\n\' Pmax = *, pmax, \'Allmax = \', allmax\nif (pmax .gt. allmax) Wx = pmax\na\nend critical\n\n*\n* Wait until final global maximum has been determined\n*\nbarrier\nprint *, \'Global max = \', allmax\nendbarrier\npmax = allmax\n\n*\n* Normalize the matrix; each force member takes its s a of cows\nhe\n*\n\n400\n\n300\n\nif (pmax .gt. 0) then\npresched do 300 i = 1, N\nprint *, \'Loop 2: Member \', id, * takes row \', i\ndo 400j = 1, N\nx(ij) = x(iJ)/pmax\ncontinue\ncontinue\n\n*\n* Wait for everyone to finish\n*\nbarrier\nendbanier\nendif\n\n*\n* And print the result matrix\n* A PARSEG is used to insure that only one force member prints the result\n*\nPg\n-\n\ncall outmat (x, N)\nendseg\nterminate\nend\n\n......................................................................\n*\n* Sequential subroutine to print result matrix\n\n*\n\n31\n\nSubroutineoutmat (x, N)\ninteger N\nreal x(N, N)\nwrite (6,*) \'printing of r e s ~suppressed\'\ns\n*\ndo 1Oi= l , N\n*\ndo l O j = l , N\n*10\nwrite (6, *) i, j, x(ij)\nreturn\nend\n\n*\n* Parallel subroutine to generate test matrix\n*\npfsub intmat (mat, N)\ninteger N\nreal mat(N,N), gen\nenddeclarations\n\n*\n* Divide the work of generating the rows among force members\n*\n\n30\n20\n\npresched do 20 i = 1, N\ndo 30j = 1, N\nmat(ij) = gen(ij)\ncontinue\ncontinue\nreturn\nend\n\n......................................................................\n*\n* Function to generate a test matrix value\n*\nreal function gen(ij)\ninteger i, j\nif ((i+j) .ge. 1) then\ngen = lOOO.O/(i+j)\nelse\ngen= 1000.O\nendif\nreturn\nend\n\n32\n\nPISCES USER\'S MANUAL:PART 2\n\nTHE CONFIGURATIONENVIRONMENT\nThe Configuration Environment is the part of the Pisces system that is used to create and edit\nconfiguration liles. The Configuration Environment also allows the user to load and execute a program\non the FLEX132 -- an action that leads to the run-time environment described in Part 3.\nWHAT IS A CONFIGURATIONFILE?\nA configuration file is just a file of data that describes the various options that you have chosen for a\nparticular nm of a Pisces Fortran program on the FLEX. Included in a configuration file are the various\nelements described in the paragraphs below. A configuration file is created by the Configuration Envimnment, and then may be saved and reused as needed for later runs of your program on the FLEX. An existing configuration file can be edited and saved under a new name. Thus, by editing a configuration file\nrepeatedly, you can create configurations for many different runs (with different uses of the FLEX\nresources).\nYou don\'t need to know anyhng about the structure of a configuration file -- the Configuration\nEnvironment reads and writes these files for you automatically, as required by your response to the various prompts described below.\nWHAT I A LOADFILE?\nS\nA loadfile is a file of executable code and data that can be downloaded to one or more of the FLEX\nPE\'s available for a parallel computation. A loadfile contains:\n1. The object files (".o"files) resulting from preprocessing and compiling the parts of your Pisces\nFortran program.\n2. The Pisces run-time library routines and the Pisces execution environment routines needed to\nexecute your program.\n3. Additional library routines containing the FLEX M M O S operating system that controls each PE\nduring program execution.\nA major step in creating a configuration for a run is to create an appropriate loadfile for the run.\nThis loadlile is created automatically by the Configuration Environment after you have specified some\nparticulars (described in 3. below). You don\'t have to know anything about how to construct a loadfile -the Configuration Environment will do this for you automatically.\nENTERING THE CONFIGURATIONENVIRONMENT\nWhen running under Unix, type the command:\nPisces\nA series of menus and prompts will appear that allow you to create and/or edit a configuration file.\nOn entry to the configuration environment, you will be asked if you want to use an existing\nconfiguration file. If you have already created a configuration file in a previous session and simply want\nto edit it, answer "yes". You will be prompted for the configuration file name, and then the existing\nconfiguration will be displayed for you to check or edit.\nIf you are not editing an existing configuration file, answer "no" at the prompt. You will be given\nthe "default" configuration as a starting point.\n\n33\n\nCONFIGURATIONOPTIONS\nThe following paragraphs provide a detailed explanation of the various options available through\nthe configuration environment menu. You are first shown the full current configuration. By choosing the\nappropriate number for the option, you may edit any of the options displayed.\n1. PROGRAM NAME/COMMENT. A comment line that can be used to identify your\nconfiguration file.\n2 TIME LIMXT. The time limit for execution of the run on the FLEX. The time limit is in\n.\nminutes. Upon expiration of the time limit, you are summarily kicked off of the FLEX PE\'s that you are\no\nusing for your parallel computation, and you are returned t the Pisces configuration environment. This\ntime limit is converted t seconds and inserted in the "mmrun" command generated by Pisces when you\no\nactually execute your program.\n3. LOADFILE CREATION. The configuration display shows only the name of the loadfile, if you\nhave already specified one, and the FLEX PE\'s that are specified for loading when the loadfile is used. If\nyou have created a loadfile during a previous session, you can reuse the same loadfile in another\nconfiguration, provided that you have not recompiled any of your Fortran programs and have not changed\nthe set of FLEX PE\'s that you want loaded. If you have made either of these changes, you must create a\nnew loadfile.\nIf you choose Option 3, you are led through a series of prompts that request the information needed\nto construct a loadfile:\na. OBJECT FILE NAMES. A table is displayed that contains all the names of your ".o"files that will\nbe included in the loadfile when it is created. You can changes these entries as required. In\nresponse to the prompts, enter the names of the ".o"files that contain all of the parts of your Pisces\nFortran program that you want included in the loadfile.\nb. TASKTYPE NAMES. A table is displayed that contains all the tasktype names that your program\nis known to use. During execution of your program, these are the ONLY types of tasks that your\nprogram can initiate or that can be initiated by you directly from the terminal. In general this table\nmust contain the names of all the tasktypes defined in your program.\nFLEX PE\'s TO LOAD. A table of options is displayed that shows the possible choices of sets of\nC.\nFLEX PE\'s to be loaded with this loadfile when your program is run. Choose a subset of PE\'s that\nis at least as large as you will need for any run with this loadfile (you can run without actually using\nall the loaded PE\'s, but you cannot expand the set of PE\'s you use after the loadfile is created).\nd. LOADFILE NAME. You are asked for the Unix filename to be used for the loadfile when it is\ncreated.\ne. DO YOU WANT TO CREATE THE LOADFILE? This prompt gives you the option of stopping\nthe loadfile creation process without actually generating the loadfile. If you have forgotten to\npreprocess/compile one of your Pisces Fortran files, or if for some other reason you choose not to\ncreate the loadfile, you can return to the main Configuration Environment menu at this point. The\ninformation entered in steps a-d will be retained in the configuration file for later editing.\nLoadfile creation is the longest step in creating a configuration for a run. You will see the FLEX\n"cf77" command appear that shows that loadfile creation is underway. Several minutes may elapse. m e\nFLEX cf77 processor is searching various MMOS libraries for the MMOS operating system, and then is\nmaking the linkages between your Fortran program, the Pisces library routines, and the MMOS routines.)\nIf the loadfile is successfully created, the main Pisces configuration menu will reappear. If not, you will\nget messages from the FLEX loader about "undefined external symbols", and then the Pisces menu will\nagain reappear. If an undefined external symbol is the name of an array, function, or subroutine in your\nprogram, you have a Fortran error. Exit the configuration environment, fix the error, and reenter to try\nloadfile creation again.\n\n34\n\n.\n\n.\n\n4. I " I A L TASWCLUSTER. You may enter a cluster number and tasktype name. A task of that\ntype will be initiated on that cluster whenever you run the program with this configuration. The initial\ntask is initiated automatically as m n as the execution of your program on the FLEX PE\'s begins.\nIf you specify no initial tasktype name, execution of your program will not begin until you explicitly initiate a task of the appropriate type by using the appropriate run-time menu option (see Part 3 of\nthis manual). However the Pisces clusters Will be set up as you specify in your configuration, and the task\ncontrollers for the clusters will be initiated as usual; it is only the initiation of your first program task that\nwill be delayed until you request it through the run-time menu.\n5. TRACE OPTIONS. Pisces provides a number of options for tracing significant "events" during\nexecution of your parallel program. currently the "events" include:\nTask initiation.\nTask termination.\nMessage send.\nMessage accept.\nLock a lock.\nUnlock a lock.\nEntry to a barrier.\nSplit of a task into a "force".\nTracing one of these types of events means generating an output line that contains:\nThe event type (e.g., INITIATE).\nThe taskid of the task(s) involved\nThe current clock time (in \'%cks") of the PE running the task.\nOther information appropriate to the event type.\nFor each type of trace "event", you can choose one of the following actions to occur each time such an\nevent happens during program execution:\nGenerate no trace output.\nGenerate a trace line, and display it on the terminal.\nGenerate a trace line, and write it to the "tracefile".\nGenerate a trace line, and both display it and write it to the tracefile.\nEvery task that your program initiates has its own set of trace option settings. In the configuration menu,\nyou set the initial option settings for all tasks. During execution of the program, you can change the settings for a particular task, or change the initial settings for all new tasks.\n6. TRACEFILE NAME. If you choose to send trace output to a file, you can enter a file name here,\nor use the default tracefile name \'ppptrace\'. Only one tracefile is used per run. After the run you can look\nh\nat the trace output in various ways by using t e UNx utility "grep",or your favorite editor, with the\ntracefile.\n7. CLUSTER CONFIGURATION. This option provides the facility for mapping the Pisces "virtual\nmachine" to the actual FLEX PE\'s that you want to use for a run. For each Pisces cluster that your program uses, you specify:\na. CLUSTER NUMBER. An integer in the range 1-25 currently.\nb. PRIMARY FLEX PE. One FLEX PE is chosen to serve as the "primary" PE for the cluster. The\nFLEX PE\'s are currently numbered 3-20. Any FLEX PE can be assigned to any cluster, but only to\none cluster. This PE will be the processor that actually executes each task that is initiated within\nthat cluster.\nc. NUMBER OF SLOTS. You choose the number of "slots" available for running your tasks in the\ncluster. The number of slots restricts the number of tasks that can be simultaneously initiated on the\no\nFLEX PE. Each running task takes a slot. If all slots are filled, then an attempt t initiate a new\n35\n\ntask will be held by the task controller of the cluster until some task terminates and a slot is freed.\nTask controllers run in system-provided slots and are not included in this slot count.\nd. SECONDARY FLEX PE\'s. You choose a set of zero or more FLEX PE\'s to sefve as "secondary"\nPE\'s to run forces that arr: initiated within the cluster. The same numbering (3-20) of the FLEX\nPE\'s is used in this specification. Any PE can be a secondary PE for any cluster, regardless of\nwhether it is also a primary PE for another cluster (a PE cannot be both primary and secondary for\nthe same cluster, by definition).\n.\nThe secondary PE\'s a ~used only when a task running in a cluster executes a "FORCESPLIT". At\nthat time, a new task of the same type is initiated on each secondary PE assigned to that cluster, and\neach new task begins execution at the point of the FORCESPLIT. These new force members do not\nxun in slots on the secondary PE\'s, but they do increase the number of concumnt tasks that are sharing the PE.\nWhen specifying the configuration information for the clusters used by your program, you may\nspecify each cluster individually, but usually it is more convenient to specify a range of cluster numbers\nthat each have the same basic configuration. The Configuration Environment requests the first and last\nh\ncluster numbers in the range. You then specify the FLEX PE to be used as the primary PE for t e first\ncluster. The remaining clusters are assigned the next FLEX PE\'s in sequence. Each cluster gets the same\nnumber of slots and is assigned the same set of secondary FLEX PE\'s.\nNOTE: The primary and secondary PE\'s assigned to a Pisces cluster must be included in the set of PE\'s\nthat will be loaded with t e loadfile when your program is xun (see Option 3 above).\nh\nTERMINATING A CONFIGURATIONEDITING SESSION\nAfter each modification to the configuration, the new configuration is redisplayed. When you are\nl\nsatisfied with the settings for al options, you can leave the editing session by choosing the "all ok" option\n(0). You are now given a chance to save the configuration in a configuration file, either a new file or the\nsame one with which you began the editing session.\nRUNNING A PISCES FORTRAN PROGRAM\nYou are finally asked whether you want to run the program for which you have just created the\nconfiguration. If you choose to run the program, sevenl additional steps are taken:\na. CONFIGURATION CHECKING. A comprehensive set of tests are applied to your configurationto\ninsure that it is valid. Two kinds of emr messages art produced during this checking:\nERROR: m e s s a g e -- indicates that the program cannot be run using your specified configuration.\nYou are returned to the configuration environment for repairs.\nWARNING: message> -- indicates that your program is executable, but the configuration may\ncause execution errors.\nb. WAIT QUEUE STATUS. The FLEX utility \'mmstat\' is invoked to list the current queue of users\nwaiting to run FLEX parallel programs. You can check the length of the queue and the time limits\nof the jobs in the queue before you decide to continue and put your job into the queue.\nIf you request program execution after seeing the wait queue, your loadfile will be taken as the input\nto an "mmrun" command, which causes your job to be placed in the wait queue. When you reach the\nhead of the queue, your loadfile is downloaded to all the FLEX PE\'s specified in your loadfile\nconfiguration.\nAfter downloading is complete, program execution begins on the FLEX PE specified as the\nsystem-defined main PE (usually the FLEX PE with the lowest number of those that you have loaded).\nThe Pisces run-time environment plays the role of the overall main program for each run (your tasks are\ninitiated as sub-tasks of the Pisces run-time environment). The Pisces run-time environment is described\n36\n\nin Part 3 of this manual.\nAfter you terminate execution of your program, or the specified time limit expires, you are kicked\noff of the FLEX MMOS PE\'s, and control return to the Pisces configuration environment. You can edit\nyour configuration again, run again, or leave the Pisces configuration environment.\nTHE FLEX "STATIC VARIABLES" BUG\nConfigurations that use clusters with multiple slots or that use one PE as primary or secondary for\nmore than one cluster will generate a WARNING message about the "FLEX Static Variables bug". The\nproblem is a potential source of execution errors in Fortran and C programs.\nYou can use configurations that generate this warning message, but you must be careful NOT to initiate two tasks of the same tasktype on t e same FLEX PE at the same time (either in two slots of the\nh\nsame cluster or using forces whose members use the same secondary PE\'s). If you use the same Fortran\nsubroutine in several tasktypes, or if you use C routines with STATIC variables, your program is also\nvulnerable to emrs whenever tasks or force members run on the same PE and use these subroutines or\nstatic variables.\nThe cause of the problem lies in the FLEX implementation of Fortran and C static variables (all\nFortran local variables; C variables declared \'static\'). The loadfile for your program contains only a single copy of each of these variables (one memory location reserved statically). Thus, after loading the\nFLEX PE\'s, each of these variables exists at a unique, statically assigned, location in the local memory of\neach FLEX PE. Each time a task or force member is initiated, it uses this same location in local memory.\nIf, while one task is running on a PE, a second task begins to run on the same PE and uses the same variable, then the tasks will interfere with each other -- each will be fetching and storing from the same local\nvariable location, without protection from the other. The result will be subtle, timing dependent, errors in\nprogram execution.\nTo avoid the problem, either choose a configuration that does not generate the WARNING message\n(one slotkluster and no overlap of secondary PE sets for different clusters), or be sure your program does\nnot initiate tasks or force members that run in parallel on the same PE and that might use the same static\nvariables.\nDATA Statements in Fortran. The same problem will make DATA statements troublesome for initializing local variables. The first task of a particular tasktype to be run will see the correct initial values.\nA later task of the same tasktype will see the values left by execution of the first task, rather than the\ns\nexpected initial values set by a DATA statement. RULE: U e assignment statements rather than DATA\nstatements to initialize local variables in Pisces Fortran on t e FLEX.\nh\nNote that this is a FLEX bug, not a Pisces bug. Unfortunately there seems to be no reasonable way\nto correct it without major changes in the FLEX MMOS operating system.\n\n37\n\nPISCES USER\xe2\x80\x99S MANUAL:PART 3\nTHERUN-TIMEENVIRONMENT\n\nh\nThe Pisces Run-time Environment provides facilities for t e programmer to monitor and control the\nexecution of a Pisces Fortran program on the FLEX PE\xe2\x80\x99s. The various commands a~ described below.\nINITIALIZATION OF A RUN\nAfter downloading of a loadfile to the FLEX PE\xe2\x80\x99s, the Pisces run-time environment takes control of\nthe system-defined main PE (usually the PE with the lowest number of those loaded). First the data structures describing the various Pisces clusters are initialized in shared memory, using the values specified in\nthe configuration file for the run. Then a task controller task is initiated on each PE that is to be the primary PE for some cluster.\nSubsequently, the run-time environment displays a menu t the user, listing the various command\no\noptions available. The user may choose a command, which is executed, and the menu is re-displayed. If\nthe configuration file specified an initial tasktype and cluster, then the user need take IW action -- the\nspecified task will be initiated automatically just before the run-time menu is displayed for the first time.\nRUN-TIME MENU OFITONS\n\nThe current run-time menu options are:\n0. TERMINATE THE RUN. The Pisces system shuts down. AU running tasks and forces are terminated. If the user program has open files due to tasks that have not terminated correctly, then Pisces\ntermination may not cause successful FLEX job termination. If the final Pisces message:\nPisces system terminates.\nis not followed immediately by the FLEX message:\nProgram execution completed.\nthen it may be necessary to hit BREAK and terminate the job abnormally (answer \xe2\x80\x98yes\xe2\x80\x99 to the \xe2\x80\x99Do you\nwant. ..\xe2\x80\x99 question).\n1. INITIATE A TASK. The user is asked for the tasktype and cluster number. An INITIATE message is sent to the task controller of that cluster, exactly as if the initiate request were generated by execution of an INITIATE statement in the program.\n2. TERMINATE A TASK. The user is asked for the cluster and slot number of the task to be terminated. Termination is not guaranteed to be safe unless the task is not actively accepting or sending\nmessages (Le., messages may be garbled). Termination frees the slot in which the task is running.\n3. SEND A MESSAGE. The message type and the receiver\xe2\x80\x99s cluster number and slot are requested.\nThe message cannot have arguments (Le., it looks like a SIGNAL). The message is sent to the designated\ntask, exactly as if it had been sent with a SEND statement in the program.\n4. DISPLAY RUNNING TASKS. A display is produced that shows the running tasks in each cluster, including the task controllers and user initiated tasks. From this display, you can determine the cluster number and slot where each task is running (for use in other commands).\n5. DUMP SYSTEM STATE. A full dump of the entire system state is generated, including free\nspace lists, the heap, the state of every cluster, each running task, etc. More information than you usually\nwant to see.\n\n38\n\nI\n\n1\n\n\'-\n\n6 DUMP MESSAGE QUEUE. The cluster number and slot of the task are requested. A detailed\n.\ndisplay of the in-queue contents of that task is generated, including message types, free space lists, etc.\n7. EDIT TRACE OPTIONS. You may choose to edit the trace settings for a particular task, or for\nall new mks initiated after the changes a e made. The options for settings and events to trace are exactly\nx\nas in the configuration menu.\nTRACE OUTPUT DISPLAY DURING EXECUTION\nIf you have chosen to have trace output displayed on the terminal during program execution, you\nwill find the output intennixed with the displays generated by the Pisces run-time environment. The\nresult can be confusing. Try hitting RETURN repeatedly to single step through trace output without generating any new Pisces displays. Usually it is easiest to use displayed trace output to check the progress\nof a run, but then also send the output to a tracefile for detailed analysis after the r n\nu.\n\nTRACE OUTPUT INTERPRETATION\nThe trace file produced by a run contains timing information in each output line, in the form:\nticks=<PE numben/<ticks count>\nEach FLEX PE has its own clock and the clocks are not synchronized. Thus timing comparisons acmss\nPE\'s are usually not accurate. The "tick" measured by the FLEX clocks is equal to 20 milliseconds.\nThe Unix utility "grep" is a convenient way to pull only particular trace lines out of a tracefile. For\nexample, to list all trace output produced on PE 9, use:\ngrep "ticks=9" <trace file>\nTo list al the TERMINATE lines, use:\nl\ngrep "TERMINATE" <tracefile>\n\nSTORAGE MANAGEMENT\nStorage management for tasks and messages is handled dynamically during program execution.\nThe implementation attempts to minimize hotspots and locking of shared memory. If you dump the system state (run-time option 5 ) during Pisces execution, you will see the major features of the storage\nmanagement organization, including the amount of storage available on each free space list and in the\no\nglobal heap block. For this reason, it is useful t have an overview of how Pisces manages storage during\nexecution.\n\nTYPES OF FREE SPACE\nThe Pisces system uses only three types of blocks of free space:\na. TASK BLOCKS. A task block is allocated t each running task to contain information about the\no\ncurrent state of that task.\nb. MESSAGE HEADERS. Every message has a header that contains infomation about the sender\nand receiver of the message, the message type, etc.\nc. MESSAGE ARGUMENT PACKETS. If a message carries argument data values, then those\nvalues are stored in a linked list of \'packets\'.\n\n39\n\nBecause there are only three types of free space blocks, separate free space lists are maintained for\neach type of block. During program execution, all free blocks are recovered and reused, with a single\nexception: argument packets on broadcast messages are not recovered. Storage management requires\nrelatively little run-time overhead -- management is via explicit allocation and return; there is no garbage\ncollection or use of reference counts.\nLOCAL FREE SPACE LISTS\nEach task maintains two local free space lists: one for message headers and one for argument packets. When a message is accepted, the header and any argument packets are returned to the local free\nh\nspace list of the receiving task. When a message is sent, t e header and packets (if any) are taken from\nthe sending task\xe2\x80\x99s local free space lists.\nGLOBAL FREE SPACE LISTS\nThe global \xe2\x80\x99heap\xe2\x80\x99 contains three f e space lists: for task blocks, for message headers, and for argure\nment packets.\nWhen a task controller initiates a task, it takes a task block from the global taskblocks list. Upon\ntermination of the task, its taskblock is returned to the global list.\nWhen an individual task sends a message, it gets the header and argument packets from its local free\nspace lists. If one of these is empty, then a group of headershackets are taken from the global list and\nmade into a new local list.\nre\nWhen an individual task terminates, or if its local f e space lists become too long, then\nheaden/packets are returned to the appropriate global free space lists.\nThis organization was chosen so as to minimize contention for the global lists, which must be\nlocked whenever blocks are allocated or returned. When message passing is fairly evenly distributed,\nmost tasks are able to allocate message headers and packets from their local lists, without going to the\nglobal lists at all. When message passing is more unbalanced, tasks that collect too many headers or\npackets return the excess to the global lists periodically.\nGLOBAL FREE BLOCK\nAll storage for taskblocks, headers, and packets is initially part of a large \xe2\x80\x99global free space block\xe2\x80\x99\nof FLEX common memory. This block is allocated by an AMOS \xe2\x80\x98CCalloc\xe2\x80\x99 request (the current block\nsize is displayed as part of the system state dump). When storage blocks are required, and the appropriate\nglobal free space list is empty, then new blocks are carved out of this large block to satisfy the allocation\nrequest.\nWhen the global free block is exhausted, another CCalloc call is made to get a new one. No storage\nis ever returned to the global free block.\nREADING THE SYSTEM STATE DUMP\nThe system state dump (run-time option 5 ) begins with a display of infomation about the global\nfree space lists and the global free block: the number of items in each list, the current size of the global\nblock, and the initial size of each block when requested from CCalloc. The status of the various locks is\nalso shown.\nThe total common memory allocation for the entire program execution to that point is also\ndisplayed. This total includes the size of a small initial block allocated for the Pisces top-level system\ninformation, and the sum of the sizes of all the global free blocks allocated so far. It does not include\ncommon memory allocated for shared variables in user programs.\nThe length and lock status of the local free lists of each task running in a cluster is shown as part of\nthe display for each cluster. The same information is also shown for the task controllers.\n40\n\nBesides providing information about overall storage use, the dump can tell you some things about\nparallel activity during program execution. For example, the length of the global taskblocks list after a\ntask completes execution tells you how many subtasks were every actually running simultaneously during\nthere\nexecution of that task. In a recent run of the MATMUL demo program with large matrices (50x50)\nwere 2500 inner product tasks spawned by the main task, but after the run was complete, there wefe only\ntwo taskblocks in the global free list. Since the main task used one of those, no inner product tasks were\never running simultaneously. Conclusion: the inner product tasks were too \'lightweight\' -- the execution\ntime of one was shorter than the time to build and send the message to initiate the next one (so the taskblock used by the first returned to the free space list in time to be allocated to the next task).\n\n41\n\nStandard Bibliographic Page\n2. Government Accession No.\n\n1. Report No.\n\n3. Recipient\xe2\x80\x99s Catalog No.\n\nNASA CR-178334\n5. Report Date\n\nJuly 1987\n6. Performing Organization Code\n8. Performing organization Report No.\n. I\n-\n\n10. Work Unit No.\n\n9. Performing Organization Name and Address\n\nInstitute for Computer Applications in Science\nand Engineering\nMail Stop 132C, NASA Langley Research Center\nHampton, VA 23665-5225\n\n505-90-21-01\n11. Contract or Grant\n\nNo.\n\nNAS1-18107\n13. Type of Report and Period Covered\n\n12. Sponsoring Agency Name and Addreas\n\nNational Aeronautics and Space Administration\nWashington, D C\n. . 20546\n15. Supplementary Notes\n\nLangley Technical Monitor:\nJ. C South\n.\nFinal Report\n16. -Abstract\n\nPISCES 2 is a programming environment and set of extensions t Fortran 77 for parallel programming.\no\nIt is intended to provide a basis for writing programs for scientific and engineering applications on\nparallel computers in a way that is relatively independent of the particular details of the underlying\ncomputer architecture.\n\nT i manual provides a complete description of the PISCES 2 system as it is currently implemented on\nhs\nthe 20 processor Flexible FLEW32 at NASA Langley Research Center.\n\n18. Distribution Statement\n\n17. Key Words (Suggested by Authors(s))\n\n61\n\n- Computer Programming and\n\n62\n\nparallel computers, parallel\nprogramming, programming environments\n\n-\n\nSoftware\nComputer Systems\n\nUnclassified\n19. Security Classif.(of this report)\n\nUnclassified\n\n20. Security Classif.(of this page)\n\nIJnclassified\n\n- unlimited\n21. No. of Pages 22. Price\n\n46\n\nFor sale by the National Technical Information Service, Springfield, Virginia 22161\nNASA Langley Form 63 (June 1986)\n\nA03\n\n'