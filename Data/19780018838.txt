b',ESL-TH-821\n\nMay, 1978\n\nResearch Supported by:\nNASA Amnes GrantNGL22-009-124\nAFOSR Grant 77-328)-"\n\nON RELIABLE CONTROL-SYSTEM DESIGNS\n\nJohn Douglas Birdwell\n\noh IEAIALZ CONTROL \n S TEM\nPh.D. Thesis (NassaChsetts Inst.\nDESIGNS \n\nCSC\n12\n260 p HC A12/? A01 \n\nTof\nech.)\n\n-\n\n\n1 Tnsa-va-157229)\n\n\n18-261\nunclas\n\n\n-G3/63 \n\n\n23298\n\n\nElectronic Systems Laboratory\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY, CAMBRIDG2, MASSACHUSETTS 02139\nBY\nREPRODUCED\n\nNATIONAL TECHNICAL\nINFORMATION SERVICE\nU.S.DEPARTMENT OFCOMMERCE\n"SRINFIELD VA. 2161\n2\n\nI\n\nU.S. DEPARTMENT OF COMMERCE\n\nNational Technical Information Service\n\n\nN78-26781\nON RELIABLE CONTROL SYSTEM DESIGNS\nJOHN DOUGLAS BIRDWELL\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\nCAMBRIDGE2 MASSACHUSETTS\nMAY\n\n1978\n\nMay, 1978\n\nESL-TH-821\n\n\nON RELIABLE CONTROL SYSTEM DESIGNS\n\nby\nJohn Douglas Birdwell\n\n\nThis report is based on the unaltered thesis of John Douglas Birdwell,\n\nsubmitted in partial fulfillment of the requirements for the degree\n\nof Doctor of Philosophy at the Massachusetts Institute of Technology\n\nin May, 1978. The research was conducted at the M.I.T. Electronic\n\nSystems Laboratory. Stipend and tuition support was from a fellowship\n\nfrom the Fannie and John Hertz Foundation; additional support was\n\nfrom NASA Ames grant NGL-22-009-124 and AFOSR grant 77-3281.\n\n\nElectronic Systems Laboratory\n\nMassachusetts Institute of Technology -\n\nCambridge, Massachusetts 02139\n\n\n,1\n\n\nON RELIABLE CONTROL SYSTEM DESIGNS\n\nby\n\nJOHN DOUGLAS BIRDWELL\n\nB.S., The University of Tennessee\n\n(1974)\n\n\nM.S., The University of. Tennessee\n\n(1974)\n\n\nSUBMITTED IN PARTIAL FULFILLMENT\n\nOF THE REQUIREMENTS FOR THE\n\nDEGREE OF\n\nDOCTOR OF PHILOSOPHY\n\nat the\n\nMASSACHUSETTS INSTITUTE OF TECHNOLOGY\n\nMAY, 1978\n\n\nQ\n\nJohn Douglas Birdwell\n\nSignature of Author......\n\nAepartment\n\nCertified by....\n\n0.14.7,111.\n.o.?\n\n1978\n\nf Electrical Engineering, May 18, 1978\n\n\n04.V\n\n............................\nThesis Supervisor\n\n\nAccepted by.............................................................\n\nChairman, Departmental Committee on Graduate Students\n\n\n1a)\n\n\n2\n\ncopyright: John Douglas Birdwell, 1978\n\nThe Massachusetts Institute of Technology and the Electronic Systems\n\nLaboratory are granted the right to reproduce and distribute this\n\nreport in its entirety without limitation. All other rights reserved.\n\n\n3\nON RELIABLE CONTROL SYSTEM DESIGNS\n\nby\nJOHN DOUGLAS BIRDWELL\n\n\nSubmitted to the Department of\n\nElectrical Engineering and Computer Science\n\non May 18, 1978 in partial fulfillment of the requirements\n\nfor the Degree of Doctor of Philosophy.\n\n\nABSTRACT\n\n\nThis report contains a method of approach and theoretical\n\nframework which advances the state of the art in the design of\n\nreliable multivariable control systems, with special emphasis on\n\nactuator failures and necessary actuator redundancy levels.\n\nThe mathematical model consists of a linear time invariant\n\ndiscrete time dynamical system. Configuration changes in the\n\nsystem dynamics, (such as actuator failures, repairs, introduction\n\nof a back up actuator) are governed by a Markov chain that includes\n\ntransition probabilities from one configuration state to another.\n\nThe performance index is a standard quadratic cost functional,\n\nover an infinite time interval.\n\nIf the dynamic system contains either process white noise\n\nand/or noisy measurements of the state, then the stochastic\n\noptimal control problem reduces, in general, to a dual problem,\n\nand no analytical or efficient algorithmic solution is possible.\n\nThus, the results are obtained under the assumption of full state\n\nvariable measurements, and in the absence of additive process\n\nwhite noise..\n\nUnder the above assumptions, the optimal stochastic control\n\nsolution can be obtained. The actual system configuration can\n\nbe deduced with an one step delay. The calculation of.the optimal\n\ncontrol law requires the solution of a set of highly coupled\n\nRiccati-like matrix difference equations; if these converge (as\n\nthe terminal time goes to infinity) one has a reliable design with\n\nswitching feedback gains, and, if they diverge, the design is\n\nunreliable and the system cannot be stabilized unless more reliable\n\nactuators or more redundant actuators are employed. For the\n\nreliable designs, the feedback system requires a switching gain\n\nsolution, that is, whenever a system change is detected, the feed\xc2\xad\nback gains must be reconfigured. On the other hand, the necessary\n\nreconfiguration gains can be precomputed, from the off-li:\n\ntions of the Riccati-like matrix difference equations.\n\n\n4\nThrough the use of the matrix discrete minimum principle, a\n\nsuboptimal solution can also be obtained. In this approach, one\n\nwishes to avoid the reconfiguration of the feedback system, and\n\none wishes to know whether or not it is possible to stabilize the\n\nsystem with a constant feedback gain, which does not change even\n\nif the system changes. Once more this can be deduced from another\n\nset of coupled Riccati-like matrix difference equations. If they\n\ndiverge as the terminal time goes to infinity, then a constant\n\ngain implementation is unreliable, because it cannot stabilize the\'\n\nsystem. If, on the other hand, there exists an asymptotic solution\n\nto this set of Riccati-like equations then a reliable control\n\nsystem without feedback reconfiguration can be obtained. The\n\nimplementation requires constant gain state variable feedback, anL\n\nthe feedback gains can be calculated off-line.\n\nIn summary, these results can be used for off-line studies\xc2\xad\nrelating the open loop dynamics, required performance, actuator\n\nmean time to failure, and functional or identical actuator\n\nredundancy, with and without feedback gain reconfiguration\n\nstrategies.\n\n\nThesis Supervisor: Michael Athans\n\nTitle: Professor of Electrical Engineering and Computer Science\n\n\n5\nACKNOWLEDGMENT\n\n\nI deeply appreciate the guidance and encouragement of my thesis\n\nsupervisor, Professor Michael Athans. I thank him for the oppor\xc2\xad\ntunity to observe his unique insight and approach to systems theory.\n\nI thank my readers, Prof. Alan Willsky, Prof. Nils Sandell, and\n\nDr. David Castanon, for their valuable advice. I am especially\n\ngrateful to Dr. Castanon for the time he spent with me, and for his\n\nassistance, in the development of the non-switching gain methodology.\n\nI would like to acknowledge the many hours of discussion with my\n\nfellow students, in particular, with Mr. C. Greene,\'Mr. W.-H. Lee,\n\nand Dr. M. Safonov. I would also like to.acknowledge Mr. J. Carrig,\n\nwho wrote the computer routines for this research. A special thanks\n\ngoes to Dr. Tse-Wei Wang for the many hours she spent helping type\n\nthis report. Lastly, I thank my parents, Mr. and Mrs. Louis T.\n\nBirdwell, for their support and encouragement during the last four\n\nyears.\n\n\nThis research was conducted at the M.I.T. Electronic Systems\n\nLaboratory. Stipend and tuition support was from a fellowship\n\nfrom the Fannie and John Hertz Foundation; additional support\n\nwas from NASA Ames grant NGL-22-009-124 and AFOSR grant 77-3281.\n\n\n6\n\nTABLE OF CONTENTS\n\n\nABSTRACT\n\n3\n\nACKNOWLEDGMENT\n\n5\n\n\nTABLE OF CONTENTS\n\n6\n\n\nLIST OF FIGURES\n\n10\n\n\nLIST OF TABLES\n\nii\n\n\n1.-\n\nINTRODUCTION\n\n\'12\n\n1.1\n\n12\n\n\n1.2\n\nGeneral Nature of the Problem.\n1.2.1 Reliability Theory.\n1.2.2 Control Theory.\n1.2.3 General Nature of Results.\n\n13\n\n13\n\n22\n\n27\n\n\n1.3\n\nRelations with Previous Literature.\n\n29\n\n\n1.4\n\nSummary of Main Contributions.\n\n35\n\n\n1.5\n\n2.\n\nMotivation for the Research.\n\nOutline of Report.\n\n36\n\n\nCLARIFICATION AND MOTIVATION OF RESEARCH\n\n38\n\n\n2.1\n\nIntroduction.\n\n38\n\n\n2.2\n\nA Simple Example--The Optimal Solution.\n2.2.1 Problem Statement.\n2.2.2 Summary of Solution.\n\n39\n\n39\n\n41\n\n\n2.3\n\nThe Dual Control Effect.\n2.3.1 A Special Case.\n\n43\n\n46\n\n\n2.4\n\nExistence of a Steady-State Solution.\n\n48\n\n\n2.5\n\nConclusions on the Switching Gain Methodology.\n2.5.1 Implications of the Dual Control Effect.\n2.5.2 Existence of a Steady-State.\n\n49\n\n50\n\n50\n\n\n7\n\n2.6 \t A Simple Example--The Non-Switching Solution.\n2.6.1 Problem Statement. \t\n2.6.2 Summary of Solution. \t\n\n52\n\n53\n\n54\n\n\n2.7 \t Existence of a Steady-State Solution and the\nUncertainty Threshold Principle.\n\n2.7.1 Formulation of Existence Problem. \t\n2.7.2 Summary of Solution. \t\n2.7.3 Graphical Illustration of Solution. \t\n2.7.4 Best Control with Infinite Cost. \t\n2.7.5 Conclusion. \t\n\n56\n\n\n2.8 \t Summary.\n\n66\n\n\n3. \t THE SWITCHING GAIN SOLUTION\n\n56\n\n57\n\n59\n\n61\n\n66\n\n\n68\n\n\n3.1 \t Introduction.\n\n68\n\n\n3.2 \t Mathematical Formulation.\n\n70\n\n\n3.3 \t\n\n72\n\n\nThe Switching Gain Solution.\n\n3.4 \t Discussion of Results.\n\n74\n\n\n3.5 \t Examples.\n\n78\n\n\n3.6 \t Summary.\n\n86\n\n\n4. \t EXTENSIONS TO THE STOCHASTIC CASE\n\n87\n\n\n4.1 \t Introduction.\n\n87\n\n\n4.2 \t Hypothesis Testing Identification.\n\n88\n\n\n4.3 \t Dual Identification.\n\n90\n\n\n4.4 \t Examples.\n\n94\n\n\n4.5 \t Summary.\n\n5. \t THE NON-SWITCHING GAIN SOLUTION\n\n100\n\n\n101\n\n\n5.1 \t Introduction.\n\n101\n\n\n5.2 \t Problem Statement.\n\n103\n\n\n5.3 \t Problem A.\n\n104\n\n\n8\n\n\n5.4\n\nThe Method of Solution.\n\n106\n\n\n5.5\n\nThe Necessary Conditions.\n\nill\n\n\n5.6\n\nProblem B:\n\n114\n\n\n5.7\n\nStability and the Steady-State Solutions.\n5.7.1 Stability and Cost-Stability.\n5.7.2 Definition of the Infinite-Time Cost.\n5.7.3 Bounded Cost and Mean-Square Stability.\n5.7.4 Cost-Stability.\n5.7.5 Equivalence of Problems AE and B.\n5.7.6 The Steady-State Solution.\n5.7.6.1 Steady-State Solution to Problem AE.\n5.7.6.2 Steady-State Solution to Problem B.\n5.7.7 The Possibility of Limit Cycles.\n\n5.8\n\nEquality of -ns\nG\n\n5.9\n\nRobustness.\n\nThe Non-Switching Solution.\n\nand G\n\xc2\xad\n\n119\n\n119\n\n120\n\n121\n\n121\n\n122\n\n123\n\n<\'124\n\n125\n\n126\n\n127\n\n130\n\n\n5.10 Examples.\n5.11 Summary.\n\n6.\n\n132\n\n141\n\n\nCOMPUTER-AIDED DESIGN\n\n143\n\n\n6.1\n\n143\n\n\n6.2\n\nThe Design Decision.\n\n143\n\n\n6.3\n\nA Trade-off of System Performance Versus Reliability,\'\n\n163\n\n\n6.4\n\n7.\n\nIntroduction.\n\nSummary.\n\n173\n\n\nCRITIQUE\n\n174\n\n\n7.1\n\nIntroduction.\n\n174\n\n\n7.2\n\nThe Switching Gain Solution.\'\n7.2.1 Deterministic Optimal Solution.\n7.2.2 Non-Extendability to Stochastic Systems.\n7.2.3 Suboptimal Extensions.\n\n174\n\n175\n\n175\n\n176\n\n\n9\n\n7.3\n\nThe Non-Switching Gain Solution.\n7.3.1 The Necessary Conditions--Unsolvability.\n7.3.2 The Equivalent Problem.\n7.3.3 Existence of a Stabilizing Gain.\n7.3.4 Problems with Convergence.\n7.3.5 Existence of a Robust Gain.\n\n178\n\n178\n\n178\n\n179\n\n179\n\n180\n\n\n7.4\n\nComputer-Aided Design.\n\n182\n\n\n7.5\n\nSuggestions for Future Research.\n\n185\n\n\n7.6\n\nSummary.\n\n187\n\n\nAPPENDICES\n\n189\n\n\nAppendix to Chapter 1.\n\n190\n\n\nAppendix to Chapter 2.\nA2.1 Exact Optimal Solution for Deterministic Case,\nChapter 2, Section 2.\n\nA2.2 Exact Optimal Solution for.Stochastic Case,\nT = 0, 1, 2 = Tf. (1-d example).\n\nA2.3 Exact Solution of Stochastic Case Over T = 0, 1,\n2 = Tf for a Specific Form of p(), Chapter 2,\n\nSection 2.3.1.\n\nA2.4 Existence of Steady-State Solution for l-d Example.\n\n192\n\n193\n\n\nAppendix to Chapter 3.\nA3.1 Proof of Theorem 1.\nA3.2 Optimal Solution for Deterministic Problem.\nA3.3 Proof of Lemma 1.\n\n206\n\n207\n\n208\n\n211\n\n\nAppendix to Chapter 5.\nA5.1 Proof of Theorem 1, Chapter 5.\nA5.2 Proof of Remark on Theorem 1, Chapter 5.\nA5.3 Proof of Theorem 2, Chapter 5.\nA5.4 Proof of Theorem 3, Chapter 5.\nA5.5 Proof of Lemma 2, Chapter 5.\nA5.6 Proof of Lemma 3, Chapter 5.\nA5.7 Proof of Theorem 4, Chapter 5.\n\n213\n\n214\n\n216\n\n217\n\n219\n\n220\n\n221\n\n222\n\n\n,COMPUTER ROUTINES\n\n223\n\n\nLIST OF REFERENCES\n\n256\n\n\n194\n\n199\n\n\n202\n\n\n10\n\nLIST OF FIGURES\n\n\n1.1\n\nExponential failure distribution. \t\n\n16.\n\n\n1.2\n\nTypical hazard rate function for a transistor. \t\n\n17\n\n\n1.3\n\nThree hypothetical system structures. \t\n\n20\n\n\n1.4 \t Configuration for structures in Figure 1.3.\n\n21\n\n\n1.5 \t Two possible structural trajectories.\n\n23\n\n\n2.1 \tA probability distribution for amplitude-limited\nwhite noise.\n\n\n47\n\n\n2.2 \t\n\nIalthreshold\n\nversus p, b.\n\n\'60\n\n\n2.3a h versus p, b.\n2.3b h versus p, b.\n\n62\n\n63\n\n\n2.4 \tg versus p, b.\n\n65\n\n\n3.1 \tThe switching gain control law.\n\n75\n\n\n3.2 \t Markov transition probabilities for Example 3.1.\n\n79\n\n\n5.1 \tMarkov transition probabilities for Example 5.2.\n\n137\n\n\nLIST OF TABLES\n\n\n2.1\n\nThe optimal control u 0 versus x 0 and\n\n.\n\n45,\n\n12\nCHAPTER 1\n\n\nINTRODUCTION\n\n\n1.1\n\nMotivation for the Research.\n\nThis report addresses some of the current problems in interfacing\n\n\nsystems theory and reliability, and puts this research in perspective\n\nwith the open questions in this field.\n\nReliability is a relative concept;\n\n\nit is, roughly, the probability that a system will perform according\n\nto specifications for a given amount of time.\nbehind this report is:\n\nThe motivating question\n\n\nWhat constitutes a reliable system?\n\n\nKnowledge of the reliability of a system is crucial.\n\nIn this\n\n\nreport, a system is reliable if it has a (quantitative) reliability of\n\none, i.e., if the probability that the system will not perform according\n\nto specifications for a given period of time is zero.\n\nTherefore, the\n\n\nquestion "What constitutes a reliable system?" can be restated as:\n\nWhat are the specifications which a system must meet in order to be\n\nreliable?\n\nA system is normally designed in two stages:\n\nFirst, the components\n\n\nare selected in such a way as to meet the reliability specifications;\n\nsecond, the control problem is formulated and solved for that configura-.\n\ntion of components.\n\nAlthough this procedure is over-simplified, it\n\n\nillustrates a second question:\n\nShould the control problem influence the\n\n\nchoice of the configuration, and if so, how can this be achieved?\nfirst part of the question is answered by history:\n\nThe\n\n\nThe control problem\n\n\ninfluences configuration design now by iteration between the two stages\n\nof design.\n\nThis is most likely not the best method!\n\nIf a theory were\n\n\n13\navailable which allowed a comparison between alternate designs, based\n\non both the expected system reliability and the expected system perfor\xc2\xad\nmance, it would greatly simplify the current design methodology.\n\nIt is\n\n\nunfortunate that at present there is no accepted methodology for a\n\ndetermination of expected system performance which accounts for changes\n\nin the performance characteristics due to failure, repair or reconfigura\xc2\xad\ntion of system functions.\n\nThis report presents such a methodology for a\n\n\nspecific class of linear systems with quadratic cost criteria.\n\n\n1.2\n\nGeneral Nature of the Problem.\n\nThis Section presents the general theoretical framework necessary to\n\n\napproach the problem of reliable control system design.\n\nFirst, a\n\n\ndiscussion of some of the concepts in reliability theory will be present\xc2\xad\ned.\n\nThe control-theoretic framework for the specific topics covered in\n\n\nthis report will then be developed.\n\nFinally, the interrelationships\xc2\xad\n\nbetween systems theory and reliability theory will be explored, leading\n\nto a mathematical formulation of the reliable control system design .\n\nproblem and a discussion of the general nature of the results presented\n\nin the remainder of this report.\n\n\n1.2.1\n\nReliability Theory.\n\nThe generally accepted definition of reliability is stated in\n\n\nAppendix 1.\n\nBasically, the reliability of a system is the probability\n\n\nthat the system will perform according to specifications for a given\n\namount of time.\n\nIn a system-theoretic context, the specification which\n\n\na system must meet is stability; also, since, at least for most mathemati\xc2\xad\ncal models of systems, stability is a long-term attribute of the system,\n\n\n14\n\nthe amount of time for which the system must remain stable is taken-to\n\nbe infinite.\n\nTherefore, the following definitions of system reliability\n\n\nare used in this report:\n\n\nDefinition 1:\n\nA system (implying the hardware configuration, or mathe\xc2\xad\n\nmaticail\'model of that configuration, and its associated control and\n\nestimrtion structure) has reliability r where r is the probability that\n\nthe systemwvill be stable for all time.\n\n\nDefinition 2:\n\nA system is said to be reliable if r = 1.\n\n\nDefinition 3:\n\nA system design, or configuration, is reliable if it\n\n\nis stabilizable with probability one.\n\n\nThesa-definitions of reliability depend on the definition of stability,\n\nand for\'-systems which can have more than one mode of operation, stability\n\nis not-that easy to determine.\neither->mean-square stability\n\nIn this report, stability will mean\n\n\n(over some random space which will be left\n\n\nunspecified for the moment), or cost-stability (again, an expectation\n\nover a-certain random space), which is basically the property that the\n\naccumulated cost of system,operation is bounded with probability one.\n\n(The definition of cost is also deferred.)\n\nThe reliability of a system will depend on the reliabilities of its\n\nvarious components and on their interconnections.\n\nThus, the systems\n\n\nengineer must have an understanding of the probabilistic mechanisms of\n\ncomponent failure, repair, and system reconfiguration.\n\nThere are a\n\n\nmultitude of models which can be used for component failure and repair,\n\nand reconfiguration.\n\nTwo good references to the mechanics of reliability\n\n\n15\ntheory are\n\n[Shooman, 1] and [Green and Bourne, 2].\n\n\n-Consider a device which begins operation at time 0 and can experi\xc2\xad\nence catastrophic (i.e., instantaneous) failure to a non-operational\n\nstate.\n\nLet the probability of failure of this device occuring in the\n\n\ninterval [0,t] be\n\nF(t)\n\n=\n\nprob. of failure in [O,t]\n\n(1.2.1)\n\nThis is the definition of the failure distribution function [Shooman, 1].\n\nDefine the hazard rate as\n\ndF(t)\n\ndt\nz(t)\n\n-\n\n1-rFt)\n\n(1.2.2)\n\nfrom [Shooman, 1].\n\nThe hazard rate is the incremental failure probabil\xc2\xad\n\nity at time t, given that the device is operational at time t.\n\nNow,\n\n\nsuppose the hazard rate of the device is independent of time; i.e., the\n\nprobability that the device will fail sometime in a time interval\n\nstarting at the present time is independent of how long the device has\n\nbeen operational.\nz(t)\n\n=\n\nThis constant hazard rate\n\n\nc\n\n(1.2.3)\n\n\nresults in the exponential failure distribution shown in Figure 1.1.\n\nThe constant hazard rate is a close approximation to the actual hazard\n\nrate of many devices.\n\nFor example, the transistor has a hazard rate\n\n\nsimilar to that shown in Figure 1.2.\ncommon [Shooman, 1].\n\nThis type of function is quite\n\n\nEarly failures in Region I of Figure 1.2 are\n\n\nfailures during the "burning-in" of the device; they are associated with\n\npoor assembly, defective materials and other random fluctuations in the\n\nmanufacturing process.\nof elements in the part.\n\nFailures in Region III are due to the wearing out\n\nRegion II is relatively constant and closely\n\n\n18\n\napproximates the constant hazard rate function-\n\nIn a large system, parts\n\n\nare generally "burned-in" before assembly is completed; therefore, the\n\nsystem begins operation in Region II.\n\nAs the system ages, periodic\n\n\nmaintenance removes old parts before the hazard rate rises in Region III.\n\nTherefore, the assumption of a constant hazard rate is usually justified.\n\nIn this report, the constant hazard rate function is used exclusively.\n\nThis is due not only to its broad applicability, but also to the fact that\n\nany non-constant hazard rate requires a reliable control system to keep\n\ntrack of the starting times of the system\'s mode of operation.\n\nIn the discrete-time case, to which this report is confined exclu\xc2\xad\nsively, the hazard rate becomes the probability of failure (or repair or\n\nreconfiguration) between time t and time t+l.\n\nFor a system with many\n\n\noperating modes, the probability of being in a given mode at a given\n\ntime, given some past probability vector over the various operating\n\nmodes, can be modeled by a Markov chain.\n\nIf -t\n is a vector\n\nIt\n\nRL\t+\n\n\nT\n-t\n\n\n(1.2.4)\n\nwhere there are L+l operating modes, then -t\n7r\nSPit\n\nis propogated in time by\n\n(1.2.5)\n\nwhere\nP\n\nE)\n=\n\nL+I x L+I1"\n(p...) e R-~ xLl(1.2.6)\n\nand\n\npij\n\n=\t\n\nprob. of system being in mode i at time t+l, given it\nwas in mode j at time t\n(1.2.7)\n\n\n(see [Paz, 33).\n\nThe probability p.j is the discrete-time equivalent of\n\n\nthe hazard rate, and is time-invariant.\n\nIn the future, a time-invari\xc2\xad\n\nant Markov chain will be assumed as a model of the modes of operation\n\n\n19\nand the statistics of the random switchings between modes.\n\n\nIt is now necessary to define precisely these modes of operation\n\nan& their dynamic transitions.\n\nThe terms system configuration and\n\n\nsystem structure will be used.\n\n\nDefinition 4:\n\nSystem Structure:\n\nA possible mode of operation for a\n\n\ngiven system; the components, their interconnections, and the informa\xc2\xad\ntion flow in the system at a given time.\n\n\nDefinition 5:\n\nSystem Configuration:\n\nThe original design of the system,\n\n\naccounting for all modeled modes of operation, and the Markov chain\n\ngoverning the configuration, or structural, dynamics (transitions among\n\nthe various structures).\n\n\nAn example of three possible structures for a given system is shown\n\ngraphically in Figure 1.3.\n\nIn this report, structures are referenced by\n\n\nconvention by the set of non-negative integers\n\nI\n\n=\n\n{0,l,2,3,... ,L}\n\n(1.2.8)\n\nThe configuration for the design illustrated in Figure 1.3 is depicted\ngraphically in Figure 1.4.\n\nThe nodes of the graph in Figure 1.4\n\nrepresent the system structures of Figure 1.3.\n\nThe edges of the graph\n\nrepresent probabilities of transfer from one node to another, and are\nelements of the matrix P.\n\npi+l,j+l\n\n= \tprob. structure i at time t+l given structure j at\n\ntime t.\n\n(1.2.9)\n\n\nThe state of the system configuration at time t is the structure in\n\nwhich the system is operating at that time.\n\n\n16\n\n76265AW018\nF(t)\n\n1-\n\nFigure 1.1:\n\nE\n\nn\n\na\n\n\nExponential failure distribution.\n\n\n17\n\n76265AW01 9\n\nZ(t)\nFTil\n\nII\n\n-\n\ni\n\nII\n\n0t\n\nI\n\nII\n\nFigure 1.2:\n\nTypical hazard rate function for a transistor.\n\n20\n\n76265AW020\n\ncomp\n\ncompo 1\n\nO\n\ncompo 2\n\ncamp0 3\n\ncamp0 3\'\n\ncmp. 4\n\nstructure 1\n\n\nstructure 0\n\noronp.\ncamp0 2\n\n\nLEGEND:\n\ncomp. = COMPONENT\n\ncomp 0 4\nstructure 2\n\nFigure 1.3:\n\nThree hypothetical system structures.\n\n\ncomp. 2\n\n21\n\n76265AW021\n\n0\n\nFigure 1.4:\n\n1\n\n\nConfiguration for structures in\n\nFigure 1.3.\n\n22\n\nk(t)\n\nstructural state at time t\n\n=\n\n(1.2.10)\n\nk(t) E I\n\n(1.2.11)\n\nThis structural state evolves in time to form the structural trajectory\n(of length T+l)\n\nxT\n\n=\n\n(k(0),k(1),\n\n.\n\n.\n\n,k(T))\n\n(1.2.12)\n\nIn general, this structural trajectory is a random variable with apriori\nprobability of occurance\np(XT)\nT (\n\n=\n\nTk(0) ,O Pk(1)k(0)Pk(2)k(1)\n\n-"(..3\nPk(T)k(T-)\n\n(1.2.13)\n\n(Figure 1.5).\n\n\n1.2.2\n\nControl Theory.\n\nIn this report, only linear systems with a quadratic cost index\n\n\nare considered.\n\nAt this time, any more general formulation is of dubious\n\n\nvalue in that the linear quadratic problems can demonstrate many of the\n\nfundamental concepts of reliable control system design.\n\nIt is\n\n\ndoubtful that any other formulation could be solved without the knowledge\n\ngained from the linear quadratic solutions presented in the remainder of\n\nthis report.\n\nAs a further restriction, perfect observation of the system\n\n\nstate x\n-t\n is assumed.\n\nThe general class of linear systems discussed in\n\n\nthis report is of the form\n\nxt+l\n\n=\n\nk(t) x t\n\nThe set of pairs\n\n+B\n\nk(t) ut\n\n(1.2.14)\n\n(Ak , k ) describe the possible system structures,\n\nwhere\nk(t) C I\n\n(1.2.15)\n\n\nThe remainder of the configuration is specified by the Markov chain\n\nequation (1.2.5).\n\nThe objective of this research is to develop control\n\n\n23\n\n76265AW022\nL\n\n3\xc2\xad\nI\n\n2L\nI\n\nL\n\n0,\ntime\n\nFigure 1.5: \n Two possible structural trajectories.\n\n\n24\n\nlaws which account for the possible structural trajectories\nwhile minimizing some function of the cost.\n\nThe cost function for a\n\n\ngiven random state and control trajectory ((x\n\nT\n\nT\n+\n\n=TQx\n\nT\n\nT Ru\n-t--t\'\n\nt--t\n\n+\n\n(1.2.12)\n\n\n,u\n-t -at\n\nT-1\n\n\nt=O\'T\n\nis\n\nx Tx\n\n(1.2.16)\n\n-T-- T\n\nThe function of the cost which is minimized is generally taken to be the\nexpected value of 3T over all possible structural trajectories x\n\n.\n\nIt\n\nis shown that this class of optimization problems yields solutions\n\nwhich are sensitive to both system performance and system reliability,\n\nas modeled in the configuration.\n\nIn the remainder of the report,/only variations in the B-matrix,\n\nor actuators are considered.\n\nAn actuator is a device which transfers\n\n\nthe control input to the system dynamics.\n\nThe actuator in the B-matrix\n\n\nmay model a physical linkage, such as is found on the control surfaces of\n\naircraft, or, for example, the effectiveness of a tax reduction on the\n\neconomy.. A single actuator may fail in many different modes.\n\nFor\n\n\nexample, the B-matrix can be of the form\n\n\nB0\n\n=\n\n[b (, I\n\nI\n\n"\n\n(1.2.17)\n\nwhere the b. Is are actuators which may fail to an actuator having zero\ngain with a failure probaility per unit time pf:\n\nb.\n\n-0\n\n(1.2.18)\n\nThen the system structures representing modes of failure would be modeled\nas B-matrices having at least one zero column.\nThis class of linear models can also be used as a model for self\xc2\xad\nreorganizing systems; the only restriction is that the reorganization,\n\nor reconfiguration, process must be modeled with a constant hazard rate.\n\n\n25\n\nAn important aspect of this research is the study of various types\n\nof redundancy.\n\nAt present, the effect of redundancy on system performance\n\n\nis poorly understood.\n\nThere are two basic types of redundancy:\n\nredundancy-and functional redundancy.\n\ncomponent\n\n\nComponent redundancy is the&use\n\n\nof two or more identical components (in this report, actuators) for the\n\nsame task.\n\nA good example is provided by equation (1.2.17).\n\ntwo actuators, b.\n\nand b. , are identical.\n\nb . is still operational, and vice-versa.\n-J\n\nof actuators b.\n\nand b.\n\n,\n\nIf b .\n\nSuppose\n\n\nfails (Equation,(1.2.18)),\n\n\nIn order to lose the function\n\n\nboth actuators must fail; this event will\n\nhave a lower probability of occurance than the event of the failure\n\nof b. ; if b\nb.\n\nwere not in the configuration the function of actuator\n\n\nwould be lost.\n\nThe problem with component redundancy in control theory-is how\n\n\nshould the allocation of control resources be allocated to the redun\xc2\xad\ndant components, and how should the component reliabilities affect the\n\nchoice of an optimal control law?\n\nThe control methodologies presented\n\n\nin this report answer the question for a specific class system confi\xc2\xad\ngurations.\n\nFunctional redundancy implies the overlapping of function of two\n\nor more components in a system.\n\nIf one of the components fails, part\n\n\nof its function is still performed by the other (redundant) component(s).\n\nFunctionally redundant actuators are modeled in this report in the same\n\nway as component redundancy.\n\nThe functional redundancy is accounted for\n\n\nin the expectaion of the cost index over the structural trajectories.\n\nThe dynamics of repair and reconfiguration are all modeled in this\n\nreport as exponential failure distributions (constant hazard rates).\n\n\n26\n\nAs an example, if two actuators (b 0\n\nand b\n\n) are in a system configura\xc2\xad\n\ntion and can each fail with probability Pf\n\nand Pf\n\nrespectively, to an actuator with zero gain (0),\ndynamics are, assuming\n=\n\nper unit time,\n\n\nthen the configuration\n\n\nindependence of failures:\n\n\nb0 1l\n\n(1.2.19)\n\n= El 1-b 1\n\n(1.2.20)\n(1.2.21)\n\n\n[ 01 0]\n\n12=\nB 3 =\n\n10\n\n(1.2.22)\n\n1\nwith probability p0( -pl) per unit time\n\n(1.2.23)\n\n\n) per unit time\n\n(1.2.24)\n\n\nB 1\n\nB\nB\n\n4\n\n--\n\n41\n\nB 1\n\n- 2\n\nwith probability pf (l-p\n\nf 0\n\nB3\n\nBi\n\nwith probability pf P2\n\n3B\n\nwith probability\n\n(1.2.25)\n\n\nf2per unit time\n\n(1.2.26)\n\n\nwith probability Pfl per unit time\n\n(1.2.27)\n\n\nB 3\n\nB2\n\nper unit time\n\nFrom this information, the Markov chain transition matrix P can be formed:\n1\n\n-Pf0 Pf +Pf0Pf\n(I -\n\nPt\n\nP\n\n0\npfl(l-pf0)\nPf0 Pfl\n\n)\n\n0\n\n0\n0\n\n1-Pf\n\n1\n\n0\n0\n\n2\n\n(1.2.28)\n\n0\n\n1-pf1\n\n0\n\n\nPf2\n\nPfl\n\n1\n\n\nRepair is considered to he component replacement, and is modeled in the\n\nsame manner; e.g.,\n\n0\n\nB\n\nwith probability p r\n\nPr\n\n(1.2.29)\n\n\n27\nReconfiguration is the restructuring of the (actuator) configuration to\n\ncompensate for failure, and is modeled as\n\nB\nwhere \t\nB\n\n+\t\n\nB4\n\nwith probability P41\n\n(1.2.30)\n\nis a new actuator configuration which will be used on reconfi\xc2\xad\n\nguration after failure.\n\nThe methodologies presented allow the study of the effects ,of\n\nfailure, repair and reconfiguration on the optimal control of linear\n\nsystems; they yield a quantitative analysis of the effectiveness of a\n\ngiven \t\nsystem design, where effectiveness is a quantity\'relating both\n\nthe performance and the reliability of a configuration design (see\n\nAppendix 1).\n\n\n1.2.3 \t General Nature of Results.\n\nThere are three classes of reliable controller methodologies:\n\nI)\nII)\nIII)\n\nPassive (Robust) Controller Design\n\nActive (Switching) Controller, Passive Configuration Design\n\nActive Controller, Active Configuration Design\n\n\nThis report concentrates entirely on classes I) and II).\nmethodologies are much more difficult to study.\n\nClass III)\n\n\nThe Markov chain models\n\n\nof configuration dynamics which work in classes I) and II) do not hold\n\nin class III); as yet, there is no satisfactory way to model the\n\nconfiguration dynamics of a system in such a way that the control rules\n\nare well-defined.\n\nClass I) methodologies are passive designs.\n\nThese designs account\n\n\nfor the occurance of failures in the initial selection of the control\n\nlaw; on-line, this class of designs does not use any current-estimate of\n\nthe structural state of the configuration.\n\nThe design is "conservative"\n\n\n28\n\nin that it continues to stabilize the system without regard to the current\n\nstructural state.\ncontroller designs.\n\nA special sub-class of these designs is the robust\n\nA robust controller will stabilize any structure of\n\n\nthe system without regard to the configuration dynamics; i.e.., if the\n\nsystem remains in any structural state forever, it will still be\n\nstabilized.\n\nThe class I) methodologies are represented by the\n\n\nnon-switqhing gain methodology of Chapter 5.\n\n-Class II) methodologies are active controllers;-in some sense,\n\nthey are adaptive.\n\nFrom knowledge of the system\'s past, these controllers\n\n\nswitch their control law on-line in order to compensate for what they\n\nestimate to be the correct structural state.\n\nFor deterministic systems,\n\n\nthese controllers can be determined analytically.\n\nFor stochastic\n\n\nsystems, the optimization problems cannot be solved analytically in\n\ngeneral due to the dual control effect [Fel\'dbaum, 4- 7].\nsuboptimal control strategies must be used.\n\nThus,\n\n\nThe class II) methodologies\n\n\nare represented by the switching gain methodology in Chapter 3 and\n\nits suboptimal extensions in Chapter 4.\n\n\n29\n1.3\n\nRelations with Previous Literature.\n\nThis research is based on a background knowledge in both reliability\n\n\ntheory and systems theory.\nfundamental in these fields.\n\nBoth mathematics and probability theory are\n\nAs general references to the techniques\n\n\nused in this report, in real analysis, and measure and integration\n\ntheory, [Rudin,8],\n\n[Segal & Kunze, 9], and [Halmos,10] are good; in\n\n\nmatrix theory, [Gantmacher,ll] is the standard reference.\n\nIn probabil-,\n\n\nity theory, [Bauer,12] and [Doob,13] are definitive; expansions on the\n\ntheory of Markov chains are found in [Chung,14] and [Derman,15].\n\nThere are several good texts on reliability theory; of these,\n\n[Greene & Bourne, 2] and [Shooman, 1] are possibly the best.\n\n[Cox,161\n\n\nand [Corcoran,17] demonstrate the current methods of the scheduling and\n\nuse of redundancy in reliability technology.\n\nOther good treatments are\n\n\nfound in [Barlow and Proschan,18] and [Gnedenko,19].\n\nIn control theory, a good treatment of the deterministic linear\n\nquadratic regulator problem is found in the IEEE Transactions Special\n\nIssue edited by [Athans,20], and in [Athans & Falb,21].\n\nThe dual\n\n\ncontrol problem is described in [Fel\'dbaum, 4- 7] and several other\n\npublications.\n\nPreviously, several authors have studied the optimal control of\n\nsystems with randomly varying structure.\n\nMost notable among these is\n\n\n[Wonham,22], where the solution to the continuous time linear regulator\n\nproblem with randomly jumping parameters is developed.\n\nThis solution is\n\n\nsimilar to the discrete time switching gain solution presented in\n\nChapter 3.\n\nThe random parameters are restricted to be a continuous\n\n\ntime Markov chain.\n\nThe most notable difference is that in [Wonham, 22],\n\n\n30\nthe assumption is made that the controller has perfect information about\n\nthe present state of the random process on-line.\n\nThe solution switches\n\n\ngains in a linear state feedback control law whenever the (Markovian)\n\nrandom parameter jumps.\n\nIn the discrete time switching gain solution\n\n\npresented in Chapter 3, the control law is determined from past observa\xc2\xad\ntions -which allow the deduction of the exact state of the random para\xc2\xad\nmeter process, and then the random parameter may switch values according\n\nto the statistics given by the Markov chain.\n\nThus, the control may be\n\n\napplied to one of a number of possible structures at the next time\n\ninstant.\n\nIn Wonham\'s development, the optimal control law is matched\n\n\nspecifically to one structure.\n\nThe analogous continuous time version\n\n\nto the-switching gain solution of Chapter 3 would be to assume on-line\n\nperfect observation of the random parameter with a fixed time delay.\n\nWonham\'s result has no such time delay.\n\nWonham also proves an existence result for the steady-state optimal\n\nsolution to the control of systems with randomly varying structure.\n\nThis result is based on conditions of stabilizability of each system\n\nstructure and observability of each structure with respect to the\n\ncost functional.\n\nThe conclusion is only sufficient; it is not necessary\n\n\nfor existence of a steady-state solution.\n\nSimilar results were obtained\n\n\nin [Beard,23] for the existence of a stabilizing gain, where the\n\nstructures were of a highly specific form; these results were necessary\n\nand sufficient algebraic conditions, but cannot be readily generalized\n\nto less specific classes of problems.\n\nThe time-varying solution of [Wonham,22] is computed using a set of\n\ncoupled Riccati-like matrix equations.\n\nThe coupling is in the form of\n\n\n31\na linear term in the solution to the matrix equations added to the normal\n\nlinear quadratic Riccati equation.\n\nThe solutidn can be precomputed by\n\n\nsolving the coupled Riccati-like equations off-line; the control law is\n\nthen switched on-line to a gain which corresponds to the current state\n\nof the Markov process.\n\nThe optimal solution requires perfect knowledge\n\n\nof the structure.\n\nIn reality, the structure is seldom known perfectly, and a noisy\n\nobservation of the random process leads to a dual control problem.\n\nAlthough much of Chapter 3 is based on the fact that the controller can\n\nobtain the structural state with one-step delay in the deterministic\n\ndiscrete time problem, this report makes the connection, for the first\n\ntime, of the existence of a steady-state switching gain controller with\n\nthat system\'s reliability and effectiveness.\n\n[Sworder, 24] has developed, using-a version of the stochastic\n\nmaximum principle, an optimal feedback control law for a class of\' linear\n\nsystems with jump parameters which is almost identical to that of\n\n51cnham,22];the coupled Riccati-like equations are identical except for\n\nnotation.\n\nThe only difference is Sworder\'s assumption that the random\n\n\nprocess is instantaneously observable from a set of sensors which are\n\nunaffected by the choice of the control law.\n\nUsing this assumption,\n\n\nSworder avoids the problems of dual control.\n\nSworder also comments on the usefulness of linear system models\n\nwith jump parameters in modeling possible failures in the system\n\n[Sworder,24].\n\n[Ratner & Luenberger,25] derive a control law for a\n\n\ncontinuous time linear system.\n\nThe system has one failure mode, and a\n\n\nmaximum number of renewals (repairs) can take place.\n\nThe objective is\n\n\n32\nto determine apriori the optimal time intervals in. which the system\n\nshould operate in the failure mode, and the optimal-control law, given\n\nthe mode of operation, over a finite time interval.\n\nThe failure process\n\n\nis assumed to have an exponential failure distribution (constant hazard\n\nrate);, the renewal process is controlled, and is not random.\n\nThe\n\n\ncontrol law is of the switching gain type, and the solution is in the\n\nform of two coupled Riccati-like matrix equations quite similar to those\n\nin [Wonham,22] and [Sworder, 2 4 ].\n\nThe optimal control policy and the\n\n\noptimal renewal policy can both be calculated off-line.\nproblems is further investigated by\n\nThis class of\n\n\n[Sworder,26] to determine over what\n\n\nregion immediate renewal is the optimal policy.\n\nBoth of these papers\n\n\nillustrate examples of class III) control methodologies; the structural\n\nstate as well as the system state is under the influence of the control\xc2\xad\nler.\n\nThe simple structure of the class of systems studied by [Ratner\n\nLuenberger,25] allows a solution.\n\n&\n\nThere is need for much more work in\n\nthis area.\nStill a third approach to the problems associated with multiple\xc2\xad\nstructure systems is given in [Bar-Shalom & Sivan, 2 7].\n\nHere, the\n\n\nmeasurements of the-system state are corrupted by additive noise.\n\nThe\n\n\nopen-loop controller and the open-loop feedback controller are derived\n\nusing dynamic programming.\n\nKnowledge of the presentstate of the random\n\n\nprocess governing the system configuration is not assumed.\n\nTherefore,\n\n\nthe (optimal) closed-loop controller would be a dual control law.\n\nThe\n\n\nopen-loop controller assumes no on-line measurements of the system state;\n\nthe open-loop feedback controller assumes future on-line measurements\n\nand thereby improves its performance.\n\nThere is little correlation\n\n\n33\n\nbetween this paper and the research on which this report is based.\n\n[Willner,28] developed a suboptimal control scheme, which allowed\n\nfor imperfect observation of the random parameter process, known as\n\nmultiple-model, adaptive control.\n\n\'In this method, the parameters -could\n\n\nonly take a discrete set of values, a cause of recent disfavor, as MMAC\n\ndoes not always work well when the parameters vary continuously and are\n\napproximated by the mathematics.\nSworder,29].\n\nSimilar work has been done in [Pierce &\n\n\nThe MMAC methodology is optimal one step backward from the\n\n\nfinal time, as is the switching gain methodology in the example of\n\nChapter 2 when applied to systems with additive white control noise.\n\nThe dual problem of state estimation with a system with random\n\nparameter variations over a finite set was studied in [Chang & Athans,30].\n\nIt is shown there that the optimal estimator consists of a geometrically\n\nincreasing set of Kalman filters, one for each possible structural\n\ntrajectory of length t+1 at time t, and an averaging process to compute\n\nthe minimum mean-square error estimate from the filter estimates.\n\nIt\n\n\nis also shown that when the parameter process is Markovian, a bank of\n\nN 2 \nestimators is optimal, where there are N possible values of the\n\nparameters.\n\nEach estimator is then conditioned on the possible values\n\n\nof the parameters at the two previous time instants.\n\nRecently, the robustness of the linear quadratic regulator has been\n\nstudied in depth.\n\nThis work is described in [Wong, et. al.,31] and\n\n\nin [Safonov & Athans,32].\n\nA long-standing problem with the linear\n\n\nquadratic design methodology has been the lack of analogs to the various\n\nstability and robustness criteria of classical systems theory.\nresearch was aimed at characterizations of robust solutions to,\n\n\nThis\n\n\n34\nspecifically, the linear quadratic regulator.\nreported in\n[Safonov,36].\n\n[Safonov & Athans,33],\n\nSupporting research is\n\n\n[Wong & Athans,34],\n\n[Wong,35], and\n\n\nThe research in this report is related to the robust\n\n\ncontroller problem, but the approach is different in that the performance\n\ncriteri6n is modified to account for possible variations in structure,\n\nsuch as those caused by failures, rather than depending on certain\n\nproperties of the linear quadratic regulator ,solution to guarantee\n\nrobustness.\n\nIn this research, the concept of stability is related to\n\n\nthe existence of a finite cost solution to the non-switching gain\n\nproblem.\n\nFor a specific class of configurations, this approach solves\n\n\nthe robust controller problem (Chapter 5, Section 9).\n\nThe existence of an uncertainty threshold for\n\nthe non-switching\n\n\ncontroller of Chapter 5, that limit on parameter uncertainty beyond\n\nwhich no controller can stabilize the system, is proven for an one\xc2\xad\ndimensional example.\n\nThis work is similar to the work by [Athans,\n\n\net. al.,37] on the Uncertainty Threshold Principle and the related\n\npapers by [Ku & Athans,38] and [Ku, et. al.,3 9 ].\n\nThis research is\n\n\nreported in Chapter 2, Section 7.\n\nLastly, parts of this research have been presented in an unpub\xc2\xad\nlished form at the 1977 Joint Automatic Control Conference in San\n\nFrancisco, and published for the 1977 IEEE Conference on Decision and\n\nControl Theory in New Orleans [Birdwell & Athans,40].\n\n\n35\n1.4\n\nSummary of Main Contributions.\n\nThere are two major contributions of this research.\n\nFirst, the\n\n\nclassification of a system design as reliable or unreliable, for the\n\ndeterministic variable actuator linear system in Chapter 3, has been\n\nequated with the existence of a steady-state switching gain and cost\n\nfor that design.\n\nIf the steady-state switching gain does not exist,\n\n\nthen the system design cannot be stabilized; hence, it is unreliable.\n\nThe only recourse in such a case is to use more reliable components\n\nand/or more redundancy.\n\nReliability of a system design can therefore\n\n\nbe determined by a test for convergence of the set of coupled Riccati\xc2\xad\nlike equations (3.3.6) as the final time goes to infinity.\n\nA similar result holds for the non-switching gain methodology of\n\nChapter 5.\n\nHere, the system design is classified as reliable or\n\n\nunreliable with respect to a constant gain linear feedback control law,\n\ndepending on the convergence, or divergence, respectively, of equation\n\n(5.6.16) as the final time goes to infinity.\n\nIf equation (5.6.16)\n\n\nconverges to a limit cycle, then that limit cycle produces a stabilizing\n\ncyclic steady-state gain.\n\nThe second major contribution lies in the robustness implications\n\nof the non-switching gain methodology.\n\nPrecisely, a constant gain for\n\n\na linear feedback control law for a set of linear systems is said to\n\nbe robust if that gain stabilizes each linear system individually, i.e.,\n\nwithout regard to the configuration dynamics.\n\nThe problem of determining\n\n\nwhen such a gain exists, and of finding a robust gain, can be formulated\n\nin the context of the non-switching gain methodology.\n\nAs a result, the\n\n\nnon-switching gain methodology gives an algorithm for determining a\n\n\n36\nrobust gain for a set of linear systems which is optimal with respect to\n\na quadratic cost criterion.\n\nIf the algorithm does\'not converge, then\n\n\nno robust gain exists-\n\nThe following Section of this Chapter will outline the remainder\n\nof this report.\n\n\n1.5 \t Outline of Report.\n\nIn Chapter 2, several one-dimensional examples are examined as\n\na clarification and motivation for the methodologies presented in\n\nChapters 3 through 5.\n\nIn addition, Chapter 2, Section 7, deals with\n\n\nthe relationship between the Uncertainty Threshold Principle and the\n\nexistence of a steady-state solution to the non-switching gain problem.\n\nChapter 3 develops the optimal solution to the class of problems\n\ndescribed in Section 2 of this Chapter.\n\nThe solution is labeled the\n\n\nswitching gain solution because the gain of a linear feedback control\n\nlaw switches in response to the exact observation of the system\n\nstructure with one-step delay.\n\nSince Chapter 3 deals entirely with deterministic systems, and the\n\nswitching gain solution does not extend optimally to the stochastic\n\ncase, Chapter 4 presents some suboptimal methods which can be used to\n\nextend the switching gain solution to stochastic problems.\nmethodologies are presented.\n\nTwo\n\n\nOne (hypothesis testing) is based entirely\n\n\non estimation of the structure.\n\nThe second (dual identification) uses\n\n\nthe dual effect of the control law to determine more precisely what the\n\nstructure\n\nis with the next observation.\n\nThe optimal control law would\n\n\nhave some characteristics of both methodologies, as is shown by example\n\n\n37\nin Chapter 2, Section 5.\n\nChapter 5 derives a control law which ignores any on-line informa\xc2\xad\ntion which might be gathered about the structural state, and results\n\nin a non-switching gain solution used in a linear feedback control law.\n\nThe stability of this non-switching solution is explored, along with\n\nthe existence of a steady-state solution, in Secion 7.\n\nIn Section 9,\n\n\nthe robustness issue is addressed, and the non-switching methodology is\n\nused to define an algorithm which can determine the existence of a\n\nrobust gain and calculate an optimal robust gain with respect to a\n\nquadratic cost functional, when one exists.\n\nChapter 6 focuses on the issues of computer-aidedldesign and the\n\napplication of the non-switching gain methodology to design problems.\n\nTwo examples are used to demonstrate the effectiveness of the non\xc2\xad\nswitching methodology in design.\n\nChapter 7 reviews the results described in the report and suggests\n\nnew directions for future research.\n\n\n38\nCHAPTER 2\n\n\nCLARIFICATION AND MOTIVATION OF RESEARCH\n\n\n2.1\n\nintroduction.\n\nThe purpose of this Chapter is to motivate all subsequent more\n\n\ngeneral \'Chapters with simple one-dimensional examples.\n\nIn particular,\n\n\nin Section 2, a one-dimensional problem is formulated and solved to\n\nillustrate the optimal (switching gain) deterministic control for\n\nlinear quadratic systems with variable actuator configurations.\n\nThe effects of process noise on this solution are examined in\n\nSection 3.\n\nThe dual effects which occur in the stochastic systems\n\n\nmotivate the suboptimal approaches described in Chapter 4.\n\nThe possibility of steady-state control of variable actuator\n\nconfiguration systems with a single linear independent control law\n\nis discussed in Section 6, motivating the work on the non-switching\n\ngain solution and robust control laws in Chapter 5.\n\nIn addition,\n\n\nthe possibility of existence of a steady-state stabilizing linear\n\nfeedback control law with constant gain is compared with the work on\n\n37\nthe Uncertainty Threshold Principle [Athans,et.al., ] in Section 7.\n\n\nSection 7 contains the only case of this report where exact algebraic\n\nconditions for the existence of a steady-state solution have been\n\nderived.\n\nUnfortunately, these results do not readily extend in an\n\n\nanalytical manner to higher dimensions.\n\nThe question of existence of a steady-state solution to these\n\nproblems is of great importance.\n\nA system design is defined to be\n\n\nreliable with respect to a certain class of control laws if there\n\n\n39\nexists a control law from that class for which the infinite time\n\ncost incurred using that control law is finite.\n\nSince the switching\n\n\nand non-switching. gain solutions are-the-optimal solutions for-their\n\nrespective classes of control laws, if they incur an infinite cost, so\n\nwill any other control law from that class.\n\nIn addition, since the\n\n\nswitching gain solution is the optimal control law for the determin\xc2\xad\nistic problem, a system design is termed deterministically reliable;\n\nor reliable if and only if the incurred infinite time expected cost\n\nis finite.\n\nIn the neit Section, a one-dimensional example is presented\n\nwhich will\'be used to motivate the remainder of this report by\n\nexamining the ramifications of the switching and non-switching gain\n\nsolutions through their specific application to the example.\n\n\n2.2 \t A Simple Example--The Optimal Solution.\n\nThe following one-dimensional example is used to demonstrate the\n\nswitching gain methodology presented in Chapter 3, and to show that\n\nthe general stochastic problem is analytically intractable.\n\nAll proofs\n\n\nand derivations are given in Appendix 2.\n\n\n2.2.1 \tProblem Statement.\n\nLet the discrete-time system be one-dimensional with one control\n\nvariable ut and state variable xt related by\n\nxt+1 = ax t + \'k\n\nt\n\n(2.2.1)\n\nThe value of the control multiplier (bk) is a random variable which\ntakes on one of two discrete values at each time t.\n\n40\n\nbk(t)\n\nb if k =0\n1/b if k = 1\n\n=\n\n(2.2.2)\n\nThe random process k(t) is governed by the Markov chain represented\nby\n= P r\n-- t\n\n\n7\n\n-t+1\n\n(2.2.3)\n\nwhere\n\nIE \t\n\nR2\n\n=\t\n\n(2.2.4)\np1\n\nP1\n\n1\n\nP21\n\n(2.2.5)\n\n2\n\nP 2 2J\n\nAt any given time t, the following sequence of events occurs:\nI)\n\nx t is observed exactly, bk(tl)is computed, and k(t-1)is\nset to 0 or 1 depending on bk(t-l),\n\nwhere k(t-1)is the\n\nvariable representing the Markov chain;\n\nII) \t bk(t-) may change values to bk(t);\n\n\nIII)\n\nu t is applied.\n\n\nFor \t ny given sample path, the performance index is given by\n\na\n\n=\n\n2\n\n(qx\n\n+ ru)\n\n(2.2.6)\n\nt=0\nwhere {0,1,.... ,T} is the time set over which the system is to be\ncontrolled.\n\nThe objective of the control problem is to minimize the\n\nexpected cost-to-go at time t, given by\nv(xt*k(t-l,)utt) = E\n(q2 + ru2)Ik(t-l4\n\n(2.2.7)\n\nwhere the expectation is taken over all possible sample paths of\n\n\nk(T),\n\nt<T<T.\n\n41\nSummary of Solution.\n\n\n2.2.2\n\nFrom Appendix 2.1, we find that the optimal control is given\n\nby\n\nut\n\nOt\n\nabSot\n\n+ IlTt\n\nt\n\n+\n\nb2S\n\nr+ 7T \n\n\n(a/b)S\n\nt+l \n\n\n(2.2.8)\n\n(1/b2)Slt+\n1\n\nwhere\n\n\n=\nit --t7\n\n[lt\n7r\n\n]\n\nI\n\n=\n\n(2.2.9)\n\nPit\n-- t-\n\nThus, the control law is linear in the state xt, and switches between\ntwo precomputable gains, depending on the value of k(t-l).\nGiven xt, xt 1 and ut_ 1\n11\nf x t-ax t-1\n\nt-1\n\n1\n\n(2.2.10)\n\nxtaxu "\n\n107\n\n-\n\n1/b\n\nt-l\nand k(t-1)\n\n=\n\n0 if\n\nt1\n\n=[1 0]\'\n\nor 1 if\n\nit-\n\n=[0 1]K.\n\nThe optimal cost-to-go is\n(22.11)\nV*(xtk=i,t) = x 2 S i\'t\n\nt\nwhere S0 t and SI\' t are propagated backward in time by the following\n\nequations:\n\n\n42\n\nAssuming k=O at time t, then nt\n\n=\n\nand\n11 P21 ] \' \n\n\nr[p labS o,t+l+p2 (a/b)Slt+l]2\n\nS\nS0t\n\n= q +222\n\nq \t[r+p\n+\n\nb2S ot+l+P2 (1/b2)Sl\'t+l ] 2\n\n\nb [PllabS0\' t+l+P21 (a/b) Sl\' t+l ]\nr 11l b So,t+l+p21(1/b2)Sl,t+l\n\n+ \t\n\n/\n\n+ 1 p\t\n2\n\n2\n\np1 1 ahSo t+1+P21(a/b) Sl t~i)l\n\nS21b[r+p\n\n11b\n\n2\n\nSO++pl 2\n\nAssuming k=l at time t, then 7t\n\n=\n\nSit+_/b\n\n2\n\nS1,t+l\n\n(2.2.12)\n\n\n[P12 P22]\' and\n] 2\n\n\nr[p 12abS ,tl+P22 (a/b),Sl,t+l\nlt =q+[r+P12b2SO,t+l+p22 (1/b2 ) S t+\n\na\n2\n\n+\n\n2\n\n\nb[P 12 abSort+l+P 2 2 (a/b)Sl,t+l\n12\n\n2\n\n\n2l2,t+1\n\n(2.2.13)\n\n\n(a _ P12abSO t+l+P22 (a/b)Sl,t+\nb[r+p\n1 2 b2So,t++P221,\n\n_ 2\n\nlt+/b 2\n\n\nNote from equation (2.2.8) that ut switches from one linear gain\nto another, depending on the value of xt -on an exact knowledge of xt .\nment noise\n\nthus,, this solution depends\n\nIf knowledge of xt is corrupted by measure\xc2\xad\n\n(or, if ut is corrupted by control noise),\n\nthen it will be\n\nshown by example that this becomes a dual control problem.\n\n\n43\n2.3\n\nThe Dual Control Effect.\n\nTo demonstrate the difficulties encountered when white process\n\n\nnoise is present, the optimal.solution for the one dimensional\n\nexample is derived over the time interval\ncontrol noise present.\nxt\n\n1\n\nf0,1,21 with additive white\n\n\nThe system is now represented by\n\n\n= axt + bk(t)ut + Et\n\n(2.3.1)\n\n\nEt is discrete time white noise with zero mean, E[t\nprobability distribution p(C),\n\n].\n\nI\n\n\nand is uncorrelated with x\n\nand k(T)\n\nT\n\nfor T<t.\nThus, the problem is to find u 0 and u I such that the expected\n\ncost-to-go is minimized.\n\nFrom Appendix 2.2, the optimal control one step back in time\n\n(at t=l) is\n\n\nxi.Ib~\n\n*, =\n\nr +\n\n7iTl\nU\n\n) b,\n\nwhere ii(l11) is the probability that k=\nset Z 1 = NO\n\n,x0\'ux1X}.\n\n(2.3.2)\n\ni, given the information\n\n\nAs expected, this control is of the same\n\nform as is the deterministic control law, equation (2.2.8), since\n\nthere is no benefit in trying to determine k\nthe use of a special control value.\n\nmore accurately through\n\n\nIn other words, there is no dual\n\n\ncontrol effect at t = Tff-l (in this example, t=l).\n\nAt t=0, the situation is different.\n\nNow, the optimal control will\n\n\nforce the system to supply more information through the state at t=1\n\nthan it normally would in the absence of the process white noise\n\nt"\n\n\n44\nIn order to compute u 0 , a numerical minimization of a numerical\n\nintegration (in general) must be performed.\n\nThus, u0 is the\n\n\nsolution -of\n\n2\n\n\n12\n\n*\n\n(x 0 ,0)\n\nV\n\n=\n\nf=0\n\nkO\n\nrain\n\n0()\nSR(x I )\n\nr (111)b]\nr+\n\nx\n\n~\n\nxq(l+a2)\n\n222 2\n\n2\n\n+ u 0 r + Eq\n\n\ni\n\n1\n10lO Jf oO )\n\nO) k k\n\nd~\n\n(2.3.3)\n\nwhere\n\n\nP(xl-aX0-bU\n0 \n\n;6 P(xl-ax0-biu\n\nk\n\n0\n\n(2.3.4)\n\n)TTi,\n\n0\n\n\nand p(xljkl,k0 ,Z0 ) is the probability measure of x I over R(xl)\n\nthe range of xi , given k 1 , kc, and Z O\n.\n\nO\n\nEquation (2.3.3) is very difficult to solve numerically, and\n\nfor any realistically-sized problem would be economically infeasible.\n\nFor the limited amount of computation that has been done with equation\n\n(2.3.3), the dual control effect is evident from Table 2.1.\n\nNote\n\n\nthat as the process noise variance increases, the trend is for the\n\n,\n\ncontrol u 0 to increase.\n\nThis is due to the need for a larger control\n\n\nto lessen the effect of noise on future estimations of the structure.\n\n\n45\nTable 2.1\n\nThe optimal control u 0 versus x 0 and\n\n\n(E-=3)\n\n0\n\nx0\n-2.0\n-1.6\n-1.2\n-0.8\n-0.4\n0.0\n0.4\n0.8\n1.2\n1.6\n\n2.3170089\n*\n\n1.3898305\n0.9255912\n0.4606236\n-0.005\n-0.4706236\n-0.9355912\n-1.3998305\n-1.8635511\n\n"0 (0=6)\n2.3188635\n1.8550055\n1.3907551\n0.9259997\n0.4606920\n-0.005\n-0.4706920\n-0.9359997\n-1.4007551\n-1.8650055\n\n0\n\n(=10)\n\n2.3201611\n1.8559061\n1.3912676\n0.9261950\n0.4607206\n-0.005\n\n-0.4707206\n\n-0.9361950\n\n-1.4012676\n\n-1.8659061\n\n\n\xe2\x80\xa2 - calculation did not converge due to numerical errors\n\n\nThe system used in the calculations is described by equation\n\n(2.2.1) where\n\n\na = 2.\n\nk(t) is 0 or 1\n\nbo= 2.\n\nb I = .5\n\nq=3.\n\nr=\n1.\n\nTable 2.1 is only.intended to demonstrate the difference in the\n\noptimal control laws at time 0 for a two-stage process; numerical\n\naccuracy is not assured.\n\nSpecifically, the values of -.005 for\n\n\n*\n\nu0 (x0 = 0) are highly doubtful, as well as the consistent\n\nasymmetry between positive and negative values in the Table.\n\n\n46\n2.3.1 \tA Special Case.\n\nIt is interesting that for one specialized probability distribu\xc2\xad\n*\n\ntion p(c), when the optimal control u0 is large enough, the optimal\n\nsolution is identical with the deterministic solution of Section 2.\n\nFrom Appendix 2.3, assuming\n\n\n, for \'/W= <\n\n<\n\n00 =\n\n(2.3.5)\n0\n\notherwise\n\n*\n\nas shown in Figure 2.1, if u 0 from the deterministic solution (equation\n\n2.2.8) satisfies\n\n\nI (bko \t *(\n\nb.)u 0\n0 \n\n\n> 2v37- for k\' 3 i\n\n(2.3.6)\n\n0\n\n\nthen u 0 is also the solution to the stochastic control problem.\n\nPhysically, because the noise is amplitude limited, it is easy\n\nto exactly deduce the structure if the control is large enough.\n\n\n47\n\n76265AW023\n\n2/\n\nFigure 2.1:\n\nA probability distribution for amplitude-limited\n\nwhite noise.\n\n\n48\n2.4\n\nExistence of a Steady-State Solution.\n\nAlthough, as will be stated in Chapter 3, little can be said\n\n\nabout the existence of a steady-state solution to the general n-dim\xc2\xad\nensional switching gain problem, for the one-dimensional example,\n\nexact conditions for the existence of a steady-state solution can\n\nbe found.\n\nThey are in the form of two simultaneous algebraic equations\n\n\nwhich can be solved analytically.\n\n\t\nb[Pllab+P2 (a/b)h]\nPll S= \n\n\n+ + 21\n\nhr\n\n=\t\n\n2\n\n\n+p 2 1 (l/b2)h\n\n\nPllab+P21(a/bh ) 2h \t\nb l2 +p21 h/b21\n\n1\n\na~\n\n(2.4.1)\n\nb [P1 2 ab+P 22 (a/b)hl\\2\n\np\n2=12a\n\n12b2+p22 (1/b 2)h\n\nb\n\n12\n\n+ P22\n\na\n\n-\n\nb+p\n\n22\n\n(/b)h)2\n\n\nP12ab+P22h(a/b)\n\n2h \t\n\nThe equations are derived in Appendix 2.4.\n\n(2.4.2)\n\nIn these equations the\n\n\nvariables F and h are defined as\n\nr\n\n= \tlim\nt --\n\n(2.4.3)\n\n\nSo\'t\nSot+l\n\n\nand\n\n\ni\'t\nO,t\nwhenever both S0, t and SIl t increase without bound as t +\nh\n\n(2.4.4)\n\n= \t lim\nt -co\n\nin equations\n\n(2.2.12) and 2.2.13).\n\n\n-\n\n,\n\nas defined\n\n\n49\nSince r is the limiting value of the ratio of the next value of\nSO\' t to the present value Sot+l, it is necessary that\n\nr > 1\n\n(2.4.5)\n\nSO\'\n\n(2.4.6)\n\nfor\nt\n\nSimilarily, if SO\' t has a limit, then F can have a maximum value of\n1.\n\nTherefore, a test can be made on the solution (h,F) to equations\n\n\n(2.4.1) and (2.4.2) for the existence of a steady-state solution:\n\nIf\n\nh 7 0 or\n\n(2.4.7)\n\nthen\nSO,S\n\nlt\n\nif\n\nr\n\n> 1\n\nSOft, Sl1 t converge if\n\n(2.4.8)\n\nr < 1\n\n(2.4\'.9)\n\nand there is no conclusion if F = i.\nBy way of eliminating all possibilities, as an aside, a limit cycle\nto the solution of equations (2.2.12) and (2.2.13) cannot occur by\n\nLemma 1 of Chapter 3.\n\n\n2.5\n\nConclusions on the Switching Gain Methodology.\n\nThe purpose of the last three Sections on the one-dimensional\n\n\nswitching gain example was to clarify the approach of this phase of the\n\nresearch, and to motivate the approach of Chapters 3 and 4.\n\nIn this\n\n\nSection, some implications of the one-dimensional example will be\n\ndiscussed.\n\n\n50\nImplications of the Dual Control Effect.\n\n\n2.5.1\n\nIt was shown in Section 2 that the optimal solution to the deter\xc2\xad\nministic class of variable actuator linear quadratic control problems\'\n\ni.e., the switching gain solution, is conceptually straightforward,\n\nalthough computationally complex off-line. Unfortunately, in Section 3,\n\nit was demonstrated that the optimal solution of the stochastic version\n\nof the same problem is infeasible.\nthe two-step optimal solution.)\n\n(Witness the problems of calculating\n\n\nTherefore, since the switching gain\n\n\ndeterministic solution is essentially the only solution which can be\n\ndescribed analytically, the research involved in developing the\n\nn-dimensional switching gain solution is justified.\n\nThis is exactly\n\n\nwhat is presented in Chapter 3.\n\nIt then remains to investigate any extensions (which will of\n\nnecessity be suboptimal) which may be made to the switching gain\n\nsolution to adapt the solution to the stochastic problem.\n4, a start is made in that direction.\nto follow:\n\nIn Chapter\n\n\nThese are two basic routes\n\n\nThe various hypothesis testing algorithms in combination\n\n\nwith the switching gain solution, and a formulation developed in\n\nChapter 4 which gives the control vector a dual effect; the control\n\nis changed to increase the accuracy of the estimation algorithm.\n\nThe optimal control would use techniques from both categories, as the\n\ndual effect is clearly seen in Table 2.1.\n\n\n2.5.2\n\nExistence of a Steady-State.\n\nAlthough for the one-dimensional example, it is possible to\n\n\ndetermine the condition for convergence of the Riccati-like equations\n\n\n51\n(2.2.12) and (2.2.13), this method does not extend to the n-dimen\xc2\xad\nsional solution.\n\nIt is at present unknown under what conditions\n\n\nthe Riccati-like equations for the n-dimensional problem converge;\n\ntherefore, there is little comment on conditions for convergence in.\n\nthe remainder of this report.\n\n\n52\n\n2.6\n\nA Simple Example--The Non-Switching Solution.\n\nIn the previous sections of this Chapter, motivation was given\n\nfor the development of the optimal (switching) solution to the linear\nquadratic\n\n-\n\nvariable actuator configuration control problem.\n\nSeveral problems with the method were pointed out in Section 5.\n\nSpecifically, the methodology does not extend optimally to the stochas\xc2\xad\ntic case due to the dual control effect.\n\nSecondly, the increase in\n\n\non-line complexity over the usual linear quadratic control problem\n\nis significant, especially in the suboptimal stochastic schemes.\n\nIn many instances, a stabilizing solution to this class of\n\ncontrol problems is desired which exhibits the same complexity as\n\ndoes the usual linear quadratic controller.\n\nFor instance, it may be\n\n\ndesired that a control law stabilize a system without requiring\n\nerror detection strategies and switching to a new form upon detection\n\nof failure.\n\nA subclass of these problems occur when a robust gain\n\n\n(one which stabilizes each configuration without regard for the\n\ndynamics of structural changes) for a set of linear systems is\n\ndesired.\n\nThe first problem within this subclass deals with the\n\n\nexistence of such a gain.\n\nThe second problem deals with the choice\n\n\nof an optimum robust gain with respect to some cost index.\n\nIn the following Subsections, an example of non-switching gain\n\nmethodology is given as an illustration of the concepts; since the\n\nderivations are quite complex, proofs are deferred until Chapter 5,\n\nwhere the entire development of the non-switching solution is presented.\n\n\n53\nThe following formulation is only for the steady-state solution;\n\nin Section 7, the conditions for existence of the steady-state solu\xc2\xad\ntion will be given and related to the Uncertainty Threshold Principle\n\n[Athans,et. al.,\n\n]\n\n\n2.6.1 \t Problem Statement\n\nIn Chapter 5, the non-switching control problem is solved for\n\nlinear systems with variable actuator configurations and quadratic\n\ncost.\n\nIt was stated in the conclusion of the previous Section that\n\n\na relationship exists between the existence of a steady-state solution\n\nand the Uncertainty Threshold Principle.\n\nIn this Subsection, the\n\n\nexistence of a steady-state non-switching solution to the one dimen\xc2\xad\nsional example presented in Section 2 will be studied to illustrate\n\nthis relationship.\n\nThe \t\nsystem to be used is\n\nx t+l= ax\n\nt +\n\nbkut\n\n(2.6.1)\n\n\nwhere x, a, b. and u are scalars, k can be either 0 or 1, and t takes\n\non integer values.\n\n\nb.i\n\n=\t\n\n(bif k=O\n\nlb\n(1/b\nif k=l\n\n\n(2.6.2)\n\nThe index k represents the structural state of the system, and\n\nis a random variable with statistics generated by the Markov chain\n\n\n54\nf t\n\n[r\n\nP =\n\nwhere 7 .\n\n(2.6.3)\n\n-P\n\nEit+lr P\n\n(2.6.4)\n\nis the probability that the structural state is i at time t,\n\ngiven some initial condition 7 (T init ) .\nThe infinite-time, or steady-state non-switching control problem\nis formulated by specifing that the solution u t is to minimize the\ncost of a trajectory (k t\nu\ns2\n2\nqx\n+ rut\nj = E\nt= T init\n\n2.6.2\n\n)\n\ngiven by the sum\ninit\n(2.6.5)\n\nSummary of Solution\n\nThe solution is computed, from Chapter 5, equations (5.7.17)\n\n\nand (5.7.18), when it exists, as the solution (So,S1 ) of\n\n\ns\n\no\n\na\n\n1\n\n2\n\n(bS0 +S1 /b)bS 0\n(b 2 S0+S /b 2 )+r\n\nS\n\n(\n+\n(Np)\n\n1\n\n\xc2\xad\n\n(bS0 +S\n+\n\n4(\n\n21\n\n2\n/A) (r+b2 S0\n\n(b2S 0 +S 1 /b\n\n)+r)\n\n0+sI/b) 2(r+S 1/b )\n\n(bS0+s1/b)S 1(bS\n12+\n\n2\n\n( (b2So+S1/b2)+r)b \n\n\n+ )\n\n1\n\n4( (b2 S +S1/b2)+r)\n\n\n+ q\nS\n\na2\n\n(2.6.6)\n(\n\na p\n\np)\n\nSo\n\n/b)bS\n(b So+S1/b 2) +r\n2\n\nS-)\\o0\n\n/\n\n(bS0 +S1 /b)S I(bS\n(- (b2s0+S l/b2 )+r)b\n\n+\n\nq(2.6.7)\n\n(bSo+S1 /b) (r+b280\n4 (1(b2So+Sl/b2 ) +r)\n2\n2\n((\ns/\n+)\n0 +S1 /b) 2(r+S1 T/b\n\n4 ( (b2S0+S/b2 )+r) 2\n\n)\n\n\n55\nand the control is given by\n\n\nu\n\nt =\n\n(bS0 +S 1/b)a\n\n-\xe2\x80\xa2xt\n\n(2.6.8)\n\n(r+ (b S0+S /b ))\nNote that the steady-state solution is a linear feedback control\n\nlaw with a constant gain which is pre-computable using equations\n\n(2.6.6) and (2.6.7).\n\nThe on-line implementation of this solution has\n\n\nthe same complexity as does the usual linear quadratic steady-state\n\n\nsolution.\n\n\n56\n2.7 \t Existence of a Steady-State Solution and the Uncertainty\n\nThreshold Principle.\n\nIn this Section, the existence of a steady-state solution to\n\nequations (2.6.6) and (2.6.7) is related to the Uncertainty Threshold\n\nPrinciple\n\n[Athans et. al.,37].\n\nThis Principle states that for a\n\n\ncertain class of systems, there exists a threshold, or bound, on the\n\ndegree of uncertainty in the system dynamics beyond which no control\n\nlaw will stabilize the system.\n\nFurthermore, it is noted in\n\n\n[Athans et. al., 3 7] that there does exist a "minimizing" control even\n\nthough the infinite-time cost in infinite.\n\nFor the non-switching gain class of controllers, it will be\n\nshown in this Section that, at least for the one-dimensional example\n\nof Sections 2 and 6; such athreshold does exist; furthermore, it will\n\nbe explicitly calculated.\n\nIn addition, it will be demonstrated that\n\n\nthe non-switching control gain -converges even when no finite cost\n\nsteady-state solution exists.\n\n\n2.7.1\n\nFormulation of Existence \'Problem.\n\nThe question is now asked:\n\nexist?\n\nWhen does the steady state solution\n\n\nI.e., when is the cost, given by\nJ2S0 +\n\n2\n\n(2.7.1)\n\nfinite?\nThis problem is solved by showing when the solution does not\n\nexist.\n\nAllowing\n\nSO\nand setting\n\n\n(2.7.2)\n\n\n57\n\nh\n\n=\t\n\nF\' = \t\n\nlir\nt --\n\nl\'t\nSo,t\n\nlrn\n-\n\n\nS(2.7.4)\n\nt\n\n(2.7.3)\n\nS0, t+l\n\n\nwhere S0, t and Sl\' t are the values of the r.h.s. of equations (216.6)\n\nand (2.6.7) iterated backwards t times from an initial value Si, 0=Q,\n\nequations (2.6.6) and (2.6.7) become\n\n\nr a2 (\n\n(b+h/b)b\n\n(1\n\n\'(b\n\n+ \t (l-p)\n\nh\n\na2\n ((1-p)\n\nhi\n\nI\n\n2+h/b\n\n-\n\n(1_\n\n2.7.2\n\n\'\n\n/\t\n\n\t\n(I-\n\nb2\n\n+(b+h/lb)2\n2 )2\n\n(b2+h/b\n\n\n\n+\n\n(b+h/b)\n(b2 +h/b 2 )b\n\n2\n\nb+h/b)\n\n+h/b 2 )\n\n-2(b2 _/b_2)b\n\n(b+h/b)2/b2\n(b2 +h/b 2 )2\n\n(2.7.5)\n\n)\n(b+h/b 2 2\n\n\n+\n\n(b+h/b)b\n3(b\n\nIh\n(\n\n2)\n\n(b 2 +h/b 2 ) 2\n\n(2~/)2\n\n(b2+h/b)\n\n/\n\n(2.7.6)\n\n2bI\n\nSummary of Solution.\n\nEquations\n\n(2.7.5) and (2.7.6) have 5 solutions.\n\nThe solutions of h\n\n\nand r of interest are:\n\n\n;\n\nFor \tp\nh\n\n= \t -(p(b 4\n\n(6-2W)-3b\n8-3)+((2b 4-2)p-b4+l)V\n\n+(4b 8-2b 4+2)p2+b8-2b4+1)/((2b 4+2)p -2pW)\nr\n\n=\n\n(2.7.7)\n\n2\n4\n2\n8\n2\n4\n2\n\na (-p[b (2p +4p-2)+(b +1)(p -2 p+l)] +(b +l)p2)\n\n/((b2 +1) 2 (2p-1) \t\n\n(2.7.8)\n\n58\nwhere\nV =\n\n2\n2\n8 2\n4\n4\n[b (p(4-4[b (2p +4p-2)+b (p -2p+l)+p -2p+l]\n2\n8\n2\n2\n+2p -2)+b (5p -21p+-1)+p -2p+l] 2\n\n2)\n\n(2.7.9)\n\nand\n8\n4\n4\n8\n2\n4\nW=b 8\nW = [(b +2b +l)p +(-2b +4b -2)p+b -2b +]\n\n(..0\n(2.7.10)\n\n;\n\nFor p =\n\nh= 1\n\n=\n\na2 (b 2-1)2\n2(b4+1)\n\n(2.7.11)\n\n<2.7.12)\n\n59\n2.7.3\n\nGraphical Illustration of Solution.\n\nEquations (2.7.7) through (2.7.12) are to6 complex for much\n\n\ninformation to he gleaned from study.\n\nTherefore, their significance\n\n\nis demonstrated graphically in this section.\n\nThese equations are used to compute the absolute values of a\n\nversus b and p above which no stabilizing non-switching control exists;\n\ni.e., since F is the limiting ratio of SO, t to S ,t+l, what threshold\n\nvalue of\n\nlal yields r = 1?\n\nSince the system (2.6.1) is a discrete\n\n\ntime one, this threshold quantifies how unstable the open-loop system\n\nmust be for there to be no stabilizing solution.\ncalled the uncertainty threshold value of\n\nIa\'threshold\n\nFor the case p\n\nk,\n\n\nis easy to compute from equation (2.7.12)\n\n\nathreshold\n\n[ (b2+1]\n\nIahl\nFor p =\n\nlal.\n\nThis quantity is\n\n\n2b_l)]\n\n(2.7.13)\n\n\n1,\n\nlalthreshold\n\n=\n\n(b2+1) [(2p-l)\n\n2\n\n/(p((b 4+l)p-[b4(2p2+4p-2)+(b 8+l)(p -2p+l]))]\n\n(2.7.14)\n\nA plot of\n\nlaithreshold versus p (long axis) and b is shown in Figure 2.2.\n\n\n60\n\n76265AW024\n\n\nlalthre2:shold\n\nIn(b)\n\n.p\nFigu~re 2.2:\n\nIaIthreshold versus p, b.\n\n\n61\nThe in(b) axis is used because\n\nIalthreshold is symmetric with respect\n\n\nIalthreshold (1/b) ). b varies\n\nto in(b) around zero (lalthreshold (b) =\n-2.5\n-.05\nNote that\n; p varies from p = 1 to p = .- 1.\nto e\nfrom e\nIalthreshold\n\n- l and/or p\n\nas b\n\n-\n\n4\n\n0.\n\nThis is because as b - 1, the\n\nsystem looks more and more like\n(2.7.15)\n\n\nxt+1 = ax t + bu t\n\n0, the system is\xc2\xad\n\nAs p\n\nwhich is controllable for all values of a.\n\nswitching more and more rapidly between the two structures; therefore,\n\neach structure has less time to influence the system unfavorably and\n\nthe system becomes easier to control, leading to\n\n\xc2\xad\n\nalthreshold\n\nBest Control with Infinite Cost.\n\n\n2.7.4\n\nAlthough the cost may be- infinite, a finite gain control exists.\n\nFrom equation (2.6.8), and allowing S0\n\nand S /S 0\n\n-\n\nh, the control\n\nbecomes\n\n(b+h/b) a\n\n*\n\n=\n\nu\n\n-\n\n2\n\n2 x\n\n(2.7.16)\n\n(b2+h/b 2 )\n\nNote that the control gain does not depend on q or r, but only on p,\n\na and b, as in the work with the Uncertainty Threshold Principle.\nplot of h versus p\n\nA\n\n\n(long axis) and b is given in Figures 2.3a and 2.3b,\n\n\nin the same manner as for F.\n\nNote that as p\n\n-*\n\n0\n\n,\n\nh\n\n-) -\n\n(except at\n\nFor this boundary, we rely on a symmetric argument, switching\n\n\nb = 1).\n\nand SI, since we only know that S 1\n\nthe roles of S\n\n.\n\n\nAn interesting symmetry exists in h with respect to p.\n\nIf h is\n\ndefined as\n=\n\nlim h\nb 0\n\n(2.7.17)\n\n76265AW025\n\n\n62\n\n\nh\n\n\nIn(b)\n\np\n\n\nFigure 2.3a:\n\nh versus p, b. \n\n\nOIGNAL PAU IS\n\nOF pO)OR Gku\n\n\n63\n\n76265AW026\n10\n\nP=1\n8\n\nh\n6\n\n4\n\n.2\n3\n-.\n\n2\n.4\n\ne -2.5\n\ne -2.0\n\n*\n\ne -1.5\n\nb\n\nFigure 2.3b:\n\nh versus p, b.\n\ne -1.0\n\ne-5\ne\n\n64\nthen\n\n(2.7.18)\n\n-p\n\n=\t\n\np\nLetting p\n\n+ x,\n\n=\n\n1 - 2x\n1 + 2x\n\n(2.7.19)\n\nand\n\nh(1)\n\n=\n\n(2.7.20)"\n\n\nThus, ln[h(p)] is symmetric around p\nproblem, because as pSO\n\nis satisfied (S 1\n\n-\n\n1, h\n-0).\n\n=\n\n.5..\n\nThis solves the boundary\n\n0 (except at b = 1),\n\nand the condition\n\nSince h is symmetric, and h(p,b) +(p)\n\nfor p- O, the solution is well-defined at p = 0.\nIn Figure 2.4, the control gain divided by a, g; is plotted as a\n\nfunction of p and b.\n\n*\n\nut\n\n=\n\n-gax\n\n(2.7.21)\n\nt\t\n\nNote that as p -) 0\ng-)\n\n(and h+),\n\nl/b, and that b 0 = b andb\n\ng - b,\n=\n\n/b.\n\nand as p ) 1\nThus, as p\n\n(and h -* 0),\n0,\n\nthe optimal gain\n\ntends towards the deadbeat controller for the system in structural\nstate 1, and as p\n\n+\n\n1,\n\nthe optimal gain tends towards the deadbeat\n\ncontroller for the system in structural state 0.\n\n65\n\n\n76265AW027\n\n\ng\nIn(b)\n\nFigure 2.4 :\n\ng versus P, b.\n\nORIGINAL QUALRY?\nOF POOR PAGE IS\n\n66\n2.7.5\n\nConclusion.\n\nIn this Section, the steady-state properties of the non-switching\n\n\nsolution to a specific example of actuator failure were studied, and\n\nwere related to the Uncertainty Threshold Principle.\n\nIn particular,\n\n\nthe existence of an uncertainty threshold has been established, and\n\nwith the help of the high degree of symmetry in the example, the values\n\nfor\n\nIalthreshold\'\n\ngiven b and p, were calculated.\n\nIt was also shown\n\n\nthat the best control with infinite cost is a function only of a, b and\n\np, a situation analogous to the solution obtained in the papers on the\n\nUncertainty Threshold Principle (Athans et. al., 3 7 ].\n\nAn analogous solution to that presented here should exist for the\n\nswitching gain problem, and in fact, the rudiments of such a solution\n\nare given in Section 4.\n\nAs a guide for future research, it would be\n\n\ninteresting to compare the two methodologies on the basis of these\n\nsolutions.\n\nUnfortunately, it is mathematically intractable to extend\n\n\nthis result to the multivariable case, although another approach may\n\nbe found.\n\n\n2.8\n\nSummary.\n\nThe unifying issue in this research is the interrelationship\n\n\nbetween the issues of control and reliability.\n\nSection 7 brushes on\n\n\nthe question of when a system design is considered a reliable design.\n\nIn Chapter 3, a reliable design will be defined as one in which the\n\nsteady-state switching gain solution exists.\n\nTherefore, questions\n\n\nconcerning the existence of such solutions become quite important.\n\nUnfortunately, little headway has been made in the development of any\n\nsimple test for the existence of the steady-state solution.\n\nOnly in\n\n\n67\nSection 7, in the specific case of the non-switching gain solution,\n\nfor a specific (relatively trivial) example, and in Section 4 for the\n\nsame example with the optimal solution, have conditions for existence\n\nof a steady-state been resolved.\n\nIn Section 7, these conditions are\n\n\ngiven explicitly; in Section 4, they are given as the solution to two\n\nsimultaneous equations.\n\nFor the general n-dimensional problems in the\n\n\nremainder of this report, existence can only be tested by iteration of\n\nthe solution equations.\n\n\n68\n\nCHAPTER 3\n\n\nTHE SWITCHING GAIN SOLUTION\n\n\n3.1\n\nIntroduction.\n\nIn this Chapter, a control methodology for linear systems with\n\n\nquadratic cost criteria and variable actuator configurations will be\n\ndeveloped which accounts for the failure, repair and reconfiguration\n\nof the actuators by switching the control gain on detection of a\n\nchange in configuration.\n\nThis problem is viewed as a control problem\n\n\nrather than as the traditional estimation problem-\n\nTherefore, a\n\n\ndeterministic model is assumed, except for the random changes in\n\nconfiguration, which are modeled\n\nby a Markov chain.\n\nThis methodology\n\n\nhas the advantage that all gain and expected cost calculations are\n\ndone off-line. The gains switch on-line with changes in the configura\xc2\xad\ntion, which are observable with one-step delay for almost all values\n\nof u\n\n(i.e., except for a set of measure zero).\n\nIn addition, the\n\n\nmethod is useful in the stochastic case, though not optimal, in\n\nconjunction with identification methods such as hypothesis testing\n\nand dual identification, which will be described in Chapter 4.\n\nThe\n\n\ngain and expected cost calculations can be used as an evaluation\n\ntechnique in computer-aided design of linear systems.\n\nAn example\n\n\nwould be in trade-off studies of various redundancy configurations\n\nwith respect to performance, reliability, and system effectiveness.\n\nThe disadvantages of the technique as it is presented here are that it\n\nrequires perfect measurement of the state and that only multiple\n\n\n69\nactuator configurations are considered.\n\nThe multiple sensor configura\xc2\xad\n\ntion problem should be dual to this work.\n\nChanges in the A matrix\n\n\nare a minor extension; however, the general problem allowing variations\n\nin both the actuators and the observers would be a major result.\n\nPreviously, several authors have studied the optimal control of\n\nsystems with randomly varying structure.\n\nMost notable among these is\n\n\n[Wonham,22], where he develops a solution to the linear regulator\n\nproblem with randomly jumping parameters in continuous time.\n\nThe\n\n\nsolution assumes apriori that the controller has perfect information\n\nabout the present state of, the random parameter process.\n\nLittle work\n\n\nwas done on the steady-state existence problem.\n\nThe solution presented in this Chapter is analogous to that of\n\nWonham\'s; however, the discrete time formulation of the problem allows\n\nthe controller to observe exactly with one step delay the value of the\n\nMarkov parameter process.\n\nThus, it is shown that for the discrete\xc2\xad\n\ntime process, the optimal controller is not dual.\n\nIn addition to this conclusion, this research makes the connection,\n\nfor the first time, of control and system reliability and effectiveness.\n\nThis is the unifying concept in the entire report, and has been discuss\xc2\xad\ned in detail in Chapter 1.\n\nThe procedure for determining the existence of a steady-state\n\nsolution to the switching gain control problem divides system designs\n\ninto two classes:\n\nIf a design allows a steady-state solution, then\n\n\nthat solution is stabilizing (see Section 7, Chapter 5); therefore,\n\nthat design is classified as a reliable design.\n\nOn the other hand, if\n\n\n70\nno steady-state solution exists, then that design is classified as\n\ninherently unreliable.\n\nAlthough no easy test exists for the existence of a steady-state\n\nsolution, the computer can always be used to iterate equation (3.3.6)\n\nbackward in time and check for stability.\n\nTherefore, this methodology\n\n\nyields a classification of systems into those which are inherently\n\nreliable and those which are not.\n\n\n3.2\n\nMathematical Formulation.\n\nIn this Section, the n-dimensional extension to the one-dimension\xc2\xad\n\nal switching gain result presented in Chapter 2 will be developed.\n\nThe only non-trivial task is to prove that the system structure is\n\nobservable for almost all values of the control.\nxt+l\n\nA\n\n(t) ut\n\n+B\n\nThe system model is\n(3.2.1)\n\nwhere\nx\n-t\n\nE\n\nu\n-t\n\nER\n\nA\n\n(3.2.2)\n\nS R\n\nR7\n\n(3.2.3)\nnxn\n\n(3.2.4)\n\nand, for each k, an element of an indexing set I\nk e I = {0,1,2,\n\n..\n\n}\nT.\n\n(3.2.5)\n(3.2.6)\n\nB1k\nwhere\nBk S\n\n-k\n\nfB1.\nf -1\n\ni(3.2.7)\n1ST\n\nThe index k(t) is a random variable taking values in I which is\n\ngoverned by a Markov chain and\n\n\n71\n-t+1\nt\n\n--- t\npit\n\n=\n\n(3.2.8)\n\nt\n\nIr\n-t\n\n(3.2.9)\n\nwhere Ti,-t is the probability of k(t) = i, given no on-lineinformation\nabout k(t),, and 1Yo\n\nis the initial distribution over I.\n\nIt is assumed that the following sequence of events occurs at\neach time t:\n1)\n\nx\n\nis observed exactly\n\n2)\n\nthen B k(t-) switches to Bk(t)\n\n3)\n\nthen u t\n\nis applied.\n\nThe control interval is assumed to be\n\n{0,,2,\n\n..\n\nT}\n\n.\n\n(3.2.10)\n\nand the cost function is selected as\nJT\n\n(xt\'--t)\nT-I\n-\n\nt0\n\n-T\n\nT3.Rt\n\n\n2tQxt\n\n+\n\nTu\n\n+ \n XTQ\n\n(3.2.11)\n\nThe objective is to choose a.feedback control law, which may\ndepend on any past information about\n\nxt or u\n\nt\n\n, mapping x\n\nt\n\ninto ut\n\n)*\n\n:RP --\n\nRm\n\n(3.2.12)\n\n4t\n\n: x--\n\nUt\n\n(3.2.13)\n\n\n-t\n\n\nsuch that the expected value of the cost function JT\n\nfrom equation\n\n\n(3.2.11)\n\nJT\n\n= E [ JT\n\n-- 0]\n\nis minimized over all possible mappings 4tat\n\n(3.2.14)\nt\n\n72\n3-3\n\nThe Switching Gain Solution.\n\nNormally, a control law of the form (3.2.13) must provide both\n\na control and an estimation function in this type of problem;\nthe label dual control is used.\n\nHere, the structure of the problem\n\nallows the exact determination of k (t-l) from x t\nfor almost all values of u\n\nhence\n\n,\n\nxtl\n\nand ut-i\n\nThis result is stated and proved in\n\n-\n\nthe following theorem.\n\nTheorem 1:\n\nFor the set {B k} kEI\' where the B.\n\nset {x\n-k,t+l\n\n=\n\nAx\n+ B u\n---t\nkt\n\n\n}\n\n\nk=O\n\n\ns are distinct, the\n\nhas distinct members for almost all\n\nvalues of u\n\n-t\n\nProof:\n\nSee Appendix 3.1.\n\n\nIgnoring the set of controls of measure zero for which the\n\nmembers of\n\n{X,\n\nt}\n\n(3.3.1)\n\nare not distinct, then for (almost) any control which the optimal\nalgorithm selects, the resulting state x t+l\n\ncan be compared with the\n\nmembers of the set (3.3.1) for an exact match (of which there is only\n\none with probability 1),\n\nand k(t) is identified as the generator of\n\n\nthat matching member xk,t+l\n\nSince perfect identification is the best any algorithm can achieve,\nthe optimal control law u\n\n=\n\nt (xt) can be calculated with the\n\nassumption that k(t-l) is known, since this is the case with probability\none.\n\nThus, this solution will be labeled the switching gain solution,\n\n\nsince, for each time t, L+1 optimal solutions are calculated apriori,\n\nand one solution is chosen on-linefor each time t, based on the past\n\n\n73\nmeasurements x\n\n,\n\nand u\n\nxt_\n\n,\nt \n\n\nwhich yield perfect knowledge of\n\nk (t-l).\nDynamic programming will be used to derive the optimal switching\n\nAt each time t, the expected cost-to-go using the\n\n\ngain solution.\n\ncontrol sequence\n\nt\n\n,U\n\nt+\n\n, ut\n\n1\n\nUT-\n\n...\n\n(3.3.2)\n\nand given the value of k(t-l) is defined as\nV(x\n\nt\n\n,u\n\nSTQx\n-t--t\n+\n\n,t)\n\n,k(t-l)\n\nt\n\n+ u TRu\n-t--t\n\nEk(t){v*(xt+ ,k(t) ,t+l)\n\nk(t-l)}\n\n(3.3.3)\n\nwhere * denotes the optimum value and V* is the optimal value of V.\n\nThen, by dynamic programming\nV Cx ,k(t-l),t)\n= min\n(X t\nR~ =\nt\n\nTQxt + uTRu\nt\n-t\n\nt(xt)\n\n+ Ek (J{VCX\n\nIk(t),t+l)\n,~\n\nI k(t-.l)0\n\n(3.3.4)\n\n\nIt is proved, from Appendix 3.2, that\n\nV (xt\n\n,kt-l),t)\n\nwhere the Sk,t\n\n= xTSk\n\n(3.3.5)\n\nare determined by a set of L+l coupled Riccati-like\n\n\nequations (one for each possible configuration):\n\n\n~t= --\n\nPik S i, t+l\n\n-\n\n-tPk \n\n\n\xc2\xb1,\n\n-\n\nt+ 1 j\n\n*~~\n\nj\n\nt i\nAi\nt\n+>\xc2\xb1~\n+\n\n] ~ +Q\n\n,IT\n\nKkt~\n\n\n(3.3.6)\n\n74\nThe optimal control, given k(t-l) = k, is\n\n\n-k,t\n\n+\n\n= - [\n\ni\n\n1Tik i,t+l\n-\n\nT\nt\n\n(3.3.7)\n\n\nWriting\n\nRk,t\n\n=G k,tt\n\n(3.3.8)\n\nthen\n\nak,t= -\n\nik\n\n+\n\nS\n\nPik\nThus, u\n\nt\n\ni-i,t+l\n\ni\n\n(3.3.9)\n\n\nAi,t1\n\n(X ) is a switching gain linear control law which\n\n\ndepends on k(t-l).\nk(t-l) = i\n\nThe variable k(t-i)\n\niff\n\nx\n\n=Ax\n\n+\n\nis determined by\n\n(3-3.10)\n\nu\n\nNote that the S it\'s and the optimal gains G k,t\noff-line and stored.\n\ncan be computed\n\n\nThen, at each time t, the proper gain is seledted\n\n\non-line from k(t-l), using equation (3.3.10), as in Figure 3.1.\n\n\n3.4\n\nDiscussion of Results.\n\nThe solution in section 3 is quite complex relative to the struc\xc2\xad\n\nture of the usual linear quadratic solution.\n\nEach of the Riccati-like\n\n\nequations (3.3.6) involves the same complexity as the Riccati equation\n\nfor the linear quadratic solution.\n\nIn addition, there is the on-line\n\n\ncomplexity arising from the implementation of gain scheduling.\n\nIn\n\n\nChapter 5, a non-switching gain solution will be presented which has\n\nan identical on-line structure to that of the linear quadratic\n\n\n75\n\n76265AW028\n\nDoC\n)\n\n___\n\nit\n\nAL\n\nUnt\n\n\nGI\n\nFigure 3.1:\n\nThe switching gain control law.\n\n\n76\nsolution, but has similar off-line computational complexity to that of\n\nthe switching gain solution.\n\nDepending on the system requirements,\n\n\neither solution could be used; the non-switching gain solution is\n\nsuboptimal, but requires less on-line complexity.\n\nThis trade-off may\n\n\nfavor the non-switching solution in some cases.\n\nA steady-state solution to equation (3.3.6) may exist, .but the\n\nconditions for its existence are unknown.\n\nThe steady-state solution\n\n\nwould have the advantage that a time-invariant set of gains result.\n\nThus, only one set of gains need be stored on-line, instead\'of requir\xc2\xad\ning a set of gains to be stored for each time t.\n\nSince the steady\xc2\xad\n\nstate solution is simply the value to which equation\n\n(3.3.6) converges\n\n\nas it is iterated backward in time, at present, the equations can\n\nbe iterated numerically until either they converge or meet some test\n\nof non-convergence.\n\nUnlike the non-switching solution presented in\n\n\nChapter 5, the possibility of limit cycle solutions in the switching\n\ngain computations is excluded by the following lemma:\n\n\nLemma 1:\n\nIf the optimal expected cost-to-go at time t is bounded\n\n\nfor all t, then equation (3.3.6) converges.\n\nProof:\n\nSee Appendix 3.3.\n\n\nOnce again, it is stressed that the existence of a steady-state\n\nsolution to the switching gain problem establishes a division of\n\nsystem designs into those which are inherently reliable and those\n\nwhich are unreliable.\n\nEven though conditions to test for the exis\xc2\xad\n\ntence of the steady-state solution are unavailable,software can be\n\nused with iteration for the test.\n\n\n77\nIn Section 5, some numerical examples are given to illustrate\n\nthe switching gain solution.\n\n\n78\n3.5\n\nExamples.\n\nIn this Section, a two-dimensional example is presented with three\n\n\ndifferent switching gain solutions to illustrate\'the switching gain\n\ncomputational methodology.\n\nThe computer routines which are used in\n\n\nthe calculation of the switching gain solution are listed in the\n\nAppendix.\n\nThe primary subroutine is READY; it calls WEIGHT.\n\nAny other\n\n\nroutines which are used are from the standard ESL subroutine library.\n\nThe main program RDYMAIN is used to call READY.\n\nExample 3.1 is a two-dimensional system with four structural\n\nstates corresponding to the failure modes of two actuators.\nexample, failure of an actuator is modeled\nzero.\nII)\n\nThus, the fou5\n\nstructures are:\n\nOne actuator failed (B\n\n(B 3).\n\nI)\n\nIn this\n\n\nas an actuator gain of\n\nBoth\'actuators working (B 0);\n\n\nand B 2 ), and III) Both actuators failed\n\n\nThe system is controllable in all structures except for the\n\n\nsturcture represented by B\n\n3\n\n"\n\n\nActuator failures and repairs are assumed to be independent events\n\nwith probabilities of failure and repair, per unit time, of pf and pr\'\n\nrespectively, for both actuators.\n\nIn Example 3.1, the matrixes Q and R are the quadratic weighting\n\nmatrices for the state x\n-t\n\nand the control ut, respectively.\n\nThe\n\n\nmatrix P is the Markov transition matrix, which is calculated from knowl\xc2\xad\nedge of the system configuration dynamics, represented graphically\n\nin Figure 3.2.\n\n\n76265AW029\n\nP4P\n\n\n0\n\nP4 4\n\nFigure 3.2:\n\nMarkov transition probabilities for Example 3.1.\n\n\n79\n\n80\nThere are three Cases to Example 3.1.\n\nEach Case assumes a different\n\n\nfailure rate and repair rate for the actuators.\n\nCase i) has a high\n\n\nprobability of failure and a low probability of repair, relative to\n\nCases ii) and iii).\n\nThe switching gain solution is not convergent for\n\n\nCase i); the gains themselves converge, but the expected costs do not.\n\nOnly configuration state 0 is stabilized with its corresponding gain,\n\nG,\n\nCases ii) and iii) both assume more reliable actuators than does\n\nCase i).\nsolutions.\n\nBoth Cases ii) and iii) have convergent switching gain\n\nTherefore, both Cases iiy and iii) represent reliable\n\n\nconfiguration designs, while Case i) is unreliable.\n\nThis difference\n\n\nis due entirely to the different component reliabilities.\n\nEquivalently,\n\n\nCases ii) and iii) are stabilized by the switching gain solution, while\n\nCase i) is not.\n\nNote that in this Example, stabilizability is not\n\n\nequivalent to stability in each configuration state, or robustness.\n\nFor this example,-no robust gain exists because the system is\n\nuncontrollable from configuration state 3.\n\nCases ii) and iii) are also presented in Chapter 5, where their\n\nnon-switching gain solutions are given.\n\nAccording to the theory, it\n\n\nshould be more difficult to stabilize a given system with the non-switch\xc2\xad\ning gain than it is with the switching gain, because of the optimality\n\nof the switching gain solution.\n\nThis is demonstrated for this example;\n\n\nin Chapter 5, the non-switching gain solution to Case ii) is not\n\nconvergent.\n\n\n81\nExample 3.1:\n\n\nL\n\n2.71828\n\n10.0\n\n0.01\n\n\n.36788\n\nj\n\n[1.71828\n\nB2\n\n=\n\n1.71828]\n\n[-.63212\n\n.63212]\n\n0.0]\n\n1.71828\n\n13\n0.0\n\n-.63212\n\np\n\n0-0]\n0.0\n\n\nt]e10\n\n.\n\n2\n1-2p +p2\nNf\xc2\xb1f\n\n1.71828\n.63212\n\n\n0.0\n\n[1 ::]\n8.\n\n[0.0\n\n[o-o\n\nB10.0\n\n0.0\n\n2\n\n(1-p )pr\nf\n\n(l-Pf)pr\n\n1.0\n\n2\np2\n\n-\n\nPf (1-pf)2Prpf\n2\npf\n\nl-Pf-pr+PfPr Pr (1-Pr)\n\n2\n(l-P\n\nPf\n\n(l-Pr)\n\n1\n\n\nThe system dynamics are\n\nXEt+l\n\nn=xA=\n---- + B k (t) a t\n2 t\n\nk(t) S {0,1,2,31\nThe cost, which is to be minimized, is\n\njE[~ LT2~t +iua\n\nRut\n\nT\n\n[x l\n=L [Xx t ,t2,] ]\n\n\nExample 3.1, Case i)\npf = .3\n\n82\n.49\n.21\n\nTI\n\n.21\n\n7t2\n\n.09\n\nPr =7\n\nT0\n\nT3\n\nrT\n\nNon-Convergent; but gains converge:\n9636\n20=\n\n1-. 9\n134\n\n1.094 x 10-6\n\n-5.835 x 10-6]\n\n-9234\n\nGI=\n\n\xc2\xad6\n1.740 x 10\n\n[1-.8699\n\n-5.136 x lo0 6\n\n-. 8094\n\n.9186 x l0\n\n- 6\n\n2\n\n[-1.020\n\n-4.05\n\nx 10 -\n\n6\n\n-. 9636\n\n1_2=\n\n]\n\n.7353\n\nx 10 -\n\n6\n\n[-.9134\n\n]\n\n-3.923 x 10-6]\n\nStability:\nConfiguration\n\nStable\n\n)\n\nyes\n\n1 (B )\n\nno\n\n2\n\n(B\n\n)\n\nno\n\n3\n\n(B )\n\nno\n\n0 (B\n\n83\n\nExample 3.1, Case ii)\nPf = .I, Pr = .9\n\n.81\n\nIt\n0\n\n.09\n\niT\n1\n\n.09\n\n.01\n\n2\n113\n\nConvergent Coupled Riccati Equations:\n\n-\' s\n[:.1 :52\n1\n\n-890\n-.7752\n\n~\n\nn\n\n.04222\n\n]\n\n-.09914\nfor i\n\n[25.57\n\n8. 611]\n\n- 8.611\n\n6.398]\n\nStability:\nConfiguration\n\n)\n\n0 (B\n\nStable\nyes\n\n1 (B)\n\nno\n\n2 (B)\n\nno\n\n3 (B\n\n3\n\n)\n\n\xe2\x80\xa2no\n\n=\n\n0,1,2,3\n\n84\n\nExample 3.1, Case iii) \n\nPf\n.01, pr\n. 98\n\n.9799\n\n0\n\n.009999\n\n1\n\n.009999\n\ni2\n\n.0001020\n\nI3\n\nConvergent Coupled Riccati Equations:\n\n\xc2\xa3=\n\nI[-.7558\n-. 8073\n\n.1270\n\n1\n\n-. 17 8 6j\n\n15.88\n\nS8.10O5\n\n8.105]\n6.137]\n\n\xe2\x80\xa21=\n\n- "\n\n7060\n\n.1186\n\n,=\n\n-8441\n\n-1.72\n\nS =16.06\n18.074\n\nG375\nG\n\n8.0741\n6.143\n\n.1090]\n\n-.7543\n\n-.1669]\n\n16.31\n\n8.1991\n\n[ 8.199\n\n6.158_1\n\n85\n\n]\n\n[-7863\n\n[-.7926\n\n-\n\n-. 1 6 19 J\n\n[16.54\n\n3\n\n.1023\n\n8.170]\n\n[8.170\n\n6.162]\n\nStability:\nConfiguration\n\nStable\n\n0 (B )\n\nyes\n\n1 (B\n\n)\n\nno\n\n2 (B\n\n)\n\nno\n\n3 (B )\n\nno\n\n86\n3.6 \t Summary.\n\nIn this chapter, the optimal solution to the linear control\n\nproblem with variable actuator configuration was developed.\n\nIt was\n\n\nshown that the optimal solution uses a linear switching feedback gain\n\nwhich depends on the previous configuration.\n\nThis configuration is\n\n\ndirectly computable from the past measurements; this fact allows the\n\ndevelopment of the switching gain solution by eliminating dual con\xc2\xad\ntrol \t onsiderations.\nc\n\nThe exact measurement of the configuration with\n\n\none-step delay holds only for the deterministic case, where there is\n\nno corruption of the state or control observations by noise.\n\nIn Chapter 4, the use of the switching gain methods-will be\n\ndemonstrated for stochastic problems in conjunction with two different\n\nof\nforms \t identification:\n\nHypothesis testing and dual identification,\n\n\na technique for "pushing" the control variable out of the noisy\n\nregion, when the noise is amplitude limited, to obtain an exact\n\nidentification of the system structure.\n\n\n87\nCHAPTER 4\n\n\nEXTENSIONS TO THE STOCHASTIC CASE\n\n\n4.1\n\nIntroduction.\n\nIn Chapter 3, the optimal solution to the deterministic linear\n\n\nquadratic control problem with variable actuator configuration was\n\ndeveloped.\n\nIt was also demonstrated that the optimal solution of\n\n\nthe general stochastic linear quadratic problem is hopelessly complex\n\nin Chapter 2.\n\nTherefore, in this Chapter, extensions to the deter\xc2\xad\n\nministic solution to allow its operation in a stochastic environment\n\nwill be studied.\n\nFrom the derivation of the switching gain solution, whenever\n\nthe structure of the system is known perfectly with one step delay,\n\nand if it is assumed that it will be measured perfectly at the next\n\ntime instant, the optimal solution is the deterministic switching\n\ngain solution.\n\nIn designing a suboptimal control system, a method\n\n\nof identifying the system structure is used, with the assumption that\n\nthe identification is perfect, and the appropriate deterministic\n\ngain is selected.\n\nTwo conceptually different methods of structure identification\n\nwill be presented in this Chapter.\ntesting.\n\nThe first is classical hypothesis\n\n\nIt is the easiest to implement, although extensions to\n\n\nn-step hypothesis testing can be made which are very complex.\n\nThe\n\n\nsecond method is labeled dual identification; the expression is used\n\nbecause it takes advantage of the dual effect of the control law to\n\nguarantee perfect identification.\n\nIn this method, a perturbation\n\n\n88\n(which may or may not be that small) to the deterministic control is\n\nintroduced which separates the effect of amplitude limited white\n\ncontrol noise from -hat of the system structure.\n\nAs a worst case\n\n\ncontrol law, this perturbation would be applied at each time instant,\n\nbut in practice, it would only be applied once every n time instances\n\nso that its overall effect on system performance would be lessened.-\n\nIn the next Section, the system model will be described,and the\n\nhypothesis testing identification algorithm will be presented.\n\n\n4.2\n\nHypothesis Testing Identification.\n\nThe system model used here is the same as in Chapter 3, but with\n\n\nthe exception that additive white noise is introduced into the\n\ndynamics:\n\nxt+l\n\n= Ax\n\n+B\n+--Bk(t)\n\ntEt\n\n(4.2.1)\n\nFor the hypothesis testing identification method, Et\n\nis assumed to be\n\nzero mean white noise with probability distribution p(t).\nassumed to be uncorrelated with k(t) and x\n\n-\n\nIt is\n\nPerfect measurement of\n\nthe state is retained.\n\nThe basic hypothesis testing method is very simple:\n\nAt each time\n\n\nt, one of L+l hypotheses is chosen, where each hypothesis H. is\n\n1\n\nH. :\n1\n\n\nk(t-l)\n\n= i\n\n(4.2.2)\n\nWith each hypothesis H., there is a probability of H. being\n\n1\n1\ncorrect, given the measurement x\n\nand the past information\n\nthe probability distribution of k(t-l),\n\nIt\n(t-lit-l),\n\n\ngiven the measurements through\n\n\nThen the updated"probability (see Appendix 2)\n\ni(t-ilt),\n\nprobability of k(t-1) = i, given all measurements through\n\nthe\n\n\nt , is\n\n\n89\ngiven by\n\n~2t.Axx\n\'t)\n\nTi (t-l\n\nB\n\nt-i\n\nt\n\nt~\n3=0 P(Xt\n\n\'\n)lri t-lit- l )\n\nu\n- t-l\n\n- j\n\n-\n\n-lt-l\n\n(4.2.3)\n\n)\n\nj\n\nHypothesis H. is assumed to be correct if\n> 7rc(t-lilt)\n\nli(t-lIt)\n\nfor all\n\nTies are resolved arbitrarily.\n\nj 3 i\n\n(4.2.4)\n\nThen, given the correct hypothesis Hi,\n\nthe corresponding deterministic optimal switching gain is used to\ncompute the control at time t\nat\n\n=\n\n,t~t\n\n(4.2.5)\n\nas in equations (3.3.8) and (3.3.9).\nThe probability distribution is then propagated with the Markov\nchain equation\nTr(tlt) = Pu\n\n(t-llt)\n\n(4.2.6)\n\nand the process repeats.\nThis algorithm can work well if there are significant differences\nin the effect of the control variable between configurations.\n\n\'When\n\nthe differences are slight, a mistracking will result until the errors\nare large enough to be detected through equation (4.2.3).\n\nThe method\n\ndoes not exploit any of the dual effect of the control variable on\nthe measurement of the configuration.\n\nThe method presented next does\n\nuse the dual effect to identify the correct structure.\n\nAnalytically,\n\nit cannot be said which method is best, as the optimal control law\nwill lie somewhere between the two.\n\nIt is possible to extend the\n\nhypothesis testing procedure to n-step hypothesis testing where a\nhypothesis is made about the last n values of k(t) and is then tested.\n\n90\nsince this investigation is not within the primary scope of this\n\nIt is\n\n\nresearch, it is left as an open problem for future research.\n\nalso possible -that a combination Of hypothesis testing and dual identi\xc2\xad\nfication may be used to gain some of the advantages of both methods;\n\ndual identification yields fast identification of the correct structure;\n\nwhile hypothesis testing does not sacrifice control of the system\n\nwhile there is a high probability that the structure is correctly\n\nidentified.\n\n\n4.3\n\nDual Identification.\n\nThe underlying concept of dual identification is to periodically\n\n\nchange the control in order to increase the accuracy of identification\n\nof the structure.\n\nIn the limiting case, the control is changed\n\n\nenough to guarantee perfect identification of the current structure\n\nwith the next observation.\nis considered.\n\nThe system model is\n\n\n=At+lt +\nwhere\n\nt\n\nFor this case only amplitude limited noise\n\n\nk(t) !t\n\n+\n\n(4.3.1)\n\nMit\n\nis Z-dimensional white noise which takes on values in the\n\nunit sphere with distribution p(g) and is uncorrelated with x\nk(t).\n\nM is an n xZ matrix which defines the ellipsoid in R\n\nand\n\nwhich\n\n\ncontains ME t\'\n\nNormally, if no identification were to be performed, and if k(t-l)\n\nwere known, the optimal deterministic switching gain Gk(t-l),t\n\nfrom\n\n\nequation (3.3.9) would be used to compute u*\n\n-t\n=0 x\n(4.3.2)\n\nn t =\nfk(t-l),t t\ng\ni\no\nm\na\ni\nIn dual identification, the goal is to compute a gain offset u \'\n\n\n91\nsuch that when the control\n\n-t\nU\n\nut\n\n+U l,t\n\n(4.3.3)\n\nis applied to the system, identification of the structure k(t) with\nthe observation x\nfor a given B\nBk\n\nand M.\nxt+I\n\nis guaranteed.\n\nwill be in a bounded convex set determined by\n\nxt+1\n\n,\n\nTo accomplish this, note that,\n\nThus,\n-Ax\n\n= B ku\n\n+ M\n\nt\n\n(4.3.4)\n\nt\n\nand Et can be any element in the unit sphere S(R\n\n.\n\nTherefore,\n\n\nperfect identification of k(t) is guaranteed if no two of the domains\n\nof xt+1\n\ncorresponding of the Bk s have a non-empty open intersection.\n\n\nThat is, the following condition must be satisfied for each pair of\n\nBk. \'s\n\nand every E-1\n\n(BkI\n\n- Bk2 )ut\n\nand _--2\n\nM(\n\n+\n\n-\n\nof S(R):\n\n\nI\n\n--\n\n)\n\n0\n\n(4.3.5)\n\nThis condition is the same as\n\n\nIM*k - ik2 ) 1 >2\n(B\nif\n\n(Bkl - Bk2 )u t\n\nF N(M)\n\notherwise,\n\n\n(B 1\n_k\nwhere M#\nof M.\n\n)\n- Bk2 )ut\n\n(4.3.6)\n\n0\n\nis the generalized inverse of M and N(M) is the nullspace\n\n\nNote that the inequality of (4.3.6) can be relaxed to equality,\n\n\nsince the intersection of the two domains of xt+1\n\nwould only be at\n\n\nthe point of tangency, a set of measure zero in either domain.\n\nThe objective is to choose ul\' t\nfor all pairs B\n\nand B\n\nsuch that (4.3.6) is satisfied\n\n\nin the reachable subset of all actuator\n\n\n92\nThe reachable subset refers to the subset of configu\xc2\xad\n\nconfigurations.\nrations B .\n\nwhich have a non-zero probability of occurance at time t,\n\ngiven-thatthe configuration was Bk(t-l)\n\nat t-l.\n\nThis is\n\nthe same as\n\nthe \t\ncondition that\n\nis in the reachable subset from B k\'t-\n\nB \t.\n\nif\n\nPik(t-l)\n\n>\n\nI .\n\n0\n\n(4.3.7)\n\nSuppose that there are J configurations in the reachable subset from\n\nfor which\n\nBk(t-l) .\n Then there are J(J+l)/2 pairs of configurations\ncondition (4.3.6) must be satisfied.\n\nAlso, since u.,\n\nstate xt+ 1 , it is reasonable to minimize its effect.\n\nt\n\naffects the\n\nTherefore,\n\n\nsince the effect of ulIt\n\nis modified by Bk(t) , it is reasonable to\n\nminimize the norm of ulIt\n\n.\n\nThus, the minimization problem is formu\xc2\xad\n\nlated subject to the constraints (4.3.6).\n\nminjf 1\n\n--l,t\n\n\n2\n\n,I \t\n\nsubject to\n\n\n4\n\nk f-~kut+\n\n-\n\n_l\'t]l\n\n2\n\n(4.3.8)\n\n<0 \t\n\nwhere\n\nM# (B\n\nD=\n\n(4.3.9)\n\n-B.) \t\n\ni\n\nFormulating this as a nonlinear programming problem, the\n\nHamiltonian is\n\n\nl,t\n\nH( _l\'t,\n\np2\n\n+\n\nXk(4-\n\nRk[\n\nu\nt+\n\nl,t]\n\n(4.3.10)\n\nXk>0\nk = 0\n\nif\n\nu\nfunction of -t\n\n2\n\n\n+u\n4-jjD k Jut+ ul,t]\n\nDifferentiating H with respect to\nand the parameter\n\n2\n\n<0\n\n.,and solving for ul\'t\n\nA,\n\n(4.3.11)\nas a\n\n93\n3H\n\nau\n\n2\n\nT\n\n2 k\n\nD\nk-k\n\n2u \t\n\n0\n\xc2\xad\n\n2l\'t\n\n*\n\n[ut +\n\nl\n\n]\n\n(4.3.12)\n\nk\n\n\nor,\n\nrr..,A \t\nI\n[-\n\n-lit u\n\njD\nk-k\n\nk\n\nAD\nE~!D\nk\n\nU*(.13\n\nDk k\n\nt\t\n\n(4.3.13)\n\nNow, using (4.3.13) in the constraint equation (4.3.11)\n\n11Rk (-I +\n\n-\n\nZ\'kDkDk\nk\t\n\n-\' Zk\n\nk\n\nk-\n\nlkt\n\xc2\xad\n\nl\n\n0\n(4.3.14)\n\n\nNoting that\n(I - X[\n\n+\n\nthen (4.3.14) simplifies to\n- II\n- -\n\nA T D I\n-1\n\n(I\n\nT\nDTD]-ID T D\n\n]\n\nt\n\nIi\n\n<\n\n(4.3.15)\n\n0\n\n(4.3.16)\n\nk\nand if (4.3.16) is a strict inequality, then\n\nAk\n\na numerical algorithm must be used to solve for\n\n=\n\n0.\n\nIn general,\n\nA in the set of\n\n\nequations (4.3.16); this can be a major drawback to the application\n\nof this methodology if the on-line computer resources are unavailable.\n\nAlthough the computational burden of this technique is a disadvantage,\n\ndual identification would most likely be implemented in combination\n\nwith a hypothesis testing algorithm.\n\nDual identification would then\n\n\nform a test to be performed on the system after some interval of time\n\nto ensure that the hypothesis testing algorithm correctly tracked the\n\nconfiguration.\n\n\n94\n4.4\n\nExamples.\n\nIn this Section, the one-dimensional example of Chapter 2, Section 2\n\n\nis implemented with additive white noise applied to the contro\n\ninput.\n\n\nThree suboptimal control algorithms derived from this Chapter are imple\xc2\xad\nmented:\n\nHypothesis testing, dual identification, and hypothesis\n\n\ntesting in combination with dual identification, which is utilized every\n\nfifth time instant.\n\nThe purpose of this example is to illustrate the\n\n\ndegrading effect of the dual identification algorithm on the system\n\nstate.\n\nThe principle subroutine used to generate the computer simulations\n\nof Example 4.1 is SWITCH; it is listed in the Appendix.\n\nSWITCH calls\n\n\nFIG and UCALC, also in the Appendix; any other routines which are used\n\nare in the ESL subroutine library.\n\nThe system in Example 4.1 has two structures, represented by the\nmatrices B\n\n(b = 2.)\n\nand B 1\n\n(1/b = .5); the Markov transition probabili\xc2\xad\n\nties are given by the matrix P.\n\nThe switching gain solution was calcu\xc2\xad\n\nlated using the software described in Chapter 3, Section 5.\n\nCase i)\n\nof the Example corresponds to the hypothesis testing methodology described\nin Section 2.\n\nThe additive white noise was amplitude-limited with zero\n\nmean and variance E = 1.\n\nCase ii) of the example demonstrates the perfor\xc2\xad\n\nmance degradation due to the exclusive use of dual identification.\n\nNote\n\n\nthat the variation among the values of the state and control are larger\n\nthan in Case i).\n\nThe advantage of dual identification is that, for\n\n\namplitude-limited white noise, perfect identification of the system\n\nstructure with one-step delay is guaranteed.\n\nIn Case iii), hypothesis\n\n\ntesting is used four-fifths of the time to partially avoid the degradation\n\n\n95\ndue to dual identification.\n\nThe control is more effective in Case iii)\n\n\nthdn in Case ii); however, for this example, it is not clear that the\n\nuse of dual identification one-fifth of the time is warranted, since a\n\nperformance degradation of Case iii) over Case i) is still evident in\n\nthis particular simulation.\n\nMore simulation would have to be carried\n\n\nout before the proper ratio of the use of hypothesis testing to the\n\nuse of dual identification could be determined.\n\n\n96\nExample 4.1:\n\nA = 1.414\n\nB0 = 2.000\n\nB1 = .5000\n\n\n\xc2\xa3\n\nR = 1.000\n\n\n= 3.000\n\nP [.7\n=\ni]\nSwitching Gain Deterministic Solution:\n\nGo \n= -.7569\n\nG1 \n= -1.008\n\nThe system dynamics are\n\nxt+ 1 = Ax t + Bk(t)ut\n\nk(t)\n\n{0,k\nt\n\n\nThe cost function which was minimized is\n\n\nJ\n\nQxt\n\nE\n\n=\n\n+ Rut\n\n_\n\nwhere\n\n[1\n\n=\n\n1\n\nT\n\nStructural transitions are of\' the form\n\n.3\n\nB\n\n0\n\n*\n\n.3\n\nB\n\n1\n\nWhen dual identification was employed, the control was set to\n\nut\n\n=\n\nl.25(sign (t))\n\nThis control was the minimum value required to establish perfect\n\nidentification.\n\n\n97\n\n76265AW033\n\niHypothesis Testing\n\na.\n\n,.\n\n* I*\n\nI\n\n\xc2\xad\n\nI\n\n*\n\nr.\n\n..\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n.\n\nV\xe2\x80\xa2\n\nOC\xe2\x80\xa2 \xe2\x80\xa2\n\nL\n\ne\xe2\x80\xa2\xe2\x80\xa2O\n\xe2\x80\xa2\n\n*tO.\n\n.\n\nCC.\n\nSimaulation rnpocan of sto t\n\nI\nN I\n\n-\n\n=\n\n\nLI I\n\nL-,OFPOR\n\nI~s \'n\n\nUAAT\nCotolu\n\nI~\n\n76265AWW2\n\n98\n\nii) Duai Identification\n\nt\'a\n\ni~\n\n*\n\nI-\n\n*\n\n.\n\n*\n\no\n\n*\n\n.\n\n\xc2\xb0\n\n.\n\n*\n\n* *S\n\n.\n\nrcc\n\nN\n\nS.\n\n=\n\n\n,..\n\n*\n\n*\n\nc* *\n\nOCntr\n\n*\n\ntc\n\nn-\n\n.\n\nJ\n\nc* *\n\nul|etfC C.ol\n-,\n\nro* **\n\ntl!,tr\n\nc.\no\n\nr .c\n\n**\n\n7\n\n99\n\n6265AW031\n\ni Hypothesis testing and Dual Identification\nii)\n\n0\n\nORIGINAL PAGE IS\n01? POOR QUALITY\n\n.\n\na\n\n-:\n\nt\n\n7\n\n*sH\n\n,\n\nH\n\n.H\n\n*~..I~ts~~s\n\n-\n\nH\n\nH\n\n*-\n\nN\n\n*\n\n.-\xc2\xb0\n\n.\n\n..\n\n.\n\n. .\n\no,\n\nC\n\no .\nC\n\nCfl\n\n.\n\n.C\n\nC\xc2\xb0\n\nC .Cr\n\nSimdlotion response of state xt\n\nI\n\nS*\n\n--\n\n" I\n\n-I\n0\n\nII\n\nCI\n\nC H\n\n*\n\ni\n\nControl ut Msing dual identification\n\n\n0-Dual identification Is applied at this tim\n\n100\n4.5 \t Summary.\n\n\'In this Chapter, two methods have been proposed to extend the\n\n-deterministic optima-i switching gain solution of Chapter 3 to the\n\nstochastic case.\n\nThe two methods represent the two fundamental\n\n\nconcepts of identification:\n\nEstimation and dual control.\n\nThe\n\n\noptimal stochastic control law, if it could be computed, would rely\n\non both concepts, using estimation when the control variable is\n\nlarge (and the state is far from the origin) and dual control to\n\nenhance estimation when the control and state variables are small.\n\nIn the dual identification technique presented here, control is\n\nsacrificed to obtain an exact observation of the structure.\n\nThus,\n\n\nthe system response would be roughly periodic, with the state being\n\ndriven away from the origin in order to obtain an accurate estimate\n\nof the configuration, and decaying back toward zero between identifi\xc2\xad\ncations.\n\nIn the period when the control is not modified, hypothesis\n\n\ntesting would be used to track the configuration.\n\n\n101\nCHAPTER 5\n\n\nTHE NON-SWITCHING GAIN SOLUTION\n\n\n5.1\n\nIntroduction\n\n*In the previous two ch&pters, the switching gain solution was\n\n\ndeveloped and studied.\n\nIn this chapter, attention will be focused\n\n\non obtaining a constant, robust, or non-switching gain which solves\n\na variable actuator configuration linear quadratic control problem,\n\nwith minimumost for this class,of solutions.\n\n\'It must be stressed\n\n\nthat this is a suboptimal solution; for the deterministic case,\n\nChapter 3 gives the optimal solution.\n\nThe interest in this chapter\n\n\nlies in determining a sequence of-gains, for a linear control law,\n\nwhich do not switch in response to the detection of a change in system\n\n-structure. For instance, it may be desirable to ensure the stability\n\nof a control system -under certain types of failure without creating\n\nthe complexity necessary-to detect those failures and compensate for\n\nthem, as is done in the switching gain solution.\n\nThis class of solutions is related to the overall robustness\n\nproblem where fault-tolerant control systems are desired.\n\nAlthough\n\n\nnot formulated in this manner, the research described in this Chapter,\n\nas in Chapter 3, is readily extendable to system with variable system\n\nmatrices as well; i.e., where the-system can be represented as a set\n\nof possible structures\n\n,\n\n) over some suitable index, even though\n\n\nthis class of problems is not as directly related to the underlying\n\n\n102\nreliability theme of this report.\n\nNon-switching gain solutions to the variable actuator configura\xc2\xad\ntion class of problems -an be obtained in-di-fferent mathematical ways.\n\nProblem A of Section 3 is reformulated as a deterministic control\n\nproblem (Problem AE), and is solved using the necessary conditions of\n\nthe Matrix Minimum Principle [Athans,41] in Section 5.\n\nUnfortunately\n\n\nthis approach, although yielding the necessary conditions for an opti\xc2\xad\nmum, does not allow an-analytic solution.\n\nTherefore, in Section 6,\n\n\na second problem (Problem B) is formulated and solved using dynamic\n\nprogramming.\n\nSection 7 is by far the most detailed and one of the most impor\xc2\xad\ntant sections of the report, along with Sections 8 ahd 9.\n\nIn Section\n\n\n7, the concepts of stability and cost-stability are defined and are\n\nused to prove an equivalence between the infinite-time versions of\n\nProblems AE and B.\n\nIn Subsection 7.6, the steady-state solutions for\n\n\nboth problems are defined.\n\nUnfortunately, nothing in the mathematics\n\n\nappears to rule out the possibility of limit cycles in the infinite\xc2\xad\ntime solution; this is discussed in Subsection 7.7.\n\nWhen the constant\n\n\nsteady-state solutions to the two problems exist, it is proved in\n\nSection 8 that they are identical.\n\nThis is a very important result, as\n\n\nit allows the steaey-state solution of a complex two-point boundary\n\nvalue problem which is much more tractable.\n\nIn Section 9, it is demonstrated that the general robustness problem\n\nfor linear systems\n\n(where one wishes to determine a single stabilizing\n\n\n103\n\ngain for a set of linear systems) is solved in this framework for the\n\nclass of systems with variable actuator configurations.\n\nExamples of\n\n\nboth the non-switching solution to Problem B and the robustness\n\nresult are given in Section 10, and a chapter .summary in Section Li.\n\n\n5.2\n\nProblem Statement.\n\nThe objective of the research described in this Chapter is to\n\n\nform a methodology which will be used to compute apriori a gain G\n\n(either time-varying or steady-state) which minimizes the expectation\n\nof the quadratic performance index over a set of linear systems with\n\nactuator variation and known transition probabilities of structural\n\nchange\n\n(Problem A).\n\nThe necessary conditions for minimization are\n\n\ngiven which this optimal gain must satisfy; it is shown that these\n\nconditions result in a\n\ncomplex two-point boundary value problem.\n\n\nA second optimization problem is formulated which is based on\n\nthe restriction to non-learning control laws which are precomputed;\n\ni.e.,\n\nit is assumed that the control law cannot benefit from knowledge\n\n\nof its past.\n\nAlthough this formulation appears to be much weaker\n\n\nthan that of Problem A, it is shown in Theorem 2 that if steady-state\n\nsolutions to the two problems exist, then the steady-state solution\n\nto Problem A is stabilizing (in the sense that the mean square value\n\nof the trajectory is exponentially bounded) if and only if the steady\xc2\xad\nstate solution to Problem B yields a system which is exponentially\n\nstable.\n\nThis result is very significant, in that a Corollary to this\n\n\n104\n\nTheorem solves the problem of finding a robust gain for a set of linear\n\nsystems and yields an explicit procedure for its calculation.\n\nThe last Theorem CTheorem 3-) of the Chapter proves that the steady\xc2\xad\nstate solutions to the two optimization problems are identical.\n\nThis\n\n\nimplies that not only does the procedure mentioned above determine\n\na\n\n\nrobust gain if and only if such a gain exists, but also that the steady\xc2\xad\nstate gain is optimal with respect to the specified quadratic cost\n\ncriterion.\n\n\n5.3 \t Problem A.\n\nConsider the system\n\nt\n\nxt+l\n\n+\n\n(5.3.1)\n\n_k(t) ! t \t\n\nwhere\n\nx\n-t\n\nE \tR\n\n(5.3.2)\n\nER\n\n(5.3.3)\n\nk(t) E I ={ 0,1,2,\'\'\',L}\nI is\n\nan indexing set for the possible actuator structures\n\n(5.3.4)\n\n{JB2kEI\n\nwhere\n\nnxmn\n\nR x\n\n-B\n\n(5.3.5)\n\nis\nk(t) \t a random variable with sufficient statistics given by the\n\nMarkov transition probabilities p.j, where the matrix\n\np\n\n=\n\n(Pij)\n\n(5.3.6)\n\n\nis a stochastic matrix, and the initial probability distribution is\n\n\n.\n\n-0\n\n(5.3.7)\n\n105\n\nSince k(t) is assumed to be a Markov chain, the probability vector\n\n-t\n\nis propagated in time by\n\n=\n\nlt+l\n\nP!_\n\n(5.3.8)\n\nt\n\nwhere there is no real-time observation with which to update\nConsider the structure space {B k } k6I indexed by I.\n\nDefine the\n\nstructural trajectory 3E T to be a sequence of element k(t) in I which\nselect a specific structure Bk(t) at time t,\nT\n\n=\n\n(5.3.9)\n\n(k(0), k(l),..., k(T-l))\n\nThe structural trajectory XT is a random variable with probability of\noccurance generated from the Markov equation (5.3.8).\n\nP(xT\n\n)\n\nT-1\n= 1\nt=0\n\n(5.3.10)\n\nIk(t),t\n\nwhere the control interval is\n\n{0,1,2 ,...\n\nT-l,T}\n\n(5.3.11)\n\nfor the finite time problem with terminal time T.\n\nThen for a given\n\nT-1\nstate and control trajectory (x t ,ut t= 0 generated by (5.3.1) and x\nT-I\n\nfrom a sequence of controls (u )\n-t t=0\n\n,\n\nT\n\n\nthe cost index is to be the\n\nstandard quadratic cost criterion\n\nT\n\nT\n\n-t\n\n-t\n\nTt-=\n\nT-I x\nxQx\n_~tkx\n\n+ uRu\n\xc2\xb1 uT\n\n+ x\n_\n\nQX\n\n(5.3.12)\n\n-T\n\nThe admissible controls are restricted to be of the linear feedback form\nut=\n\n*\n\ni,e,\n\nGtx\n\nf0\n\n=\n\n(5.3.13)\n\nt\n\n(1 0 ... 0) or (0 1 0...0) or ...\n\n(0 0...0 1).\n\n106\nwhere the gain matrix G t\n\nis restricted to be a function only of time\n\n\nand the initial conditions; i.e., it cannot depend on x t\n\nThe objective\n\n\nis to minimize over the set-of admissible controls the expectation of\n\n(5.3.12), where the expectation is taken over the set of possible\n\nstructural trajectories\n\n\nu\n\nx T E:\n\n(5.3.14)\n\nT\nand \t\nthe set of initial conditions x0\n\n\nThus, the optimal control law u\n\nshould minimize the\n\n= -txt\n\ncost\n\nJT\n\nE[) \tHi-F\n\nT\nQx + u TRu + x\n\nE[\n\nTQ xTI T \t\n\n(5.3.15)\n\nover \the set of admissible controls.\n\nt\nSince the structure of -t\nu\n\xe2\x80\xa2\n\n=\n\n-\xc2\xad\n\ntxt is fixed, the problem is equiva\xc2\xad\n\nlent to minimizing, in an open-loop sense, the cost function\n\nEElfir0]\n\n=\n\nE\n\n[ttQ\n\nt\n\n+\n\nt\n\n_GGtt. XQXT\n\n%0]\n(5.3.16)\n\n\nwith respect to the gain matrix Gt , t=0,l,...,T-l.\n\nEquation (5.3.16)\n\nis simply obtained by substituting equation (5.3.13) into equation\n(5.3.14).\n\n\n5.4 \t The Method of Solution.\n\nThe matrix minimum principle [Athans,41] will be used to determine\n\n*\n\nthe \t ecessary conditions for the existence of u t\nn\n\n(or equivalently,\n\n\nt ) "\t To solve the problem using the matrix minimum principle, the\n\n\n107\nformulation presented in the last section must be converted into an\n\nequivalent deterministic problem.\nstate x\n\n0\n\nstructure.\n\nKo\n\nFor this purpose, let the initial\n\n\nbe a zero mean random variable which is independent of any\n\nLet\n\n\nE[XoXTLf 0 ]\n\nE[Xoxo\n\n=\n\n(5.4.1)\n\n]\n\nbe the convariance matrix of x\n\n-0\nas\n\nDefining the covariance of x\n-t\nE[xt x- I-0]\nt\n\n(5.4.2)\n\nthen, by direct calculation, we obtain\n\nT\n\nL\n\nL\n\nit 2 0\n\ni t -=0\n\nt-\n\n0\n\nt-2 t-3\n\nt-2\n\nG\n3\n\n(A+B.\nj=0\n\n0\n\nT\n\nt-2\n\nt-1\n\nac\n\n)\n\nI0\n\n(A+B . G)\nIj\n\nLj=O\n\n\'-J \n\n\n(5.4.3)\nI\n\nSimilarly, if we define\n\nZ.\n\nE[x\n\n=\n\n(5.4.4)\n\nxT k(t-1) =i10\n\nthen, we deduce that\n\n\n1r3\n\n\nt\n\n-\n\n[tE\n__=0\n\nAB.\n\n. G.j.)\n\nj=0\n\n.\n\n(A+BiGt\n\nT\n\n(5.4.5)\n\n108\ncan be defined recursively as\n\nThe matrix E-iSt\n,t+l\n\nP\n\nit\n\n(A+Bat )\n\n,\n\n(A+B\n\nGT\n\n(5.4.6)\n\nfor t > 1.\n\n= (A+B a\n\n--jS l\n\n)S0 (A+Bj G 0\n\n(5.4.7)\n\n)T\n\nand the relation\n\n-i,t\n\n, t\n\n> 0\n\n(5.4.8)\n\nis. obvious from direct calculation.\n\n\nRemark 1:\n\nAt this stage, an equivalent deterministic problem (Problem AE)\n\nwill be defined with state (\n\n-\xc2\xb14\n\n)\nfor t>O and state E\ni=0\n-0\n\nThe system dynamics are then defined by equations\n\nfor t\n\nand matrix control G\nover (G\n-t\n\nJT\n\n=\n,\n\n=\n\n0.\n\n(5.4.6) and (5.4.7).\n\nDefinition (Problem AE): \n For the system with matrix state\nfor t>0 and -0\nZ\n\nat t\n\n(Z-It) L\n\n-it i=0\n\n0 with dynamical equations (5.4.6) and (5.4.7)\n\nminimize the equivalent deterministic cost\n\nT-l\n-\n\nt=0\n\nT\n\n\n-\n\nx\'x 0\n\n=\n\nX\n-- ----\n\n\n\n\nST\n\nt+\nxTG\n\nR~2\n\n\nQx\n\n\nT-1\n-trE\n\n-t\n\n(\n\n+ C\n\n-t--t\n\nRC\n\n+\n\ntrEE QJ\n-T\xc2\xad\n\n(5.4.9)\n\n109\n\nNote that since the expectation in equation (5.3.13) is over all\n\nstructural trajectories x and the initial x 0\nJT\nT\n\n=\n\nalso,\n\n\nJ(5.4.10)\n\nT\n\n\nThe symbol JT will be used exclusively in the future.\n\nThe one-stage,\n\n\nor instantaneous, cost at time t is\n\nJt\n\n=\n\ntr[t (Q\n\n+\n\n\nG\n\n(5.4.11).\nTL=0\n0\n\nRG t\n\nProblem AE is completely deterministic in the state (i,t\n\n)\n\n\nand control Gt\n\nAt this point, the minimization will be decomposed into two parts\n\nusing the Principle of Optimality [Athans and Falb, 21].\n\nT-11, and for this the matrix\n\n\nminimization is over the interval {1,2,....\nminimum principle will be used.\nin general on the choice of G0\n\nThe first\n\n\nThe resulting solution will depend\n\nand on the initial conditions 20\n\nand\n\n\n7T\n\n0 \'\n\nLet V (G0 be the optimal cost resulting from the use of G0\n)\ni ,\n\nthe optimal sequence\n\nG\nThe second minimization is then over -0\nJ\n\n=\n\ntr[E\n\n0\n\n(Q\n\n+\n\nG T RG\n\nfor the interval {l,2,... ,TI.\n\n\n. G-\n\n2\n\n)]\n\n+\n\nand\n\n\nof the cost\n\n\nV (G\n\nO)\n\n(5.4.12)\n\nThe Principle of Optimality states that these two minimizations\n\n*T-I.\n\n\nresult in the minimizing sequence (G )T-1 for Problem AE.\n\nt t=0\n\n\n110\nFrom [Athans,41], the lamiltonian for the minimization over\n\n{1,2,...,T-l} is\n\nH(\n\n(Ei,)L i=0\n,t\n\n(S\n-j,t+l\n\n\'\n\nG\n-t\n\nL\n\nj=O\n\nL\n\ntr\n\n6\n\nAi~\n\nirt\n\n(Q+ Gt\n\np\npr\n\n( 7-\n\n+ \t tr \n\n\nitit \n\n\nt\n\n\n(A+BG t a\n1_l\n\n\nfor t 6 {1,2,3,...,T-lI\nwhere the costate matrix is (S\n-j,t+l\nRemark:\n\nt (A+B\n\nGt\n\n)T\nj t+l\n\n\n(5.4.13)\n\nL\n\nj=O\n\n\nWe have now formulated Problem AE-I, which minimizes the accumu\xc2\xad\n\nlated cost over the interval {l,2,... ,T} with respect to the sequence\n\nT-i\n\n(Gt)\nusing the matrix minimum principle and results in the optimum\ncost, given G\n\n,\no \n\n\nV (G\n\nProblem AE-2 is then the minimization of\n\n).\n\nequation (5.4.12) over G\n\nO\n\n.\n\n\n5.5\n\nThe Necessary Conditions.\n\nThe matrix minimum principle yields necessary conditions which\n\n\nan optimum must satisfy.\n\nThere are two conditions of importance.\n\n\n(The third condition yields equation (5.4.6)).\n\nFrom the necessary condition for the costate,\n\n\n*\n\n(5.5.1)\n\nt\n\nS l\n\n-i,t\n\nI\n\nthe propogation of S.\n\nS.lt\n\nbackward in time is derived.\n\n\nt_\n\nPji\n\n+ _\n\nT\n\nQ +\n\nt\n\nRG\n\nt\n\n+\n\nj,t+A\n\n+A\n\nTS\n\n- t--\n\nA~sjt+IB--j Gt\nB\n\nj,t+l--j-t\n\n+GTBTS\nt -t-j\n\n,t+l-- ]}.(5.5.2)\n\nI1\nT-l\n\n\nThis equation is well-defined for any sequence {G t\n\nand t >0.\n\n\nThe cost V of using this arbitrary sequence over the interval\n\n{l,2,...,TI\n\nV(\n\nis given by\n\n)\n\n(Gt\n\n=\n\ntr\n\n[\n\nil,l]\n\n(5.5.3)\n\nThe total cost over the interval {O,l,... ,T} using this sequence is\n\n\ntr\n\nJT\n\n-\n\nS\n-il\n\nt\n\ntr\n\ni= 0\n\n(A+B\n\n\n\nEi\n,\n\nG\n1__\n\n+\n\ntr[(Q + G\n\n0\n\n)z0 (A+BiG0)Tsi,\n.\n.\n.\n.\n\nRG0\n\n-o\n\n+\n\n(5.5.4)\n\n-0\n\n+\n\nGoRG\n.0-- \xc2\xad\n(5.5.5)\n\n\n= tr\n\n+ G TRG\n\n+\n\n(A+Bi_\n\nT_\n\n(A+Bfi.0\n\n]\n\n(5.5.6)\n\n112\nDefine\n\ns\n\n(A+B+B0 )GSi\n\no\n\nl(A+i\n\n30)+\n\nQ + \t GT RG_\n\n(5.5.7)\n\n-0--a\n(5.5.6) and (5.5.7)\n\nThen from equations\nJT\n\n=\n\n]\n\nS\n\ntr[0\n\n(5.5.8)\nT-I\n\nThus, the cost of a given sequence ( G\ntr[S- S\n0\n\n=\n\nJT\n\n(Go\n\n0\n\n\'GI\n\n..\n\n)T-1\n\nt-tt=0\n\nGT-1)\n\nof length T is\n\n]\n\n(5.5.9)\n\nFor future reference, define the matrix S.\ni-,t by\n\nI\n\nASi\'t\n\n-it \n\n\n7T.\n\nit\xc2\xad\n\n(5.5.10)\n\n1\n\nand note that equation (5.5.2) becomes\n\n\nTRG\n\nSG\n\n+\n\nj=0\n\nPi[ATsj,t+IA + GT B TS\n\nA S\nB\nBt+ _ t +C\nB.~jS j\nA]\n+ATSi+GT\n13T\n--- j,t+l-!\n-t-3\n-j 4 t+l-j-t\n\ntB\n\n(5.5.11)\n\nFrom the Hamiltonian minimization necessary condition\n=\n\n-t\n\n(5.5.12)\n\n0\n\n*\n\nthe following relation between Z\n\n=\n\n+\n\nt\n\n7\n\nS \t\ni\'t ,t~l\n\nand G\nis obtained.\n\n-t\n\n\nit_1 hit\n\n1]3 \t\n\n+J\n\nT\n\nA\n\n]i,t\n\n(5.5.13)\n\n113\nRemark:\n\nAt this point, a two-point boundary value problem has been\n\n\ndefined with the constraint (5.5.13) relating equations (5.5.2) and\n\n(5.4.6).\n\nEquation (5.5.13) is not explicitly solvable for G-t\n\n\nbecause -i,t\n cannot be factored out of the sum over j; thus, it cannot\n\nE .\nbe used as a substitution rule in the other two equations.\ntime, the solution for Gt\n\nappears intractable.\n\nAt this\n\nThus, although necessary\n\nconditions for the existence of GC , the minimizing gain, have been\n--t\n\nestablished, they do not readily allow for the solution of\ncertainly do not admit a closed-form expression.\n\n\nand\n\n\n114\n5.6\n\nProblem B:\n\nThe Non-Switching Solution.\n\n\nAlthough the methodology presented in Section 4 yields the\n\nnecessary conditions for an optimum, these conditions are not analyti\xc2\xad\ncally illuminating.\nis formulated.\nAthans,40].\n\nIn this section, a second optimization problem\n\n\nAn equivalent formulation was presented in [Birdwell &\n\n\nThe solution will admit a closed form\n\nexpression for u\n\n"\n\n\nAlthough this solution is not the optimal ,solution for the first\n\nproblem, in that this solution does not necessarily satisfy the neces\xc2\xad\nsary conditions for problem AE,\n\nit will be proved that the two solu\xc2\xad\n\ntions are equivalent in the sense that for the steady-state solutions,\n\nas defined in Section 7, either both solutions stabilize the system,\n\nor neither one stabilizes the system.\n\nEVen better, it will be proved\n\n\nthat the steady-state solutions to the problems are identical.\n\nFor the system (5.3.1), the objective is to minimize at each time\n\nt the weighted sum, with respect to It\ngiven the control u\n\n= it\n\n(x\n\nt\n\n)\n\nof the expected costs-to-go,\n\n,\n\nand u\n\n= -\n\n(x\n\n) for T>t, and given\n\nthat the structure at time t-i was k(t-l) = i, for each i.\nFormally, let C be the expected cost-to-go, given xt\n\n,\n\n!I\n\n,\n\nand\n\nk(t-1) at time t be defined as\nC(x\n-t\n\n,\n\nit\'\n\nk(t-l),\n\n-t\n\nt)\n\nA xT\n\n=\n\nEk(t)\n\nt\n\n+\n-t-\n\nt\n\n= arg min\n\n-t\n\n[C (x t+\n\nwhere * denotes the optimum value, and -t\nu\nt = arg min\n(Tt-1 ,C(t)>\nLt\n\nTR u +\n,k(t)\'t+l)l\n\nk(t-l)]\n\n(5.6.1)\n\nis computed as\n(5.6.2)\n\n(x t)\nT\n\n7t\n\nC(t)\n\n(5.6.3)\n\n115\nand\n\n*\n\n*\n\no (x\n\n= C(x\n\n,k(t-1),t)\n\nt\n\n,u\n\nt\n\n,k(t-1),t)\n\nt\n\n(5.6.4)\n\nwhere\n\n\n[c(x\nC(t)\n\nt\n\n,u\n\nt\n\n,k(t-1)=Ot)\n\n,u\n\nt\n\n=t(5.6.5)\n\n\nC(x\n\n,k(t-l)=L,t)\n\nand\n\nT\n\nC(T)\n\nC*(T)\n\n=\n\n=\n\n(5.6.6)\nT"\n\nThus, the problem is\n\n\n7i\n\nmin\nuEt[\n\nt\n\n(x\n\n+\n\nt\n\nE[C*(x-t+ l\n\ni.\nT\n\nu t =it\n\nZPjiC*(Ax\n\nt\n\nFrom the formulation, u\n\nXTQ\n\n+ Bj u\n\nt\n\nt\n\nThen for t\n\n,k(t-1),t)\n-t\n\n+\n\n(5.6.7)\nRU\n\nj,t+l)]\n\n(5.6.8)\n\nis non-learning in that it depends only on\n\n\nfor its knowledge of the past.\nC*(x\n\nuTRu\n\nI-iTQt\n\n=\n\n(x t)\n\n+\n\n+\n\nk(t),t+l)Ik(t-l)=il]\n\nmin\n\nE-t-1\n\nT Qx t\n\nt)\n\n=\n\nT\n\nXtS\nx\n-t--k,t-Xt\n\nLet C* be of the form\n\n(5.6.9)\n\n=T,\n\n\nI\n\nSk, T\n\n=Q\n\n(5.6.10)\n\n116\nAnd equation (5.6.8) becomes\n\n\t\nT\n\nmin\n\ntQ\t _\n\n7it_l\n\nutRujt\n\nu-t\n\n\ntPj(Axt\n\n+\n\n+ Bju\n\nTS\n\nt\n\n(Ax\n\nt\n\n+ Bju\n\n(5.6.11)\n\nAt the minimum, differentiating (5.6.11) with respect to u\n\n,\n\nwe\n\nobtain\n\n\n0\n\n7rRT \t\nt-l[----t\n\n+\n\nBB u\nj li\nu\n\npji(Bjj,t+E\n\nBs\n\n+Bj-j,t+1-x\n\nt\n\nAx\n\n(5.5.12)\n\nSolving for u\n\nt\n\n\nut=\n-\n\n+\t\n\nt\n\nR\nBisit+iliJ\n\nj-\n\nF\n.Sj,t+\nJtJJit\n\nAX\n\nt\n\nt\n\n(5.6.13)\n\nand hence the gain matrix is given by\n\n\n*\n\na\n\nG1\nk + i\n\n=\n\nt\n\nA\n\nj\n\njlt+l\n\n!j\n\njjt+la\n\n(5.6.14)\n\nwhere -tu = G tx\n\nt\n\nFrom (5.6.11) and (5.6.4),\n\nT \'\t\nXt-k,t-t\n\n+\n\n0\n\nT [\nxt\n\nPjk(A+B jG\n---\n\n*T\n+tR\n\nt \t )T\n\nt\n\n\n- t~\n\n(A+BjGt jfx\t\nt\ni --\n\n(5.6.15)\n\nt\n\nor, since (5.6.15) holds for all -t\n\nx\n\nI+\n\nSk\n\n*T\n=\n\nQ+\n\n*\n\ntRG\n\nt\n\nS\nTS*T \t\n\n+A\nPjk\n\n,t+lA + A \t\n\n-j,t+\n+G*BS\n-tG -R\n\nT\n\n+ G\n\nS\nT*A \t\n\njt\n\nA\n\n-t-j-j,t+l\xc2\xad\n,\n\n-jt+l -J\n\n.G\n-t\n\n)\n\n(5.6.16)\n\n117\nThus, (5.6.16) proves by induction that equation (5.6.9) is valid.\n\nNote that equations (5.6.16) and (5.5.11) are identical.\n\n*\n\nTherefore, the unconditional cost of Gt\n\n,\n\nt=0,l,...,T-l, is, from\n\n(5.5.9)\n\nJ\n\n=\n\ntr[0 S0 (G0 \'\n\n....\n"\n\n)\t\n\n(5.6.17)\n\n)x \t\n\n(5.6.18)\n\nT-1\n\n,1\n\nwhich in this case is simply\n\n\t\nJ\n\n=\n\nT\n\nTS\n\n-\n\n0\n\n-o- Gl\n\n(G\n\n,G\n\n...\n\n-o\n\n\nT-l\n\n*\n\n\nThe matrices -t\n are called the non-switching, or non-learning gains,\n\nG\n*\n\nand will hereafter be denoted G\n.\n-nst \t\nthe solution to equation (5.5.13).\n\nThe label Gt will be reserved for\n\xc2\xad\n\nThe optimal value of the cost-to-go\n\n\nat time t=0 for this problem will be called the non-switching cost index,\nand is given by\nT\nJ\nlirS\n\nns T\n\ni---\n\n+ x T (Q + G\n\nx\n\n-\n\n-ons0\n\n1-\n\nCRG\n\n--\n\n(5.6.19)\n\nns 0 )-0\n\nTT\n-x\n\nT\n-0\n\nI. (A+B .G\n0\n1_\n- -ns\n\n?\n\nZ\n\n+ \tQ+\n\nNote that if G ns\n0\n\n- ns\n\n--\n\n(A+B. 1+ins\nG\n\nX0 \n\n\nRG\n\nG\n\n= \xc2\xadt\n\nT s.\ni,l\n\n0\n\n0\n\n(5.6.20)\n\n\nns\n\n0\n\n\nfor all time (i.e., if the solutions to the\n\noptimal control gain problem and to the non-switching control problem\n\n\n]\n\nare the same, then E [n\nT\n\n=\n\nJT\n\n118\nsummary:\n\nIn this Section, the non-switching, or non-learning, gains\n\n\nhave been derived.\n\nThese gains are called non-switching or non-learning\n\n\nbecause they do not depend on the past trajectory of x t and ut , but\n\nonly on the initial probability vector over I,\n\n70"\n\nIt was further\n\n\nshown that if the solutions to Problems AE and B were identical, then\n\nNx 0 1J nsTT\n =\nE\nJ\n\nT(5.6.21)\n\n119\n5.7 \t Stability and the Steady-State Solutions.\n\nIn this Section, the concept of stability for this class of\n\nFrom this, a natural concept of a\n\n\nsystems will be precisely defined.\n\nsteady-state solution to Problems AE and B will be given, and a very\n\nstrong result relating the solutions to the two problems will be\n\nproved.\n\n\nStability and Cost-Stability.\n\n\n5.7.1\n\nFor this class of systems, two definitions of stability will be\n\ntendered.\n\nThe first is the usual definition of mean-square stability;\n\n\nthe second definition, that of cost-stability, has a strohg relation to\n\nthe existence of solutions to the infinite time versions of Problems AE\n\nand B.\n\n\nDefinition 1:\n\nG is a constant stabilizing gain if and\n\n(Stability).\n\nonly if the resulting system given by equation (5.3.1) and repeated here\nxt+l\n\n=Ax\n\nis mean-square stable:\nP\nT\n0\nE[x x ]\n\n-t -t\nDefinition 2:\n\n(5.3.1)\n\n+ Bk(t) ut\n\nas\n\nt\n\n(Cost-Stability).\n\n.\t\n\n(5.7.1)\n\nThe system (5.3.1) is cost-stable,\n\n\nif and only if the scalar random variable\n\nTx \t\n\n+ uTRu\n\nt=0\n\nwith probability one.\n\n\t\n\n<\n\n(5.7.2)\n\n120\n5.7.2 \t Definition of the Infinite-Time Cost.\n\nIn this research, the infinite-time problem is defined as a\n\nminimization of\n\n\nJ\n\n=\n\nli \tT\nT"K\n\n(5.7.3)\n\nwhere JT is the cost function for the corresponding finite-time problem.\nThe sequences which solve these infinite-time versions of Problems AE\nand B are (Gt )=\nand (G\n)wO\n,\nrespectively, when a solution exists.\n-ns tt=0\n\n_t t=_0\nA solution will exist if there exists a sequence of gains for which the\n\nlimit in equation (5.7.3) exists.\n\nThis definition of the infinite-time\n\n\nproblem is chosen rather than the definition requiring a minimization\n\nof the average cost per unit time\n\nJl\n\n=\n\n1\n\n1JT\nT\n\n\nlim\nTO\n\n(5.7.4)\n\n\nbecause there is a direct correlation between the boundedness of JT\n\nover all T for a constant sequence of gains G and mean square stability\n\nof the system (5.3.1).\n\nIt is necessary, however, to prove that the\n\n\nset of problems for which JT is bounded for some sequence of gains is\n\nnot vacuous.\n\nThis fact is demonstrated by any of the convergent non\xc2\xad\n\nswitching gain examples in Section 10.\n\nAs further demonstration of the validity of using equation (5.7.3),\n\nnote that if 0 < Jl < -, then the cost per unit time has a non-zero\n\nsteady-state value, which implies that the system (5.3.1) is not mean\xc2\xad\nsquare stable since\n=\n\nwhereZss\n\ntr[s\n\nss\n\nand Gss\n\n(Q\n\n+\n\nG TRGs)J\nss--ss\n\n-\n\n(5.7.5)\n\nare the steady-state values of E t and Gt , when\n\nthey exist, and, since Q + G T RG\n-\t\n\n-ss--ss\n\nis positive definite, E\n\n-ss\n\n5 0.\n\n121\n5.7.3\n\nBounded Cost and Mean-Square Stability.\n\nIn choosing equation (5.7.3) as the basis for the definition of an\n\n\ninfinite-time problem, a major requirement was that the existence of\n\nan infinite-time solution, namely of a sequence of gains which yields a\n\nfinite cost in equation (5.7.3), imply mean-square stability.\n\nFor\n\n\nthe case where the sequence is constant, the following result is\n\nproved.\n\n\nTheorem 1:\n\nA constant sequence of gains (G)\n\nis mean-square stabiliz\xc2\xad\n\ning if and only if there exists a bound B < - such that\n\nJT < B\nProof:\n\nRemark:\n\nfor all T\n\n(5.7.6)\n\n\nSee Appendix 5.1.\n\n\nFor a sequence (Gt)t=0\n\ntt-0\n\nJ\n\n<B<cVT implies\n\nt.\n\n(Gt)\n-t t=o\n\nis\n\nmean-square stabilizing, but (G )t= mean-square stabilizing does not\nimply JT is bounded for all T.\n\nProof:\n\n5.7.4\n\nSee Appendix 5.2.\n\n\nCost-Stability.\n\nAs yet, the definition of cost-stability has not been utilized.\n\n\nIn this Subsection, it will be shown that the system described by\n\nequation (5.3.1) is cost-stabilized by a sequence of gains (G )w\nif and\n\n-t t=o\nonly if J is finite-valued for this sequence.\n\nOne direction of this\n\nresult is proved in the following theorem.\n\n\nTheorem 2:\n\nAny sequence (Gt\n)t=\n\nwith probability 1.\n\nProof:\n\nSee Appendix 5.3.\n\n\nfor which J< w cost-stabilizes (5.3.1)\n\n\n122\nThe other direction of this result is obvious:\n\nIf a sequence\n\n\n(Gt)t=0 is cost-stabilizing with probability one, then the random cost,\n\ngiven by equation\n\n(5.7.2), is finite except on a set of structural\n\n\ntrajectories of measure zero.\n\n(The appropriate measure on this set is\n\n\ngiven in the proof to Theorem 2.)\n\nSince the expected cost J is the\n\n\nintegral of equation (5.7.2) with respect to the probability measure\n\non the set of structural trajectories (see Appendix 5.3),\n\nthen J is\n\n\nfinite.\n\nThus, the cost-stability and the existence of an infinite-time\n\nsolution are equivalent.\n\n\n5.7.5\n\nEquivalence of Problems AE and B.\n\nThe first major result of this Chapter will now be stated.\n\nThis\n\n\nresult establishes a strong equivalence between the solutions to\n\nProblems AE and B.\n\n\nTheorem 3:\n\nA cost-stabilizing solution (Gns) t=\n,t\nthere exists a cost-stabilizing solution (Gt)\n-t t=0\n\nall i and\nProof :\n\nRemark 1:\n\nexists if and only if\n,\n\nassuming\n\nI.>\n\na.\n\n0 for\n\n0>0.\nSee Appendix 5.4.\n\nThis result provides a computationally feasible methodo\xc2\xad\n\nlogy for arriving at a sequence of gains (Gnst)t=\n\nwhich cost-stabilize\n\nthe original system (5.3.1) with probability 1, whenever such a se\xc2\xad\nquence exists.\n\nThe coupled matrix equations of Problem B (5.6.16) can\n\nbe iterated backward in time.\nergodic distribution\n\ni\n\nIf the weighted sum with respect to the\n\nconverges, then the resulting sequence of gains\n\ncost-stabilizes the system (5.3.1) with probability one.\n\n\n123\n5.7.6\n\nThe Steady-State Solution.\n\nA steady-state solution to optimization Problems AE and B can\n\n\nexist only if there exists a steady-state probability distribution\n\nit\n\n\nover the set of possible configurations indexed by I such that\n\nT= P I\n\n(5.7.7)\n\n\nand\n\n=\n\nlim 7t\n\nF\n\n(5.7.8)\n\nFrom equation (5.7.7), it is apparent that for\n\nit\n\nto exist, the matrix\n\n\nP must have an eigenvalue at 1, and it must be in the subspace spanned\n\nby the eigenvectors of P corresponding to that eigenvalue.\n\nThe fol\xc2\xad\n\nlowing lemma states precisely when t exists.\n\n\nLemma 1:\n\n7F exists if and only if one of the following three conditions\n\nis satisfied for each diagonal element\n\na. of the Jordan normal form A\n\nof P, where\nP\n\n=\n\nT A T\n\n0\n\n(5.7.9)\n\n0\n\na1\n\n51\n\n0\n\na2\n\nA =.i\n\n=\n\n0.\n\nL\n\nLL\n\nFor each i,\n\n\n0 or 1\n\n(5.7.10)\n\n124\n\ni)\n\naj1 <i\n\n\nii)\n\na.\n\n=\n\nI\t\nj 1i ai\n1,\n\niiX)\nProof:\n\n1\n\n1,\n\n-\n\n(T\n\n7r0)\n\n=0\n\nObvious.\n\n5.7.6.1 \tSteady-State Solution to Problem AE.\n\nNote that for Problem AE, initially, the gains G\nwill depend on Z,\n\no\n\n, G,\n\n\nand near the final time, the gains ... G\n\nwill depend on a time-varying SI.\n\nam\n\n-T-1\n\nThus, the steady-state solution for\n\nProblem AE is defined as the limiting solution to equations\n\n(5.4.6)\n\n(5.5.2) and (5.5.13) at time t, first as T +* and then as tc,\n\nlimit exist.\n\n,\n\n-T-2\n\nO\n\nThe steady-state values for B, S\n\ni\n\n, and E.\n\n,\n\nif this\n\nwhen\n\nthey exist, satisfy the following equations:\n13\ng\n\nPj\n\n-J~\n\nS.\n\nA\n\nR\n\npji\n\n(A+B.G )_ -. (A+B.G)T--\t\n_\n-i\n\n---\n\n- 3\n\n+ GTRG+A\n\n=.\n\n(5. 7\'. 11)\n\nS.A +\n\nB.S.B.G + A s..\n\n\n~~T \nT\n\n+ GB3SjA \t\n\nO=RG\n\n(5.7.12)\n\n\n[B.S.GB+.S.BS.G \t\n\nA\n(5.7.13)\n\n\nwhich are the limit of equations (5.4.6),(5.5.2), and (5.5.13), given\n\nthat the limiting solution E,\n-j\'t\n\nequations (5.7.7) and (5.7.8).\n\nand G\n-t\n\n\nexist, where Tr satisfies\n\n\nThe cost of this steady-state solution\n\n\nis\n\n\nJ \t = lim J\nT_)\nas in equation (5.7.3).\n\n(5.7.14)\n\n125\n\n5.7.6.2\n\nSteady-State Solution to Problem B.\n\n\nThe solution to Problem B depends on its past only through the\n\nprobability distribution lr(t) over the structure index set I.\n\nTherefore, to develop the steady-state solution, let the initial pro\xc2\xad\nequal the steady-state value 7 from equations\n\n\nbability distribution 7\n\nThen the steady-state solution can be defined as\n\n\n(5.7.7) and (5.7.8).\n\nthe limit, when it exist, of the gain G\n-ns\n .calculated for the problem\n\nending at time T, and of the solutions to the coupled Riccati-like\n\nequations (5.6.16), S\n\n\'\n\nas the final time approaches infinite.\n\nLet\n\n\nI\n\nS 0\n\n-ns\n (T) and S i(T)be the solutions at time zero for Problem B with\n\nfinal time T.\n\nThen\n\n(5.7.15)\n\n\nlim -ns 0\n (T)\nG\nG\n-ns \t= T\n0\n\nT\nS.=lim Si,0\n.T\n\n(T) , iEI\n\nwhen the limits exist.\n\n(5.7.16)\n\nThe steady-state solution is said to exist\n\n\nwhenever the limits of equation (5.7.16) exist.\nand -.\n\nS .\n\nthen G ms\n-G\n-ns \t\n\nmust satisfy, from equations (5.6.14) and (5.6.16).\n\n+\n\n--\n\nIf these limits exist,\n\n\n.B\nS.B.]l\n-3 -3 -3 --\n\nZ\n\n.BT -3 A \t\n3-3 S. -\n\n(5.7.17)\n\nTT\n\n\nS=Q+GT\n\nk\n\nRG\n\n-ns - -ns\n\n\n-\n\n( T\n.. .\n\n+\t\n\nT\n\nT\'\n\n\n-ns B.,S.B.G ns ) \t\n- --\n\n+ G\n\nT\'\n\nT\nT\'\nG\nA S.B.G\n- - -I\n-ns + -ns B.S..A\n\n(5.7.18)\n\nThe cost of this steady-state solution, given x, is, when the limit\n\nexists\n\n\nT\nJns\n\n5.7.7\n\nT+ Jn sT =x$\nlim\n\nT\n\n,\n\n126\n\n1=\n\n-1l\xc2\xad\n7.S. x\n\n(5.7.19)\n\n\nThe Possibility of Limit Cycles.\n\nThe discussions in the last Section do not rule out the possibi\xc2\xad\n\nlity of limit cycles in an infinite-time solution.\n\nIn Problem B,\n\n\nthe expected cost is directly computable from a set of coupled Riccati\xc2\xad\nIf\xc2\xad\n\nlike equations (5.6.16), as is the-non-switching gain (5.6.14).\nthese coupled matrix equations converge whenever the solution is\n\n\nbounded, then the non-switching gain is always directly computable when\n\nit exists.\n\nBoundedness implies convergence of the expected cost\n\n\n(Lemma 2); however, the possibility of the existence of a limit cycle\n\nin the solution to equation (5.6.16) is not ruled out.\n\nIt is con\xc2\xad\n\njectured, but not proved, that such a limit cycle cannot exist.\n\n\nLemma 2:\n\nIf the expected cost JT for Problem A is bounded, then it\n\nconverges.\n\n\nProof:\n\nSee Appendix 5.5.\n\n]\n\n\nSince Ex[Jn\nT\n\n=\n\nJT, Jns\n\nalso converges.\nT\n\n127\n5.8\n\nEquality of -ns\n\nG\n\nand G\n\n\nIn this Section it will be shown that when a steady-state G-ns and\n\nG\n\nexist, with finite cost J\nand J\n-ns\n\n\nthe gains are equal.\n\n,\n\nThis\n\nresult is extremely important in that it yields a method of calculating\n\nthe steady-state solution to a two-point boundary value problem as the\n\nlimiting solution to an equivalent (in the steady-state) single boundary\n\nvalue problem. It is taken as a working hypothesis in this Section that\n\nboth problems have a steady-state solution and that the ergodic distribu\xc2\xad\ntions of ffand Z.\n\n,\n\nfor all i, exist.\n\nThen the steady-state cost of the\n\noptimal problem is\n\nJ\n\n=\n\n(Q + GRG\n\ntr[_\n\n)]\n\n0\n\n+\n\ntr[ZiS\n\ni\n\n)\n\n(5.8.1)\n\nFor any constant gain G for which the limits exist, the value would\n\nbe\n\n\nJss(G)\n\n=\n\ntr[Z\n\ntr[\n\n=\n\n0\n\n0\n\n(Q + GT RG)]\n\n(2 + G T RG)]\n\n+\n\nZ\n\n+\n\nZ\n\ntr[Ei\n\ntr[l(A+BiG)S\n\n0\n\n(G)S\n\ni\n\n(G)]\n\n(5.8.2)\n\ncA+BiG)Tsi (G)]\n(5.8.3)\n\ntr [\n\n{\n\n+ GTRG\n\n+\n\n(A+B.G)T.\n\n(5.8.4)\n\n(G)(A+BiG)}]\n\nSimilarly, equation (5.8.1) becomes\n\n\nJss\n\n=\n\ntr\n\nZ\n\nGo\n\nGo\n\n+\n\n(A+BG\n\n(A_+Bi\n\n)S\n\n0\n\n(5.8.5)\n\nFor the non-switching, or non-learning problem, the steady-state cost\n\nfor any G for which the Si\n\nt\n\n\nconverge is, given x\n\n0\n\n,\n\n\n128\n\nJ nss(G)\n\n=\n\nXT Q+\n\nGTRG)x\n\n0\n\n+ E [V\n\nx\n\nS\n\n(G)X]\n\n(5.8.6)\n\nT (Q +-GT R-G)-x\n0\n0\n+T\n\n=0\n\n0\n\n__:\n\nr. (A.G)TS\nI.\n\nG AB(5.8.7)\n\n(C (A+B i)x0\n\nG3\n\n.\n\nTaking expectations with respect to x\n\nE J(C)]\nE Js\n\n=\n\n- I\n\n+\n\ntr[E\n\ntr[E-0 (\n(A+B\n\n0\n\n+ GTRG)]\n)T\n\n-(A+B\n\n(5.8.8)\n\nor,\n\nEj\n\nJ\n\n(G)] =J\n\n(5.8.9)\n\n(G)\n\nThus, the costs are equivalent for any G for which the equations\n\nconverge.\n\n\nBy Lemma 3, if the non-switching expected cost is bounded for a single\n\nG, then the equations converge; i.e., there can be no limit cycle.\n\n\nLemma 3:\n\nFor a given gain G,\n\nthen it converges.\nProof:\n\nif the expected cost JT (G) is bounded\n\n\n-\n\nSee Appendix 5.6.\n\n\nThus, either equation (5.8.9) holds, or both costs are infinite. There\xc2\xad\nfore, if the cost is finite for any single G,\nwhich minimizes both costs.\nG\n(T) - G\nnst\nGopt\nTheorem 4.\n\n\nas T\n\n.\n\nthen there exists a Gopt\n\n\nFurthermore, given that -nst\n(T) converges,\n\nG\nThis result with an extension is stated in\n\n129\nTheorem 4:\n\n,t\n\nAssume the values -t\nG\n\nconverge.\n-nst (T)\nG\n\n-opt\'\nGo\n\nB)\n\nG\n-ns\n\n,\n\nand G\n\nG\n--\n\nas T\n\n+\n\nS\n\n(T), and\n\n\nwhere Gns\n\n% which minimizes equation (5.8.9).\nis the steady-state value of -ns\n\nG\n\nis the steady-state value of C\nlim\nt+ \n\n\nProof:\n\n(T), -i,tit\n\nS\n(T),\n\nt\n\n\nThen\n\nA)\n\n=\n\n(T), G\n~-ns\n\nlim -t\xc2\xad\nG\nI\n\n\n(T)\n\n=\n\n(T),\n\nt\n\n\n(T):\n\n\nG\n\n(5.8.10)\n\nSee Appendix 5.7.\n\n\nDiscussion:\n\nThe result of Theorem 4 B) gives a direct computational\n\n*\n\nprocedure for calculating the,optimal steady-state gain G\nlimiting gain -ns\nG\n\n.\n\nas the\n\nThere are, however, still some open questions\n\n\nconcerning the existence of limit cycles in the calculation of -ns\n\nG\n\nTheorem 3, however, guarantees cost-stability using (Gnst) t=\ncost-stabilizing sequence of gains exists.\n\nif\n\na\n\n130\n5.9\n\nRobustness.\n\nThe original problem (Problem A) can be formulated in such a way\n\n\nthat the sequence (Gnst) t=\n\nwill cost-stabilize a set of linear systems\n\n\nwith different actuator structures individually whenever such a stabiliz\xc2\xad\ning or robust gain exists.\n\n\nA gain G is robust if\n\nDefinition 3:\n(\n\n(At+lB kc)t\nA +\nis stable for all k.\n\n(5.9.1)\n\nThis is the same as requiring the matrix (A+BkG)\n\n\nto have eigenvalues inside the unit circle for all k.\n\n\nCorollary 1:\n2tx l\n\nFor the set of L+l systems\n=tAx\n\nuBkt\n\n+\n\n(5.9.2)\n\nwith\nP=\n\nI\n\n7T\n\n(5.9.3)\n(5.9.4)\n\nL+I\n\n\nif a robust gain exists, then (G\nns t\n\n)\nis a stabilizing sequence for\n\nt=0\n\n\n(5.9.1) for each k, and if the gains -ns\nG\n\nt\n\n(T) converge, then -ns\n is a\n\nG\n\nrobust gain.\nProof:\n\nFor the expected cost to be finite, for any G ,\n\nG must be\n\nrobust, since each structure is equally likely and no structural changes\ncan occur.\n\nTherefore, if a robust\n\nG exists, then certainly (Gt)t=0\n\nwill be stabilizing, and by Theorem 3, so will (Gs\n)\n-ns t t0*\nG\n-ns\n\n(T) converges as T\n\n+\n\nAlso, if\n\n, the G ns\n will be robust since it will have\n--\n\n131\nfinite cost J(G\n-ns\n ), which implies stability, in this case, for all\n\n\nk E I.\nQ.E.D.\n\n\nDiscussion:\n\nWith Corollary 1, a specific existence problem for robust\n\n\nlinear gains is solved.\n\nExistence of a robust gain is made equivalent\n\n\nto the existence of a finite cost infinite-time solution to Problem B,\n\nwhich is readily computable from equations (5.6.14) and (5.6.16).\n\n\n132\n\n5.10\n\nExamples.\n\nIn this section, two examples are presented to illustrate the\n\n\nnon-switching gain computational methodology.\n\nExample 5.1 is ana\xc2\xad\n\nlogous to Example 3.1 of Chapter 3; it demonstrates the effect of\n\ncomponent reliability on system stabilizability with a non-switch\xc2\xad\ning gain control law-\n\nThe first case of Example 5.1 is not conver\xc2\xad\n\ngent;.the second case is convergent.\n\nThe only difference between\n\n\nthe two cases is the reliability of the actuators.\n\nCase i) corresponds\n\n\nto Case ii) of Example 3.1; Case ii) corresponds to Case iii) of\n\nExample 3.1.\n\nNeither case results in a robust control law, but ro\xc2\xad\n\nbustness is not possible because the system is uncontrollable in\n\nstructural state 3.\n\nAs an aside, it is interesting that the "optimal"\n\n\nnon-switching gain in Case i) ignores state x 2 ; the system is decoupled\n\nin that there is no interaction between x1 and x 2 .\n\nSince state x 2\n\n\nhas stable dynamics, and the dynamics of state x I are unstable, the\n\nentire control effect is concentrated on state xI\n\n.\n\n\nThe computer routines which are used in the calculation of the\n\nnon-switching gain solution are listed in the Appendix.\nsubroutine is AIM; it calls WEIGHT.\n\nThe primary\n\n\nAny other routines which are\n\n\nused are from the standard ESL subroutine library.\n\n\n133\nExample 5.1:\n\nA\n\n[2.71828\n\nA=\n\n0.0\n.36788]\n\n\n0.0\n\nS\n\n[1.71828\n-.63212\n\n[0.0\n0.0\n\n1.71828.63212\n\n71828\n1..63212\n\n]3\n\n-[1.718280.1\n\nR =\n01\n\n0.1\n-\xc2\xad\n2\n-2f\npf\n\n1.0\n2\nPr\n\nr\n\n(-pf )P(1-f\n\n2(- pP\n\nPr\n\nPrP\n\nlPf-Pr+PfPr\nfr\n\nPfPf\n\n(Pr(1-P)\n\nPp\n\n2=PfPf\n\nf\n\nPrf\n\n2\nPf\n\n2\n1_2pr+p2\n\n(lPr)pf\n\n(lpr)pf\n\nThe system is\nXt+l\n\ntx\n\n+ Bk(t) ut\n\nAxt\n=\n\nk(t) E {0,1,2,3}\nThe cost to be minimized is\n\n\nJ\n\n=\n\nE\n\ng\n[t=0\n\ntQx\n\nt\n\n-+\n\xc2\xad\n\n[x\n\nt\n\nx2,t]T\n\n134\n\n134\nExample 5.1, Case i)\nPf\n\nPr\n\n.81\n\nTr\n1\n\n.09\n\nr2"\n\n.01\n\n=9\n\n0\n\n.09\n\n=\n\nr\nr3\n\nNon-Convergent; but gain converges at\n\n=\n\n[-1.246\n\n0.0]\n\n1.039\n\nG\n\n0.0\n\n\nStability:\n\n\nConfiguration\n\no(B 0\n\nStable\n\n\nno\n\n1 (B\n\n)\n\nyes\n\n2 (B\n\n)\n\nyes\n\n3 (B 3\nInterpretation:\n\nno\n\nThe coupled Riccati equations are unbounded.\n\nNote\n\n\nthat since state x 2 has stable dynamics, the convergent non-switching\n\ngain -ns\n concentrates on stabilizing x1 , which is open-loop unstable.\n\nG\nFrom the above stability table, the control law\n\nu1\n\n-t\n\n=0\nx\n\n-ns -t\n\nstabilizes only configuration states 1 and 2; since the configuration\n\nhas a high probability of being in state 0 (unstable), the cost diverges.\n\n\nExample 5.1, Case ii) \n\nP = .01\n.01,\np =\npf\n\n135\n\n\n.9799\n\n.98 \n\n\n0\n\n\n.009999\n\nIT\n1\n\n\n.009999\n\nit2\n\n\n.0001020\n\n3 IT\n\n\nConvergent Coupled Riccati Equations.\n\nG\n\n=\n\n[-.7563\n-.8070\n\n.1266\n\n-.1784\n\n\nStability:\n\n\nConfiguration\n\nStable\n\n0 (B0)\n1 (B )\n\nno\n\n2 (B2)\n\nno\n\n3 (B3)\n\nInterpretation:\n\nyes\n\nno\n\nWith more reliable actuators, the non-switching gain\n\n\nexpends less force on the stabilization of configuration states 1 and 2\n\n(unstable); since configuration state 0 is stabilized, and the system\n\nhas a (relatively) higher probability of being in configuration state 0\n\nthan in Case i), the non-switching coupled Riccati equations converge,\n\nresulting in a finite cost.\n\n\n136\nExample 5.2 uses the same system dynamics as in Example 5.1;\n\nhowever, only structures 0,1 and 2 (the controllable structures) are\n\nconsidered.\n\nThe configurition dynamics are modeled\n\nas being in any\n\n\nstructural state with equal probability of occurance initially and\n\n,remaining in that state forever; this model is illustrated graphically\n\nin Figure 5.1.\n\nThe state dynamics are\n\nt+l\n\n= Axt +B\n\n= [Xl\n\n1t-tx\nuk(t)\n\nt\n\nx2,t\n\n]T\n\nk(t) E {O,1,21\nThe cost to be minimized is\n\n\nJ\n\n=\n\nE\n\nEtQxt\n\n[t=0\n\n\n+u\n\nRUtI7\n\nThe non-switching methodology yields a robust control law of the\n\nform\n\nu t\n-t\n\n0\nx\n\n-ns-t\n\n\n137\n\n76265AW030\n\n\nFigure 5.1:\n\n-Markov transition probabilities for Example 5.2.\n\n138\nExample 5.2:\n\n=2 .71828 \n\n\n0.\n\nA=\n[0.0\n\n]9\n\n\nA 679\n\n\n[1.71828\n\n1-63212\n\n[0.0\n1 =311\n\n\n1.71828.63212\n\nJ\n\n-0=\n\n[0.0\n\n.63212\n\n\n1.\n\n21.71828\n\n0.0\n\n1632 1 2\n\n2\n\n1.71821\n\n\n0.0]\n\nP\n\n0.\n\n0\n\n1.\n0. 0\n\nConvergent:\n\n-.008413]\n\n"-1.089\nS -1.028\n\nI\nFS\n2. 1 S.\n\n1\n]=C\n\n0\n\n=\n\n112.8\n\n8.992]\n\n8.992\n\n-\n\ni=\n\n[\n\n-.01444\n\n\n6.835\n\n\nA\n\n\nStability:\n\nConfiguration\n\n0 (B\n\n0\n\n)\n\n1(B)\n2 (B\nRobust:\n\nyes\n\n\nStable\n\n\nyes\nyes\n\n)\n\nyes\n\n0.\n\n139\nRiccati Solution:\nL09.8\n\n9.030]\n\n-0 -9.030\n\n6.821]\n\n114.3\n\n6.2851\n\nS 1= 16.285\n\n6.836]\n\n[114.4\n[11.66\n\n11.66]\n6.849\n\n-2\n\n140\n\nThe non-switching solution converges for the system in Example 5.2,\n\nand the three resulting configurations are stabilized. Therefore G\n\n-ns\n\nis a robust gain.\n\nHad the solution not converged, by Corollary 1 of\n\n\nSection 9, no robust gain would exist.\n\nThe apriori expected cost (before the configuration state is\n\nknown) is, given x\n\nJ\n\n=\n\nx\n\nCx\n\n141\n\n5.11 \t Summary.\n\nIn this Chapter, an optimization problem was defined on linear\n\nsystems with variable actuator configurations and quadratic cost criteria.\n\nThe objective of this approach was to compute apriori a sequence of\n\ngains to be used in linear feedback control which do not depend on\n\nany on-line information about the process.\n\nThese gains were to\n\n\nboth \t tabilize the overall system, accounting for the various possible\n\ns\nstructures and minimize the expected value of the quadratic cost crite\xc2\xad\nrion, where the expectation is taken over the possible sequences of\n\nactuator configurations.\n\nThis solution depends on both the perfor\xc2\xad\n\nmance, and on the reliability of the various structures, as represented\n\nby the Markov transition probabilities between structures.\n\nThe matrix minimum principle [Athans,41] was used to establish the\n\nnecessary conditions for optimality of a solution to an equivalent\n\ndeterministic problem to that described above, known as Problem AE in\n\nthe Chapter.\n\nThese conditions unfortunately do not yield an analytic\n\n\nsolution for the gain sequence, but instead yielded an ill-posed two\xc2\xad\npoint boundary value problem which must be solved numerically (Section 5).\n\nTherefore, a second problem (Problem B) was formulated which was solvable\n\nanalytically using dynamic programming (Section 6).\n\nThis solution has\n\n\nidentical cost-stabilizing properties to the solution of Problem AE,\n\nbut has the advantage of being directly computable.\n\nThe steady-state solutions to the infinite-time versions of both\n\nproblems were defined, when they exist, and it was proved that, in addi\xc2\xad\ntion to the equivalent stabilizing property of the two solutions, the\n\nsteady-state values are identical, and this value is the same as the\n\n\n142\n\noptimal constant gain which minimizes the expected cost over the infinite\n\ntime interval.\n\nIn addition, the general robustness question of when one gain can\n\nstabilize a set of linear systems with different actuator configurations\n\nwas formulated in the context of Problem A and was solved by Problem B.\n\nThus, a test for when a robust gain exists can be performed by iterating\n\na set of coupled matrix Riccati-like equations and testing for converg\xc2\xad\nence of a function of the solutions.\n\nIf, in addition, the individual\n\n\nsolutions converge, then the robust gain which minimizes the expected\n\nquadratic cost index can be calculated directly.\n\nIt was noted that the\n\n\nextension to systems with variable dynamics (variations in A), as well\n\nas variable actuator structure, is trivial as long as the dimension of\n\nthe state is constant.\n\nThe major applications of this work are in the calculation of a\n\nrobust gain for a set of linear systems and in the calculations of\n\nstabilizing gains for systems with variable structure, such as occurs in\n\nfailure, repair, or reconfiguration.\n\nA second application will be\n\n\ncovered in the next Chapter and involves using these calculations in a\n\ncomputer-aided design procedure for the determination of the relative\n\neffectiveness of various redundant component configurations.\n\n\n143\n\nCHAPTER 6\n\n\nCOMPUTER-AIDED DESIGN\n\n\n6.1\n\nIntroduction.\n\nIn this Chapter, two specific applications of the non-switching\n\n\ngain methodology to computer-aided design are presented.\n\nExample 6.1\n\n\nillustrates the usefulness of the non-switching gain methodology in\n\nthe selection of an actuator design.\n\nFive possible designs are\n\n\nanalyzed using the non-switching gain calculations as a basis for ranking\n\nthe designs with respect to their expected performance.\n\nExample 6.2\n\n\ncompares two actuators, of which one is more reliable, but less\n\neffective\nthe other.\n\n(in that it incurs a greater cost for the same action) than\n\nThree cases with various actuator reliabilities are presented\n\n\nas a study of the trade-off between actuator reliability and effective\xc2\xad\nness.\n\nThese two examples are intended to demonstrate the usefulness of\n\nthe non-switching gain methodology in design studies.\n\nNo general method\xc2\xad\n\nology for computer-aided design using the results presented in this\n\nreport is presented.\n\nInstead, tools are presented which can be used in\n\n\nthe computer-aided design of system configurations.\n\n\n6.2\n\nThe Design Decision.\n\nA designer often has many means of achieving a desired goal;\n\n\nhowever, no unified methodology exists which can be used to choose a\n\ngiven design that is "better" than any other.\n\nAt best, a set of tools\n\n\ncan be developed which are applicable to specific situations and classes\n\n\nof systems.\n\n144\nOf these tools, all that are presently available evaluate\n\n\na system either on the basis of performance or on the basis of reliabil\xc2\xad\nity.\n\nThe methodologies described in this report optimize a performance\n\n\nindex which depends on both system reliability and system performance.\n\nTherefore, it is logical to apply these methodologies to the computer\xc2\xad\naided design of system configurations.\n\nExample 6.1 is an aid in the design of a linear system for which the\n\nstate dynamics are fixed, but the actuator configuration is to be at\n\nmost two actuators (one level of either component or functional redundancy)\n\nchosen from two types of actuators.\n\nThe system in Example 6.1 is de\xc2\xad\n\nfined by\n\nxt+l\n\n+\n\nLtx+t Bk(t)\n\n(6.2.1\n\n\nk(t) c 1\n\n(6.2.2)\n\nwherex t = [xlxt\' x2,t\nin Cases iii), iv),\nJ\n\n= E\n\nX3,t.\n\nT\n\nIn Cases i) and ii),\n\nv), I = {0,1,2,3}.\n\nTI\n\nI = f\n\n,i\n\nThe cost to be minimized is\n\n+T\n\n(6.2.3)\n\nThe cost of each actuator (labeled b\n\n-oand b ) is to-be the quadratic\n\n-i\n\n\ncost incurred by the control input to that actuator.\n\nThese costs are\n\n\nrepresented by the quadratic weights r 0 and rl, respectively, and are\n\nequal in Example 6.1.\nsystem; actuator b\n\n0\n\nThe actuators act on different states of the\n\n\napplies the control force to state x 2 , while -i\n\nb\n\n\napplies the control force to state x 3 .\nactuator with zero gain, 0.\n\nEach actuator can fail to an\n\n\nRepair constitutes replacement of the\n\n\nfailed component with a new actuator, identical to the original ac\xc2\xad\ntuator.\n\nThe repair action is modeled using a Markov transition pro\xc2\xad\n\nbability pr\' the probability of repair per unit of time.\n\nThe actuators\n\n\n145\n\nhave identical probabilities of failure and repair per unit time, pf and\n\nPr" respectively.\n\nThe five possible actuator configurations are, in the\n\n\norder in which they are presented in Example 6.1,\n\n\nE\'=\n\nIL.(]\n\n(6.2.4)\n\nR2 \n=\n\nl1\n\n(6.2.5)\n\n(6.26)\n\n= I 0\n~=\n-\n\n9\n\n(6.2.7)\n(6.2.8)\n\n=bo\n\nConfigurations B\n\nand B\n\nhave two-state configuration dynamics directly\n\n\ndefined by the failure and repair probabilities per unit time.\n\nCon\xc2\xad\n\nfigurations B3 , B 4 and B5 have four-state configuration dynamics re\xc2\xad\npresented graphically by Figure 3.2 of Chapter 3, Section 5.\n\nIt is\n\n\nnot immediately obvious from the configurations and the state dynamics\n\nwhich configuration is optimal.\n\nWhen a non-switching gain control is\n\n\nused, the expected steady-state cost, given by equation (5.7.3), is\n\na measure of the expected performance of each configuration, and can be\n\nused to rank the five configurations in order of system effectiveness.\n\nSystem effectiveness is a measure of the expected performance of a\n\nsystem, taking into account all postulated modes of operation.\n\nThere\xc2\xad\n\nfore, in Example 6.1, the non-switching gain and expected cost is com\xc2\xad\nputed for each of the five design configuraitons.\n\n\n146\nExample 6.1:\n\n\nA\n\n=\n\n.5000]\n\n.5000\n\n[2.0000\n\n1.ooo]\n\n0.0\n\n[o.U\n\noao\n\n0.0\n\n0.0\n\n1.\n\n1.\n\n.0\n\n-1.000\n\n1.0\n\n[\n\nbo\n\nb.\n\n0.0\n\n0.0\n\n\nro\n.] 1.0\n\n\n1.00\n\n0\n\n\n--.\n\n0\n\n\n0\n\nPr\n\n01\n\np\n\n=\n\n=\n\nPf.\nb.\n-1 l\n\n<\n\nr.\n\n2l\n\n\n0\n\xc2\xad\n\np\n\n=\n\n.98\n\n147\nExample 6.1 Case i)\n\nB0\n\n= conf.\n\n[!,]\n\n=\n\n0\n\nB1\n\nR\n\ncant. 1\n\n=\n\n-pf\n[\n\n(conf.\n\n0-\n\n1.]\n\n.02\n\n\n=I\n\n\n1-P\n\npf\n\n=\n\n.91\n\n\n01\n\nI\n\n=t\n\nconfiguration)\n\nr0 ]\n\n=\n\n99\n\nPr]\n\n=\n\n[98991\n\n\n[.01010]I1]\n\nConvergent Coupled Riccati Equations:\n\n\nG\n\n-.2582\n\n[-4.863\n\n=\n\n-0n\n\n\n-1.7331\n\n182.5\n\n57.93\n\n\n37.06\n\n9.943\n\n12.32\n\n\n57.93\n\n12.32\n\n22.81\n\n\n37.39\n\n60.09]\n\n37.39\n\n9.961\n\n12.44\n\n[60.09\n\nS0\n\n37.06\n\n12.44\n\n23.58]\n\n\n.188.6\n\n=\n\n182.6\n\nExpected cost\n\n=\n\n=\n\n57.95\n\n37.07\n\n9.943\n\n12.33\n\n57.95\n\n.\n\n37.07\n\n12.33\n\n22.82\n\nxT C x\n\nC\n\n148\nStability:\nConfiguration\n\nStable\n\n\n045B0 ),\nI (Bi)\nInterpretation:\n\nyes\nno\n\nThe steady-state non-switching gain exists; it\n\nstabilizes configuration 0 (B0), but does not stabilize configuration\n1 (B)\n\nSince the probability of being in configuration 0 (stable)\n\n(T0 ) is much greater than the probability of being in configuration 1\n(unstable) (\n\n), the system configuration is stabilized using the\n\n\nnon-switching gain G\n!It= *ns-t\n\nin the control law\n\n\n149\n\nExample 6.1 Case ii)\nB0\n\n1l\n\n=\n\nB1\n\np\n\nconf. 0\n\n=\n\n0\n\nconf. 1\n\nr\n\n=\n\n1\n\n.02]\n\n[ro]\n\n.9899]\n\n=f\n\nL9-\n\n- 1-P\n\n[\n\nVi\n0\n\nR =\n\nConvergent Coupled Riccati Equations:\n\n\n--s\nns\n\n\n=\n\n-1.484\n\n[-12.59\n\n-4.097\n\n1035.\n\n33.04\n\n\n33.04\n\n73.8a0\n\n\n1069.\n\n129.0\n\n282.6\n\n\n129.0\n\n19.31\n\n34.34\n\n[282.6\n\n=\n\n18.84\n\n\n271.4\n\nS.\n\n271.4\n\n\n125.0\n\n\n0\n\n125.0\n\n34.34\n\n77.43]\n\n\n1035.\n\n=\n\n18.85\n\n33.05\n\n[271.6\n\nExpected cost\n\n271.6]\n\n\n125.0\n\nSi\n\n125.0\n\n33.05\n\n73.83]\n\n\nxT C x\n\nAC\n\n\n150\nStability:\n\nConfiguration\n\n-0\n1\nInterpretation:\n\nStable\n\nyes\n\nno\n\n\nThe steady-state non-switching gain exists; it\n\nstabilizes configuration 0 (B 0), but does not stabilize configuration\n).\n\n1 (B\n\nSince the probability of being in configuration 0 (stable)\n\n( T 0 ) is much greater than the probability of being in configuration 1\n\n(unstable) (7i), the system configuration is stabilized using the\n\nnon-switching gain G\n-ns\n-t\n\n- ns-t\n\nin the control law\n\n\n151\nExample 6.1 Case iii)\n\n= conf. 0\n\nbo\n\n=0\n\n1\n\nB.1\n\nr\n\np2pf\n\n_0\n\n1\n\n]\n\ni\n\n= conf. 2\n\njcont. 3\n=o\n\n21Pfp(\xc2\xad\n\nPr\n\n-p\nfIp f\n=\n\n=\n\n[1.0\n\n1-pfP2\n\nP\n\n,\n\n1\n\n=o=con.\n\n0.0\n\n0\n\nB.\n2\n\n--\n\n(1-\n\nPr(pf)\n2\n\nl-rP\n\npf (-fp\n\nIPrl-P p f\n\n"\n\nf(\xc2\xad\n\n-Pfr\n\nf{\xc2\xad\n\nr\n\n.9801\n\n.9702\n\n.9702\n\n\'9604\n\n.0099\n\n.0198\n\n.0198\n\n.0196\n\n.0099\n\n.0098\n\n.0098\n\n.0196\n\n.0001\n\n.0002\n\n" .0002\n\n.0004\n\n.9799\n\n\'if\n\n.009999\n\nTr2r\n\n.009999\n\n73\n\n.0001020\n\nit4\n\nTr\n\n+P2Pr\n\n1P1-\n\n+p\nr\n\nPt\n\n1P\nr2\n\nf\nr\n\nPr\nl\n\n-r\n2\n\nPr+Pr\n\n152\nConvergent Coupled Riccati Equations:\n\n\nf-2..469\n\n-.1279 \n -.8983]\n\n\n1-2.469\n\n-.1279\n\n-.8983]\n\n\n15.1\n\n32.81\n\n48.01]\n\n\n32.81\n\n9.050\n\n10.2]\n\n\n[48.01 0.92 19.03]\n\n154.4\n\n32.88\n\n48.48\n\n\n9.054 1095\n\n48.48 10.95 19.20j\n\n\nS32.88\n\n154.4\n\n9.054\n\n10.951\n\n48.48\n\n10.95\n\n-19.20\n\n\n155.8\nS3\n\n48.48\n\n\n:32.88\n\n2\n\n32.88\n\n32.95\n\n48.96\n\n32.95\n\n9.058\n\n.l0.97j\n\n=\n\n[48.96 10.97 lb.38_\n\n153.2\ni \n\n\n32.82\n\n9.050\n\n10.92\n\n10.92\n\n19.04J\n\n\n=\n\n48.021\n\n48.02\n\n.S\n\n32.82\n\nExpected cost = xTC x\n\n\nA\n\n153\nStability:\n\n\nConfiguration\n\nStable\n\n0 (B 0 )\n\nyes\n\n1 (Bi)\n\nno\n\n)\n\nno\n\n2\n\n3 (B 3 )\nInterpretation:\n\nno\n\nThe steady-state non-switching gain exists; it\n\n\nstabilizes configuration 0 (B 0), but does not stabilize configurations\n\n1,2,or 3.\n\nSince the probability of being in configuration 0 (stable)\n\n\n(O0 is much greater than the probability of being in any other con\xc2\xad\n)\n\nfiguratibn (Ci i=1,2 or 3) (unstable), the system configuration is\nstabilized using the non-swithcing gain G\n-\n\nut =G\nx\n\n-t-ns-t\n\n\nns\n\nin the control law\n\n154\nExample 6.1 Case iv)\n\n\nB\n\nk\n\n0\n\ncanf. I\n\nBLf\n\nan\n\n= cant.\nlj\n\nr10]\n\nB\n\n3\nB\n\n=1.0\n\n\nP and R are the same as for Case iii).\n\n=\n=\n\nIaIa\n\ncan.\n\n2\n\n\nconf. 3\n\n\n155\nConvergent Coupled Riccati Equations:\n\n\n6.097\n\n24.64\n\n\n24.64\n\n52.13\n\n\n95.92\n\n197.3\n\n15.27\n\n24.89\n\n[197.3\n\n24.89\n\n52.83\n\n\n768.7\n\n95.92\n\n197.3\n\n195.92\n\n15.27\n\n24.89\n\n197.3\n\n24.89\n\n52.83\n\n\n775.3\n\n96.71\n\n199.5\n\n\n96.71\n\n15.36\n\n25.16\n\n\n199.5\n\nS\n\n15.18\n\n195.92\n\n-2\n\n195.1\n\n\n[768.7\n\n=\n\n95.14\n\n95.14\n\n=\n\n-2.011\n\n\n195.1\n\no\n\n-.7347\n\n762.2\nS\n\n-2.011]\n\n\n6.097\n\n-ns\n\n-.7347\n\n25.16\n\n53.55]\n\n\n762.3\n\nExpected cost\n\n=\n\n=\n\nx C x\n\n195.2\n\n\n95.15\n\n15.18\n\n24.64\n\n195.2\n\n.\n\n95.15\n\n24.64\n\n52.14\n\n\nC\n\n156\nStability:\n\n\nConfiguration\n\nStable\n\n\n0 -(B0\n\nyes\n\n1 (Bi1\n\nno\n\n2 (B\n\n2\n\n3 (B3)\n\nInterpretation:\n\n)\n\nno\nno\n\nThe steady-state non-switching gain exists; it.\n\n\nstabilizes configuration 0 (B 0 ),.but does not stabilize configurations\n\n1, 2, or 3.\n\nSince the probability of being in configuration 0 (stable)\n\n\n(Tr\n is much greater than the probability of being in any other con\xc2\xad\n0)\nfiguration (T.,\n\ni=1,2 or 3) (unstable), the system configuration is\n\nstabilized using the non-switching gain G\nin the control law\n-xns\n\nUt\n\n--\n\nG\n\nx\n\n\nns- t\n\n\n\xc2\xad\n\n157\nExample 6.1 Case v)\n\n\nL,\n\n=\n\nB\n\nR\n\nconf.\n\n: ]1\n\nr 0.0\n\nB2\n\n=onf. 0\n\nh\n\nBO\n\n[\n\n1\n\nB\n\n1.0\n\n\nP and Tr are the same as for Case iii).\n\n\n[ 0\n\nI \n cont. 2\n\n0\n\ncon.\n\n3\n\n\n158\nConvergent Coupled Riccati Equations:\n\n\n-3.815 \t -.1312\n\n24.86\n\n32.32\n\n\n7.066\n\n6.842\xc2\xad\n\n32.32\n\n6.842\n\n10.69\n\n128.4\n\n24.93\n\n32.8\n\n\n24.93\n\n7.096\n\n6.863\n\n\n32.88\n\n6.863\n\n10.85\n\n127.3\n\n25.01\n\n32.72\n\n5.01\n\n7-097\n\n6.921\n\n32.72\n\nS\n\n-1.486]\n\nr\n\n\n24.86\n\n6.921\n\n10.89].\n\n129.2\n\n25.08\n\n33.28\n\n25.08\n\nS1\n\n-.\n5815\n\n126.5\n0\n\n-1.106]\n\n\n-2.556\n\nns\n-s\n\n7.100\n\n6.942\n\n28\n\n6.942\n\n1:.05J\n\n=\n\nS\n\n3\t\n\nE33.\n\n126.5\n\n24.86\n\n32. 3\n\n24.86\n\n7.067\n\n6.843 1\n\nk32.33\n\n__ .S \'=\n\n6.843\n\n10.69\n\nExpected cost =xTC X\n\nc\n\n159\nStability:\n\nConfiguration\n0 (B\n\n0\n\nStable\n\n\n)\n\nyes\n\n1 (B)\n2 (B\n3 (B\nInterpretation:\n\n2\n3\n\nno\n)\n\nyes\n\n)\n\nno\n\nThe steady-state non-switching gain exists; it stabil\xc2\xad\n\nizes configuration 0 and 2 (B 0 and B\n\n).\n\nbeing in configuration 1 and 3 (B 1 and B\n(unstable) , the system configuration is\ning gain G\n-ns\n\n-t\n\nin the control law\n\n- ns-xt\n\n\nSince the probabilities of\n3\n\n) are small (ai and\n\nif3\n\nstabilized during the non-switch\xc2\xad\n\n160\n\nFrom the results in Example 6.1, the design configurations are\n\nranked as follows, where > is defined as "is better than".\n\nB5 >\n\n>\n\nB\n\nB\n\n>\n\n>\n\n2\n\n\n(6.2.9)\n\n\nOne configuration is more desirable than another (BJ > Bk) if\n\n\nt\n\nz\n\n>\n\n.\n\n-\n\nj\nThis criterion is reasonable; if B\n\n0\n\n(6.2.10)\n\n(negative definite)\n\n> Bk, then the expected cost using\n\n\nk\n\ndesign configuration Bj is always less than that using B .\n\nIf the left\n\nhand side of equation (6.2.10) is not negative definite, but is only\n\nsemi-definite, then some other criterion must be used in addition to\n\n(6.2.10) to rank the various designs.\n\nFor example, if one assumes a\n\n\nuniform distribution of the initial system state x 0 in the unit sphere,\n\nand if the elements of the diagonal of the left hand side of equation\n\n(6.2.10) are all non-positive, then the trace operator may be used as a\n\nranking function.\n\nIf the trace of the left hand side of equation (6.2.10)\n\n\nis negative, then B j > Bk.\n\nIf the left hand side of equation (6.2.10) is\n\n\nnot semi-definite, then the designer must choose which of the state\n\nvariables are most important in an effort to eliminate the ambiguity of\n\nequation\n\n(6.2.10).\n\nIn Example 6.1, equation (6.2.10) alone is sufficient\n\n\nto rank the designs.\n\nThe results stated in (6.2.9) are somewhat surprising.\nconsider b 0\n\nand b\n\n"\n\nFirst,\n\n\nA control input at time t using b 0 enters the\n\n\nx T\n\nsystem dynamics in state x 3 , where x\n\n= [xlt x2,t x3,t I\n-3,t\n\n\n.\n\nAt time t+l,\n\nthe same control is applied to state x1 with a gain of .5; also,\n\nx2,t+\n\n= x3, t\n\n.\n\nAt time t+2, that control is again applied to state x 1\n\n\nwith a gain of .5\n\n.\n\nNow, consider\n\n161\n\nthe same situation, but with b\n\ninstead of b\n\nIn this case, at time\n\n\nt+l, the control is applied to state x i , with a gain of .5, but\n\nx3,t+ 1\n\n=\n\n-x2, t\n\n.\n\nTherefore, at time t+2, the negative value of the original\n\n\ncontrol is applied to state x1 , thus partially cancelling the effect of\n\nthe original input.\n\nThe same process occurs using b 0\n\n,\n\nbut is delayed\n\none time step; thus, the control affects state xI positively one additional\n\ntime step when b\nover bl\n\nI B\n\n1\n\nis used.\n\nBecause of the added effectiveness of b0\n\n\n2\n4\n> B , and in fact, B 1 > B.\n\nThus, even after accounting\n\nfor component reliability, configuration B , which has no component\nredundancy is more desirable than configuration B 2 or\n\neven though\n\nconfiguration B 4 employs one level of component redundancy.\nUsing this reasoning, one would expect B 3 to be the optimal design\n\nchoice; however, the example demonstrates that this is not the case.\n\nFrom G ns\n for Case iv), note that the control which is applied to b0\n\n-depends mostly on the unstable state x1 l,while more emphasis is given\n\nto states x 2 and x3 in the calculation of the control for actuatorb \n\nThus, actuator b\n\nacts partially to stabilize the dynamics of state\n\nxI\n\n,\n\n\nwhile actuator b\n-i\n acts partially to counteract the negative effects of\n\nthe subsystem of states x 2 and x3 .\n\nThis type of control action is an\n\n\nexample of the use of functional redundancy, and is not possible with\n\n3\n4\n\ndesign configurations B or B .\n\nThe non-switching gain analysis of the proposed design configura\xc2\xad\ntions yields information not only about the effect of various actuator\n\nconfigurations but also about the effect of component reliability on\n\nthe expected performance.\n\n4\n\nThus, B\n\n2\n3\nis more effective than B , and B\n\n\nis more effective than B ; B 4 and B3 are versions of the configurations\n\n\n162\n1\n\nB and B1, respectively, with one level of component redundancy,. Con\xc2\xad\n5\n\nfiguration B is an example of functional redundancy; both actuators\n\n2\n\nprovide control input to the same system, but are not identical components.\n\nThus, the additional reliability of component redundancy contributes\n\nto ranking (6.2.9).\n\nThe trade-off between system performance and system\n\n\nreliability will be further demonstrated in Section 3.\n\n\n163\n6.3\n\nA Trade-Off of System Performance Versus Reliability.\n\nThe non-switching gain methodology can be used to study the\n\n\nrelative effects of actuator reliability and actuator effectiveness\n\non expected system performance.\n\nIf a designer has a choice between\n\n\nusing a high reliability actuator rather than one with relatively low\n\nreliability, but with a higher effectiveness, on what basis can a\n\ndecision be made?\n\nIn Example 6.2, two actuators are considered.\n\nEach\n\n\nactuator may fail to an actuator of gain zero (0) and be repaired\n\n(replaced). \tThe probabilities of failure and repair are pf\n\nand pr.\ni\n\nwhere i=0 or I and refers to the actuator (b\n\nor b\n\n1\n\n\' respectively).\n\nOne actuator (b 0) has good reliability, but the actuator gain is unity.\nA second actuator (b I) has an actuator gain of ten (higher effective\xc2\xad\nness), and a lower reliability.\nbility, then actuator b\nfor the same effect.\n\nIf the actuators had the same relia\xc2\xad\n\nwould be preferable--it incurs a smaller cost\n\nIn Case i) of Example 6.2, this reasoning is\n\ndemonstrated numerically; the steady-state non-switching gain favors\nactuator b\n\n(the second column of B 0 ).\n\n(The two rows of the gain\n\nmatrix are compared; the top row corresponds to actuator b 0.)\nIn Cases ii) and iii) of Example 6.2, the reliability of actuator\nh1\n\nis lower than the reliability of actuator b 0\n\nprobability of failure per unit time of actuator b\n\nIn Case ii) the\n\nis five times\n\ngreater than the probability of failiure per unit time of actuator b 0\nin Case iii),\n\nit is ten times greater.\n\nunit time for actuator b\nTherefore, actuator b\n\nNote that in Case ii),\n\nThe probabilities of repair per\n\nare also lower than for actuator b0\nis significantly less reliable than actuator b0\n\nthe optimal non-switching steady-state controller\n\n\nfavors actuator b\n\n-0\n\n\nb\n\n164\n\nby a gain factor of 2.5 - 2.6; in Case i), actuator\n\n\nis favored by a gain factor of 2.3.\n\nfavored by a gain factor of 5.1.\n\nIn Case iii),\n\nactuator bo\n\nis\n\n\nTnUs, the non-switching gain calcula\xc2\xad\n\ntions-can -be quita sensitIve to changes in component reliability.\n\nAlthough the configuration states are identical for all three Cases of\n\nExample 6.2, the configuration dynamics are modified by the changes in\n\nactuator reliability.\n\nThe effect of modifications in actuator reliability\n\n\non the non-switching steady-state gain and cost is pronounced.\n\nThe\n\n\nsteady-state gain is very sensitive to the actuator reliabilities; the\n\nexpected steady-state cost increases as the reliability decreases.\nsecond effect demonstrated by Example 6.2 is interesting.\n\nIn Case i),\n\n\nconfiguration state 2 is not stabilized by the non-switching gain.\nthe reliability of actuator b\n\nA\n\n\nAs\n\n\ndecreases, the average steady-state\n\n\nprobability that the configuration is state 2 (actuator b\nactuator b 0 operational) increases.\n\nfailed,\n\n\nTherefore, the non-switching gain\n\n\nsolution must concentrate more effort on stabilizing configuration state\n\n2.\n\nNote that in Cases ii) and iii), configuration state 2 is stabilized\n\n\nby the non-switching gain solution.\n\nIt is interesting to note also that\n\n\nthe non-switching gains in Cases ii) and iii) are robust with respect to\n\nconfiguration states 0, 1 and 2.\n\n(Configuration state 3 is uncontrolla\xc2\xad\n\nble.)\n\nThe system dynamics in Example 6.2 are\n\n= Axt+l +\nt +Bt k(t)\n\n(6.3.1)\n\nk(t) e I\n\n(6.3.2)\n\nwhere I = 10,1,2,31 and x\n-t\n\nx\n\n=[x\n\nlt\n\nx\n2,t\n\nT\n\nThe set\n\n{\n\ni\n.\n\n3,t\n\nof configuration states is given in Example 6.2.\n\ni=\nThe cost to be\n\n\n165\nminimized is\n\nE\n\nxT\n\nR\n\nT\n\n(6.3.3)\n\n166\nExamPle 6.2:\n\n[0.0\n\nA\n\n1.0000\n\n\n0.\n.0\n\n-1.0000\n\nO.\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\nB1\n\n0.0\n\nB\n\n0.0\n\n0.0\n\n0.0 \t\n\n0,0\n\n1.0\n\n0.0\n\n0.0\n\n=\n\n0.\n0.0\n\n0.0\n\nconf. 2\n\n0.0 \t\n\n=\n\n1\n\nconf.\n\n10.0\n\n0\n\nI0.0\n\n0.0\n\n\nconf.\n\n3\n\n1.0\n\n1t-Pfl-P f2+pf1Pf 2 \n\n\n[5.0\n\n0.0\n\n(1-Pf 2)pr 1\n\n(\nPfl1 l-Pf2\n\nP\n\n0.0\n\n0.0\n\n1.0\nQ \t=\n\n0\n\n00] \t\n\n0.0\n\n2\n\nconf.\n\n"0.0 \t\n\no0\nB\n\n0.0\n\n\n0.0\n\n0.0\n\n1.0\n\nB0\n\n.5000]\n\n\n.5000\n\n[2.0000\n\n+r 1f 2\n\n0.0\n\n5.0\n\n(1-Pfl1\n\n)\n\npr2\n\nPrl1Pr 2\n\nPf Pr2\n\n)\n\n(1-Pr2\n\n1\n\n=\nPf2 (1-pfl)\n\nfi2\nPf1 f2 \n\n\nPf2Pr\n\n(lr\n\n1\n\n)Pf\n\nl-Pf-pr2+Pfr2 (1-PrI\n\n2\t\n\n(1-p\n\n2\n\n)Pf\n\n1\n\n1\n\n2\n\n-rr -prlr p\n\n1\n\n2r\n\n1\n\n2\n\n167\nExample 6.2 Case i)\n.01\n\n.9799\n\n0\n\n.00 9999\n\nPr\n\nO\n.1\n011\n\n=\n\n=\n\n_i\n\n.98\n\n-T0\nII\n\n=\n\n.009999\n\niT\n2\n\n.0001020\n\niT\n3\n\nConvergent:\n\nrs-.2059\n\n-. 01076\n\n-. 07574]\n\n-. 4 8 2 9\n\n-.02505\n\n-.1789\n\n134.5\n\n41.49\n\n30.06\n\n8.459\n\n9.981\n\n41.49\n\n9.981\n\n16.44\n\n13 4 . 5\n\n30.06\n\n41.49]\n\n30.06\n\n8.459\n\n9.981\n\n[41.49\n\n9.981\n\n16.44]\n\n[138.5\n\n30.27\n\n42.96]\n\nI 30.27\n\n8.470\n\n10.06\n\n[42.96\n\n10.06\n\n16.98]\n\n[138.5\n\n30.27\n\n42.97]\n\n30.27\n\n8.470\n\n10.06I\n\n42.97\n\n10.06\n\n16.98]\n\nSO=\n\n30.06\n\nS\n\nS\n\n3=\n\n134.5\n= .S\n\n30.06\n\n41.51]\n\n30.06\n\n8.459\n\n9.982\n\n[41.51\n\n9.982\n\n16.45]\n\nC\n\nT\n\n168\n\n\nC x\n\nExpected cost = x\nStability:\nConfiguration\n\nStable\n\n0 -M0)\n1\n\nyes\n\n(B2\n\nno\n\n3\n\ni=0 and 1.\n\n(B 1 )\n\n2\n\nInterpretations:\n\nyes\n\n(B)\n\nno\n\nThe system x-t+l\n\n=\n\n[A + B.G\n] xt\n- i--s--n\n\n\nis stable only for\n\nThe probabilities of the configuration being in states 2 and 3\n\n\n(\'It2 and T3 ) are small; the system configuration is stabilized using the\ncontrol gain G\nin the control law\n-ns\n\nn\n=G\nxt\n\n-t\n-ns \xc2\xad\n\n169\nExample 6.2 Case ii)\n=\n\n.01\n\n=\n\n.98\n\np rl- =\n\n.90\n\nf0\n\n-.\n9378\n\nT0\n\n0\n\n.009212\n.05\n\n[-1.041\n\n-. 05848\n\n-.36391\n\n\nn-.4058\n\n1\n\n-.02163\n\n-.1464\n\n\nI\n\n\n176.6\n\n55.71]\n\n\n36.39\n\n9.798\n\n12.06\n\n12.06\n\n21.85]\n\n\n37.56\n\n62.83\n\n\n37.56\n\n9.868\n\n12.46\n\n\n12.46\n\n24.35]\n\n\n166.4\n\n35.79\n\n52.08\n\n\n35.79\n\n9.762\n\n11.861\n\n52.08\n\n3\n\n36.39\n\n[62.83\n\n=\n\n21.81]\n\n\n197.4\n\n1\n\n12.06\n\n[55.71\n\n=\n\n-\n\n12-061\n\n\n[176.9\nl\n\n9.797\n\n55.60\n\n0I\n\n\n55.60\n\n\n36.37\n\nS\n\n36.37\n\n11.86\n\n20.58]\n\n177.7\niTS\n\n=\n\n_f3\n\n\n=\n\nConvergent:\n\n\nG\n\nT2\n\n.0005316\n\n=\n\nTi\n1\n\n.05206\n\nfl\n\nIf\n\n36.43\n\n55.981\n\n\n36.43\n\n9.801\n\n12.08\n\n55.98\n\n12.08\n\n21.94\n\n\n=c\n\n170\n\nExpected cost = xTC x \n\nStability:\n\nConfiguration\n0 (B\n\nStable\n\n\n1 (B\n\n)\n\nyes\xc2\xad\n\n)\n\n0\n\nyes\n\n2 (B\n\nxt+\n\n1\n\n)\n\nyes\n\n3 (B\nInterpretation:\n\n2\n\n3\n\n)\n\nno\n\nThe system\n\n= [A + B . G\n\nJ x\n\nt\n\nis stable for i = 0,1,2.\nConfiguration state 2 is stabilized because the probability of the\nconfiguration state being 2 (B 2 ) is larger than in Case i).\n\n\n171\n\nExample 6.2 Case iii) \n\nPfo \n =\n\n.01\n\n1 \n=\n\n.10\n\n=\n\np\n\n-98\n\n.8909\n\n.09891 \n\n\npr\n\n-.,\n729\n\n=\n\n-. 09453\n\n-. 6062\n\n\n-.3400 \n -.01858 \n -.1195\n\n\n67.28]\n\n41.04\n\n13.61\n\n10.76\n\n[67.28 \n 13.61\n\n26.29]\n\n, 213.2 \n 41.14\n\n68.26]\n\nj1.14 \n 10.75\n4\n\n13.66\n\nL68.26 \n 13.66\n\n1 \n=\n\n26.661\n\n67.92\n\n212.3 \n 41.09\n\n1s\n\n41.09\n\n\n 10.75\n\n13.64\n\n[67.92 \n 13.64\n\n26.53]\n\n[196.0 \n 40.19\n\n,\n\n62.11]\n\nI \n\n40.19\n\n13.32\n\n10.70\n\n24.471\n\n[62.11 \n 13.32\n\n210.7\n\n40.99\n\n1\nii= \n\n\n713_\n\n\n.90\n\n[210.6 \n 41.04\n=\n\n72\n\n\n0\n\n\nConvergent:\n\n\nSo\n\n\'I1\n\n\n.001010\n\n-ns \n\n\n-%\n\n.009172\n\n0 \n\n\n67.281\n\n\n1\n\n40.99\n\n10.75\n\n13.60\n\n[67.28\n\n13.60\n\n26.28\n\n\n0\n\n\nI\n\n172\n\nExpected cost = xTc x \n\nStability:\n\nConfiguration\n\nStable\n\n0 (B 0)\n1 (B 1)\n\nyes\n\n\n3 (B )\n\nx t+\n\nyes\n\n2 (B 2)\n\nInterpretation:\n\nyes\n\nno\n\n\nThe system\n\n\n= [A + B.G\n\n] x\n\nt\n\nis stable for i = 0,1,2.\n\nConfiguration state 2 is stabilized because the probability of the\n\nconfiguration state being 2 (B 2 ) is larger than in Case i).\n\n\n173\n\n6.4 \tSummary.\n\nIn this Chapter, two applications of the non-switching gain method\xc2\xad\nology to computer-aided design (CAD) were presented.\n\nThe purpose of\n\n\nthese examples was to demonstrate the usefulness of the non-switching\n\ngain methodology in the design process.\n\nCAD has two uses:\n\nFirst, it is\n\n\nused by the system designer in the evaluation and design of a system.\n\nSecond, it is quite useful to the theorist.\n\nIn this research, for\n\n\nexample, without CAD techniques, a thorough knowledge of the methodologies\n\npresented in this report could not have been gained.\n\nThe equations\n\n\ndescribing the switching and non-switching gain methodologies can be\n\nderived, but their meaning in a specific context cannot be determined\n\ntheoretically.\n\nThe purpose of this research was to study the inter\xc2\xad\n\nactions between system reliability and optimal control.\n\nThe method\xc2\xad\n\nologies presented in this report allow this study to proceed.\n\nThe two\n\n\nExamples of this Chapter study two specific areas of interaction\n\nbetween system reliability and control.\n\nThe door has now been opened to\n\n\nthe answers to questions on reliable control system designs.\naided design can provide the signposts to these answers.\n\n\nComputer\xc2\xad\n\n174\n\nCHAPTER 7\n\nCRITIQUE\n\n\n7.1 \t Introduction.\n\nIn this Chapter, the major results of the report will be summarized.\n\nIn Chapters 3 and 4, the switching gain solution was developed and\n\nextended suboptimally to stochastic systems.\nswitching gain solution was developed.\n\nIn Chapter 5, the non\xc2\xad\n\nThe problems associated with\n\n\nsystem stability, including definitions of what constitutes a stable\n\nsystem, and with the steady-state solutions to Problems A (Sections 3\n\nthrough 5) and B (Section 6) were studied in detail\n\nin Section 7.\n\nThe\n\n\nequivalence of the two approaches to the non-switching gain solution is\n\nproved in Section 8.\n\nThe existence of a robust steady-state linear\n\n\nfeedback control system was studied in Section 9.\n\nIn the following sections, each major result will be discussed; in\n\nSection 5, some suggestions for future directions in research will\n\nbe made.\n\n\n7.2 \t The Switching Gain Solution.\n\nThe switching gain solution was derived in Chapter 3 as a control\n\nmethodology for linear system with quadratic cost criteria and variable\n\nactuator configurations.\nthe failure,\n\nThe resulting control law was to account for\n\n\nrepair and reconfiguration of the actuators by switching\n\n\nthe control gain on detection of a change in configuration.\n\nThis type\n\n\nof control law is, from Chapter 1, Section 4, a class 1I reliable control\n\nmethodology; an active (switching) controller is used with a passive\n\n\n175\n\nconfiguration design.\n\n\n7.2.1\n\nDeterministic Optimal Solution.\n\nThe \t\nswitching gain solution of Chapter 2 is derived as the optimal\n\n\nsolution for the discrete-time deterministic optimal control problem.\n\nIt is the optimal control simply because the structure of the discrete\xc2\xad\ns\ntime \t ystem allows perfect observations of the system structure\none-step delay.\n\nwith\n\n\nTherefore, there is no need for the control law to\n\n\na\nhave \t dual effect; in fact, there can be no dual effect, since the\n\ncontrol law does not affect the observation process, for almost all\n\nvalues of the control.\n\nA minor drawback to the switching gain solution is the computa\xc2\xad\ntional burden of iterating the Riccati-like equations (3.3.6), and solving\n\nfor the optimal control using equation (3.3.7), backward in time for\n\n\t\neach time instant of the control interval, or until the steady-state\n\n\t\nsolution is achieved, when one exists.\n\nFortunately this computation is\n\n\ndone \t ff-line, and the various optimal gains are then stored for on-line\n\no\nuse.\n\nOn-line, the controller simply determines which structure the\n\n\nsystem was in at the previous time instant and chooses the corresponding\n\n(stored) gain.\n\nThe control law is then a linear feedback control using,\n\n\nthat particular gain.\n\n\n7.2.2 \tNon-Extendability to Stochastic Systems.\n\nUnfortunately, the switching-gain solution does not extend optimally\n\nto systems where noise is present.\n\nWhen noise is present, it is no\n\n\nlonger possible (in general) to determine exactly the previous value\n-\n\nof the system structure.\n\nIt was shown in Section 3 of Chapter 2 that\n\n176\n\nin such a case, the optimal control law exhibits a dual effect; i.e.,\n\nthe control law influences the measurement of the system structure.\n\nIn\n\n\na real-life situation, it is unlikely that a system with no internal\n\nnoise will be found.\n\nUnfortunately, the optimal (dual) control law is,\n\n\nin practice, unsolvable due to the immense computer resources which are\n\nrequired.\n\n\n7.2.3\n\nSuboptimal Extensions.\n\nBecause of the dual control effect, the deterministic optimal\n\n\nsolution is the\n\nonly closed-form solution available.\n\nThus, it is in\n\n\nour interest to look for suboptimal methodologies which extend the\n\nswitching gain solution to the stochastic case.\nthese methodologies were studied:\nfication.\n\nIn Chapter 4, two of\n\n\nHypothesis testing and dual identi\xc2\xad\n\nWhile hypothesis testing is a measurement strategy, dual\n\n\nidentification modifies the control in order to guarantee a perfect\n\nobservation of the system structure with the next measurement.\n\nBoth\n\n\nmethodologies are presented in their simplest form, since the problems\n\nof stochastic control of systems with variable structure are not within\n\nthe scope of this research.\n\nTwo comments are in order, however:\n\n\nFirst, at least in the form presented in Chapter 4, a dual identifica\xc2\xad\ntion algorithm is computationally intensive.\n\nSince it is an on-line\n\n\nalgorithm, a significant computational capacity may be required in its\n\nimplementation.\n\nSecond, it is observed that the optimal stochastic\n\n\ncontrol law, if it could be calculated, would rely on both estimation\n\nand dual control, the two concepts which are represented in Chapter 4 by\n\nhypothesis testing and dual identification, respectively.\n\n\n177\n\nIn a suboptimal implementation using dual identification, the\n\nalgorithm would most likely be used only at intervals; the implementa\xc2\xad\ntion would rely on an estimation algorithm for the remainder of the\n\ntime.\n\nThis scheme would attempt to minimize the degrading effect of\n\n\ndual identification on the state trajectory by using it only to guarantee\n\nthat the estimation algorithm was tracking the system configuration\n\nproperly.\n\nThus, the system response would be roughly periodic, with\n\n\nthe state being driven away from the origin in order to obtain an\n\naccurate estimate of the configuration, and decaying back toward zero\n\nbetween uses of the dual identification algorithm.\n\nThis type of control strategy deserves some attention in future\n\nresearch activities.\n\nIt is similar to the class of self-testing\n\n\nsystems which perform diagnostic testing of their configurations\n\nat intervals.\n\nIt is also, at present, the only methodology which takes\n\n\nadvantage of the dual property of the control law in systems with\n\nvariable, imperfectly observed, structure.\n\n\n178\n\n\n7.3 \t The Non-Switching Gain Solution.\n\nThe non-switching gain solution of Chapter 5 was derived as an\n\nalternative to the switching gain solution of Chapter 3.\n\nAlthough\n\n\nthe non-switching solution is, in general, suboptimal, the on-line\n\ncomplexity of the solution is less demanding than that of the switching\n\nOn-line, the non-switching gain solution has the same\n\n\ngain solution.\n\ncomplexity as does the standard linear quadratic solution.\n\nOff-line,\n\n\nthe computational requirements are equivalent to those of the switching\n\ngain solution.\n\n\n7.3.1 \t The Necessary Conditions--Unsolvability.\n\nWhen the non-switching control problem is formulated as an\n\nequivalent deterministic control problem (Chapter 5, Section 4),\n\nthe\n\n\nnecessary conditions from the matrix minimum principle [Athans,41]\n\nyield a two-point boundary value problem which is not explicitly\n\nsolvable; at the present time, the solution to this problem appears\n\nintractable.\n\nThe necessary conditions are used, however, in conjunction\n\n\nwith an equivalent problem (Chapter 5, Section 6),\n\nto prove some strong\n\n\nproperties of the solution to the equivalent problem.\n\n\n7.3.2\n\nThe Equivalent Problem.\n\nThe equivalent problem formulated in Section 6 of Chapter 5 has\n\n\nthe advantage over the original formulation that a closed-form expression\n\nfor the solution can be readily obtained.\n\nFrom the necessary conditions\n\n\nof Section 5 in Chapter 5 for the original formulation, it is shown that\n\nthe accumulated costs over the control interval for a specified gain\n\nsequence are identical for the two formulations.\n\nFrom this, in Section 8\n\n\n179\n\nof Chapter 5, it is shown that if the steady-state solutions to both\n\nproblems exist, then they are identical.\n\nThis is a major result, since\n\n\nthe \t\nsteady-state solution to the second formulation is calculable,\n\nwhile the solution to the first formulation is not.\n\n\n7.3.3 \t Existence of a Stabilizing Gain.\n\nOnly one major result remains; one would hope that the steady-state\n\nsolution to the second formulation exists if and only. is the steady-state\n\nsolution to the first formulation exists.\n\nIn Section 7 of Chapter 5, the\n\n\nmeaning of "steady-state" is precisely defined for both problems.\n\nIn\n\n\norder for the concept of a steady-state solution to be well-defined, an\n\nexact definition of stability must be given.\ned.\n\nTwo definitions are present\xc2\xad\n\nStability is defined as the usual concept of mean-square stability.\n\n\nA definition of cost-stability is presented as the condition when the\n\nexpected cost for the infinite horizon problem (unnormalized by time)\n\nis bounded.\n\nIt is proved that the solutions to the two formulations\n\n\nare equivalent in that one solution is cost-stabilizing if and only if\n\nthe other is also.\n\nCost stability is shown to imply mean-square\n\n\nstability; the reverse is not necessarily true.\n\n\n7.3.4\n\nProblems with Convergence.\n\nThere are two criticisms of the results of Chapter 5.\n\nFirst,\n\n\nalthough cost-stability is not implied by mean-square stability, it is\n\npossible that, for the specific form of the non-switching gain solution,\n\nthe two definitions are equivalent.\n\nThis is a minor point, in that the\n\n\nequivalence result is already very strong; it yields a procedure for\n\nthe calculation of the steady-state solution to the two point boundary\n\n\n180\n\nvalue problem which converges if and only if that solution exists.\n\nSecond, there is still a minor problem concerning the convergence\n\nof the non-switching gain solution.\n\nThe equivalence theorems of\n\n\nChapter 5 only require the solution to have a steady-state, which may\n\nbe a limit cycle.\n\nA limit cycle is still copacetic, but it is harder\n\n\nto implement than one gain would be.\n\nTherefore, it is desired that\n\n\nconditions be found for which the possibility of a limit cycle is\n\nruled out.\n\nThus, two possible topics for future research are the examination\n\nof the exact relationship between cost-stability and mean-square stability\n\nfor the non-switching solution and the determination of conditions for\n\nwhich the possibility of limit cycles as solutions is eliminated.\n\n\n7.3.5\n\nExistence of a Robust Gain.\n\nA spin-off of the non-switching gain solution of Chapter 5 is\n\n\nthe development of an algorithm which determines when a robust gain\n\nfor a set of linear systems exists (Section 9).\n\nA robust gain is a\n\n\ngain which stabilizes each mode of the system configuration regard\xc2\xad\nless of the configuration dynamics.\n\nThis algorithm is developed by\n\n\nnoting that the robustness problem can be reformulated as a non-switch\xc2\xad\ning gain problem.\n\nSince the non-switching gain is, in the steady-state\n\n\ncase, the solution to the first formulation (Section 4, Chapter 5),\n\nand\n\n\nsince it is stabilizing if and only if a stabilizing gain exists, then\n\nby the special structure of the robust formulation (Section 9), the\n\nsteady-state non-switching gain is robust when it exists.\n\nIn addition,\n\n\nif the non-switching solution is not cost-stabilizing, then no robust\n\n\n181\ngain exists.\n\nThis is a very important result; it is unfortunate that\n\n\ndetermination of existence of the robust gain requires the solution\n\nof the non-switching gain problem.\n\nAt present, however, no test on -a\n\n\nsystem exists which determines when the non-switching gain solution\n\nis cost-stabilizing,.\nthe future.\n\n\nIt is hoped that such a test will be developed in\n\n\n182\n\n7.4\n\nComputer-Aided Design.\n\nChapter 6 demonstrates the usefulness of the non-switching\n\n\ngain calculations in computer-aided design (CAD).\n\nThese calculations\n\n\nprovide the backbone for comparison studies on the relative system\n\neffectiveness of various designs.\n\nIn the first example, it is demon\xc2\xad\n\nstrated that the non-switching control methodology yields a numerical\n\nvalue based on the expected performance of a design configuration\n\nover the effect of the structural dynamics.\n\nThis example demonstrates\n\n\nthat relatively subtle qualities of an actuator can be used to rank\n\nvarious actuator configurations; in this case, the ranking depends\n\non the manner in which the control affected the system state and is\n\nnot obvious on a casual inspection of the configuration.\n\nThe second example demonstrates the ability of the non-switching\n\ngain methodology to observe the trade-off between high reliability and\n\nhigh effectiveness in an actuator.\n\nBoth qualities are desirable, but\n\n\nin this example, one actuator is highly reliable, while the second\n\nactuator is not as reliable, but is highly effective in-that it incurs\n\na much smaller cost in applying the same control effect to the system.\n\nThe non-switching gain problem is solved for a range of actuator reli\xc2\xad\nabilities for the highly effective sensor.\n\nIt is demonstrated that\n\n\nthe trend exists to depend more heavily on the high reliability sensor\n\nas the reliability of the highly effective sensor decreases, even\n\nthough the operation of the highly reliable sensor incurs more cost.\n\nChapter 6 only touches upon the field of computer-aided design.\n\nThere is much work to be done in this field, and the purpose of Chapter 6\n\nis only to establish the usefulness of the non-switching gain methodology\n\n\n183\n\nin the design process.\n\nIn the future, the applicability of the non\xc2\xad\n\nswitching gain methodology to CAD should be studied in great detail;\n\nin particular, a comprehensive methodology for the application of the,\n\ntechniques of Chapter 5 to CAD should be developed.\n\nThis methodology\n\n\nshould include a strong argument for the validity of using the non-switch\xc2\xad\ning methodology in CAD.\n\nSpecifically, research needs to be carried out\n\n\non the relationship of the costs incurred by various design configurations;\n\nthis is similar to justifying the use of the quadratic cost criterion\n\nin the linear quadratic regulator.\n\nIn order to compare two designs, a\n\n\nvalid basis of comparison, or cost index, must exist.\n\nThe non-switching\n\n\nmethodology is proposed as being a valid cost index for the class of\n\nsystems for which it is applicable; this conjecture should be verified.\n\nIn addition to the usefulness of the non-switching methodology, it\n\nhas been mentioned previously that a valid definition for a reliable\n\ndesign is that the design is cost-stabilizable.\n\nSince, for the deter\xc2\xad\n\nministic control problem presented in Chapter 3, the switching gain\n\nsolution is the optimal solution, the existence of the steady-state\n\nswitching, gain solution is equivalent to the stabilizability of that\n\ndesign.\n\nHence, the existence of the steady-state switching gain solution\n\n\nis necessary and sufficient to classify a design reliable.\n\nIn theory, the computation of the steady-state switching gain\n\nsolution can be used as a method in CAD for determining if a proposed\n\ndesign meets the minimum requirement of stabilizability.\n\nIn practice.,\n\n\nhowever., the proposed design will operate in a stochastic environment;\n\ntherefore, the switching gain solution is not an absolute measure of the\n\nstabilizability of the design.\n\nIn the future, research should be\n\n\n184\n\nconcentrated on the development of the concept of stabilizability to\n\nmore general stochastic systems than has been done previously.\n\nAn\n\n\nexample of work in this direction has been given with the Uncertainty\n\nThreshold Principle [Athans, et. al., 3 7 ], which is basically the deter\xc2\xad\nmination of conditions of stabilizability for a specific system with a\n\nspecific type of control law.\n\nThe work on the existence of the non\xc2\xad\n\nswitching gain solution for a simple system (Chapter 2,-Section 7)\n\nis another example.\n\nIt has been demonstrated in this research that the\n\n\nconcepts of systems reliability and stabilizability are crucially\n\ninterconnected.\n\nIt is left to future research to determine more general\n\n\nconditions of reliability and stabilizability and to implement these\n\nconditions in computer algorithms which can be used by the designer.\n\n\n185\n7.5\n\nSuggestions for Future Research.\n\nSeveral suggestions for future research have been presented in\n\n\nSections 2,3 and 4 of this Chapter.\n\nIn-this Section, a summary of these\n\n\nsuggestions will be given.\n\nIn Chapter 1, three classes of reliable control methodologies\n\nwere given.\nI)\nII)\n\nIII)\n\nThese are\n\n\nPassive (Robust) Controller Design\n\nActive (Switching) Controller, Passive Configuration\n\nDesign\n\nActive Controller, Active Configuration Design\n\n\nOf the methodologies presented in this report, the non-switching\n\ngain design is a class I methodology, and the switching gain design is\n\na class II methodology.\nin this report.\n\nClass III methodologies are not represented\n\n\nThis class is currently largely in the realm of\n\n\n"blue sky" theory.\n\nUnfortunately, there is as yet no adequate model\n\n\nof configuration dynamics which exhibits a state and control structure.\n\nOver the next ten years, one should see much research activity in the\n\narea of class III methodologies and their control structures.\n\nIn class II methodologies, much effort should be concentrated on\n\nextensions, either optimal or suboptimal, of the switching class of\n\ncontrol laws to stochastic systems.\n\nAt present, most work has been done\n\n\nin estimation theory, since the difficulties associated with dual\n\ncontrol are widely recognized.\n\nThe ability of a control law to perform\n\n\ndiagnostic testing for changes in configuration has yet to be exploited\n\ntheoretically, although many heuristic algorithms have been used, both\n\nin control systems and in the more established field of fault detection\n\n\n186\n\nand identification in digital systems.\n\nDual control is a form of self\xc2\xad\n\ntesting, and can be utilized as such, even if an optimal control is\n\nnot known.\nexample.\n\nThe dual identification methodology of Chapter 4 is an\n\n\nThis field requires a large effort, and should be rich in\n\n\nresearch opportunities.\n\nThe class I methodologies are represented in this research by the\n\nnon-switching gain solution.\n\nThe work done in Chapter 5 on mean-square\n\n\nstability and cost-stability of solutions is not unique to this class of\n\nproblems.\n\nMuch remains to be done in the classification of what consti\xc2\xad\n\ntutes a stabilizable system, whether with respect to a non-switching\n\ncontrol law or something more general.\n\nSince reliability can be defined as stabilizability with respect\n\nto some class of control laws, research into the stabilizability of\n\ndynamic configuration systems is the key issue in reliable control\n\nsystem designs.\n\nMuch work, including this research, has been done on\n\n\nthe assumption that the system is stabilizable; however, little progress\n\nhas been made in determining why a given design is stabilizable.\n\nAlthough iterative tests were developed in this report for determining\n\nstabilizability, a thorough understanding of the reason these tests\n\neither converge or fail to converge is lacking.\ndone.\n\nMuch work still must be\n\n\nWith this should come a resolution of the problems with limit\n\n\ncycle steady-state solutions to the non-switching gain methodology.\n\nIn Chapter 6, the usefulness of the non-switching gain solution in\n\ncomputer-aided design was demonstrated.\n\nCAD is a field unto itself; many\n\n\nopportunities exist for research in this area.\nresearch is application-specific.\n\nUnfortunately, most\n\n\nCAD is useful not only to the designer,\n\n\n187\n\nbut also to the researcher.\n\nIt is a powerful tool in the building of\n\n\nthe concepts of reliable control systems design, and it should be\n\ndeveloped in parallel with any future research.\n\n\n7.6\n\nSummary.\n\nIn summary, the main purpose of this research was to establish a\n\n\nfoundation in reliable control system design methodology which would\n\nprovide the basic concept of a reliable control system.\n\nIn achieving\n\n\nthis goal, the linear quadratic variable actuator control problem was\n\nstudied in some detail.\n\nOptimization problems were formulated which\n\n\nrepresented both system performance (in the quadratic performance index)\n\nand system reliability (in the expectati6n of the performance index over\n\nall possible structural trajectories).\n\nThe optimal control law was\n\n\nsolved analytically for the deterministic system; this was the switching\n\ngain solution.\n\nIt was clearly illustrated by example in Chapter 2 that\n\n\nthe switching gain control law could not be extended analytically to\n\nthe control of stochastic systems.\n\nThis example demonstrated the dual\n\n\neffect of the control law; in general, the control law will influence\n\nthe measurement accuracy optimally (in the sense of minimizing expected\n\ncost) when the control can influence the accuracy.\n\nStochastic extensions to the switching gain methodology were proposed\n\nin Chapter 4.\n\nIn particular, the dual identification algorithm is an\n\n\nillustration of the self-testing capacity of dual control laws.\n\nThe\n\n\nstudy of the uses of the dual control effect in the design of reliable\n\ncontrol systems is a promising research area of the future.\n\n\n188\nIn Chapter 5, the non-switching gain solution was developed.\n\nThis\n\n\nsolution led to an algorithm for the determination of robust linear\n\nconstant gain control laws for a set of linear systems with different\n\nactuator configurations.\n\nIn addition, the resulting gains are optimal\n\n\nwith respect to a given quadratic performance index and exist if and\n\nonly if any robust gain exists.\n\nIn conclusion, the unifying concept of this report is:\nconstitutes a reliable control system, or a reliable design?\n\nWhat\n\nA major\n\n\nconnection was established in this research between the concepts of\n\nreliability and stabilizability.\n\nIterative procedures were developed\n\n\nfor the determination of whether or not a given linear system of the\n\ntype considered in this report is reliable, with respect to both class\n\nI and class II controllers; i.e., non-switching and switching gain\n\ncontrollers, respectively.\n\n\n189\n\nAPPENDICES\n\n\n190\n\n\nAPPENDIX\nTO\n\nCHAPTER 1\n\n\n191\nDEFINITIONS FROM MIL-STD-721B\n\n25 August 1966\n\n\nRELIABILITY\n\nThe probability that an item will perform its intended function\n\nfor a specified interval under stated conditions.\n\nAVAILABILITY\n\nA measure of the degree to which an item is in the operable and\n\ncommittable state at the start of the mission, when the mission is\n\ncalled for at an unknown (random) point in time.\n\nDEPENDABILITY\n\nA measure of the item operating condition at one or more points\n\nduring the mission, including the effects of Reliability, Maintain\n\nability and Survivability, given the item condition(s) at the start\n\nof the mission. It may be stated as the probability that an item will\n\n(a) enter or occupy any one of its required operational modes during a\n\nspecific mission, (b) perform the functions associated with those\n\noperational modes.\n\nCAPABILITY\n\nA measure of the ability of an item to achieve mission objec\xc2\xad\ntives given the conditions during the mission.\n\nOPERABLE\n\nThe state of being able to perform the intended function.\n\nMAINTAINABILITY\n\nA characteristic of design and installation which is expressed\n\nas the probability that an item will be retained in or restored to a\n\nspecific condition within a given period of time, when the main\xc2\xad\ntenance is performed in accordance with prescribed procedures and\n\nresources.\n\nSURVIVABILITY\n\nThe measure of the degree to which an item will withstand hostile\nman-made environment and not suffer abortive impairment of its\nability to accomplish its designated mission.\n\n192\n\nAPPENDIX\n\nTO\n\nCHAPTER 2\n\n\n193\nA2.1 \tExact Optimal Solution for Deterministic Case, Chapter 2,\n\nSection 2.\n\nFrom (2.2.7) and using dynamic programming, we wish to minimize\n\nV(X\n\n,\t\n\n2\n2\n\nk(t-l), ut, t) = E(qxt + ru t\n\n\nu\n\n+ v*(axt\n\n,k(t), t+lI x )\n\n(A2.1.1)\n\n\nwhere V (-,k(t), t+l) represents the minimum cost-to-go, given\n\nk(t) at time t+l-.\n\nThis minimization can be carried out because xt is known exactly\n\nat time t, and therefore ft-lis knownexactly by equation (2.2.10).\n\nThe control ut is computed from\n\n0\n\nqs2 + ru\n+Tr\n\nV\nt\n\n\nt +\n\n(axt+\n\nut\n\n0tV (ax +bu\n\nt\n\n,\n\nk=0,t+l)\n\nk=l,t+l)\n\n(A2.1.2)\n\n\nand the assumption that\n\n*\t\n\n2\n\nV (Xe, k=i, t) = xt Si~ \t\n\n\nresulting in equation (2.2.8).\n\n(A2.1.3)\nEquations (2.2.12) and (2.2.13) are\n\n\nthen obtained by substitution of (2.2.8) into\n\n(A2.1.1); these\n\n\nequations validate assumption (A2.1.3) by induction.\n\n\n194\nA2. 2\n\nExact Optimal Solution for Stochastic Case, T=0, 1, 2= Tf\n(l-d example).\nThe formulation is the same as in A2.1, except the system is\n\nnow represented by\nbk(t) ut +\n\nXt+l =axt+\n\n(A2.2.1)\n\nt\n\nt is white noise with zero mean, variance\n\nE, and probability dis\xc2\xad\n\ntribution p (i), which is uncorrelated with any other variable.\n\nTo\n\n\nillustrate the complexity of the solution, the time set is chosen as\n\n{0,1,2}.\n\nThe problem is to find u0 and u I such that\n\n\nv(x ,0)\n\nE(J)\n\n=\n\n. [\n\n( q+ u2r) +2q(A2.2.2)\nt=0\n\n\n*\n\nis minimized.\nut =\n\nLet V\n\ndenote the minimum value of V.\n\nAssume\n\n\nt(Zt)\n\n(A2.2.3)\n\nt is a mapping from the information at time t (Z ) into the\n\nwhere\n\ncontrol space.\nZt =47T0\'\nthen\n\nx 0\'\n\nu 0\'\'\n\nu t-I\n\n12\n\n*\nV (x 0\n\n,\n\n0)\n\n0\n\n(Z0\n\nby dynamic progranming.\n\nV*(xl)\n\nBut V (x2 ,.2)\nV*\n\n=\n\n1\n\n0 r\n\n+V\n\n(x 1 ,l)I Z0\n\n(A2.2.5)\n\nAlso\n\n\nmi\nU=\n\n*\n\nEj x 0 q+u\n0\n\nmin\nu0=\n\n*\n\n(A2.2.4)\n\nI xt]\n\nE\n(Z )\n1\n\nx 2\ng\n1\n\n\n+\n\nu2 r\n1\n\n\n+ V\n\nzj\n\n(x 2)J\n\n(A2.2.6)\n\n2\n\nx 2 g, so (A2.2.6) becomes\nUl= rmin\n01l(Z\n\n1) 1\n\nS\n\nUl=\n\n)\n\nE Ix2lq+ u{2r+ x2qiz 1 }\n1\n1\n1\n\nmin\nE\ni (Z 1 )\n\nx2\n\nq +\n\nu2r+\n\n(ax\n\n1 +\n\n(A2.2.7)\n\nu\n\nb\n\n+C\n\nqiZl\n\n1\n(A2.2.8)\n\n\n195\nnow, Z1\n\n{Tr0 \'X0u0x\nl}\' so\n\n=\n\nU =\n1\n\n(A2.2.8)\n\n+\n\ni (lll)\n\nwhere\n\n+ n2r\nxq\n14)q(+\n\n(Z) ) )1I2r\nI\n\n[t\n\nIfi (l1)\n\nmin\n\n=\n\nE\n\n2\n\n(axl+ biUl+\n\nis the probability that k I\n\n=\n\nl2q]\n\ni, given Z1.\n\n(A2.2.9)\n\nBringing the\n\nexpectation inside the sum,\n\n(A2.2.9)\n\nin\nu 1 1 (Z1)\n\n=\n\nxg + u~r\nq\n\n2 2\n\n\n2x2\n+\n\nt\n\nr(11) (a x\n\n+bu\n\n+ n + 2abixlUq\n\nI\n\n(A2.2.1O0\n\nDifferentiating (A2.2.10) w.r.t. u1 and setting the result equal to\nzero:\n\n2ru 1\n\n+\n\ni (Illl) (2b2\n\n+ 2ab xl)q\n\n1\n\n(A2,2.11)\n\nor\n\n=\n\nJr (ll)bi\n\n-\n\nr +\n\n[t\n\nqa\n\nii(l11)b\n\nq\n\n(A2.2.12)\n\n\nq\n\nSubstituting (A2.2.12) back into (A2.2.10), define S 1 and T\nT1\n\n=\n\n-q\n\nS1\n\n=\n\nas\n\n(a2 + 1)q\n\n2\na\n\n(A2.2.13)\n\n1\nrTr\n\n(411)b2\n\ni\n\n(1I1)b]\n\n(A2.2.14)\nq\n\n196\nand\n\n\n2\n\n*\t\n\nV(xl)\n\nXlS\n\n=\n\n1\n\n11\n\n+ T \t\n1\n\n(A2.2.15)\n\nA few remarks must be made about the probability distribution over kt\n\ngiven Zt or Zt+.\n\n\nNotation:\n\nr.(tlt)\n\n=\n\n1. \t\n\nprobability that k t = i, given the available information Zt\nt\n\n\xc2\xad\n\nprobability that kt = i, given the available information\n\n\nI\'.(tlt+l) \t =\n\nZ t+t\n\n\nFrom the Markov property,\n\n7r(tlt)\n\n=\n\npi7(t-1It)\n\n(A2.2.16)\n\nEquation (A2.2.16) is the propagation equation for the distribution W.\n\nThe form of the update equation is given and proved in the following\n\nlemma:\n\n\nLemma A2.1:\n\n\n7Fi(tlt+l)\n\n=\n\nP(xt+ 1 t-b ut)T\xc2\xb1(tlt)\n(tlt)\n30 p (Xt+l-aXt-bju t )7 j\n\nProof:\n\nNote that\nP(Xt+l-axt-b iu\n\n=\n\nP(x\nt+iztut,k(t)=i)\n\nwhere u t is not a random variable.\n7i(tlt)\n=\np(k(t)=iZ t)\n\np(k(t)=i,Tf 0 \'x 0 ,Uo\n\nP O XOUo.... xt)\n0\n\'\n\nAlso,\n\n...\n\nxt)\n\n(A2.2.17)\n\n197\n\nthen (A2.2.17) becomes:\n\n\np(k(t)=ilz\n\nP(Xt+iIzt ut k(t)=i)p(k(t)=iIzt)\n\nP(x t+l Zt , u t )\n\n)\n\n\nt l\n\nwhich is Bayes rule.\n\nQ.E.D.\n\nReturning to equation (A2.2.5), and substituting (A2.2.15),\nV (x0 ,0)\n\n=mn\n\nmin\n\n=\n\nE\n\nx2q + u2r + x2S\n1\n\n0 x2q\nUo=4 o(Zo E (\n\n\n+ T1 lo\n\n\n0\n\n0\n\n0\nUo=4 o(Z\no)\n\n(A2.2.18).\n\n+ u 0r + 7q\n\n[trcI1b2q2a2]\n1+)\n\nr\n\n-\n\n+\n\nV2\nminu\nu0\n\n(I1)b2q]\n\nZo}\n\n(A2.2.19)\n\n2\n\nx q\n0\n\n[\n\n\n+\n\n+\n\nu0 r\n\nq\n\n\n(\nx\n\n\n0\n\nrr\n=\n\n(\n\nr\n\n2\nr +\n\nI0\n\ndp(xl)k l\n\n, k 0 , Z 0 )p k l 1\n\n1)bij2q 2a2\n\nii\n\nITi(lIl)b]\n\nk\n\nqJ\n\nI\n\n(A2.2.20)\n\n\xc2\xb1Ikrkw&Pk] ir0,\nwhere\n\nIk\nirk\n\n(I \n\n\n=\n\nPkt\np(xl-ax0 -b\n121)\nk\n\n0\n\n)iu , \n\nj(A\nj0\n\nI\n\n)\n\n4\n\np (x l\n 0 -b i u 0 ) i,\n-ax\n\n0\n\n\n2.21)\n\n198\n\nEquation (A2.2.21) is a combination of equations (A2.2.16) and (A2.2.17).\n\nEquation (A2.2.20) can only be solved numerically (in general); this\n\nrequires a numerical minimization of a function -he -computation of which\n\nrequires four numerical integrations -- a difficult task.\n\n\n199\nA2.3\n\n0, 1,\' 2 = Tf\nExact Solution of Stochastic Case Over T\nfor a Specific Form of PQ(), Chapter 2 Section 2.3.1.\n\nAssume, for the problem in A2.2, that\n\n2/SE P(\n0\nSuppose\n\n-V3= < C <y7\n\n, for\n\n=(a2.3-1)\n\n)\n\n,otherwise\n\nIu 1 > 0 is large enough such that\n0\n\nP(2(b k-bi)u\n\n0\n\n+\n\n0,\n\n=\n\ni\n\nk0 and\n\n0\n\ns\n\n[-E/i0C\n,9\n\nThen\n\nt\n\n1\n\n3\n\nl__i\n\n0\n\n4-O\n\np i j p (x -ax0 -b j u 0 )b.\n1\n\n.\nP(xl1-ax O-bk uO Fk,G\n\nT 1)\n(01\n\n2v\'E)\n=\n\n=\n\nt\n\n(A2.3.2)\n\n0\n\nb}\n\npikb,\n\n(A2.3.3)\n\n(A2.3.4)\n\nSimilarly,\n\nb2(235\nik b\n\nIT.(11l)b\n=I\n\n(A.35\n\nThen, from equation (A2.2.14),\n\nS(a\n\n+)q\n\n-\n\na\n\nPikbi\n\nr +\n\n[\n\n2q2\n\nOpi\n\n(A2.3.6)\n\nq\n\n200\n\n\nu0=\noo\n\n\nFrom equation (A2.2.20),\n\n*\t\n\nx0,0)\n\n2\n\nq + u0 r+\n\nx2\n\nmin\n\n+\t\n\nEq\n\n\n(ax\n\n=\n\nu\n\n+b\n\n+\n\n2\nd0 (k)O\n\na \n\n\nCa\n\nkR(Ek0\n\n~~ ~ r2\n\n2\n\n(A2.3.7)\n\n\n=mi.n\n\n00\n\n2\nx0 q + u2\n0\n\n.\n\n(z)\n\n\nu0=\n\ntko\n\n+\t\n\n0\n\nPkk\nO\n\n0\n\nik0\n\na2\n\t\n\nq2\n\nik0 b\nr\n\n+\n\nu\n\n2\n\nabk X\n\n0\n\n2o0 0\n\n(\n\n+\n\n(a2+1) q-\n\n+\n\n(ax\n\n0\n\nk1 k\n\n-\t\n\n+\xc2\xb1\n\no\n\n++Uor+ \t\n\na\'\n\nk 0 =0\n\nHEq\n\nr +\n\nik 0\n\n\'\n\n)\n(A2.3.8)\n\n__\n\ni\n\nDifferentiating with respect to u0 , and noting that S\n\ndoes not depend\n\non a0,\naV*(XC ,0)\n0\n0 \tu\n\nD\n1\n=\n\nThen,\n\n\n2u\n\n0\n\nr+\n\nL\n0=0\n\n1\n\n0\n\nt\nk0\n\nk\n\nkk(\n\n2\n\nb2 u\n\n+2ab0x 0 ) S\n0\n\n\n(A2.3.9)\n\n4\n\n201\n\n1\n\n1\n\n\nu0\n\nr + k00 7k,0\nk00\n0\n\nZ\n1=\n\nThis solution is valid only when\n\nx\nPklk b\nS\n1o 00\n\n\niu 0 !\n\nI (bk0-b i\n\n)\n\nu0\n\nC 1\n0\n\n>\n\nV3 n ,\n\n>0 is large enough such that\n\n[F0 V3-,\n\nQ((bk0-bi)u 0 + g0 )=o, i7k0 and\n+\n\n(A2.3. 10)\n\nt 0 E: [\n\n-\n\n3 -\n\nV3ET. \n Thus,\n\n,3 V\n\n(A2.3.11)\n\nmust be satisfied.\ni)\n\nAssume (bk -bi) u0> 0.\n\nThen (A2.3.11) is satisfied if\n\n> V\n\n(bk -bi)u 0-\n\n(A2.3.12)\n\nor\n\n(bk-b.) u0 > 23r-E\n\nii)\n\n(A2.3.13)\n\n\nAssume (b\nk-b )U 0 < 0, Then (A2.3.11) is satisfied if\n\n\n(bk-bi)u0 + V\n\n< -V3=\n\n(A2.3.14)\n\nor\n\n(b\nk-bi)u0\n\nT\n\n<-2jr3\n\nTherefore, u 0 must satisfy\n\n\nI(b\n\n-b )uI > 2V(2\n\nfor (A2.3.10) to hold.\n\n0\nNotice also that "when (A2.3.10) is the optimal solution, no is\n\n\nidentical to the deterministic solution.\n\n\n(A2.3.15)\n\n\n202\nA2. 4\n\nExistence of Steady-State Solution for l-d Example.\n\nFrom Chapter 2, Section 2.2, the coupled Riccati equations for\n\n\nS\n\nand S1 are\n\n] 2\n\nS,t+ 1 + P21 (a/b)S ,t+l\nlab \n\n1[r\n+ pl1\n\n0,t+l + P21 (1/b2)Sl,t+]2\n\n\nr[p\n0,t\n\nq\n\na b S 0 ,t + \n\n\nb[pp\n++ p\n+p1 a\n\n+\n\nS\n\n11\n\n-\n\n+ P21(a/b)S ,t+l 12\n\n\nb \n\n\n+ p \t\n\n0t+1t\n\n\'1/b2)Sl\n\n,t+l\n1~\n\nP 2 1(a/b)S\n\nS\n\np 1 abs 0 ,t +\n + P 2 1 (a/b)-Sl,t+l\n1\nbr\nl 2 ,t+1\nP21(1/b2)Sl,t+l]\n\n(a1\n\n2\nSI,t+l\n\n(A2.4.1)\n\n] 2\n\n\nSI~\n\nr [p12abS0,,t+l + P22 (a/b)Sl,t+l\nq + -[r \n + pl b2S0,\n+ P22(1/b 2)Sl\n12\n\nrP2\n\n+\n\n(a\n\n22 \t a\n\nO,t+\n\n+ p2\n\nP 1 2 abS\n\nl\n\nb\n\n22\n\n2oSt,t+l\n\nt +\n\n0\n1+\n\n22\n\na\n\n+\n\n2l\n\nt+l\n\nP22 (1/b2)S,t+\n\n\n(a/b)S l,t+l\n\n2\nb[r + p 1 2 b So,t+ 1 + p 2 2 (1/b )S ,t+l\n\n)\n\n2\n\nlt+1\n\n(A2.4.2)\n\nDefine\n\n\nht\n\nSih t\nS0, t\n\n\n(A2.4.3)\n\n\n203\n=\n\nr\n\nS\n\n0,t\nS0,t+l\n\n\n(A2.4.4)\n\n\nDividing both sides of equations (A2.4.1) and (A2.4.2) by Sot+l\n\n,\n\nmanipulating terms, and using equations (A2.4.3) and (A2.4.4) yields:\n\n\nr \n\n\n-\n\n1\n+\nSo\'t+l\n_\n\nq\n\nSot+l\n\nt+ 1 2\n\n2 (a/b)h\nr[P 1 1 ab +p\n 1\n[(/SOt+l) + Pllb + P21 (/b2 )h2t+l\n\n\na\n[pll1 b+ p21 (a/b)ht+l].\n(r/S0,t+l) + Pllb 2 + P2l(1/b 2)ht+l\n\n+b\n1\n\np la b + P 2 1(a/b)ht+l\n1\n+ P21 (a\n\n-b(r/\n\n2\n)\n\n\n2\n\nb2 \n\n\n+ p 2 1 (1/b2 )ht+)\n\nSo,t+ 1 a) P\n+\n\nh\nht+i\n\n(A2.4.5)\n\n\nh F\n\n+\n\n- q\nS0,t+l\n\n2\n12\n\n1\nS0,t+l\n\n\n\n\n[r/S\n\n0\n\n+ p\n\nb2\n\n+\n\nl2\n\n2\n\n+ P2(11b2)ht1l\n\n\nb[Pl 2 ab + P 2 2 (a/b)ht+l]\n2\n\n(r/S0,t+l) + P 12 h +P 22 ( 1\nS\nP2ab\n\np2\n2\n\nt+\nr[P 1 2 ab + p 2 2 (a/b)h\n\n2\nh~\n\n\np 22 (a/b)ht+\n\nb[(r/S 0,t+l) +lb\n12\n\n2\n+ P22ht/lb 2\n]\n\nt+ 1\n\n(A2.4.6)\n\n\n204\n,t\n\nAssume S 0\n\nas t\n\n"\n\nand h t\n\n-\n\nrt\n\nh,\n\n2\n\nlab + p 2 1 (a/b)h]\n\nS1b[p\n\nThen\n\n- r.\n\np 1 1\xc2\xad 2 + P 2 1 (/b2)-\xc2\xad\nb[pll1b 2\nP1lab + p+ 2 p 21 h/b2 ]\t\n1 (a/b)h\n\n+ 21\n\nA2.7\n(A2.4.7)\n\n2h \t\n\nand\nb[Pl 2 ab + p 2\n\n(\n=\n\nh\'\n\np1 2\n\n2\n\n-\n\n2\n\n(a/b)h] )2\n\n+ p 2 2 (1/b2 )h\n\n(A2-4.8)\n\n\nb 1\nab + + 2 (\nP [p12 b2 p 2 p 22h/b ]2 \\\n2\n\nP22\n2\n\nLet\n[P\n\n[P\n\np 1 21\n\n[p21 p\n22]\n\n1-\n\n2 ](A2.4.9)\n\n1il 2\n\nThen\n\np=1 (a-b[lab\n\n(1-p ) (a/b2)h h\nI\nSp b 2 -+ + (l-pl)(a\n1\n\n+\t\n\n)h\n\n(a/b\n\n+\naib (1-p)\n\n(a\n\n/\n\n)2\n\n\np ab\n\n+ (-p)(a/b)h\n2\nb2 + (1-Pl)h/b\n[p 11\n\n(-p\n\n(A2.4.10)\n\n2h\n\nand\n\n\nhr\n\n(1-p\n\n2\n\n) (a\n\n-\n\nb[(1-P2)ab + P 2 (a/b)h] \\2\n\n2\n)h]\n\n(1-p 2 )b 2 + p 2 (i/b\n\n/\n\n(-P\n\nP2\na\n\nb[(l-p 2 )b2 + p 2 (1/b2)h]\n\n2 )ab\n\n+ p\n\n2\n\n(a/b)h\n\n2h\n\n(A2.4.11)\n\n206\n\nAPPENDIX\n\nTO\n\nCHAPTER 3\n\n\n205\nSolving for h and F from equations (A2.4.10) and (A2.4.11), if\nthen there exists no steady-state solution.\n\nr\n\n> 1,\n\n207\nA3.1\n\nProof of Theorem 1.\nAssume x k,\n\nx\n\n=\n\n,t+\n\n1\n\nfor k/i.\n\nThen (Bk - B\n\nwhich implies ut-1 is in the null space of B\nNow, dimension (N(B k\n\n-\n\nk\n -\n\nBP\n\n)ut\n.N (B\n\n-k\nB\'\')<m because the Bk\'arditn.\n\n1\nk\n\n= 0,\n\n- B\n\n).\n\n-k\n\n\nTherefore,\n\nN(B -B\n)) <m\ndimension (U\nm\nk,i\nhas measure zero in R .\nN(Bk -13\nTherefore the set\n\nk, P\n\n(A3.1.1)\nQ.E.D.\n\n208\nA3. 2\n\nOptimal Solution for Deterministic Problem.\n\nFor the system\n\nx t+\n\nAxt+ Bk(t\n\nl\n\nBk(t)\n\nwhere\n\nut\n\n(A3.2.1)\xc2\xad\n\nk\n\n=\n\nlt+l\n\n)\n\n(A3.22)\n\nR L+ l\n\ntE\n\nEat\n\n(A3.2.3)\n\n= probability of B\n\nT\ni\n\nat time t.\n\nAssume that\n1) -t\n\nx\n\nis observed exactly\n\n\n2) then Bk(t-l) changes \n to\nBk(t)\n3) then ut is applied\n\nFrom dynamic programming, the optimal cost-to-go at time t is given\n\nby\nV*(x\n\nt\n\n,k(t-l),t)\n\n= min\nut 4\xc2\xa2-t It\n+ V (xt+\n\n1\n\nE\n\n,k(t),t+l)\n\n(x T\nk\n\n+Qx Ru\nT\n\nt\n\n(A3.2.4)\n\nAssume\nV*(x\n-t\n\n,k(t-l),t)\n\n=\n\nT\nxT S\nx\n-t-k,t-2Et\n\n(A3.2.5)\n\nThen\n\nT\nXt~kmt x\n\n+\n\nt\n\ninxtT\nrant-u ( x t\nI t\nt\n\nZPik(AXt\n\n+ Bit\n\n)\n\nQx\nx\n\n+\n\nuT\nt\n\n)Tsi,t+l\n\n(Axt + Biuti\n\n(A3.2.6)\n\nlz+IIQ+G\n\nG 11\n\n215\nfor all T.\n\n-\n\n-I\n\n(A5.1.10)\n\nII\nQ.E.D\n\n214\n\nA5.1\n\nProof of Theorem i, Chapter 5.\n\n\ntr[Et (Q+GT RO )] + tr[ETQ\n\nJTT =\n\n(A5.1.1)\n\n]\n\nT\nand JT<B.\n\nSince Q + G\n\nlir tr[StI\nt\n\nRG > 0 and is constant for all t, this implies\n\n0\n\n=\n\n(A5.1.2)\n\nwhich is exactly Definition 1.\n\nFrom equation (5.4.6), note that\ni=0 = F((-i\'t L )\n=0(A5.1.3)\n\n(--i,\n()L t+l\n\nL\n\ni=0"\n\nwhere F(-) is linear in (E-\n\nSince\n\n] = 0\n\nlim tr[E\nt+>\xc2\xad\n\nfor any choice of 1-"0\n\n:J\n\nF n\n\n(A5.1.4)\n\n,\n\nF 11 is bounded and\n\nF\nIi 11< 1. \n (Otherwise,\n\n(Z--0 )11-_4 0.)\n\n\nThen\n\n1 J\nn JT\n\n<\n\n<\n\n=T\nA.4\n\n1tr[\nn\n\nI\n4-It\n\n1 tr[Z(Q\n-t-n-T\nn\n\nt\n\nGT\n\nR\n\n\n1 1 tr[Q + GTRG]\nn\n\n1Eo11 II 1Q\n\n<tS lFIjlt (iII\n\n- F\n\n+\n\n+\n\nG\n\n+ 1 tr[)Z\n\n+ 1 tr[Z\nn\n-T\n\nI -tr[Q]\nn\n\n\nGTRGII +jF IIT 1II 1111211\n\nT\niIQ + G RGII )\n\niII 11Ri\n\n(A5.1.5)\n\n\n(A5.1.6)\n\n(AS.1.7)\n\n(A5.1.8)\n\n209\n\nand\n\n(A3.2.6) =\n\nmain\n\n+ \t \t Pk\n+\n\nT\n+ ut-Ti-i\'t+S\n\ni\'t+iLxt A x\n\nx\nT T\ntA\n\n+\n\n+ uT Ru\n\n\nxTQx\n\nt-t\n(x t )\n\n\n-t -\n\nT\n\n1\n\ni1\n\nT\nA\n\n-utBSi\'\n\ni\'t+lBit\n\nBiu\nli~\n\nDifferentiating the r.h.s. of (A3.2.7) w.r.t. u\n\nt\n\n(A3.2.7)\n\nand setting equal\n\n\nto zero:\n\n\n0\n\n= \t 2Ru-t\n\nPik\n\n+\n\n-l-~\n2B .S\n\nB\n\n+\n\niu\n\n2BS\n\nAx\n\n(A3.2.8)\n\n\nor\n\n\nU \t\n\nR\n\nf\nis the \t ptimal ut\no\n\nPikBiS i,t+l Bi\n\n\n+\n\ni\n\nS i,t+l Ax\nL\t\n\nik\n\n(A3.2.9)\n\ngiven k(t-1).\n\n\nSince no noise is present in the system, k(t-l) is obtained from\n\nx-t andx\n\nk(t-l)\n\n,\n\n= i\n\nalong withu\n\niff\n\nxt\n\n=\n\n,\n\nas\n\n---- t-l\n\n+ Biut_\n\nSubstituting (A3.2.9) into (A3.2.7), and eliminating x\nx\nequation must be true for all -t\n\n(A3.2.10)\n\n1\t\n\nt\n\nbecause the\n\n\nand the matrix equation is symmetric,\n\n\n210\non simplification we obtain\n\nk\n\n=\n\nM\n\nPik\n\nAT\n\nSi,t+l\n\nPik 2i,t+l~i\n\nPik\n\n4i -i,t+l\n\n]\n\n1\n\n+\n\nA\n\n+\n\n=\n\nQ\n\nik\n\n%i-it+itj \n\n\n-I\n\n(A3.2.11)\n\n\nwhich verifies assumption (A3.2.5) by induction, along with the initial\ncondition\nSk,T\n\n(A3.2.12)\n\n211\nA3.3\n\nProof of Lemma 1.\n\nConsider the optimization of the cost-to-go given k(t-l) at time\n\n\nt with final time T.\n\nThis optimal cost-to-go is simply\n\n\n*\n\nV\n\n(xt\n\n,k(t-1),t)\n\n(A3.3.1)\n\nwhere T denotes the final time.\n\nFor the process with final time T+l,\n\nthe optimal cost-to-go is\nV T (x\n\n,k(t-1),t)\nT\n\nT-t\n\n\nE\n~~~~xQx\n\n+ uT Ru T\n----\n\n+XTQk(t1 I kt-l)\n-T+l Q-T+l\n(A3.3.2)\n\n\nSince this optimal sequence is not necessarily optimal for the problem\n\nwith final time T, it must not incur less cost over\n\nIt,...,T}.\n\n\nVT+l (x t ,k(t-l),t)\n>\n\nV\n\nT\n\n(x\nE\n\n+\n\n,k(t-l),t)\n\nt\n\nUT hUT + X T\n\nI\n\nQx\n\nk(t-)\n\n(A3.3.3)\n\nSince the expectation term of equation (A3.3.3) is non-negative,\nVT+\n\n(xt\n\n,k(t-l),t)\n\n> V T (x\n\nt\n\n,k(t-l),t)\n\n(A3-3.4)\n\nNow, note that\n\n\nT\n\n*\n\nVT (x\n\n,k(t-l),t)\n\nx TS\n\n(A3.3.5)\n\nand that equation (3.3.6) depends only on the number of iterations\n\n(T-t) for the calculation of S itT\n\nVT (x\n\nt\n\n,k(t-1),t-1)\n\n=\n\nVT+ 1 (x\n\nand therefore,\n\n\n,k(t-l),t)\n\n(A3.3.6)\n\n212\nTherefore,\nS\n-i,t-1\n\n{S i\'t) t=T is an increasing sequence in that\n-S-lt -\n\n>0\n\nSince, by hypothesis, VT\n\n(A3.3.7)\nis bounded over t, the S\n\nconverge.\n\nQ-i,t\n\nQ.E.D.\n\n\n213\n\n\nAPPENDIX\n\nTO\n\nCHAPTER 5\n\n\n216\nA 5.2\n\nProof of Remark on Theorem 1, Chapter 5.\n\n\nJ\n\ntr[Et\ntrt\n\n=\n\n(\n\n+\n\nTRGt)]+ tr[T\n2tL\n\n-T-\n\n(A5.2.1-)\n(S2L\n\nand\n\nt= tr[Z tQ\n\n(A5.2.2)\n\n<_ JT\n\nSince Q > 0\n\nt\n\ntr[\n\nt ] is bounded.\n\n(A5.2.3)\n\n\nTherefore\n\ntr[Z\n\nt\n\n] +0\n\nas t-+-.\n\n(A5.2.4)\n\nThe reverse implication is shown to be false by example*\n\nExample 1:\n\nConsider\n\n\t\nxt+1 = u t\n\n(A5.2.5)\n\n\n\n\n\nxt\n\nut =\n\n(A5.2.6)\n\n\n\n\n\nThen\n\n\t\nE[x 2 ]\n\'t\n\n=\n\nt 1l\nt-Il\n\n0\n 0\n\n(A5.2.7)\n\n0\n\n\nbut\n\nT\t\n\n2T\n\nS]\n\n*\n\n=0t=0\n\n+\n\n\nExample 1 is provided by Dr. D. Castanon of ESL.\n\n217\n\nA5. 3\n\nProof of\'Theorem 2, Chapter 5.\n\n\nLet I = {O,\n\n1, 2,\n\n,\n\n-..\n\nL}(A5.3.l)\n\n\nand\n\n=\n\n{(k(O),\n\n--1 k(i)t\n\nk(1),\n\nI\n\n(A5.3.2)\n\nDefine the function 11on the cylinder sets of \xc2\xa3 (I)\nK-\n\n{(k(O),\n\nk(l),\n\n...\n\n)I\n\nk(i) fixed for i<T}\n\n(A5.3.3)\n\nfor arbitrary T by\nP(k)\nwhere 7\n\n0\n\nk() 0Pk(1)k(0) \'k(2)k(1)\n\n=\n\nPk (T)k (T-)\n\n(A53.4\n\nis the initial probability distribution over I and P = \'(p..)\n0i\n\n\nis the stochastic matrix of transition probabilities for the Markov\n\nchain.\n\nBy a theorem of Andersen and Jessen [Loeve, p.91,42], this\n\n\nfun6tion defines a measure, x , on the a-algebra of 2P(I) generated by\n\nthe cylinder sets, cit(I))\n\nSince p(C(I))\n\n1, from the definition\n\n\nof jion the-cylinder sets of k.(I-,.\n\n\nU: a(.\n\n(I)) + [0,1]\n\nCA-5.3.5)\n\nis a probability measure, and since V extends uniquely from the cylinder\n\nsets, it is the probability of occurance of elements of\'C(9\n\n(1)).\n\n\nLet\n\nT (x)\n\n: Rn\n\n(A5.3z6)\n\n[0,-]\nT-\n\nJT(;) (x)\n\n=\n+\n\n+\n\nAitQxt\n\nXTQXT\n\nutRu\n\nt\n\n(AS.3.7)\n\nwhere\n\nx\n\n= A x\n\n+B k\n\nn\n\n(A5.3.8)\n\n218\n\nUt\n\n=\n\nGtx\n\nxc= (k(0),\n\n(A5.3.9)\n\nt\n\nk(1),\n\nk(2),...)\n\n(A5.3.10)\n\nand let\n.1. lim\n=\nT+\n\n(A5.3.11)\n\n\nSince JT is constant on the cylinder sets with fixed sequences of\n\nlength T+l, JT is measurable.\nsets.)\n\n(There are a finite number of such\n\n\nBy Theorem A of [Halmos, p.84,101,J is measurable with respect\n\n\nto ].\nJ()\n\n\xc2\xa3 (1)\n\n[0.,c]\n\n(A5.3.12)\n\nLet\nIx Ckw(I)1\n\nX,\n\nJ(x) (x) <-\n\nfor xEsRn }\n\n(A5.3.13)\n\nand\n\n-x\n\nX\nThen\n\n=\n\nX\n\nandX2 are measurable subsets of\n\nEU]\n\n<\n\n*\n\n(A5.3.14)\n\n1\n\n2\n\n(I),\n\nand therefore\n\nP X2) = 0\n\n(A5.3.15)\n\nbecause J(x) is a non-negative function on R 1\n\nBut\n\n3\nx[E[]] = tr[Z0 sJ\n\n(A5.3.16)\n\nfrom equation (5.7.14), and by hypothesis, r.h.s\nTherefore, any trajectory x is an element of X\n\n1\n\n(A5.3.16) is finite.\n\nwith probability 1,\n\n\nand has finite cost.\n\nTherefore, {Gt=\n\n0\n\n\ncost-stabilizes (5.3.1) with probability 1. Q.E.D.\n\n\n219\n\nProof of Theorem 3, Chapter 5.\n\n\nA5.4.\n\nIn the proof, the sequences (G)m\n\nNotation:\n\nwill\n\n\nrespectively.\n\n\nG\nand -ns\n\n--\n\nbe referred to by G\n\nand (G\n\nProof:\n\nSuppose G-ns\n\n(>)\n\nI)\n\nThen J(G ns ) <\n-\n\n-\n\n\nTherefore, J(G )< J(G ns )=>J(G )< m.\n\n\nminimizes J.\n\nBut G\n\nis cost-stabilizing.\n\nis cost-stabilizing.\n\n\nThus, G\n\n(<=)\n\nII)\n\nJ(G )\n\nThen J(G )<\n\nis cost-stabilizing.\n\nSuppose G\n\nwhere\n\n*\n\n*\n\n(A5.4.1)\n\nJrn\nJT(G )\n\n=\n\nE\n=\nSince E [Jfls (G)] \n JT(G),\n\nJ(G ) =\n\nr\n\nx\n\nT+\n\n(C)] = E [Jns(G\n[J\nx\nns-\n\n]\n\n(A5.4.2)\n\nwhich implies\n\n((A5.4.3)\n\n)<\n\nJ(G\n\n**\n\nSince GCn\n\nn,\nminimizes Cl\n\nns -ns\n\nns \xc2\xad\n\n)-\n\nand, since Ex[Jns\nJ(Gns\n\n)\n\n<\n\nthen\n\n]\n\n= JT for all T, for fixed G,\n(A5.4.5)\n\n-.\n\nG\nwhich implies that -hs\n\n\nis stabilizing.\n\nQ.E.D.\n\n\n220\n\nA5.5\n\nProof of Lemma 2, Chapter 5.\n\nFor the control interval starting at time 0 and ending at time T,\n\n\nthe expected cost for the optimal control Gt is\n\nJT = tr[z\n\n0\n\nS 0]\n\n(A5.5.1)\n\nT\nfrom equation (5.5.8), where the subscript T refers to the endpoint\nof the control interval.\n\nSimilarly,, for the same process ending at\n\n\nT+l, the optimal expected cost is\n\n*\n\nJT+l = tr[Z 0 S 0 (T+1)I\n\n= E E T\nr\n\nxT\nt(Q\n\n+*\n+ G\n\n+ xTIQ XTl\n\n=\n\n(A5.5.2)\n\nT R\nT+I)\nR Gt4l\nx t\n\n_t -t\n\n\n(TI)\nt(\nz_0 I Tr\n\n(A5.5.3)\n\nT+)T R Gt(T+l)\n\n\nEx\n\n+XTQX\n+E\n\n\xc2\xad\n\n-t\n011\n\n\n-t\n\nt-- t\n\nIhL , io\n\n0\n\nxT (G* (T+l)T R G\n\n(T+l) x\n\n- -T\n\n-T -T\n\n-T\n\n+\n\nQ\n-T+12---T+l\n\nI\n\n-0 ,--0\n-\xc2\xad\n\n(A5.5.4)\nThe first expectation of equation (A5.5.4) is the cost corresponding\n\nto the interval [0,T],\n\nand must be greater than or equal to JT; the\n\n\nsecond term is positive.\nJT+I\n\n>\n\nTherefore,\n\n\nJT \n\n\nSince JT is bounded by hypothesis for all T, there exists a J\n\n(A5.5.5)\n\nsuch\n\n\nthat\n\nlim JT =\nT.\n\n\nJ\n\n(A5.5.6)\nQ.E.D.\n\n221\nA5.6\n\nProof of Lemma 3, Chapter 5.\nBy direct computation,\n-J T+(G) = JT(G) + E[x\n\nT\n\n--. ..-f\nGT R G x\n\n+ xT T+1\n\nT\ng x T+\n\n(5..1\n(A6.1)\n\nand since the expectation is positive,\nJ T+(G) > J T(G)\nSince JT(G) is bounded, it converges.\n\n(A5.6.2)\nQ.E.D.\n\n222\n\nA5.7\nA)\n\nProof of Theorem 4, Chapter 5.\n\nnst\nG -- -.-G optbeas\nbecause G\n\n\nconverges to the steady-state value\n\n\nwhich minimizes the infinite-time horizon cost J\n\n, and therefore,\nns\n\nss\n\nby the argument given above, also minimizes equation (5.8.9).\n\n\nB)\n\nGiven E>0,\n\nI\n\na T>0 can be chosen which guarantees\n\nljji*t- F\n\nIIti<and\n\nJTr<E\n\n, for all\n\n-\n\nG I<e\n\n,\n\nt>T.\n\nThen, by the Principle of Optimality, the sequence {\nminimizes the infinite-horizon cost-to-go at time T.\n\n}t\nI\n\n\n\n\nconsider the\n\n\nproblem min Jss(G) for initial condition E, , ir , which has a solution\n\n\nG\n\nindependent of\n\n--\n\n.\n\nIn the limit as S 0, the sequence\n*ns\n\napproaches the constant sequence of gains C .\n\nSuppose\n\n2*t 1t=T(6)\n\n} 6>0\n\n- VT(s),\n\n\nthe optimal cost-to-go, satisfies\nVT()\n\n< Jss\n\n6\n\n(A5.7.1)\n\nThen the sequence of constant gains G\n\nwould yield a strictly\n\nlower\n\n\ncost J ss (G)\n\nJ\n\n(G)\n\n< J\n\n(A5.7.2)\n\nsince VT(S) approaches the optimal cost-to-go, given the constant\n\nsequence of gains G\n\n,\n\nin the limit, which is the solution to the\n\nequivalent problem min Jss(G) for initial conditions E\'\nG\n\ni"\n-\n\n\nTherefore\nG\n\nG\n\n-Ens\n\n(A5.7.3)\nQ-\n\nQ..E.DJ.\n\n\n223\n\nCOMPUTER ROUTINES\n\n\n224\nAIM FORTRAN\n\nSUBROUTINE AIM(NAAjX,t B, NQ,NR, GS,hA,\nN,M, ICCN,A,B, R,Q,P,\n1 SBT, E, S, M, U,V,W,X, Y, R,PZ, GNORM, R\\D, PADINV, BSB,WCRK, IPVI, IEND,\n\n2 IPRT)\nC\n\nC\t\n\n***\n**PARV4ETERS:\nINTEcER NAA, A,N3,NQ, NR, NG,NS,bA, N,M, ICN,IPVT (N) ,\nIEND, IPRT\n\nDOUBLE PRECISION BSB (NS, ?SA, IWCN),X (A, N) ,RAD (QRA, N) ,RADINV NRA, N)\n\nDOUBLE PRECISION E (KCCN) ,SBT(NS,N) ,A(NA,RkxA) ,T(NB,NAA, BCCN)\n\nDOUBLE PRECISION Q(NQ,N) ,R(NR,M) ,PC\'A,1ICCN ) ,S (NS, A,ECCN)\n\nDOUBLE PRECISION SB(NS,NhA,ICON) ,U(NA,N) ,VVNA,N)\n\n,W(NA,N),Y NA,N)\n\n-DOUBLE PRECISION PR() ,WRK(N)\n,PZ(N) ,(GORM(NG,&AA,kON)\n\n\nC\n\nC \t\n\n*****LOCAL VARIABLES:\nDOUBLE PRECISION COND\nINTE(ER KIN, BOUT, I,K,KKM ,KK, J,JEND, L,KP,KN 1,ICTM1,IM I\nINTEGER ICOUNT\n\nC\n\nC\nC\n\n*****SUBROURINES CALLED;\n\nM F,MAUD,MLINE Q,TRNATB, MMUL, MSCAIE,MATIO,EIGVAL,WEIGIT,WNATA\n\n\nC\n\nC\n\n.......\n\n::::::..\n\n:\n:::::.............."\n\n:\'::\n\n..........\n\n.... :.....\n\nC\nC\nc\n\n*****PURPOSE:\n\nC\n\nTHIS DOUBLE PRECISION SUBROUTINE CCMIUES THE STEADY-STATE OPTIMAL\n\nC\nC\nC\n\nSOLUTION AND THE CCRRESE0NDING OPTIMAL GAINS FCR.THE PROBLEM\nESCRIBED IN THE PUBLICATION: \' ON THE RELATIONSHIP BETWEEN\nRELIABILITY AND LINEAR QUALRATIC OPTIMAL CCNTROL\'\n\nC\nC\nC\nC\nC\n\nBY J. DOUGLAS BJRU9ELL AND M. ATHAN3.\n(EQUATIONS (29) AND (30)).\n\nC\nC\n\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\n*****pARMEa\'ER DESCRIPTION:\nI4 INPUT:\nNAA\n\nTHE SECOND DIMENSION OF THE ARRAS S,SB,Ci4ORM,\nBSB,B AS EECLARED IN THE CALLING PROGRAM\n\nDIMENSION STATEMENT;\nNA,B,NQ, NR,\nNG,NS,NRA\n\nTHE FIRST DIMENSION OF THE ARRAS\nA (AND P, X,U,V,W,Y) ,B(AND BSB) ,Q,R, NOR4A,\nS (AND SB,SBT) ,FAD (AND RADINV) RESPECTIVELY\nAS DECIARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\n\nN\n\nTHE NU14BER OF STATES;\n\nM\n\nTHE NU4BER OF OBSERVATIONS;\n\nICCN\n\nTHE NUMBER OF CCNIGURATIONS;\n\nA\n\nN BY N S)STEM MATRIX;\n\nORIGINAL PAGE IS\n\nOF POOR QUALITY\n\n225\n\nAIM FORTRAN\n\nC\nC\n\nB\n\nN BY M BY KCN SET OF INPUT MATRICES;\n\nR\n\n-MBY M CONTROL WEIGHTING MATRIX;\n\nQ\n\nN BY N STATE WEIGHTING MATRIX;\n\nP\n\nC\n-C\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\nKCCK BY KCCN PROBABILITY MATRIX;\n\nE\n\nC\n\nVEC2OR OF LENGTH KCCN CONTAINING THE NORMALIZED\nEIGENVEC[OR OF P CRRES FUNDING TO THE EIGENVALUE\nONE;\n\nQ\'J O1.WHIT:\n\n\nC\nC\n\n\nFR, FZ\n\nSCRA\'ICH VEC1IORS OF LENGTH N;\n\n\nC\nC\nC\nC\nC\nC\nC\n\nU,V,W, ST,\nX, Y\n\nN BY N SCRATCH ARRA)S;\n\nS\n\nN BY N BY KCN SET OF SOLUTIONS,\n\nSB,BSB\n\nN BY N BY KCCN SCRATCH ARRA\\S;\n\nC\nC\nC\n\nNORM\n\nN BY M BY KCCN ARRAY WHICH WILL CCNTAIN THE\nMXIN MATRICES FCR THE NOPRAL LINEAR QUAERATIC\n@J[SSIAN PROBLEM;\n\nC\nC\n\nRAD, RADINV\n\nN BY N SCRATCH ARRA)S;\n\n\nC\n\nC\n\nWORK\n\nSCRATCH VECTOR OF LENGTH N;\n\n\nC\nC\n\n\nIPVT\n\nSCRATCH WCWOR OF IENGTH N;\n\n\nC\nC\nC\n\nIEND\n\nNUMBER OF ITERATIONS USED IN SOLVING BOTH THE\n\nLINEAR WUAERATIC A\\LSIAN PROBLEM AND THE\n\nPROBLEM DESCRIBED ABOVE;\n\n\nIPRT\n\nFIRST ITERATION AT WHICH THE SOLUTIONS\' WILL BE\nPRINTED;\n\nC\nC\nC\n\nC\nCG&4CN/INOU/KIN, N0O1\n\nICOULNT =\n\n\nDO 215 KK=1,ECN\n\nDO 4 J=1,N\nDO 3 I=1,N\n\n3\nY (I, J)= 0.0D0\n\n\n4\n\nY(J,J)= 1.2D0\n\nDO 210 K=1,IEND\n\nCALL MF(NA,?B,lA,N,M,Y,B(1,1,RK) ,U,WCRK)\n\n\n226\n\nAIM FORTRAN\n\nCALL MADD qA,NR,,DA,M,M, U,R, U)\n\nORI\nPOOR QUALITY\n\nDO 14 J=1,M\n13\n\n14\n\nDO 13 I=1,M\n\nV (I, a)= 0.00\n\n\nV(J,J)= 1.0)0\n\nCALL MLINEQ(NA,W\\,M,M, U, V,CCND, IPVr,WCRK)\nCALL TRNATB (NA, M, N,M,B (1, 1, KK) ,X)\nCALL MMUL (NA, NA, DA, N,M, N, X, Y, U)\nCALL MML VA, NA, M, N,M, N, U,A, X)\nCALL M[F\'(NA,I\'&,NRA,M,N, V,X,PADWCRK)\nCALL MSCAIE 6qRA,N,N, -1. 030, PAD)\n\n210\n\nCALL M F (NA, M , NA, N,N, Y,A, U,WCRK)\nCALL MAD) (NA, NA, 1A, NN, U, Q, U)\nCALL MAUD (NA, NRA, NN, N, N, U, RAD, Y)\nCONTINUE\nKKqMI = KK - 1\n\nWRITE (KOUT, 44441)\nWRITE (KOUT, 44442) KKMI\nCALL MATIO (NA,N, N, Y, 3)\nCALL MMUL 0G, NA\\,M, N,M,M,V, X, NORM (1, 1, XK))\nCALL MSCAIE (NG,M, N, -1. OD0, (NORM (1, 1, K))\nCALL MI4L (NB,NG, M&, N,N,M,B(1, 1, KK) , (NORM (1, 1, 1) ,V)\nWRITE (KOUT, 6000)\nCALL MATIO (NG,M, N, (NORM (1, 1, KK) , 3)\nCALL MADD (A, NA, NN, N, N, V,A, V)\nWRITE (KOU.P, 44443)\nCALL MATIO (NA, N, N, V, 3)\nCALL EIGVAL (NA, N, V, V, FR, PZ,WORK, IPVT)\n215 CONTINUE\nJEND= 1\n\nWRITE KOUT, 8000)\nCALL MATIO (NA, ICON, ICON, P, 3)\n\nDO 35 K=I,ICCN\nDO 30 J=4,N\n\nDO 40 I=1,N\n\nS(I,J,K)= 0.00\n40\nCONTINUE\n30\n\nS (J, J, K)= 1.DO\n\n35 CONTINUE\nC\n\nSTART ITERATION TO CALCULATE S(1),S(2),.\n\n.S(K),(I)P\n\nC\nC\n\nCALCULATE SB\n1 CCTINUE\n\nDO 50 K=I,ICON\nCALL MMULNS,bN,b,M,N,N,S(1,1,K),B(1,1,K),SB(1,1,K))\n50 CONTINUE\nCALL WEIGHT (NS, NAA, CON, IS, N,M, E, SS, EBT)\n\nc\nC\n\nCALCULATE RADICAL\n\n227\n\nAIM FORTRAN\nDO 55 K=I,BCQN\nCAIL MCF (NS,I8, 1B, N,M, S (I, I, K) ,B(1, 1, K) ,BSB(1, 1,1K) ,WORK)\n55 \tCONTINUE\n\n\nCATL WEIGHT (NB,M*A,C-C, NRA,M,M,E, BSB, RD)\n\nCALL MADD (NRA,lMR,N,M,M, MD, R, U)\n\nDO 54 J=I,M\n\nDO 53 I=1,M\n\nRADINV(IJ)= 0.EDO\n\n53\nRADINV(J,J)= 1.OD\n\n54\nR\nCALL MLINEQ(NA,NRA,MM,U, RAaI[NV, CCND, IPV ,WC K)\nC\nC\n\n,OCCN\nCALCULATE NEW \t SI,I=1,2 ......\n\n100 DO 1000 K=1,ICCN\n\nCALL MMUL (IS, NRA, IA,M, N,M, BT, RADINV, U)\n\nCALL WEIGHT CNS,NAA,ICCN,lM,N,M, P(1,K) ,SB,V)\n\nCALL TRNATB(NA,M, N,M,V,W)\n\nCALL MMUL (NA,MI<A, N,N,M, U,W,X)\n\nCALL TRNA h (NA, M, N,M, U,W)\n\nCALL MUL (NA, M, IA, N,N,M, V,W, Y)\n\nCALL MAID (NA, U, M, NN, X, Y, X)\n\nCALL MSCALE (NA,N,N,-1. OD0, X)\n\nCALL TRNATA (NA, N, X)\n\nCALL WEIGHT (NA, WA, ICN, A, N, N, P (1, K) ,S, V)\n\nCALL MAE CNA, M, A, N,N, X, V, X)\n\n,M,M, P (1, K) ,BSB, Y)\n\nCN,\nCALL WEIGHT (NB, 1N1A,\nCALL MAED (NA, NA, Mk,M MI Y, R, Y)\n\nCALL MMDL NA, M, MA,M, N,M, U, Y, V)\n\nCALL MMUL (NA, M, IA, N N,M, V,W, Y)\n\nCALL MAID (NA, M, M, N, N, X, Y, X)\n\nCALL M F (NA, M, IA, N, N, X, A, U, WCRK)\n\nCALL MAID (NQ, M, NS fN, N, Q,U,S (1, 1, K))\n\n1000 CONTINUE\n\nIF (ICOUNT-IEND) 11, 12, 12\n\n11 ICOJNT= ICOUNT + 1\n\nIF(ICOUr. IT. IPRT) GO TO 1\n\nICM1 = ICCUNT -I\n\nWRITE (KOU, 5000) IC241\n\n\nDO 1005 K=1,ICCN\n\nK41 = K-I\n\n\nWRITE (KOUL, 4000) KMI\n\nCALL MATIO CS, N, N, S (1, 1, K), 3)\n\n1005 CCNtrINUE\n\n\na\n\nTO I\n\n\n12 CONTINUE\n\n\nC\n\n*\tC\n\nCCMI{TE OPTIMAL CCST FUNCTION\nCAIL WEIGHT (NA, MlA, lCCN, bA, N, N, E, S, U)\n\nWRITE (KOU, 7000)\nCALL MATIO GqA, N, N, U, 3)\n\n228\nAIM \t FORTRAN\nGD TO\nC\nC\n\nC\nC\n\n(23, 22),JEND\n\nC(IMFUrE G OPT\n23 \tCALL MMUL NA, A, N,M, N,W, A, U)\nCALL MSCALE (NA,N,N,-1. MD0, U)\nWRITE (KOUT, 6000)\nCALL MATIO NA,M, N, U, 3)\nDO 217 KP=1,ICCN\nCALL MMUL (NA, B,I, N,N,M,B(1, 1, NP) ,U,W)\nCALL MAED (A, MA, N, N, N, A,W,W)\n\nCALL EIGVAL (NA, N,W,W, R, PZ ,WCRK, IPVr)\n\n217 CqTINUE\n\nORIGINAL PAGE IS\nOF POOR, QUALITY\n\n\nCALCULATE CCMI4ARISON WITH GNORM\nICOUNT= 0\n\nDO 130 K=1, ICCN\n\nDO 120 J=I,N\n\nDO 110 I=1,N\n\nS(I,J,K) = 0.00\n\n110\nCONTINUE\n\n120\nS(J,J,K) = 1.0\n\n130 CCGflINUE\n\nJEND= 2\n\n400 \tCCNrINUE\n\nDO 98 K=,ICCN\n\nCALL WEIGHT (NS, bMA, KCN, M, N, N, P (1, K) ,S, U)\n\nCALL M(F (NA, NA, D, N, N, U, A, X,WCRK)\n\nDO 96 L=1,ICCN\n\n\nCALL MQ\n((NS,\n96 \t\n\n95 \t\n\nN,\n\nIZ, N,M, S (1, 1, L) ,B (1,1, L) , SB (1,1, L) ,WORK)\n\nCCWTINUE\n\nCALL WEIGHT (NS, MYA, fC1\'ON, DA,M,M, P (1, K) ,SB, Y)\n\nCALL MF (NA, NA, M, N, Y, GNORM (1, 1, K) ,O, WORK)\n\nCALL MAD (NA, NA, M\', N, N, U, X, X)\n\nDO 95 L=I, lCQN\n\nCALL MMUL (NS,tB,M,N,N,S(1,1,L),B(1,1,L),SB(1,1,L))\nCC TINUE\n\nCALL WEIGHT (NS,NA, 1caN,b&, N,M, P(1,K) ,SB,Y)\n\nCALL TRNATB (NA, NA, N,M, Y,W)\n\nCALL TRNATA (NA, N, A)\n\nCALL MMUL\nNA,\nA,M, N, N, A, Y, V)\n\nCALL MMUL CA, NG, N, N,M, V, NORM (1,\n 1, K) ,Y)\n\nDA,\nCALL MAWDD L&,A, A,N, N, Y, X, X)\n\n%,\nCALL TRNATB (NG, NA, M, N, (NORM (1, 1, K) , V)\n\nCALL MM (NA, A, M,\nNN,\nM, V,W, U)\n\nCALL TRNATA (NA, N, A)\n\nCALL MMUL (NA, b, DA, N, N, N, U, A,W)\n\nCALL MADD (NA, NA, M, N, N,W, X, X)\n\nCALL MADD (NA, NA, M\'A, N,N, X, Q, X)\n\nCALL MQF (NR, NG, Wk,M, N, R, (NOR4 (1, 1, K) ,U,WCRK)\n\n\n229\n\nAIM FORTRAN\nCALL MADD NA, N, NA, N,N, X, U, X)\n\nCALL SAW (NA, NS, N, N, X, S (1, 1, K))\n\n98 CONTINUE\n\nIF(ICOUNT-IEND)\n\n4010,4011, 4011\n\n\n4010\' ICONT= ICOUNT + 1\n\nGO)O 400\n\n4011 \tWRITE (KOUP, 9000)\n\nCALL MCF (NA, NA, bl, N, N, X,A, U,WCRK)\n\nDO 1006 L=1,ICCN\n\nLMI = L-1\n\n\nWRITE (KOUT, 4000) LM11\n\nCALL MATIO fS, N,N, S (1, 2, L) , 3)\n\n1006 \t ONTINUE\n\nC\nG) TO 12\n\n4000 \tORMAT (/, 41\nF\n5000\n6000\n7000\n8000\n9000\n9500\n9600\n9700\n9800\n9900\n44442\n44443\n44441\n\nS,1I5,/)\n\nFORMAT (/,1H\nITERATION ,I3)\n\nFOEMAT (//,10H G OPTIMAL )\n\nFORMAT(//,39H OPTIMAL COST FflCTION X\'CX, WHERE C IS,/)\n\nPORMAT(//,31 P,/)\n\nFORMAT (/, 38H CCST COM1ARISON WITI NORMAL SOLUTION\n\nFORMAT (2D25.15)\n\nFORMAT (/,31 A\n\nFORAT(/,31 Q\n\nFORMAT (/,31 R\n\nB,15,/)\n\nFOEMAT(/,3\nFORMAT (/,31 S , I5,/)\nFORMAT(/,13H A + B*GZERO)\nFORMAT (1,45H SOLUTION TO STANDARD OPTIMAL CONTROL PROBLEM)\n\n2 STOP\n22 RETURN\nEND\n\n\nORIGINAL QUALITY\nOF POOR PAGE 1$.\n230\n\nS ICH FORTRAN\n\nAq\n\nSUBROUTINE SWITHI\n\n,N\n\nNIC, N, IR, IAA, ICCN,M, A,B, P,C,G,\nNGR,\nS,\n\nIX0, E, ETEMP, EM,WCRK, Y, U, VW,Vq, IPVr, ARRAY, Dr, NFOINT, NGRIDH,MCGq)\n\nC\n\n*****PARAM ETERS :\nICCN,M, NroINT, NG\nINTE (ER NA, Nb, K, IAR, MC, N, IR, AA,\nINTE(aR MCO CNPOINT) ,IPVr (N)\nDOUBLE PRECISION A(NA, N) ,B(NB,NAA, ICCON) ,C(NC,N) ,X0 (N)\nDOUBLE PRECISION G qG,NILA,Ic0N) ,YN) ,WCRKq) ,EM(NA,N)\n1\nON) ,W(NA,N) ,V (A,N)\nDOUBLE PRECISION U(M),V1(NA,\nDOUBLE PRECISION ARRAY(NAR, NNC) ,P(NA, BCCN) ,E(KCCN) ,ETEZ4P(KCCN)\n\nC\nC\n\n*****LOCAL VARIABLES:\n\nINTE(ER IN (27) ,NSY4(1),r (10, I)\n\nDOUBLE PRECISION WT(1) ,SUM, TtOPI,YMIN, MAX, )SF(10),ZERO, X4AX,T, Dr\nDOUBLE PRECISION DD\nDIMENSION R(30)\nC\nC\nC\nC\n\n*****SWBROUINES CALLED:\nMiMUL,MSCAIE ,MEXP, SAWE,FIG, THPLT\n\nC\n\nC<**B, UCAIOS-\n\nC\nC\n\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\n:::::::::...\n\no\n.....................\n\n.. :::\n\n-:.........\n\n.... .\n\n.......\n\no..\n\no\xe2\x80\xa2.......\n\xe2\x80\xa2...........\n\xe2\x80\xa2\n\n.... \xe2\x80\xa2: \xe2\x80\xa2\xe2\x80\xa2...........\n\n......\n\n*****PUROSE:\nTHIS DOUBLE PRECISION SUBROUTINE PERFORMS THE CCMFUPRATIONS\nAND PRINTS THE DATA FOR SIMULATION OF THE SWITCHING GAIN\nPROBLEM RELATING TO THE PUBLICATION: \'ON THE RELATIONSHIP\nBETWEEN RELIABILITY AND LINEAR QUADRATIC OPTIMAL CONTROL\'\nBY J. DEOUGLAS BIRDWELL AND M. ATHANS.\n*****PARAM EER DESCRIPTION:\nIHE FIRST DIMENSION OF THE ARRAS A (AND EM,\nNN, 0B, NC,W.,\nVA,W,V) ,B,C,GAND ARRAY RESFECTIVELY AS\nMR\nLECIARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\nNNC\n\nCOLUMN DIMENSION OF HE ARRAY CCNTAINING ARRAY\nAS DECLARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\n\nN\n\nNUMBER OF STATES;\n\nIR\n\nNUMBER OF OUTPUTS;\n\nNAA\n\nTHE SECCND DIMENSION OF THE ARRA)S B AND G AS\n\nC\nC\n\nC\nC\n\nDECLARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\n\n231\nSWITCH FORTRAN\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\nICCN\n\nTHIRD DIMENSION OF THE ARRA)S B AND G AS\nDECLARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\n\nM\n\nNUMBER OF CCNTROLS;\n\nA\n\nN BY N S)STEM MATRIX;\n\nB\n\nN BY M BY KCCN SET OF OUTPUT MATRICES;\n\nC\n\nIR BY N OUTPUT MATRIX;\n\nG\n\nM BY N BY KCCN SET OF FEEDBACK MATRICES;\n\nX0\n\nINITIAL CONDITION VECTOR OF LENGTH N;\n\nMCCN\n\nVECTOR OF LENGTH NPOINT CCNTAINING THE EXACT\nCCFIGURATION INDICES;\n\nE\n\nSCRACH\n\nErEMP\n\nSCRATCH VECTOR OF LENGTH KCCNt;\n\nWCRK\n\nSCRATCH VECOR OF LENGTH N;\n\nY\n\nVECTOR OF LENGTH N;\n\nU\n\nVEC\'IOR OF LENGTH M;\n\nVW,iMEM\n\nN BY N SCRATCH ARRA)S;\n\nIPVT\n\nSCRATCH VECTOR OF LENGTH N;\n\nARRAY\n\nNAR BY NAC WCRKEING ARRAY;\nDAR MUST BE GREATER THAN OR EUAL TO NSTEPS + 1\nNAC MUST BE GREATER THAN OR EQJAL TO IR + M;\n\nDr\n\nSTEP SIZE;\n\nNFOINT\n\nNUMBER OF STEPS\n\nNGRIDH\n\nNUMIBER OF MAJOR ORDINATE DIVISIONS USED\nIN PLOTTING\nNGRIDH MLST BE LESS THAN OR EQUAL T10 12;\n\nECTOR OF\n\n*****NOTES:\nBOrH THE OUTPUT AND THE CCNTROL\n\nENGFH ICCN;\n\n+ 1;\n\nU ()\n\n= -G (I)*X (T) ARE CC4PUED.\n\nORTOINAL PAGE 19\nOF POOR QUALI\n\nSWI CH FORTRAN\n\n232\n\nC\nGGUB IS A RANDOM NLI4BER (NERA\'IOR\n\nC\n\nC\nICALC IS A LEER-SUPPLIED,\nCALCULATE THE CCJTROL U.\n\nC\nC\n\nAPPLICATION SECIFIC FWCTION \'TO\n\nC\nC\nC\nC\nC\n\n*****HIS\'IORY:\nWRTI\'TEN BY J.A.K. CARRIG (ELEC. S)S. LAB., M.I.T.,R4. 35-307,\nCAMBRIDGE, MA 02139, H. : (617) - 253-2165), JANUARY 1978.\nMCST RECENr VERSION: MARCH 22, 1978.\n\nC\nC\n\n:: .. ::- .::::.....::::\n..\n\n.... :o\n\n.......\n\n:.........\n\n::.........."..--....:\n\nC\nCa4McN/INOU/KIN, LOUt\nLCON =\n\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\nDATA\n\n1\n\n/\nSF/10*. D 0/,IBANK/4H\nTWOPI/3. 1459/\nMSC,MA2ES, IXY, IEGY, ZERO,MM, NLG, IZERO/1, 0, 0, 1, 1. OD0, 1, 0, 0/\n\n,4H4\n\n,412\n,4H3\nIN (1), IN (2), IN(3), IN (4)/4HI\n,47\n,4118\n\n,4H6\nIN (5) ,IN (6) ,IN (7) ,IN (8)/4H 5\n,441H2\n/\n\n,4H10 ,411\nIN(9),IN(10),IN(11),IN(12)/4H9\n/\n\n,414\n,4i15 ,4H16\nIN(13),IN(14),IN(15),IN(16)/4H13\n,419 ,4H20\n/\n\n,4H18\nIN(17),IN(18),IN(19),IN(2)/4H17\n,4H22\n,4123 ,4124 /\n\nIN(21),IN(22),IN(23),IN(24)/4H21\nY,41\nU/\n\n,q4\nIN(25),IN(26),IN(27)/4H25\n1),IT (4, 1),TI (5, 1)/4HVERS, 4HUS T, 4HIME /\n\nIr(3,\n,41\n,41\n\nIT (6, 1),IT (7, 1), IT (8, 1)/4H\n,48\n/\n\nIT (9, 1),IT (10, 1)/4H\n\nIX=35\n\nDO 61 IZ=1,NPOINT\n\n61 MC\'N (IZ) = MCCN (IZ) + I\n\nTWOPI = 2. D0*iWOPI\nNSTEPR\n\n-\n\nNPOINT -1\n\nT= 0. OD0\n3001 \t FORMAT (24H\n\nEXACT CCNFIGURATION\n\n=\n\n13)\n\nCALL MMUL (NC, N, N, M, IR, N, C, XS, Y)\nCALL MMEL (NA, N,M,MM,M, N, G(1, 1,MCCON (1)) ),O,U)\nWRITE (KOUr, 1500)\nWRpE (KOUF, 1200)\nWRITE (KOtIr, 1300)\nWRIEE (KOUr, 1000) T\n1001 FORMAT (/, 12H GAIN MATRIX)\nWR~rE (KOUt, 1100) (Y (I) ,I=I,IR)\n\nC\n\nWITE CKOUr, 1102) (0(I),I=1,M)\nWRITE (KOU, 1001)\n-30 ARRAY(1,J)= Y(J)\nDO 40 J=1,M\n40 ARRAY(1,IR+J)= U (J)\n50 DO 100 K=1,NSTEFS\n\n233\n\nsITCH \tFO~rRAN\n\nWRITE (KOUr, 1002) K\n\nIF(N. EQ. 1) GO TO 72\n\nG\nCALL \tGUB(IX,1,R)\n\n\nWI (2)= TWOPI *R-(L)\n\nCALL GGUB(IX, 1,R)\n\nWT(1) = R(1)*DCCS (WT(2))\n\nWI (2)= R (1)*DSIN (WT(2))\n\n\nGO TO 73\n\n72 \t\n\nCALL GGUB(IX, 1,R)\n\nWT(1) = (R(1)*2.QD)-I.DO\n\n\n73, \t CALL MMJL VA, N, N,MM, N, N,EM,WT, WORK)\nCALL MMUUL(NA, N, N,.M, N,M, B(1, 1, MCQN (K)) , U, ETEMP)\nCALL MADD ( ,N, N, N,MM, ETEMP,WCRK, ETEMP)\nCALL MMUL (NA, N, N,MM, N, N, A, XG,WCRK)\nCALL MAID (N, N, N, N,MM, ERtEMP,WCRK, XO)\nDO 52 KK = 1,ICON\nCALL \t MMUL (NA,N,N,MM, N,M,B(1, 1,1KK) ,U, Y)\nCALL MSUB (N, N, N, N, MM, EIEMP, Y, Y)\nSLM= 0. OD0\nDO 55 IIJ= 1,ICN\n55 \t\nSLM = SUA + Y(IIJ)*Y (IIJ)\n\nSU4 = DSQRT (SM)\n\n56\n52\n881 \t\n\nWI (KK) = 0. 0\n\nIF(SU4.IE. 1. OD 0) WT (KK) = 1. D0\n\nCONTINUE\n\nCALL \t FIG (KCN, E, ETEMP,WT, ICON)\nFcPMAT(181\nPIUr-I/T-i)\n= ,4)25.15)\n\nWRITE (KOUt, 881) (E (IO) ,0=1, 1CON)\n\n\nCALL MMUL (NA, LCON, iCON, 1, iCCN, ECON, P, EJEMP, E)\n\n882 \t\n\nWRITE (KOUT, 882) (ETaMP(IO) ,IO=1, lCN)\n\n=\n,4D25.15)\n\nFOQMAT (18H PI M -1/T)\nICQNM1 = LCN -1\n\n\nWRITE (KOU.T, 4001) LCON1M\n\nMCCNMI = MCON (K+) - 1\n\n4001 \t\n1002 \t\n\n70\n\nWRITE (KOUr, 3001) MC(ONM1\n\nFORMAT (291 CAICLIATED CO\'NFIGURATION\nFCR4AT (/,10H TIME STEP, 13)\n\n90\n\n,13)\n\nCALL MMUL (NC, N, N, M, IR, N,C, X0, Y)\nCALL MMUL (NA,N,M,MM,M, N, G(1, 1, ICCN) ,X0, U)\nDO 70 \tII= 1,M\nU(M) = UCAIC(U, IM,B(1,1,1),B(1,1, 2))\n\nT= T+\nWRITE\nWRITE\nDO 80\n\n80\n\n=\n\nDT\n\n(KOUti,1100)\n(KOUT, 1102)\nJ=I,IR\n\n\n(Y(I) ,I=1,IR)\n\n(0(I) ,I=,M)\n\n\nARRAY(14K, J)= Y(J)\n\nDO 90 J=I,M\n\nARRAY(I+K, IR+J)= U(J)\n\n\n100 CONTINUE\n\n\n234\nSWITCH FORTRAN\nM4AX = DF LOAT (NSTEFS)*I)T\n\nIW= KOE!r\n\n\nNSYA(1)= 25\nIT (1, 1)= IN (26)\n\nORIGINAL PAGE 18\nOF POOR QUALITY\n\nDO 110 J=i,IR\nIF(J.LE.25) IT(2,1)= IN(J)\nIF(J.G. 25) IT(2,1)= IBIANK\nCALL THPLT (IW, IEGY, N1OINT,ZERO, MAX, NGRIDH, YMIN, Y4AX, \\SF, IT,\nARAY(I,J) ,1IJR,NLG,MSC,MAXES, IXY,IS4)\nIT (1, 1)= IN (27)\n\n110\n1\n\nNS)M(1)\n\n= 21\n\n\nDO 120 J=1,M\n\nIF(J.LE. 25) IT(2,1)= IN(J)\n\nIF(J.GT. 25) IT(2,1)= IBTANK\n1100\n1000\n1102\n\nCALL THELT (IW, IEGY, NPOINT, ZERO, X-4AX, NGRIDH, Y4IN, MIAX, )F,\nARRAY (1, J+IR) ,NMR, NLG,MSC,MAXES, IXY, NS74)\n\nFOR4AT (4H Y = ,5(2X, PD19.8))\n\nFORMAT(5H T = ,F5.2)\n\nFORMAT(4H U = ,5(2X,IPD19.8))\n\n\n1200\n1300\n\nFOP4AT (11H\nFORMAT (12B\n\n120\n1\n\n1400\n1500\n\nOLUTR) Y)\n\nCCNTROL U)\n\n\nFORMAT (/, 28H SIMLIATION OF LINEAR S)TEM,/)\n\nFORMAT(/,31H SIMLIATION OF LINEAR REGJLATOR,/)\n\nRETURN\n\nEND\n\n\nIT,\n\n235\n\nREADY FORTRAN\n\nSUBROUTINE READY (NAA,tA, NB, NQ,NRNG,NS,NRA,N,M, CCN,A,B,R, Q, P,\nIWR,WI, S, S, U, V,W, X, Y, NOB, LAD, WADINVBM,WCRK, IWIT,IEND, TERS)\nC\n\nC\n\n*****PAR t4ETERS :\nINTE ER NAA, MB, NQ, NR, N, NS, NRA, N,M, ICON, IPVT (N)\nDOUBLE PREC ISION A(NA, N) ,X A,N) ,Q1Q, N) ,R-qR, M)\nDOUBLE PRECISION S (S,k4A,ICON) ,P(NA,ICON) ,SB(NS,nA, ICON)\nDOUBLE PRECISION GNOR4 (NG, l\'A, ICON) ,BSB(NB,MKA, ICON) ,WR(N) ,WI (N)\n\nDOUBLE PRECISION B(NB,MWA, ICON) ,IAD(NRA,N) ,RADINV(NRk,N)\nDOUBLE PRECISION U(NA,N),V(NA,N),W(NA,N),YNA,N),WORK\n\')\nC\nC\n\nC\nC\nC\nC\n\n*****LOCAL VARIABLES:\nDOUBLE PRECISION COND\nINTEGER KIN, kOUI, L, 4 1, 3, 1, K, JEND, NEND, L, EM I\n*****SUBROUTINES CALLED:\nM F ,MAII, MLINEQ, TRNATB,WIMUL,MSCAIE, EIGVAL, SAVE,WEIGHT\n\nC\nC\nc\nC\nC\nC\nC\n\nTHIS1 DOUBLE PRECISION SUBROUTINE SOLVES THE SWrICHIING-GAIN PROBLEM\nRELATING \'10 THE IUBLicATIOR4: \'ON THE RELATIONSHIP BETWEEN\nRELIABLILITY AND LINEAR QUIADRATIC OPTIMAL CONTROL\'\nBY 3. OUGJLAS BIREWELL AND M. ATBAbS.\n\nC\nC\nC\nC\nC\nC\nC\n\n****R\nON INPUT:\nNAA\n\nC\nC\nC\nC\nC\nC\n\nDESCRIPTION:\nTHE SECOND DIMENSION OF THE ARA S S,SGORM,\nBSB ,B AS LEGCLARED IN THE CALLING PROGRAM\nDIMENS ION STATEMENT;\n\nNAM, NQ,TNR,\n\nTHE FIRST DIMENSION OF THE ARRA)S\n\nNG,NS,SRA\n\nA (AND P, X, U,VW, Y),B(AND BSB) ,Q,R,C(NORM,\nS (AND SB) ,RAD (AND RADINV) RESPECTIVELY\nAS ECLEARED IN THE CALLING PROGRAM DIMENSION\nSTATEMENT;\n\nN\n\nTHE NUMBER OF STATES;\n\nC\nC\nC\nC\nC\nC\nC\nC\n\nM\n\nTHE NUMBER OF OGSEVAETIONS;\n\nICON\n\nTHE NUMBER OF CONFIGURATIONS;\n\nA\n\nN E NN\nSYTEM\n\nB\n\nN BYM BYLK4C\n\nC\n\nR\n\nM BY M CONTROL WEIGHTING MATRIX;\n\nC\n\nOATRIX;\nSET OF INRT MATRICES;\n\n236\n\nREADY FORTRAN\n\nc\nC\nc\nC\nC\nC\nC\n\nQ\n\nN BY N STATE WEIGHTING MATRIX;\n\nP\n\nKCGq BY KCCN PROBABILITY MATRIX;\n\nON OUTPUT:\nWR,WI\n\nSCRATCH VECTORS OF LENGIH N;\n\nS\n\nN BY N BY KCN SET OF SOLUTIONS;\n\nORIGINAL PAGE IS\n\nC\nC\n\nSB,B,BSB\n\nN BY N BY KCCN SCRATCH ARRA)S;\n\nOF POOR QUALITY\n\nC\n\nU,VWJX, Y\n\nN BY N SCRATC H ARR)S;\n\nC\n\nC\n\nC\nC\nC\nC\nC\nC\n\nERM\n\nN B\' M BY KCON ARRAY USED TO STORE THE\nGIN MATRICES FOR THE NORMAL LINEAR QUk1ATIC\nG(AESIAN PROBLEM. ON RETURN, GNORM CONTAINS THE\nGAINS ASSOCIATED WITH THE SWITCHING GAIN PROBLEM;\n\nRAD, RADINV\n\nN BY N SCRATCH ARMAS ;\n\nC\nC\nC\nC\nC\nC\n\nWORK\n\nSCRATCH VECTOR OF LENGTH N,\n\nIPVI\n\nSCRATCH VECTOR OF LENGTH N;\n\nLEND\n\nNUMBER OF ITERATIONS WSED IN SOLVING THE NORMAL\nLINEAR QUAERATIC @1SIAN PROBLEM;\n\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\nNSTERS\n\nNU4BER OF TIME STEPS WSED IN COMPUTING S\n\nc\n\n*****NOTES:\nTHE SOLUTIONS TO THE NORMAL LINEAR QUADRATIC PROBLEM,\n\'TE EIGENVALUES OF THE MATRICES\n(A + B(I)*GNOPM(ERO))\nAS WELL AS THE EIGENVALUES OF THE MATRICES (A + B (I)*G (I))\nARE PRINTED.\n*****HISIORY:\nWRITTEN BY J.A.K. CARRIG (ELEC. S)5. LAB., M.I.T., FM. 35-307,\nCAMBRIDGE, MA 02139, HI. : (617) - 253-2165), JALNUARY 1978.\nMCST RECENT VERSION: MARCH 22, 1978.\nC\n\n.... ::::.:::::-.:::.......:::.......\n\nc\nc\nCCN/INOU/KIN, IDUf\nWRITE (KOUT, 9600)\nCALL M4ATIO 6qA, N, N,A, 3)\nWRITE (KOUT, 9700 )\n\n..............\n\n.........\n\n237\nREADY \t FORTRAN\nCALL MATIO (NA, N, N, Q, 3)\n\nWRITE (KOMr, 9800)\n\nCALL MATIO (NR, N, N, R, 3)\n\nDO 222 KL=l,COCN\n\nMl = KL-1\n\nWRITE (KOU, 9900) KMI1\n\nCALL MATIO (B,N,M,B(1, 1,1L) ,3)\n\nDO 4 J=I,N\nDO 3 I=1,N\n\n3\nY (I, J)= 0.EDO\n\n4\nY(J,J)= I. D0\n\nDO 210 K=1,IEND\nCALL MQF (NA, B,, IN,M, Y,B(1, 1, L) ,U,WORK)\nCALL MADD (NA, NR, DA,M,M, U,R, U)\nDO 14 J=1,M\n\nDO 13 I=I,M\n\n13\nV (I, J)= 0. OD0\n\n14\nV(J,cJ)= i.0O\n\nCALL MLINEQ(NA,bk,M,M, U, V,CQND, IPVr,WCRK)\n\nCALL TRNATB (NB,MA,N,M,B (1, 1, KL) ,X)\n\nCALL MMUL (NA,\n, mN,M, N, X, Y, U)\n\nCALL MM4UL (NA,,\nN , N,M, N, U, A, X)\n\nCALL MOF (NA, N DA\xc2\xa3,M, N, V, X,W,WORK)\n\nCALL MSCAIE CA,N,N, -1. OD0,W)\n\nCALL MF M(NA, g,\nMr,N, N, YA, U,WCRK)\n\nCALL -MAED QA, NA, N\'., N, N, U, Q, U)\n\nCALL MADD NA, NA, IA, N, N, U,W, Y)\n\n210 \t CcWTINUE\n\nWRITE (KOUT, 44441)\n\nWRITE (KOME, 44442)\n\nCALL MATIO VqA,N,N, Y, 3)\n\nCALL M1UL A, NA, NG, N,M,M, V, X, OR (1, 1, L))\n\nQ\nCALL MSCALE VA,M, N, -1. ED0, (NORM (1, 1, XL))\n\nWRITE CKOU, 6000)\n\nCALL MATIO (NG,M, N, (NORM (1,1,\n1L) , 3)\n\nCALL MI4UL NB, NG, M, N, N,M,B (1,1,KL) ,fNOR M(1,1,1 ) ,V)\n\nCALL MADD VA, NA, DA, N,N, V,A, V)\n\nWRITE (KOU, 7008)\n\nCALL EIGVAL (NA, N, V, VWRWI,WCRK, IPVI\')\n\n222 COTfINUE\nJEND= 1\n\n26 CONTINUE\n\nWRITE (KOMi, 8000)\n\nCALL MATIO (NA, ECCN, ICON, P, 3)\n\nDO 5 K=I, ICON\n\nCALL SAVE VQ, %, N, N, Q,S (1, 1, K))\n\n5 CWEINUE\n\nDO 91 NEND= 1,INETEtS\n\nWRTE (KOU, 4500) NEND\n\n\n238\n\nREADY \t FORTRAN\n200 \t\n\n80 \t\n\n97\n98\n\n60\n70\n\nCONTINUE\n\nDO 90 L=I,ECCN\n\nDO 80 K=1, ICON\n\nCALL MCF(NS,bB,hB,N,M,S(1,1,K),B(1,1,K),BSB(1,1,K),WRK)\nCALL MMUL(NS,B,S,M,N,N,S(1,1,K),B(1,1,K),SB(1,1,K))\nCONTINUE\n\nCALL WEIGHT (NS,PA,4CaqrN,M,P(1,L) ,SB,V)\n\nIN, DA,M,M, P (1, L) ,BSB,\n AD)\nC,\nCALL WEIGHT (NS,\nCALL MADD NR, NRA, M,M,M, R, RAD, U)\nDO 98 J=1,M\nDO 97 I=1,M\nRADINV(I,J) = 0.OD0\nRO\'UGINAL PAGE\nRADINV(J,J)= 1.0D0\nPOOR QUJA\nCALL MLINEQ (NA, NRA,M,M, U, PADINV, CCND, IPVT,WCRK)\nDO 70 K=I, CON\nDO 60 J=1,N\nDO 60 I=1,M\n\nBSB(I,J,IK) = SB(J, I, K)\n\nCONTINUE\n\nCALL WEIGHT (NS, 10A, ICON, NN,M, N, P (1, L) ,BSB, U)\n\nCALL MMUL (NRA,N, A, N,M,M, PADINV, U,W)\n\nCALL MMUL (NA, NN, A, N, N,M, V,W, Y)\n\nCALL MMUL NA, NN, N,N,M, N,W,A, (NORM (1, 1, L))\n\nCALL MSCAIE (NG,M, N, -1. 0D0, (NORM (1, 1, L))\n\n\nIMI = L-1\n\nWRITE CKOUr, 2005) EMI1\n\nCALL MATIO CqG,M, N,G\'ORM (1, 1,L), 3)\n\nIF(NEND.NE.hWTEIS) GO TO 73\n\n1,L) ,W)\n\nN\nCALL M4UL 60B, WG, N, N,N,M,B(1, 1,L) ,ORM(1,\nCALL MADD (NA,M , M, N, N,A,W,W)\n\nWRITE (KOUt, 7009) EM1, IM1\n\nCALL EIGVAL (NA, N,W,W,WR,WI,WCRK, IPVT)\n\nCALL MSCAIE VA,N,N, -1. E0, Y)\n73 \t\nCALL WEIGHT NA, IA, ICON, M, N, N, P (1, L) ,S,W)\n\nCALL MADD UA, NN, NN, N, N,W, Y, Y)\n\nCALL M-F (NA, NA, MA, N, N, Y,A,W,WCRK)\n\nCALL MADD eNA, NN, M, N, N,W, Q, S (1, 1, L))\n\nWRITE (KOUT, 4000) [M1\nCALL MATIO (NS,N, N, S (1, 1, L) , 3)\n\nCONTINUE\n\n90\n91 CONTINUE\n\n2000 FORMAT (3D25. 15)\n\n\n4005\n2005\n4000\n4500\n5000\n6000\n7000\n\nFO14AT (3H\nFOR4AT (4H\nFORKAT(4H\nFORMAT (11H\nFOI4AT(11H\nFOMAT(10H\nFCRMAT (40H\n\nS)\n\nG,13)\n\nS,13)\n\nTIME= T2 -,13)\n\nITERATION ,13)\n\nG OPTIMAL )\n\nOPTIMAL COST FLUCTION X C X, WHERE C IS)\n\n\n.1\n\n,239\n\nREADY FORTRAN\n7008\n7009\n8000\n9500\n9700\n9600\n9800\n9900\n44441\n2\n44442\n\nFOR4AT (21H A + B (I) *GSTAR (ZERO))\n\nFORMAT (7H A + B, 13, 1 * G, 13)\n\nFOGMAT (3H P)\n\nFORMAT,(3D.25._15)\n\nFOR AT (3H Q)\n\nFOR4AT(3H A)\n\nFOR\'4AT (3H R)\n\nFORMAT (3H B, I3)\n\nFC4AT (/, 45H SOLUTION TO STANDARD OPTIMAL CONTROL PROBLEM)\nSTOP\nFORL4AT(3f1 S\nRETURN\nEND\n\n\n240\nWEIGHT FCRTRAN\nSWIBROU INE WEIGHT (NA, 1bUA, KCCN, NX, N, M, E, A, X)\nC\nC\n\nC\nC\n\n******PARAKETERS:\nINTEGER NA, NA, 1GN,NX,N,M\nDOUBLE PRECISION E (KCCN) ,A(NA,lkA,\n\nCN) ,X(X,M)\n\n*****LOCAL VARIABLES:\nINTE(ER I, J, K\nDOUBLE PRECISION SUM\n\nC\nC\nC\n\n*****SWBROUTINES CALLED:\nNONE\n\nc\nC\n\n*****PURFOSE:\n\nORIGINAL PAGE IS\n-F POOR QUALITY\n\nC\nC\n\nTHIS S.RBOUTINE COMATES THE WEIGHTED SUM\n\nC\nC\n\nC\n\nS[MMATION E(I)*A(I,J,K);\n\nI=1,N; J=1,M; K=IICON.\n\n\n*****PARAMETER DESCRIPTION:\n\n\nC\nC\n\nNA\n\nTHE FIRST DIMENSION OF THE ARRAY A AS DECIARED IN\n\nTHE CALLING PROGRAM DIMENSION STATEMENT;\n\n\nC\nC\nC\n\nC\n\ntAA\n\nTHE SECCND DIMENSION OF THE ARRAY AS DECEARED IN\n\nTE CALLING PROGRAM DIMENSION STATEMENT;\n\n\nICCg\n\nTHE THIRD DIMENSION OF THE ARRAY A AS DECLARED IN\n\n\nC\n\n\'IHE CALLING PROGRAM DIMENSION STATEMENT;\n\n\nc\n\nC\nC\nC\n\nC\n\nNX\n\nTHE FIRST DIMENSION OF THE ARRAY X AS DECLARED IN\n\nCALLING PROGRAM DIMENSION STATEMENT;\n\n\nN\n\nTHE ROW SIZE OF A;\n\n\nC\n\nM\n\nTHE COLUMN SIZE OF A;\n\nC\nC\n\nC\nC\n\nC\nC\nC\nC\nC\n\n\nE\n\nc\n\nA\n\nECIOR OF LENQrH KCCN;\n\nN BY;\'M ARRAY\n\n\n*****HISTORY:\n\nWRITTEN BYJ.A.R. CARRIG (ELEC. SYS. LAB., M.I.T., RA. 35-307,\n\nCAMBRIDGE, MA 02139, Hi.: (617) - 253-2165), JANUARY 1978.\n\nMCST RECENT wRSION MARCH 22, 1978.\n\n\nC\n\nc\n\nDO 10 J=1,M\n\nDO 10 I=1,N\n\nX(I, 3) =0. ED0\n\n\n241\nWEIGHT FORTRAN\n\n10\n\nDO 10 K=1,lCN\n\nX(I,J) = X(1,J) + E(K)*A(I,J,K)\n\nRE PURN\n\nEND\xc2\xad\n\n242\n\nUCALC FORTRAN\nF WNCTIO\nUCAIC (U, EM, B,C)\n\nDOUBLE PRECISION U (10, 2) ,EM(10, 2) ,B(10, 2) ,C(10, 2)\n\nRETURN\n\n\nEND\n\n\nO\n\n\n243\nFIG FORTRAN\n\nSUBROUTINE FIG (KCcN, E, ETEMP,WORK, rCCN)\nC\nC\n\n*****PAPAMETERS:\nDOUBLE PRECISION WCRK(KCCN)-, E(KCCN)-,ET4P-(KCCQN)\n\nC\nC\nC\nC\nC\nC\nC\n\nC\nC\nC\nC\nc\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\nC\n\n*****LOCAL VARIABLES:\nINTEGER MI, LTEMP, IFIAG, KK, IP, IU\nDOUBLE PRECISION St4\n*****SLBROUTINES CALLED:\nNONE\nC\n\n...\n-::::::.:"\n\n-::-::.........\n\n.. ....\n\n::.........\n\n.\n\n"\n"\xc2\xb0\n..\n... o..:.....o:......\n\n. .......\n........\n:.\n\n*****PURFOSE :\nTHIS DOUBLE PRECISION SUBROUTINE IS [EED IN HYPOTHESIS TESTING.\nAT EACH TIME T, ONE OF ICON HTHESES IS CHOSEN.\nRHO(X(r) - A*Xfr-1)\n\n- B(I)*U T-I1))*PI\n\n(T-I/T-1)\n\nPi (r-1/T)=\nI\nSM(RHO (X1T) - A*X f-1) -B(J)*U (-1))*PI\n\nfr-I/T-i)\nJ\n\nHYPOTHESIS H (I) IS ASSUI4ED TO BE C(RRECT IF\nPI (T/T-i) > PI (T-IT) FOR ALL J NOT EQUAL I\nI\nJ\nTIES ARE RESOLVED ARBITRARILY.\nRHO (X) DENOTES THE PROBABILITY DISTRIBUTION OF X.\n*****PARAMErER LESCRIPTION:\nCN INPUT:\nNON\nTHE NUMBER OF HYPOTHESES;\nE\n\nVECTOR OF LENGtH KCI\'N CONTAINING PI (-I/T-I);\n\nWORK\n\nVECTOR OF LENGTH KCCN CONTAINING\nRHO (X(r) - A*X(r-I) - B (I)*U (T-1));\n\n(N OUTPUT:\nETEMP\nICON\n*****HIS\'IRY:\n\nVECTOR OF LENGTH KCCN TO STORE PI (T/1-1);\nINDICATES WHICH HYPOIHESIS HAS BEEN CHOSEN;\n\n244\nFIG FOGrRAN\nC\nC\nC\n\nC\n\n\nWRITTEN BY J. A.K. CARRIG (ELEC. S)S.\nAB., M.I.T., R4. 35-307,\n\nCAMBRIDGE, MA 02139, P.:\n(617) - 253-2165), JANUARY 1978.\n\nMCST RECEaf VERSION MARCH 22, 1978.\n\nC\n\n:-:::::-:--:-:-::................\n\n........\n\n.\n\n.:............".\n\n\nC\nCC4CN/INOU/KIN, IcUr\nMM = 1\n\n\nLTEMP = LCCN\n\nSUM = 0.QD0\n\nDO 10 IP = 1,ICCN\n\n\n10\n\nSLM = SM + WORK(IP)*E (IP)\n\nDO 20 IP=1,ICCN\n\n20\nETEMMP(IP) = WORKRU P)*E (IP)/SLM\n\nDO 60 KK = 1, ICON\n\nIFEAG = 0\n\n\nDO 89 IU= 1,INOCN\n\nIF(KK. EQ. IU) GO TO 79\nIF(ETE4P(KK).Gr.E(IU)) IFlAG = IFIAG + 1\n\n79\nCONTINUE\n\n89\nCONTINUE\n\nIFIAG = IFIAG + 1\n\nIF (IFLAG. EQ. ECGN)\nLW= K\n\n60 CONtINUE\n\nIF (LCq. EQ. 0)\n\nLCON = LTEM P\n\n\nRETURN\n\nEND\n\n\nV3? p0?-2JJr\n\n\n245\nRD)MIN FcRTRAN\nC LATEST WRSION 3/9/77\nDOUBLE PRECISION COND,BEE,WR(10) ,WI (10)\nDOUBLE PRECISION A(10, 3) ,X(10, 3)\n\nINTECER MDOMNR (2)., HR4MC C(2-), VPME(2-), rIME (2)\nDOUBLE PRECISION GNORM(10, 3, 4)\nDOUBLE PRECISION BSB(10, 3,4)\nDOUBLE PRECISION S (10, 3, 4) ,P(10, 4) ,SB(10, 3, 4)\nDOUBLE PRECISION SBT(10,3 ) ,Q(10, 3) ,R(10, 3) ,B(10, 3,4)\nDOUBLE PRECISION PR(4),Pl,P2,FZ(4),HD(10,4),S(4)\nINTECER IPVT (10)\nDOUBLE PRECISION AZERO,ACNE, ATWO\nDOUBLE PRECISION RAD (10, 3) ,PADINV(10, 3) ,U(10, 3)\nDOUBLE PRECISION V(10,3),W(10 ,3),Y(10, 3),SM,WORK(10)\nCat4MCNiINOU/KIN, IOUT\nNAA= 3\n=\nA WO -3.\n\n0\n\n\nAZERO = -4.EDO\n\nAONE =6.E 0\n\nP1= 05D0\n\nP2 = .75D0\n\nKIN= 5\n\n\t\nKOUT= 6\n\nN= 3\n\nM= 3\n\nN2 = 6\n\nKCCW = 3\n\nNS = 10\n\nIPRT= 17\n\nIEND= 25\n\n\nIcOUNr = 0\n\nNSTEFS = 25\n\n\nNA= 10\n\nNM=NA\n\nNRA= 10\n\n\nNR= 10\nNB= 10\n\nNQ= 10\n\nNG=10\n\n22 IF(ICOUNT.NE.0)\n9500 \t FORMAT (3D25.15)\n\nDO 11 JK= 1,N\n\nDO 11 JL = 1,N\n\nQ(JL, JK) = 0.00\n\n\nREAD(KIN, 9500, END=2)\n\nR(JK, JL) = 0.0M0\n\nO\n11 A(JL, JK) = 0.D\nBEE = -10.\nP (1, 1) =\n\nP(2,2) =\nP(3,3) =\n\nCD\n\n\n. 0-PI\n\n.tD0- P2\n\n.D0\n\n\n(PR(I),PZ(I),I=1,N)\n\n\n246\nRDtAAAIN F CR.N\nP(1, 2) = 0. ED0\n\n3)\nP (1, = 0. M30\n\nP (2, 1) = P1\n\nP(2,3) = 0.030\n\nP(3,1) = O.QDO\n\nP (3, 2) = P2\n\nA(1,1)= 0.O3\n\nA(2,2)= 0.D00\n\nA(3, 3) = -AZEPkO\n\nA(1,2) = 1. 00\n\nA(2,3) = I..ODO\n\nA(3, 1) = -ATWO\n\nA(3,2) = -AONE\n\nQ(1, 1)= 3.D030\nQ(2,2) = 3.OD0\nQ(3,3) = 3.0)0\nR(1,1)= 1. D\nR(2,2) = I.030\nR(3,3) = .D0O\n\n8 (1, 1, 1)= 00.03\nB8(2, 2, 1) = 0. OD0\nB(2, 1, 1)= 0.O00\nB(1, 2, 1)= 0.30\nB(1, 3, 1)= 0.00\n3(2, 3, 1) =O. 00\n\nB(3,3,1) = 1.03\n\nB(3, 1, 1) = 1. WO\n\nB(3,2,1) = 1. OD0\n\nB(1,1, 2) = 0. 0A\n\nB(2,2,2) = 0.030\n\n\nB(2,1,2)\nB(1,2,2)\n5(1,3,2)\nB(2,3,2)\nB(3,3,2)\nB(3,1,2)\n\n8(3,2,2)\nB(1, 1, 3)\nB(2,2,3)\nB(2,1,3)\nB(1, 2, 3)\nB(1,3,3)\n\n=0.00\n\n= 0. 030\n\n= 0.D03\n\n= 0. WD\n\n= BEE\n\n= 1. W0\n\n= 1.03\n\n= 0. M0\n\n= 0.OD0\n\n= 0. OD0\n\n= 0.0\n\n= 0.0DO\n\n\nB(2,3,3) = 0. M0\n\nB(3,3,3) = 0.D03\n\n\nB(3,1,3) = 1. W0\n\n1.0DO\n\nB(3,2,3)\n= .05D0\n\nPR(1)\nPR(2) = .75D0\n\nP(1,1) = .00 - PR(1)\n\n\nOWO\npaG\n/\nOF Poem QG\n\nLt2\'y\n\n247\n\nRDYMAIN FGRTRAN\nP(2,1)\nP(3,1)\nP (1,2)\nP(1,3)\nP(2,2)\nP(3,2)\nP(2,3)\nP (3, 3)\n\nC\n\n2\n\n=\n=\n=\n=\n=\n=\n=\n=\n\nPR(1)\n\n0. D0\n\n0. OD0\n\n0.DO\n\n1. EDO - PR(2)\n\nPR(2)\n\n0. O0\n\n1. ODO\n\n\nCAIL TIME (MEGYR, HRfMN, SC, Vrf4E, TIME)\nCALL READY (NAA, NN, N3, NQ, NR, NG, NS, IRA, N,M, ICON, A,B, R, 9, P,\n1 WR, WI, S, S3, U, V,W, X, Y, NORA, PAD, MhDIN V,BS,WCRK, IPvr, TEND,\n2 NSTE PS)\nSTOP\nEND\n\n248\n\n\nSQMAT \t FCRTRAN\nC LATEST \\ERSION 2/17/78\nDOUBLE PREC IS ION E (4), ETEMP (4), SLM, SIGMA, SIG4 1, ES INV, ESIGMA, SIN V4 1\nDOUBLE PRECISION CCND, WUDOLF\', LDItV, DOLFMI,Er(10, 2) ,X0 (10) ,DINM1\nDOUBLE PRECISION ARRAY(100, 50) ,YO (10) ,UO (10)\nDOUBLE PRECISION A(10, 3) ,C(10, 3) ,FR1, FR2, X(10, 3)\nE(1) = 1. a)0\nEM(1, 1) = 1.O 0\nE4(2, 2) = 1. OD0\nE(2-) = 0. D0\nETEMP(2) = E(2)\nE (3) = 0. O0\n\nORIGINAL PAGE IS\nOF POOR QUALITY\n\nETEMP (3) = E (3) \t\nETEMP(1) = E (l)\nE(4) = 0.0)\n\n\nDOUBLE PRECISION IORM (10, 2, 4)\n\nDOUBLE PRECISION BSB(10,4, 3)\n\nDOUBLE PRECISION S (10, 3, 4) ,DT, P(10, 4) ,SB(10, 3,4)\n\nDOUBLE PRECISION WR (4) ,WI (4) ,HH (4, 4), XX (4, 4) ,ACL (10, 3)\n\nDOUBLE PRECISION SBT(10,3 ),Q(10, 3),R(10, 3),B(10,2,4)\n\nDOUBLE PREC IS ION PR (4),,PZ (4), PD (10, 4), S (4)\n\nINTEGER IPVT (10) ,MCCN (100) ,DSTERS, NGRIDH, ICON (100)\n\n3\nDOUBLE PRECISION RAD(10, 3),fDINV(10, 3),SNEWq(10, 3,4),U(10, )\n\nDOUBLE PRECISION V(10, 3) ,Vq(10, 3) ,W(10 , 3) ,Y(10, 3) ,SLM,WORK (10)\n\nLOGICAL NOISE\n\nCC4N/INOU/ IN, IoUE\n\nK0=0\n\nIA = 1\n\nREAD(5, 11111) NPOINT\n\n33333 READ (5, 11111, END=22222) ITIME, K\n\n11111 FORMAT (214)\n\nDO 44444 IXYZ = IA, ITIME\n\n44444 \tNCCN (IXYZ) = K0\n\nMCCN (ITIME)= K\n\nIA = ITIME\n\n\nK0= K\n\nGO 10 33333\n\n22222 DO 55555 IMYZ = ITIME, NPOINT\n\n55555 MC(!\' (IXYZ) = K0\n\nLUDJLF= 2.718281828459045D0\n\nLUDINV= 1. 0O/LUDJLF\n\nDOLFM1 = LUDOLF - 1.0)0\n\nDINWM1 = LUDINV NAA = 2\n\nNC = 10\n\n=\n\nKIN\t 5\n\nKOOT= 6\nN= 2\n\nM= 2\n\nN2 = 4\n\n\n1.0)0\n\n\n249\nS MAT FCRTRAN\n\niCN = 4\nNH= 4\n\nNS= 10\n\nIPR= 17\n\nIEND= 50\n\nIPRT = 49\n\nIcOUNr = 0\n\nNA= 10\n.NB= 10\n=NA\n\nNRA= 10\nNR -\n10\nNQ = 10\nNG=10\nPZ(1) = ]DO\n\nPR(1)= .DO\n\nDO 15 I=2,N\n\nPR (1)= PR (1)\n\n15 PZ(I)= PZ(1)\n\nREAD(KIN, 9500, END=2)\n22 IF(ICOUNT.NE.0)\nSIG4A= 1.030\n\nESIG4A= LUDOLF**SIGMA\n\nESINV= LUDINV**SIYIA\n\nC (1,1)\n1. a.)0\nC(2,2) = .D0\n\nC(1,2) = 0. OD0\n\nC(2,1) =0.ODD\n\nUr = 1. OD\nNSTEFS = 50\nA(1, 1)= ESIGMA\nMR= 100\nNAC = 50\nA(2,2)= ESINV\n\nA(2,1) = 0.D0\n\nA(1,2) =0.0DO\n\n1)= 14. O0\n\nQ (1,\nQ (2, 1)= 8.00\n\nQ(1,2) =8.OD\n\nQ(2,2) = 6.OD0\n\nR (1, 1)= 1. W0\n\n*R(2,1) = 0. O0\n\nR(1,2) =O.fD\n\nR(2,2) = i.LDO\n\n\nB(1,1,1)= ESIG4A -l.flOD\n\nB(2,1,1)= ESINV- 1. OD 0\n\nB(2,2,1) =-B(2,1,1)\n\nB (1,2, 1)= B (1, 1, 1)\nB(1,1,2) = 0.G02\nB(2,2,2) = -DINV41\n\n(PR(I),PZ(I),I=1,N)\n\n\n250\n\nS*MAT FORTRAN\n\n\nB(2, 1,2)= 0. OD\n\nC\n46\n47\n\n222\n44\n\n14\n667\n\nB(1, 2,2) = DOLFM1\n8(1,1,3) = DOLFMI1\nB(1,2,3) = 0. O30\nB(2,1,3) = DINM1\nB(2,2,3) = 0.030\nPRI =. DO\nPR2= .ID0\nP(1,1) = .81D0\nP(2,2)\n.09D0\nP(3,2) = 0.09D0\nP (3, 3) = .09D\nP(1,2) = .81D0\nP(3,1) = .09D0\nP(2,1) = .09D0\nP(1,3) = .81D0\nP(2,3) = 0. 09D\nP(4,1) = .01D0\nP (1, 4) = .81D0\nP 14, 2) = . 1DO\nP(4,3) = .01D0\nP(4,4) = .01D0\nP(2,4) = .09D0\nP(3,4) = .09D0\nWRITE (KOUT, 9903)\nCALL MATIO VA, ICON, ICON, P, 3)\nWRfE (KOU, 46)\nFORAT(/,4\nPI,/)\nFO4AT (3D25. 15)\nWRITE (KOUT, 9600)\nCALL MATIO NA, N, N, A, 3)\nWRITE KOLT, 9700)\nCALL MATIO GA, N, N, Q, 3)\nWRITE (KObT, 9800)\nCALL MATIO R, N, N, R, 3)\nDO 222 K=1,ICON\nK41 = K-i\nWRITE (KOU, 9900) R41\nWRITE (KOU, 9500) ((B(I,J,K),J=,M) ,I=1,N)\nCOGNTINUE\n\nDO 14 IN=1,50\n\nLCCN (IN) = ICCN ()i\n\nCONTINUE\nFORMAT (515)\n\nXo (1) = .02D0\nGNORM(1, 1,i)= -1.06336184D0\n\nGNORM (2,1,i)= -7.9015188D-1\nGNOPM (1,2, 1)= -1.88787889D-02\nGNORM(2, 2,1)= -5.83582496D-02\n\nORGNAL\nOFPOOR QUALImy\n\n251\nS\'JMAT \t FORTRAN\n(NORM (1,\nNORM4(2,\nGNOR4(1,\nNOP1(2,\nGNORP(1,\nGNORIM(2,\nGNORM(1,\n\n1,\n1,\n2,\n2,\n1,\n1,\n\n2)=\n2)=\n2)=\n2)=\n3)=\n3)=\n\n-3.69012096D-01\n\n-1. 14016534D0\n\n1. 04948339D-01\n\n-1.36308767D-01\n\n-1. 42566767D0\n\n-2. 87451308D-01\n\n\n2, 3)= 1.51884285D-02\n\nGNORM(2, 2, 3)= -7.27012438D--02\n\nIR = 2\n\nNPRRL = 1\n\nDO 57 1K = ICCN\n\nIK40l = IK - 1\n\n\n57\n\nWRITE (KOUr, 9992) IN41\n\nWRITE (KOUT, 9500) ((GNOt\'4(IJ, IL,IK) ,IL=1,N),IJ=,N)\n\nNGRID= 5\n\n\nV (l,\n\n)\n\n8(2,2,1)\n8(2,1,1)\n= B(1,2,1)\nCALL MEL (NA, M , MA, N, N,M, V, QNORM, U)\nCALL MADD CA, t, M, N,N, U, A, ACL)\nCALL MSCAIE CAG,N,M, -1. D,(ORM)\nV(2,2)\nV(2,1)\nV(1,2)\n\nC\nC\nC\n\nB\nB(1, 1, 1)\n\n=\n=\n\nIONE = I\n\nC\n\nCALL MMUL (NC,N, N, ICOE, IR, N,C, XO, YO)\n65 FORMAT (1X, 3)25. 15)\nC\nCALL DR(1IM (NA, NC, MG, MAR, MAC, N, IR,M, ACL, C, QORM, X0,WORK,\nC\n1Y, U, IPVr, ARRAY, Dr, bSTEFS, NPREL)\nC\nCAL READY2 (NAA, bA, IB, NQ, NR, NG, N, MtA, N,M, fCCN,A,B, R, Q,P,\nC\n1 WR,WI, S, SB, U, VW, X, Y, W3ORM, FAD, PADINV, B3 ,WCRK, IPVr, IEND)\nDT = 1. WD0\nXO(1) = .02D0\nC\nCALL MSCAIE (NG, N, M, -1. OD0, GNOR4)\nXO (2) = 0. 0)0\nCALL SWITCH QNA, ENZ,\nN3,\n%R, AC, N, I, MA, XON,M, A,B, P,\n1 C, C ORM, XO, E, ETEMP, EM,WCRK, YO, U0, VW, \\W, IPVT, ARRAY, Dr, izTES,\n2 NGRIDH ,MCCUq)\n9500 FOR14AT (2D25. 15)\n\n2000 FOR4AT (/,3)25. 15)\n\n9600 FORMAT(/,31 A\n\n9700 FORM4AT(/,31 Q\n\n9800 FORMAT (/,3 R\n\n9900 FOMAT(/,31 B ,15,/)\n\n9903 FO4AT (/,31 P )\n\n9902 FORMAT (/,3H\n,I5,/)\n\n2\t\nSTOP\nEND\n\n252\n\n\nS4MAT2 FORTRAN\nC LATEST VERSION 2/17/78\nDOUBLE PRC IS ION E (4),ETEMP (4) ,S14, SIG4A, SIG1 , ESINV, ESIQIA, SIN41\nDOUBIE PRECISION CCND, UJWLF, UDINV,DJLFM1, EM(10, 2),X0 (10) ,DINM 1\nDOUBLE PRECISION ARPY(100, 50) ,Y0 (10) ,U0 (10)\nDOUBLE PRECISION A(10, 3) ,C(10, 3) ,PR1,HR2, X(1C, 3)\nE(1) = 1. DO\nEM(I,1) = 1.D0\nEM(2, 2) = 1.a)0\nE(2) = 0.W0\n\nETEMP(2) = E (2)\nE(3) = 0.\nE\'rM4P(3) = E(3)\nETU4P(1) = E(l)\nE(4) = 0.QDO\n\nODLA\nORIGINAL PAGE 18\nOF POOR OTTATTPV\n\nDOUBLE PRECISION GiNORM(10, 2, 4)\n\nDOUBLE PRECISION BSB (10, 4, 3)\n\nDOUBLE PRECISION S (10, 3, 4) , Dr, P(10, 4) ,SB(10, 3, 4)\n\nr-ECISION WR (4) ,WI (4) ,HH (4, 4) ,XX (4, 4) ,ACL(10, 3)\n\nDOUBLE\nDOUBLE PRECISION SBT(10,3 ),Q(10, 3),R(10, 3),B(10,2,4)\n\nDOUBLE PRECISION PR (4) ,PZ (4) ,PD (10, 4) ,FS (4)\n\nINTEGER IPV (10) ,MCCN (100) ,NFOINT, NGRIDH, CON (100)\n\nDOUBLE PRECISION RAD(10, 3) ,PADINV(10, 3) ,SNEW(10, 3,4) ,U(10, 3)\n\nDOUBLE PRECISION V(10, 3),SI(10,3),W(10 ,3),Y(10, 3),SM,WORK(10)\n\nLOGICAL NOISE\n\nCCMMCN/INOU/KIN, NDUr\nKO=0\nIA = 1\nREAD (5, 11111)NPOINT\n\n33333 READ(5, 11111, END-22222)ITI4E, K\n\n11111 FORMAT (214)\n\nDO 44444 IXYZ = IA, ITIME\n44444 \tMCN (IXYZ) =K0\n\nMCCN (ITIME)=K\n\nIA = ITIME\n\n\nKG=K\n\n\nGO TO 33333\n\n22222 DO 55555 IXYZ = ITIME, NPOINT\n\n55555 MCCN (IXYZ) = K0\n\nLUDOLF= 2. 71828182845945D0\nLUDINV = 1. WO/LUDOLEF\nOLFM1 = LUDOLF - 1. 0D 0\n\nDINM1 = LUDINV - 1. O0\n\nNAA = 2\n\nNC =10\n\nKIN= 5\n\nKOUIT= 6\n\nN= 1\nM =\n 1\n\nN2 = 2\n\n\n253\n\nSWMAT2 FORTRAN\nKCCN = 2\n\nNE =\n 4\nNS= 10\n\nIPRT= 17\n\nIEND= 50\n\nIPRT = 49\n\nICOUNT = 2\n\nNA= 10\n\nNB= 10\n\n\nNR NA\nNRA= 10\n\nNR= 10\n\n\nNQ= 10\nNG=10\nPZ(1) = .1]0\n\n\nPR(1)= .ID0\n\nDO 15 I=2,N\n\nPR (I)= PR (1)\n15 PZ(I)= Pz(1)\n\n22 IF(ICOUNT. NE. 0) READ (KIN, 9500, END=2)\nSIG4A= 1. DO\n\nESIG4A= LUDOLF**SIG4A\n\nES INV= LUDIN V**S ICMA\nC(1,1) = 1.00\n\nC(2,2) = 1.D 0\n\nC(1, 2) = 0.00\n\nC(2,1) = 0.O0)\nDr = 1.9 0\n\nA(,1)= 1.4140D0\n\nNAR= 100\n\nNAC = 50\n\nQ(1,1) = 3.00\n\n\nR(1,1)= 1.ADO\n\nR(2,1) = 0.O 0\n\n\nB(1,1,1i)=\n\n2.EDO\n\nB(1,1,2)= .M0\n\nP(1,1) = .7D0\n\nP(2,2)\nP(3,2)\nP(3, 3)\nP(1,2)\nP(3,1)\nP(2,1)\nP(1, 3)\n\nOD\n\n=\n= 0.0DD9\n\n= .. 09D0\n\n=.30\n= .09D0\n=.30\n\n= .81D0\n\n\nP(2,3) = 0.09D0\n\nP(4,1) = .01D0\n\nP(1, 4) = .81D0\n\nP(4,2) = 01D0\n\nP (4, 3) = .01D0\n\n\n(PR(I),FZ(I),I=1,N)-\n\n\n254\nS[lAT2 FCRTRAN\nP(4,4) = .01D0\nP(2,4) = .09D 0\n\nP(3,4) = .09D0\n\nWRITE (KOUT, 9903)\n\nCALL MATIO (NA, ICCN, 1CN, P, 3)\n\nC\nWRITE (KOUT, 46)\n46 FOPf4AT(/,41 PI,/)\n47 FORSAT (3D 25. 15)\nORIGINAL PAGE IS\nWRITE KOUr, 9600)\n\nOF POOR QUALIT\n\nCALL MATIO NA,N,N,A, 3)\nWRPE (KOUr, 9700)\n\nCALL MATIO INA, N, N, Q, 3)\n\nWRITE (KOUT, 9800)\n\nCALL MATIO (NR, N, N, R, 3)\n\nDO 222 K=TICON\n\nlMl = K-i\n\nWRITE KOUT, 9900) IM1\n\n222 \tWRITE (KOUT, 9500) ((B(I,J,K),J=1,M) ,I=1,N)\n44 COorINUE\n\nWOR4(l, 1,1) = -1.06336184D0\n\nGNOR,4(1,2,1) = -1.88787889D-02\n\nGNOR (2,1,1) = 7.90151884D-01\n\nGNORM (2,2,1) = -5.8358246D-02\n\nGNORM(1,1,2) = -3.69012096D-01\n\nGALIRM(1, 2, 2)=1. 04948339D-01\n\nGNOM (2, 1,2) = -1.14016354D 0\n\nGNOP(2, 2, 2) = -1.36308767D-01\n\nGNOR14 (1,1, 3)= -1. 42566767D0\n\nGNOBM(2, 1,3)= -2.87451308D-01\n\nGNORM (2, 2, 3) = -7. 27012438-02\n\nG40IR(1, 2, 3) = 1.51884285D-02\n\nOPNOM (1,1,4) = 0. WO\n\nGNORM(2, 2, 4) = 0. 302\n\nGNORA (1, 2, 4) = 0.0:0\n\nGNORM(1, 2, 4) = O. DO\n\nDO 14 IN=l, 50\n\nCON \t (IN) = LMCN (1)\n14 CCNUUE\n667 \t FOR4MAT (515)\n\nX0(1) = .02D0\n\nIR = 1\n\nNPRPL = 1\n\nDO 57 1K = 1, CCN\n\nIM1 = IK - 1\n\nWRITE (KOUT, 9902) IKI1\n\n57\nWRITE KOUT, 9500) ((GNOI l(IJ,IL, IK) ,IL=1,N) ,IJ=1,N)\nNGRIDH\n5\nV(1,I)\nB (2,I,1)\nV (2, 2)\nB (2, 2, 1)\n\n255\n\n&%?NAT2FOIrRAN\n\nC\nC\nC\nC\nC\nC\nC\nC\n\nV(2,1) = 8(2,1,1)\nV(1,2) = (1, 2,1)\nCALL M4-L (NA, M, M, N, N,M, V, \'OM, U)\nCAIL MADDINA, M\\, A, N, N,1J- A, AC )\nCALL MSCALE aqG, N,M, -1. OD0,CNORM)\n1ONE = I\nCALL MMLJL (NC, N, N, IONE, IR, N,C, X0, Y0)\n66 Fg\'AT (lX, 3325. 15)\nCALL DRnflIM(NA, DC, NG,MR, NMC, N, IR,MLACL,C, (NORM, X0,WORK,\nIY, U, IPVT, ARRAY, DP, NFOINT, NPRFL)\nCALL READY2 (NAA,\nM,\nYNQ, NR, W, NS, A, NM,\nCN, A,B, R, Q,P,\nI WRW I, S,S U, VW, X, Y, NOR4, RAD, PADINV, BS,WCRK, IPVr, SND)\nS,\nC\nDT = 1. OD0\n\nX0(1) = . 02DO\nC\n\nCALL MSCALE NG, N,M,-1. ED0, NOPM)\n\nXO (2) = 0. OD0\nCALL SWITCH (NA, M, C, IC, MR, AC, N, IR, NIA,\nON,M,A,B, P,\n1 C, GNORM, X2, E, ETEMP, D4,WCRK, YO, UO, V,W, SW, IPVr, ARRAY, Dr, NPOIR ,\n2 NGRIDH,MCaq)\n9500 FOMAT (2D25. 15)\n20@0 FORMAT (/, 3325.15)\n960 FOMdAT(/,31 A\n9700 FORMAT (/,3 Q\n9800 FCMATyV,31 R\n9900 FOP!AT(/, MB ,I5,/)\n9903 FcORMAT(/,ai P )\n9902 FOQ4AT(/,31 G ,I5,/)\n2\nSTOP\nEND\n\n\n256\nLIST OF REFERENCES\n\n[1]\n\nShooman, Martin L., Probabilistic Reliability:\ning Approach. New York: McGraw-Hill, 1968.\n\n[2]\n\nGreene, A.E. and Bourne, A.J., Reliability Technology.\nLondon: Wiley-Interscience, 1972.\n\n[3]\n\nPaz, Azaria, Introduction to Probabilistic Automata.\nNew York: Academic Press, 1971.\n\n[4]\n\nFel\'dbaum, A.A., "Dual-Control Theory. I," Automation and\nRemote Control, vol. 21, no. 9, pp. 874-880, April 1961.\n\n[5]\n\nFel\'dbaum, A.A., "Dual Control Theory. II," Automation and\nRemote Control, vol. 21, no. 11, pp. 1033-1039, May 1961.\n\n[6]\n\nFel\'dbaum, A.A., "The Theory of Dual Control. III,"\nAutomation and Remote Control, vol. 22, no. 1, pp. 1-12,\nAug. 1961.\n\n[7]\n\nFel\'dbaum, A.A., "The Theory of Dual Control. IV," Automation\nand Remote Control, vol. 22, no. 2, pp. 109-121, Sept. 1961.\n\n[8]\n\nRudin, W., Real and Complex Analysis. 2nd ed.\nMcGraw-Hill, 1974.\n\n[9]\n\nSegal, I.E., and Kunze, R.A., Integrals and Operators.\nNew York: McGraw-Hill, 1968.\n\n[10]\n\nHalmos, Paul R., Measure Theory.\n1974.\n\n[il]\n\nGantmacher, F.R., The Theory of Matrices, vols. I & II.\nNew York:\nChelsea, 1960.\n\n[12]\n\nBauer, H., Probability Theory and Elements of Measure Theory.\nNew York: Holt, Rinehart & Winston, 1972.\n\n[13]\n\nDoob, J.L., Stochastic Processes.\n\n[14]\n\nChung, Kai Lai, Markov Chains with Stationary Transition\nProbabilities, 2nd. ed. New York: Springer-verlag, 1967.\n\n[15]\n\nDerman, Cyrus, Finite State Markovian Decision Processes.\nNew York: Academic Press, 1970.\n\n[16]\n\nCox, D.R., Renewal Theory.\n\nNew York:\n\nLondon:\n\nNew York:\n\nAn Engineer\xc2\xad\n\nNew York:\n\nSpringer-Verlag,\n\nJohn Wiley, 1953.\n\nMethuen, 1970.\n\n257\n(17] \t\n\nCorcoran, Henry, "Optimal Policies in Reliability Problems,"\n\nM.S. Thesis, Dept. of Elec. Engr., M.I.T., Cambridge, Ma,\n\n1964.\n\n\n[18] \t\n\nBarlow, R.E. and Proschan, F., Mathematical Theory of\n\nReliability. New York: John Wiley, 1965.\n\n\n[19] \t\n\nGendenko, B.V., Belyayev, Yu. K., Solovgev, A.D., Mathematical\n\nMethods of Reliability Theory. New York: Academic Press,\n\n1969.\n\n\n[201 \t\n\nAthans, M., ed., Special Issue on the Linear-Quadratic-Gauss\xc2\xad\nian Estimation and Control Problem. IEEE Trans. on Automatic\n\nControl, vol. AC-16, no. 6, pp. 527-869, Dec. 1971.\n\n\n[21] \t\n\nAthans, M. and Falb, P.L., Optimal Control.\nMcGraw-Hill, 1966.\n\n\n[22] \t\n\nWonham, W.M., "Random Differential Equations in Control\n\nTheory," from Probabilistic Methods in Applied Mathematics,\n\nvol. II. A.T. Bharucha-Reid, ed. New York: Academic Press,\n\n1970.\n\n\n[23] \t\n\nBeard, R.V., "Failure Accommodation in Linear Systems\n\nThrough Self-Reorganization, Ph.D. Thesis, Dept. of Aero.,\n\nM.I.T., Cambridge, Ma., Feb. 1971.\n\n\n[24] \t\n\nSworder, D.D., "Feedback Control of.a Class of Linear Systems\n\nwith Jump Parameters," IEEE Trans. on Automatic Control,\n\nvol. AC-14, no. 1, pp. 9-14, Feb. 1969.\n\n\n[25] \t\n\nRatner, R.S. and Luenberger, D.G., "Performance-Adaptive\n\nPenewal Policies for Linear Systems," IEEE Trans. on\n\nAutomatic Control, vol. AC-14, no. 4, pp. 344-351, Aug. 1969.\n\n\n[26] \t\n\nSworder, D.D., "Uniform Performance-Adaptive Renewal Policies\n\nfor Linear Systems," IEEE Trans. on Automatic Control, vol.\n\nAC-15, no. 5, pp. 581-583, Oct. 1970.\n\n\n[27] \t\n\nBar-Shalom, Y. and Sivan, R., "On the Optimal Control of\n\nDiscrete-Time Linear Systems with Random Parameters,"\n\nIEEE Trans. on Automatic Control, vol. AC-14, no. 1, pp. 3-8,\n\nFeb. 1969.\n\n\n[28] \t\n\nWillner, Dieter, "Observation and Control of Partially\n\nUnknown Systems," Rpt. No. ESL-R-496, Electronic Systems\n\nLaboratory, M.I.T., Cambridge, Ma., Sept. 1971.\n\n\n[29] \t\n\nPierce, B.D. and Sworder, D.D., "Bayes and Minimax Controllers\n\nfor a Linear System with Stochastic Jump Parameters," IEEE\n\nTrans. on Automatic Control, vol. AC-16, no. 4, pp. 300-307,\n\nAug. 1971.\n\n\nNew York:\n\n\n258\n\n[30] \t\n\nChang,. C.B. and Athans, M., "Hypothesis Testing and State\n\nEstimation for Discrete Systems with Finite-Valued Switching\n\nParameters," Rpt. No. ESL-P-758, Electronic Systems\n\nLaboratory, M.I.T., Cambridge, Ma., June 1977.\n\n\n[31] \t\n\nWong, P.-K., Stein, G., Athans, M., "Structural Reliability\n\nand Robustness Properties of Optimal Linear-Quadratic\n\nMultivariable Regulators," Rpt. No. ESL-P-745, Electronic\n\nSystems Laboratory, M.I.T., Cambridge, Ma., May 1977.\n\n\n[32] \t\n\nSafonov, M.G. and Athans, M., "Gain and Phase Margin for\n\nMultiloop LQG Regulators," IEEE Trans. on Automatic Control,\n\nvol. AC-22, no. 2, pp. 173-179, April 1977.\n\n\n[33] \t\n\nSafonov, M.G. and Athans, M., "Robustness and Computational\n\nAspects of Nonlinear Stochastic Estimators and Regulators,"\n\nRpt. No. ESL-P-741, Electronic Systems Laboratory, M.I.T.,\n\nCambridge, Ma., April 1977.\n\n\n[34] \t\n\nWong, P.-K. and Athans, M., "Closed-Loop Structural Stability\n\nfor Linear-Quadratic Optimal Systems," IEEE Trans. on\n\nAutomatic Control, vol. AC-22, no. 1, pp. 94-99, Feb. 1977.\n\n\n[35] \t\n\nWong, P.-K., "On the Interaction Structure of Linear Multi-\n\nInput Feedback Control Systems," S.M. Thesis, Dept. of Elec.\n\nEngr. and Comp. Sci., M.I.T., Cambridge, Ma., Sept. 1975.\n\n\n[36] \t\n\nSafonov, M.G., "Robustness and Stability Aspects of Stochastic\n\nMultivariable Feedback System Design," Ph.D. Thesis, Dept. of\n\nElec. Engr. and Comp. Sci., M.I.T., Cambridge, Ma., Sept. 1977.\n\n\n[37] \t\n\nAthans, M., Ku, R., Gershwin, S.B., "The Uncertainty\n\nThreshold Principle: Fundamental Limitations of Optimal\n\nDecision Making Under Dynamic Uncertainty," Rpt. No.\n\nESL-P-688, Electronic Systems Laboratory, M.I.T., Cambridge,\n\nMa., Oct. 1976.\n\n\n[38] \t\n\nKu, R.T. and Athans, M., "Further Results on the Uncertainty\n\nThreshold Principle," Rpt. No. ESL-P-727, Electronic Systems\n\nLaboratory, M.I.T., Cambridge, Ma., March 1977.\n\n\n[39] \t\n\nKu, R., Athans, M., Varaiya, P., "The Effects of Discounted\n\nCost on the Uncertainty Threshold Principle," Rpt. No.\n\nESL-P-749, Electronic Systems Laboratory, M.I.T., Cambridge,\n\nMa., April 1977.\n\n\n[40] \t\n\nBirdwell, J.D. and Athans, M., "On the Relationship Between\n\nReliability and Linear Quadratic Optimal Control," Proc.\n\n1977 IEEE Conference on Decision and Control Theory,\n\npp. 129-134, Dec. 1977.\n\n\n259\n[41]\n\nAthans, M., "The Matrix MinimumPrinciple," Information and\nControl, vol. 11, pp. 592-606, 1967.\n\n[42]\n\nLoeve, Probability Theory.\n\nNew York:\n\nVan Nostrand, 1963.\n\n'