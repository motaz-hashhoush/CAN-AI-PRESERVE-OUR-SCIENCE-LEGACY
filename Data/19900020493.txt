b'N90_2<,\n\nA:lt, onon:ous\n\nSensor-Based\nl\'(a:ll\n\nt_,vian \\\\Tilcox\n\nTso\n\nD::al-A:ln\nTodd\n\n_0atellite\n\nLitwin\n\nSalmd\n\nJet. Propulsion\nl,aboralor3\n(\'alifovnia\nInsl.itut, e of \'Tcclln(,\nPasadena,\n\n(:A\n\nGrapI)ling\nBruce\n\nIlavati\n\nBen\n\nogy\n\n9110!1\n\nAbstract\nThe NASA Tch\'robotic\nI/esearch\nfor on-orBit\nassembly,\nmaintenance,\nof its more challenging\nThe t_sk involves\n\nProject\nis exploring\nlhe fi asil,ility of using rolmls in space\nand repair operalions.\nI), al-arm salellite\ngrappling\nis one\n\ntasks.\nthe integration\n\nof technologies\n\ndevelopc,\n\nl in lhe\n\nSensing\n\nand\n\nI_ercept.ion\n\n(S,_:P) Subsystem\nfor object acquisition\nand tracking,\nand the ).lanilmlator\nCentre[\nand Mechanizat.ion\n(MCM)\nSubsystem\nfor dual-arm\ncontrol.\nS,_P acqu,res\nand tracks the position,\norientation,\nvelocity, and angular\nvelocity of a slowly spimfing\ns:t.ellite,\nand sends tracking\ndata\nto the M(_M subsystem.\nMCM grapples\nthe satellite\nand 1,rings it to rest, controlling\nthe arms\nso that no excessive forces or torques\nare exerled on the sat.ell;te or arms.\nThe demonstration\nsetup includes\na 350-potmd\nsatellile\nnlockul) which can spin fl\'eely on\na gimbal for several ntinutes,\nclosely simulating\nthe dynatuics\nof a real satellite.\nThe satellite\nmockup\nis fitted\nwith a panel under which inay be mount,,.l\nvarious\nelements\nsuch as line\nreplacement\ntnodules and electrical\nconnectors\nthat will I., us_ d t,o demonstrate\nservicing\ntasks\nonce the satellite\nis docked.\nThe subsystems\nare housed in three MicroVAX\nII inicro,om;mlers.\nThe hardware\noflhe S&P\nSul_s\\stem\nillcludcs CCI) cameras,\nvideo digiliz,\'rs,\nfram,\' lmll,\'rs, 1MI:EX (a CIl:";lOIII\npipelined\nvid,\'c; processor),\na lime-co,h\'\ngenerator\nwith millisecond\n1,r,\'cisi m, and a M icroVA X 11 COlUputer.\nl{s s_>l\'tware is wrilten\nin Pascal and is based on a locally wri;len\nvision software\nlil_rary. The\nhardware\nof lhe _ICM Sul,sys/(\'m\nincludes PUMA .%0 r,_l-)t :u\'ms, Lord f\xc2\xa2)r(\'e/tor(ple\nsellsors_\ntwo M icroVAX I1 COmlmlcrs, and (!nimal ion pneumatic\nl>:_ralh I grilq_ers.\nIt s software is written\nin (:, and is I>;m,\'_l on a robot language\ncalled t{(\'(\'L.\nThis papc:r describes\ntl_e two subsyslems\nand I_rovi,h\':. t,>t. results\nsatellite\nnlockup\nwilh rolal i(.,llal rales of up to :2 rplJl.\n\n1\n\nis explotin_\n\nlhe\n\nl ilne-consuming\n\nrepair\nThis\n\nsatellites.\n\nl>_ssil>ilili\xc2\xa2\'s\n\noperali(ms,\n\nI\'ve.jeer is looking\nand\n\ngralq>ling\n\nof lhe\n\nIntroduction\n\nNA.qA\nor\n\n(m lh,\'\n\nThat\n\nsuch\n\nas\n\nautono::_ous\n\nextra\n\nat llw use _,f a:ll(momous\n\noperalhms.\npaper\n\nof using\n\nAll of llwse\n\nis colkcerned\nchallenge\n\nwith\ncenlets\n\nop,,ralions\nat\'ound\n\nv(,hh\'ulav\n\nsystems\n\none challenge\nthe\n\nsv,,_ eln ; ill place\n\npresent\nassociated\nfacl\n\n3O7\n\na(livi\'v.\n\nThe\n\nfor t)el I\'o:\'::,ing\n\nthat\n\ncl_alh,ny,\'s\nv,ilh\nJn_,sl\n\nol\'asl\nNASA\n\nol:-orlfit\nIt, lho\n\nfield\n\nsalelliles\n\nfl)r dangerous\n\n\'l\'eh,r<>l>ol\n\nasselnldy,\n\nll:e repair\ns_lch\n\nrot:auts\n\nResearch\n\nlnaintenance.\n\nof rol*ot it\'s.\n\nof arliticial\n,re\n\nearlh-o\'b\n\nI ng\n\nspin-slal>ilized.\n\nIn\n\nORIGINAL\nBLACK\n\nAI\',,:D WHITE\n\nPAGE\ni:.\'ii,JfOGRAPPI\n\n\\\n\\\n\nFigure\n\norder\n\nto repair\n\nsuch a satellite,\n\na dual-arm\nrobot\nThe Testbed\ncomposed\nSubsystem\ninvolved\nsatellite\ndata\n\nSetup\n\nfirst be de-spun.\n\nAn investigation\n\nwas made into tile use of\n\nwith visual assist to grapple and de-spin a rotating\nsatellite mockup.\nof tile NASA Telerobot\nProject,\nhoused at the Jet Propulsion\nLaboratory,\n\nof several subsystems.\nand the Manipulators\n\nTwo of these subsystems,\nand Control Mechanization\n\nis\n\nthe Sensing and Perception\n(S_P)\n(MCM) Subsystem,\nwere directly\n\nin the effort to grapple a spinning satellite.\nS&P visually acquired and tracked tilt rotating\nand transmitted\nthe satellite\'s\nstate information\nto MCM in real time. MCM, using tile\n\nfrom Sg:P, directed\n\nBelow\ntechnique.\n\nit must\n\n1: Testbed\n\nwe will discuss\n\nthe arms to grab\nthese\n\nthe satellite\n\ntwo subsystems\n\n308\n\nand\n\nand to stop its motion\nprovide\n\ntile details\n\nas shown\n\nof tile satellite\n\nin Figure\ngrappling\n\n1.\n\n2\n\nTestbed\n\nSetup\n\nThe Testbed of the NASA Telerobot Project is a facility which is composed\ndivided into three main sections: the computer\nfacility, the operator control\n\nof many parts.\nIt is\nstation, and the test\n\narea.\nIn the computer facility there are various computer\nsystems to support the subsystems.\nIncluded\namong them are several MicroVAX\nII microcomputers,\nSun workstations,\nand a Symbolics\nLisp\nmachine. There are also other specialized processors used at low levels of support.\nThe operator\n\ncontrol\n\nworking surfaces,\n\nstation\n\ncomputer\n\nprovides\n\nterminals,\n\na place\n\nfor the\n\nvideo monitors,\n\ngood view of the test area.\nThe test area contains everything\n\nelse. It houses\n\noperators\n\nduring\n\nand joysticks.\n\nTestbed\n\nIt is situated\n\nthe t_\'o manipulation\n\narms,\n\nuse.\n\nIt has\n\nso as to give a\nplus a third arm\n\nused for holding movable video cameras (not used for satellite grappling),\nand all of the video\ncameras. The satellite mockup, as well as other targets for telerobotic\nresearch, are in this area. In\naddition, there is a calibration fixture used to calibrate\nto a common coordinate system.\nSatellite\n\nthe cameras\n\nin SL:P and the arms\n\nin MCM\n\nMockup\n\nThe satellite\n\nmockup\n\nis a 350-pound\n\nmodel\n\nof a generic\n\nartificial\n\nsatellite.\n\nIt is suspended\n\nfrom a\n\ncounterweight\nby a long cable which is connected\n-- through\na fairly wide opening in the top of\nthe satellite -- to a gimbal near its center of mass. The method of suspension\nallows the satellite\nto move within a small area in a manner similar to its free space counterparts.\nThe sides of the mockup\ntypical\n\nof real satellites.\n\nelements\n\ndemonstrate\nS&P\n\nof real solar panels,\n\nThis gives S&P a realistic\n\nspecular reflections.\nOn one side of the\nvarious\n\nconsist\n\nmockup\n\nthere\n\nservicing\n\nvisual\n\nis a removable\n\nsuch as line replacement\n\nmodules\n\ntasks once the satellite\n\nframed\n\nin the gold-foil\n\ntarget,\n\ntask\n\npanel,\n\nand electrical\n\nis grappled\n\ncomplete\n\ninsulating\n\nwith\n\nunder\n\nwhich\n\nconnectors.\n\nvisual\nmay\n\nThese\n\nmaterial\nclutter\n\nand\n\nbe mounted\n\ncan be used to\n\nand docked.\n\nHardware\n\nThe S&P Subsystem\nhardware consists of a DEC MicroVAX II microcomputer\nand several other\npieces of special equipment.\nThere is a time-code\ngenerator,\nshared with MCM, which allows\ntime tagging the data to millisecond\nprecision.\nmounted\nto the rear of the test area, yielding\ntwo are mounted\ndescribed here.\nThe cameras\nprocessor.\n\non a robot\n\nThere are five video cameras.\nThree of them are\ngood overall views of the work region. The other\n\narm and are used for close-up\n\nfeed their signals into video digitizers,\n\nThe processor\n\nis called IMFEX,\n\nviews;\n\nthey\n\nwere not used in the work\n\nwhich in turn feed a custom\n\nthe Image Feature\n\nExtractor,\n\nvideo pipelined\n\nand it uses a thresholded\n\nmodified-Sobel\noperator to find high-contrast\nedges in video images. The output of IMFEX is fed\ninto video buffers for storage, access, and manipulation\nby the MicroVAX\nII. The video buffers\nhave internal\ngraphics\n\nD/A\n\ngenerated\n\nconverters\n\nto allow viewing\n\nby the MicroVAX\n\nof their\n\ncontents,\n\nII, or a combination\n\nof the\n\nwhich may be a captured\ntwo.\n\nA 16-by-16\n\nvideo\n\nframe,\ncrossbar\n\nswitchis usedto route all of the analogvideosignalsbetweenthe components entionedabove,\nm\nand overto the videomonitorsin the operatorcontrolstationfor display.\nS&:P Software\nThe S&Psoftwareis composedf two majorsections, oth written in VAX Pascal.The first section\no\nb\nis a 30,000-line\ngeneral-purpose\nvision softwaresupportlibrary. It containsthe softwareusedto\ncontrol and access varioushardwarecomponents S&:P,as well as routines to performall\nthe\nof\nmannerof supportservices machinevision. Includedin this library are the routinesusedto\nfor\nperformthe functionsof acquisitionandtrackingdescribed\nbelow,to performcamera\ncalibration,\nand to dealwith objectmodels.The second\nmajorsectionof the softwareis a 20,000-line\nsoftware\npackage\nwhichis the S_:P-specificpplicationcode.It is decomposed five separate\na\ninto\ntasks,all\nrunning concurrently.\nMCM Hardware\nThe MCM Subsystem\nhardware\nconsists two PUMA 560robot arms.Eacharm is equipped\nof\nwith\na Unimationpneumaticparallelgripper whichhasbeenfitted with simpleparallelfingersholding\na specialgrapplingtool. Eachtool hasa flexiblehandleanda Velcropad at the endin orderto\nhold to the satellite mockup,which has the two complementary elcropadsattachedon either\nV\nsideof the task panel. Eacharm is alsoequippedwith a commercial(Lord Corporation)wrist\nforce/torquesensor.The wrist force/torquesensors reusedto readthe forcesandtorquessensed\na\nin all six dimensions.The computinghardwareconsistsof two DEC MicroVAX II computers.\nEachoneis interfacedto the LSI 11/73microprocessors the Unimatecontrollervia two DRVll\nof\nparallelcards.The Unimatecontrollerreadsthe LORD force/torquesensor ata throughanother\nd\nDRVll parallel card. The S_zP\nobject statedata is obtainedthrough a 9600baudRS-232serial\nline connected\nbetweenthe S&PMicroVAXto the MCM MicroVAXs.Figure2 shows schematic\na\ndrawingof the hardware.\nMCM Software\nThe MCM MicroVAXsrun undera modifiedBerkeley\nBSD4.3 Unix operatingsystem.The main\nrobot languageis RCCL (Robot Control C Library) which was developed\noriginally at Purdue\nUniversityby VincentHayward[3]based\nonRichardPaul\'sroboticstextbook[4]andlater enhanced\nby John Lloyd [5] and ported to a MicroVAX II [6]. RCCL is a collectionof C functionswhich\nprovideeasyandgeneral obot programming. he software\nr\nT\ncanbe partitionedinto two mainparts:\nthe planningleveland the real-timecontrollevel.\nThe planninglevelconsists functionsthat allowthe programmero specifydesiredcoordinate\nof\nt\nframesfor the robot end-pointtarget position. The programmer ustspecifyseveralrames,such\nm\nf\nas wherethe robot is in the world frame and in the tool fraane. He/shemust alsospecifythe\nvelocity,and whetherthe motionshouldbe carriedout in Cartesianor joint-interpolatedmodes.\nThe relationships\nbetweenthe variousframesareenteredin the codeexactly as onewouldwrite\nthem in mathematicalnotations.A functioncalledMakeposition\ninterpretsthe codeand setsup\n\n310\n\nS&P\nMic_VAX\n\nSerial lntea\'fac\xc2\xa2\nII\n\nMicroVAX\nRCCL\nUNIX/C\n\nII\n\nMic_VAX\nRCCL\nUNIX/C\n\nII\n\nTIME-CODE\nGENERATOR\n\nFigure\n\nappropriate\n\nmatrix\np\n\nThis simply\n\n2: Schematic\n\nequations.\n\nIts general\n\n= Makeposition\n\n("P\',\n\nsets up a matrix\n\ndrawing of the hardware\n\nform is:\n\nZ,...,\n\nT6,...,\n\nobjective\n\nU, TOOL,\n\nR)\n\nequation\n(Z...)T6(...R)\n\nThe main\n\nR, EQ, A, B,...,\n\nis to solve this equation\n\n= AB...U\n\n(1)\n\nfor T6 as\n\nT6 = (Z...)-I(AB...U)(...R)\n\n-1\n\n(2)\n\nwhere T6 represents\na homogeneous transformation\nrelating the link 6 frame in the 0th (or shoulder)\nframe. The planning level runs in a normal time-shared\nmanner.\nA program can develop many\nmotions and place them in a queue for the control level to execute sequentially.\nAn important\nfeature of RCCL is that it allows one to modify the matrices in equation\n(1) in the control level.\n\n311\n\nThese\n\nmodifications\n\nfrom\n\nS_:P object\n\ncan be triggered\nstate\n\nwork to implement\nmockup.\n\ndata\n\nboth\n\neither\n\nby the planning\n\nor force/torque\n\nthe tracking\n\nand\n\ndata.\n\nlevel or by external\n\nThis feature\n\nforce/compliant\n\nhas been\n\ncontrol\n\nsources\n\nsuch\n\nused extensively\n\nduring\n\ngrappling\n\nas\n\nin our\n\nthe satellite\n\nThe control level which is called RCI (Robot Control Interface) is a general robot programming\nenvironment.\nOne can write his/her own robot control programs\nand create custom trajectories\nto\nrun the robots.\nIn the normal RCCL operations\nthis level receives the motions from the motion\nqueue\n\nand\n\nuses a trajectory\n\ninverse kinematics\nprocessors\nvia the\nThe system\n\ngenerator\n\nto interpolate\n\nis performed\nto obtain\nLSI 11/73 computer.\n\nworks\n\nby a hardware\n\nthe joint\n\nclock (located\n\nbetween\n\nthe\n\nspecified\n\nangle set points\n\nvia\n\npoints.\n\nFinally,\n\nto be sent to the joint\n\nin the Unimation\n\ncontroller)\n\nmicro-\n\nwhich periodically\n\nsends an interrupt\nto a communication\nprogram in the LSI 11/73. At every interrupt,\nthis program\ngathers information\nfrom the arm -- which includes the joint angles and other sensors that have\nbeen interfaced\nto the LSI 11/73 -- and makes them available to the MicroVAX in shared memory; it\nsignals the MicroVAX with a hardware\ninterrupt.\nThe MicroVAX reads these data and immediately\nsends the joint angles that have been computed\nin the previous cycle back to the LSI 11/73 for\nexecution.\nNote that in this implementation\nthe VAL language\nis completely\nbypassed.\nThe\nhardware\nof the Unimate controller\nremains intact, however, and one can switch between the VAL\nlanguage\nand RCCL without any hardware\nmodifications.\n\n3\n\nSgzP\n\nAcquisition\n\nand\n\nTracking\n\nAlgorithms\n\nThe task of watching\na moving object is broken\nacquisition.\nThis is the stage wherein the object\n\ndown into two stages, the first of which is called\nof interest is first localized within the views of the\n\ncameras, and an initial computation\nis made as to its location\ncomputationally\nintensive,\nand cannot perform quickly enough\nkeep up with a moving object in real time.\nThe\n\nsecond\n\nstage\n\nis call tracking.\n\nand is used to follow the\nprovided\nby acquisition.\n\nobject\n\nTracking\n\nand movement\nwithin\non currently\navailable\n\nis more computationally\n\nas it moves,\n\nupdating\n\nthe\n\nstate\n\nBoth stages compute\nthe following time-tagged\nstate information\ntranslational\nvelocity, orientation,\nangular velocity, and a covariance\n\nefficient\n\ninformation\n\nthan\nthat\n\n3-space. It is\ncomputers\nto\nacquisition,\nwas initially\n\nin three dimensions:\nposition,\nmatrix of these values.\n\nAcquisition\nA fully autonomous\nacquisition\nalgorithm\nis currently\nunder development\nat the Jet Propulsion\nLaboratory\nand was not tested in the grappling experiment.\nA moment\'s\nreflection, however, will\nreveal that it is not possible to track an object without first acquiring it in some fashion. In order to\nsatisfy this need, a "quick-and-dirty"\nfor the current work.\n\noperator-assisted\n\nversion called\n\nhand acquisition\n\nwas designed\n\nIn hand acquisition,\nan a priori position is used as a starting\npoint. Using this position,\nS&P\ndisplays a wire-frame\nprojection\nof the satellite\'s\nobject model in the display, superimposed\non the\nraw video. While the satellite was held still, the operator\nuses the joysticks to move the wire-frame\noverlay\n\n--\n\nand thus the state\n\nof the object\n\nmodel\n\n312\n\n-- until it roughly overlaps\n\nthe satellite\n\nmockup\n\nin all camera views.\n\nOnce complete,\n\nthe operator\n\nof a moving\n\nwas attempted\n\nwith mixed\n\nsatellite\n\nsignals that\n\ntracking\n\nmay start.\n\nHand\n\nacquisition\n\nresults.\n\nTracking\nThe tracking algorithm\nwas designed by Donald B. Gennery. Detailed descriptions of the algorithm\nare given elsewhere [1,2]. The tracker performs its operations\nin five major phases.\nIn the first\nphase it acquires\n\na frame\n\nof video and notes the time tag associated\n\nwith the data.\n\nIn the second\n\nphase the old object state is propagated forward to the time of the new data. In the third phase a\nprojection of the propagated object state\'s edges is made into the view of the camera which took the\nnew data. In the fourth stage measurements\naxe made of tile discrepancies\nbetween the locations\nof edge points in the projected edges and the locations of edge points in the data. In the fifth and\nfinal stage the projected object state is adjusted by using a least-squares\ntechnique\nwith respect to\nthe measurements\ntaken in the fourth stage. Uncertainties\nare propagated and determine\nthe effect\nthat\n\nany\nThese\nis sent to\ncontinues\n\ngiven data set has on the current object state.\nfive stages constitute one tracking cycle. Between cycles, the updated state information\nMCM. Then the tracker selects the next camera and performs another tracking\ncycle. It\nin this fashion until told to stop or until it loses track. If track is lost, S&P cycles back\n\ninto acquisition\n\n4\n\nMCM\n\nThe\n\ntwo\n\nand repeats\n\nthe entire\n\nTracking\n\nrobots\n\nare\n\ndriven\n\nand\n\nprocess.\n\nGrappling\n\nindependently\n\nAlgorithms\n\nby two MicroVAXs.\n\nThey\n\nrun\n\nthe\n\nsame\n\ncopy of the\n\nsoftware except each has its own coordinate\nframes because of the different locations\nof the robots\nand because they grapple different points on the satellite m<)ckup. Two machines are used because\nthe computing\n\npower\n\nof one MicroVAX\n\nis not adequate\n\nto control\n\ntwo robots\n\nduring\n\nthe tracking\n\nphase. The two robots are coordinated\nbecause they are basically driven from the same source of\ndatathe S&P object states of the satellite mockup.\nThe MCM software receives the satellite object state at a rate of about two times per second.\nThe object state consists of a time-stamp,\nof the satellite mockup, the translational\nA complete\n\ncycle of satellite\n\nposition vector and orientation\nquaternion\nof the centroid\nand angular velocities, and their covariances.\n\ngrappling\n\nis comprised\n\nof four phases:\n\napproach,\n\ntracking,\n\ngrappling,\n\nand docking.\nIn the approach\nphase, the MCM software monitors\nthe orientation\nand angular velocity of the\nsatellite mockup.\nIt deploys the robots to the approach\npositions when the satellite\nmockup is\nspinning with a rate at or below two rpm.\nhave the maximum\nwork space for tracking\nis described\n\nThe approach\nand grappling.\n\npositions are chosen so that the robots\nThe approach position of the left robot\n\nby the follow equation:\nw\no TL \xc2\xb0TL 6_T = =\nL\n:TI_\n\nwhere\n\n\'_TL is a transformation\n\napproach\n\nframe\n\nThe robots\nfacing\n\nof the left robot\n\ndescribing\n\nas shown in Figure\n\nwait in the approach\n\nthe tools with a designed\n\nthe 0th\n\npositions\n\ndistance\n\nframe,\n\n(3)\n6TL is the\n\n313\n\nand\n\n\'fTL is the\n\n3.\n\nuntil the mockup\n\nof 100mm.\n\ntool frame,\n\nAt that\n\nhas rotated\n\nmoment\n\nsuch that\n\nthe robots\n\nstart\n\nthe pads are\ntracking\n\nthe\n\nP\n\nP\n\n0\n\nLeftRobot\n\nW\n\nFigure 3: Coordinate\n\nsatellite\n\nmockup\n\ndriven by the S&P object\n\nRight Robot\n\nFrame Assignments\n\nstate data.\n\nAt the same time the distances\n\ntools and the pads axe gradually reduced until they contact each other.\nequation is used to specify the motion in the tracking phase:\n\nOrLe\n_TL\n\nbetween\n\nThe following\n\nthe\n\nkinematic\n\n\xe2\x80\xa2\n= wT pTL\n,\n\n(4)\n\nwhere _T is a transformation\ndescribing the centroid of the satellite mockup frame, and _TL is the\ntransformation\nfrom the satellite mockup centroid to the left pad. The distance between the tools\nand the pads, initially 100mm, is faked in equation (4) by making the tool 100mm\nphysical length. This distance is reduced during tracking until contact.\nIn RCCL,\n\none\n\ncan generate\n\ntrajectories\n\nby using\n\nthe trajectory\n\ngenerator\n\nlonger\n\nthan\n\nits\n\nor by an external\n\nmeazls.\nThe latter is made possible since one can modify any of the transformations\nexcept T6\nin equation\n(1) in real time. The satellite tracking uses the latter strategy\nsince it would be too\ntime-consuming\nif planning is done each time MCM receives an updated object state.\nHence tracking is done in the control level which drives the robots in the following way: Every\ntime an object state is received, the current frame of the satellite _T is predicted\nazcording\nto the\nreceived data, and the frame of the tool _T is computed\nfrom the joint angles of the robot.\nThe\n\n314\n\ndifference\n\nbetween\n\n\'_TL and\n\n_TL is computed\n\nfrom\ne\n\nAL\n\ne\n\nw\n\n=- pTL = wTL pTL\n\nwhere _T = _T \xc3\x97 iT. In order to track the satellite,\nthe\' robots are required\nto have moved\nthis A by the time the next state update is received.\nThis means that, in every sampling\nperiod,\nthe robots are moved by _ = A \xc3\x97 -_, where\nintcr-arrival\nperiod of the object state.\nThe tools approach\nthe grappling\npads\nforce/torque\nsensors\nforce servoing.\nThe\n\nt is the robot\nuntil\n\ncc,ntrol\n\na contact\n\nsampling\n\nis initiated.\n\nand after the c.ontact the motion is ch_nged from\nfollowing kinematic\nequation\nis used to specify the\n\nperiod,\nThis\n\nand\n\nis sensed\n\nT is the\nby the\n\nvision-based\nservoing to\nmotion in the grappling\n\nphase:\n\'_TL \xc2\xb0TL 6TL = _T\nwhere\n\nCOMPLY\n\nis a "small"\n\ntime-varying\n\n3\n\npTL COMPLY\n\ntransformation\n\nand\n\n(6)\n\nhas the following\n\nform\n\n1\nCOMPLY\n\nSince the COMPLY transformation\na small amount each sample time.\n\n- _#y\n0\n\n6#=\n0\n\n(7)\n\nI\n()\n\nis placed after the pTL, it will modify the ideal trajectory\nby\nBecause of integral force control, the COMPLY\ntransformation\n\nwill be modified based on the force/torque\nforces have been nulled.\nSince the satellite\n\nsensor readings\nmockup cannot\n\nand will keep its value even after the\nbe stopped instantaneously\nonce it is\n\ngrappled,\nthe software decelerates\nthe mockup according\nto a trajectory\nwhich is generated\nbased\non the initial velocity at the moment of contact.\nOnce the satellite mockup is stopped,\nit is pulled to the docking fixture.\nActive force control\nis used to nullify\noccur -- detected\nby letting\n\n5\n\nthe satellite\n\nConclusions\n\nWe have\nhigher\n\nthe force built up due the dual-arm\ncoordiaated\nmotion.\nIf grappling\ndoes not\nby the lack of contact between the tools and pads -- the whole cycle is repeated\n\nsuccessfully\n\nspeed,\n\nmockup\n\nand\ngrappled\n\nspin one more\n\nFuture\nthe satellite\n\ndue to the communication\n\ntime.\n\nImprovements\nmockup\ndelay\n\nand\n\nwith rolational\ncontrol\n\nrates\n\ni_laccuracies,\n\nof up to 2 rpm.\nthe\n\nrobots\n\nstart\n\nWith\nto miss\n\nthe pads.\nIn the present MCM implementation,\nthe computation\nis performed\nwith two MicroVAX computers, which limits its control rate to once every 28 msec. h_ the near future, we plan to port our\nsoftware to a Sun 4/260 computer\nwhich will increase the control rate to 200 Hz. This increase\nwill improve the force control capabihty\nand hence reduce th,, build-up of forces at the moment of\ncontact and subsequent\ngrappling.\nThe improved\nversion\nfor two robots. As such, more precise coordination\nboth\nachieved.\n\n315\n\nof RCCL [7,8] can coordinate\ntrajectories\n_tt tlke planning\nand control levels can be\n\n6\n\nAcknowledgements\n\nThe research described in this document\nInstitute of Technology, under contract\n\nwas performed at the Jet Propulsion\nwith the National Aeronautics\nand\n\nLaboratory,\nCalifornia\nSpace Administration.\n\nReferences\n[1] D. B. Gennery,\n"Tracking Known\nNational\nConference\non Artificial\n\nThree-Dimensional\nObjects,"\nProceedings of the AAAI\nIntelligence,\nPittsburgh\nPA, August 1982, pp. 13-17.\n\n[2] B. Wilcox, D. B. Gennery,\nB. Bon, and T. Litwin,\n"Real-Time\nfor Object Acquisition\nand Tracking,"\nProceedings of the SPIE\nAngeles CA, January\n1987.\n\nModel-Based\nInternational\n\n[3] V. Hayward, and R. Paul, "Robot Manipulator Control Under Unix RCCL,"\nJournal of Robotics Research, Vol. 5, No. 4, Winter 1987, pp. 94-111.\n[4] R. Paul,\n[5] J. Lloyd,\npartment\n\nRobot\n\nManipulators:\n\nMathematics,\n\nProgramming,\n\nand Control,\n\nMIT\n\nSecond\n\nVision System\nConference,\nLos\n\nThe International\n\nPress,\n\n1981.\n\n"Implementation\nof a Robot Control Development\nEnvironment,"\nM.S. Thesis,\nof Electrical\nEngineering,\nMcGill University,\nMontr6al,\nQu6bec, 1985.\n\n[6] J. Lee, S. Hayati,\n\net al., "Implementation\n\nof RCCL,\n\na Robot\n\nII," Proceedings\nof the SPIE Conference\non Advances\nOctober\n1986, Cambridge\nMA, pp 26-31.\n\nControl\n\nin Intelligent\n\nDe-\n\nC Library, on a MicroVAX\nRobotics\n\nSystems,\n\nVol. 726,\n\n[7] J. Lloyd, M. Parker, and R. McClain,\n"Extending\nthe RCCL Programming\nEnvironment\nto\nMultiple Robots and Processors,"\nProceedings of the IEEE International\nConference\non Robotics\nand Automation,\nPhiladelphia\nPA, April 1988, pp. 465-469.\n[8] S. Hayati, T. Lee, K. Tso, P. Backes, and E. Kan, "The\nMechanization\nSubsystem\n(MCM),"\nPasadena\nCA, January\n1989.\n\nProceedings\n\n316\n\nJPL Telerobot\n\nof the NASA\n\nManipulator\n\nConference\n\non Space\n\nControl\n\nand\n\nTelerobotics,\n\n'