b'_______________________________________\nSYNTHETIC VISION SYSTEMS\nL.J. Prinzel and L.J. Kramer\nResearch and Technology Directorate, Crew Systems and Operations Branch (D-318), Mail Stop 152,\nNASA Langley Research Center, Hampton, VA 23681, USA\n\n1. INTRODUCTION\nA \xe2\x80\x9csynthetic vision system\xe2\x80\x9d is an aircraft cockpit display technology that presents the visual\nenvironment external to the aircraft using computer-generated imagery in a manner analogous to\nhow it would appear to the pilot if forward visibility were not restricted. The purpose of this\nchapter is to review the state of synthetic vision systems, and discuss selected human factors\nissues that should be considered when designing such displays.\n1.1. Background\nAviation has been witness to the introduction of many new avionics systems (e.g., attitude\nindicators, radio navigation, instrument landing systems, ground proximity warning systems) that\nhave sought to overcome the issues associated with limited outside visibility for the pilot. Still,\nlimited visibility remains the single most critical factor affecting both safety and capacity in\nworldwide aviation operations. In commercial aviation alone, over 30% of fatal accidents\nworldwide are categorized as Controlled Flight Into Terrain (CFIT), where a normally\nfunctionally, mechanically sound aircraft impacts terrain or obstacles that the flight crew could\nnot see due to the lack of outside visual reference or impaired crew terrain/hazard situational\nawareness. In general aviation, the largest accident category is Continued Flight into Instrument\nMeteorological Conditions, in which a non-instrument rated pilot continues to fly into\ndeteriorating weather and visibility, leading to a loss of the visual horizon and a potential impact\ninto unexpected terrain or spatial disorientation and loss of control. Finally, the greatest factor\naffecting airport delays is limited visibility that reduces runway capacity and increases distances\nrequired for air traffic separation when weather conditions drop below visual flight rule\noperations.\nSynthetic vision is a visibility solution to this visibility problem that would allow all aircraft to be\nflown under the virtual equivalent of visual meteorological conditions or clear daylight\noperations.\n2. DEFINITIONS\n2.1. Enhanced Vision\nPast solutions to enhance pilot visibility have been sought through imaging sensors. Such\nsystems are termed \xe2\x80\x9cenhanced vision systems\xe2\x80\x9d and consist of active or passive sensors\nthat are used to penetrate weather phenomena such as darkness, fog, haze, rain, and snow.\nEnhanced vision systems have been installed on military aircraft but are infrequently\nfound on commercial transport aircraft due to cost, complexity, and technical\n\nperformance. Enhanced vision sensor imagery depends upon the external environment\nand the sensor characteristics. For example, high-frequency radars (e.g., 94 GHz) and\ninfrared sensors may exhibit degraded range performance in heavy precipitation and\ncertain fog types. On the other hand, low-frequency (e.g., 9.6 GHz) and mid-frequency\n(e.g., 35 GHz) radars have improved range, but often have poor display resolution.\nActive radar sensors can suffer from mutual interference when multiple users are in close\nproximity. Finally, present enhanced vision sensors do not extract color attributes which\nmay potentially create misleading visual artifacts under certain temperature or radar\nreflective conditions.\n2.2. Synthetic Vision\nA \xe2\x80\x9csynthetic vision system\xe2\x80\x9d is an electronic means of displaying the pertinent and critical\nfeatures of the environment external to the aircraft through a computer-generated image\nof the external scene topography using on-board databases (e.g., terrain, obstacles,\ncultural features), precise positioning information, and flight display symbologies that\nmay be combined with information derived from a weather-penetrating sensor (e.g.,\nrunway edge detection, object detection algorithms) or with actual imagery from\nenhanced vision sensors.\nAll aircraft categories can benefit from synthetic vision system applications, including\ngeneral aviation aircraft, business jets, cargo and commercial airliners, military cargo and\nfighter jets, and rotorcraft. These systems may be shown on head-down, head-up,\nhelmet-mounted, and navigation displays and be combined with runway incursion\nprevention technology; database integrity monitoring equipment; enhanced vision\nsensors; taxi navigation and surface guidance maps; advanced communication,\nnavigation, and surveillance technologies; and traffic and hazard display overlays. What\ncharacterizes the Synthetic Vision Systems technology is the intuitive representation of\nvisual information and cues that the pilot or flight crews would normally have in day,\nvisual meteorological conditions.\n\nPrimary Flight Display\n\nNavigation Display\n\nSurface Guidance Map Display\n\nHead-Up Display\n\nFigure 1. Examples of Synthetic Vision System Displays\n\n3. DESCRIPTION\n3.1. Enabling Technologies\nSeveral research and technological developments have made synthetic vision systems\npossible. Fundamentally, these systems require only precise ownship location, a\ndatabase, available graphics and computing capability and display media. Additional\ninformation and capability may be required depending upon the intended function. Many\ntechnical breakthroughs are responsible for the growing efficacy of synthetic vision\nsystems, which include:\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nHead-Up Display and Helmet-Mounted Display development\nEfficient and effective display symbology and presentation format development,\nincluding Pathway/Tunnel/Highway-In-The-Sky development and ground\noperations displays.\nGlobal Positioning System/Inertial Navigation System (GPS/INS) development\nMapping, Charting, & Geodesy Enhancements, Including Shuttle Radar\nTopography Mission (SRTM) and published, accepted standards (e.g., RTCA\nDO-255, -272, -276, -291)\nDatalink capability (ADS-B, CPDLC, TIS-B), enabling Cockpit Display of\nTraffic Information (CDTI), Runway Incursion Prevention System (RIPS) and\ndigital transmission of Air Traffic Control instructions.\nImproved computer processing and graphic processors\nDatabase Integrity Monitoring Equipment (DIME) development\nEnhanced Vision System imaging sensors\n\n3.2. Synthetic Vision System Elements\nThe synthetic vision system is composed of four elements: Enhanced intuitive view,\nhazard detection and display, integrity monitoring and alerting, and precision navigation\nguidance.\n(a) Enhanced Intuitive View --- Synthetic vision systems present the display of pertinent\nand critical features of the environment external to the aircraft through computergenerated imagery particularly when weather conditions prevent the pilot from\neffectively seeing these factors through the cockpit window. The display is intuitive\nbecause it displays these data in the way that the pilot normally would see in day visual\nmeteorological conditions and includes symbology that reduces flight technical error and\nfosters instant recognition and awareness.\n(b) Hazard Detection and Display --- Terrain, cultural, traffic, obstacles, and other\nhazards are graphically represented to the pilot to maintain the pilot\xe2\x80\x99s situation awareness\nand proactively ensure terrain and hazard separation. Synthetic vision systems provide\nfor pilot detection, identification, geometry awareness, prioritization, action decision and\nassessment, and overall situation awareness not afforded by today\xe2\x80\x99s avionics which\nrequire the pilot to be reactive to alert cautions and warnings.\n\n(c) Integrity Monitoring and Alerting --- Some level of integrity monitoring and alerting\nis required in all SVS applications because pilots must trust that the synthetic vision\nsystem provides an accurate portrayal (i.e., not hazardly misleading information). A\nflight-critical level of integrity, redundancy, and the inclusion of reversionary modes may\nbe needed to achieve the ultimate potential for a Synthetic Vision System. In this case,\nindependent sources to verify and validate the synthetic vision presentation (e.g., radar\naltimeters, enhanced vision sensors, TAWS) fashioned to create integrity monitoring\nfunctions may be necessary. If the integrity monitoring discovers a mismatch, the\ndisplays degrade gracefully to reversionary modes and trigger an alert to the pilot that\nsynthetic vision is no longer available nor reliable. The system effectively prevents a\npilot from using erroneous or misleading synthetic vision information.\n(d) Precision Navigation Guidance --- Synthetic vision system elements (e.g., surface\nguidance, taxi maps, tunnels/pathways/highways-in-the-sky, velocity vectors, command\nguidance cues) allow pilots to rapidly and accurately correlate ownship position to\nrelevant terrain, desired flight paths/plans, cultural features, and obstacles. These\nelements enable the pilot to monitor navigation precision to meet Required Navigation\nPerformance (RNP) criteria and compliance with complex approach and departure\nprocedures (RNAV, GLS, curved, step-down, noise abatement) without the need for\nland-based navigation aids (e.g., ILS, VOR, DME, ADF, NDB, LORAN) that are\nexpensive to install and maintain.\n3.3. Synthetic Vision System Components\nThere are many potential conceptualizations of synthetic vision systems dependent upon\nthe class of aircraft (CFR Title 14 Parts 23, 25, 27, 29) to which the system is being\ndesigned. As an example, the National Aeronautics and Space Administration (NASA)\nsynthetic vision system concept for Part 25 aircraft has the following synthetic vision\nsystem components:\nSynthetic Vision Database/Sensors\n\xe2\x80\xa2 On-board synthetic vision databases\n\xe2\x80\xa2 Weather Radar\n\xe2\x80\xa2 Radar altimeter\n\xe2\x80\xa2 Forward Looking Infrared (option)\n\xe2\x80\xa2 Millimeter Wave Radar (option)\nSynthetic Vision Displays\n\xe2\x80\xa2 Primary Flight Display, or imbedded display features\n\xe2\x80\xa2 Navigation Display, or display features/pages\n\xe2\x80\xa2 Interface with other cockpit displays, e.g., TAWS\n\xe2\x80\xa2 Head-Up or Helmet-Mounted Displays (option)\nComputers/Embedded Computational Functions\n\xe2\x80\xa2 Image Object Detection and Fusion\n\xe2\x80\xa2 Data confidence, detection threshold filtering, expected error\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nSource data reasonability and integrity estimation\nHazard detection\nData fusion (correlated position of potential hazards)\nImage enhancement and fusion, where appropriate\nIntegrity self monitoring and alerting\n\n\xe2\x80\xa2\n\nSystem Integrity, Verification and Validation\n\xe2\x80\xa2 Database reliability, integrity, expected error\n\xe2\x80\xa2 Other source data reasonability and integrity estimation\n\xe2\x80\xa2 Generate appropriate system alert messages\n\xe2\x80\xa2 Integrity self monitoring and alerting\n\n\xe2\x80\xa2\n\nComputations and Symbology Generation\n\xe2\x80\xa2 Cleared and actual path depiction\n\xe2\x80\xa2 Hazard element display integration and depiction\n\xe2\x80\xa2 Runway Incursion Prevention System\n\xe2\x80\xa2 Hold Short and Landing Technology\n\xe2\x80\xa2 Navigation and hazard situation awareness enhanced display elements\n\xe2\x80\xa2 Alert and warning generation and presentation\n\xe2\x80\xa2 Overall display symbol generation and/or integration\n\xe2\x80\xa2 Integrity self monitoring and alerting\n\nEquipment\n\xe2\x80\xa2 Dedicated synthetic vision system support equipment and crew interfaces\n\xe2\x80\xa2 Interface with other aircraft systems\nAssociated Aircraft Systems\n\xe2\x80\xa2 Differential Global Positioning System\n\xe2\x80\xa2 Inertial Reference Unit/Attitude Heading Reference Set (IRU/AHRS)\n\xe2\x80\xa2 Air Data Computer (ADC)\n\xe2\x80\xa2 Radio\n\xe2\x80\xa2 RADAR\n\xe2\x80\xa2 Traffic Collision and Avoidance System (TCAS)\n\xe2\x80\xa2 Data Link aggregate (e.g., IFF Mode S, ADS-B)\n\xe2\x80\xa2 Terrain Awareness and Warning System (TAWS)\n\xe2\x80\xa2 Laser Altimeter (option)\n\nSensors/Database\nFLIR\n(potential)\n\nComputation\nSVS Computer\n(dedicated or\nimbedded)\n\nMMWR\nRadar\n(potential)\n\nSensor/Imagery\nTransformations\n\nWeather\nRadar\n\nImage/Data\nFusion\n\nAircraft Nav Data\n(Database, DGPS,\nDIME, FMS, etc.)\n\nImage Object\nDetection\nSymbology\nGeneration\n\nAircraft State Data\n(INS, ADC,\nAHRS, Radalt,\netc.)\n\nHazards Info Sys\n(Datalink, TAWS,\nTCAS, IOD, RIPS,\nWx Radar, etc.)\n\nIntegrity\nMonitoring\nTerrain Feature\nExtraction\n(potential)\nInterface and\nCommunication\n\nOther Aircraft\nSystems (i.e.,\nFMS, GPWS,\nCAWS, etc.)\n\nFigure 2. NASA Synthetic Vision Concept\n\nDisplay\n\nPrimary Flight\nDisplay\nHead Mounted\nDisplay (potential)\nNavigation\nDisplay\nVertical Situation\nDisplay\nHead-Up Display\n(potential)\nElectronic Moving\nMap/RIPS Display\n\nAux Displays (i.e.,\nPilot Info,\nWeather, TCAS,\netc.)\n\n4. BENEFITS\n4.1. Safety Benefits\nSynthetic Vision Systems are characterized by the ability to represent visual information\nand cues of the environment external to the aircraft that are intuitive and resemble visual\nflight conditions with unlimited ceiling and visibility. In terms of safety benefits,\nsynthetic vision may help to reduce many accident precursors including:\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nLoss of vertical and lateral path and terrain awareness\nLoss of terrain and traffic awareness\nUnclear escape or go-around path even after recognition of problem\nLoss of altitude awareness\nLoss of situation awareness relating to the runway environment and incursions\nUnclear path guidance on the surface\nUnusual attitude / upset recognition\nRunway incursions\nNon-compliance with Air Traffic Control (ATC) clearances\nTransition from instruments to visual flight\nSpatial disorientation\n\nThese safety benefits are particularly evident during non-normal and emergency\nsituations. In these non-normal events, mental workload and tasking/attentional demands\nplaced on the pilot are high. Synthetic vision systems, through their intuitive display and\npresentation methods, off-load the pilots from basic spatial awareness tasking (to avoid\nterrain, traffic, and obstacles) and increase their speed of situation recognition.\n\n4.2. Operational Benefits\nThe aviation safety benefits alone of synthetic vision may be reason enough to pursue the\ntechnology, but operational and economic benefits must be considered for Part 121 and\n135 operations because of the costs associated with implementation of these systems.\nAnalyses have demonstrated that synthetic vision could serve to increase national\nairspace system capacity by providing the potential for increased visual-like operations\ngate-to-gate even under extreme visibility restricted weather conditions (e.g., Category\nIIIb minimums). For example, a NASA-sponsored cost-benefit analysis of 10 major US\nairports calculated the average cost savings to airlines for the years 2006 to 2015 to be\n$2.25 Billion. While these savings are predicated on several technology developments\nand success implementation/certification, this analysis indicates the potential order of\nmagnitude savings and operational efficiencies offered by these technologies.\nOperational benefits of synthetic vision systems may include:\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nIntuitive depiction of ATC cleared flight paths and taxi clearances\nEnhanced surface operations (e.g., rollout, turn off and hold short, taxi)\nReduced runway occupancy time in low visibility\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nReduced departure and arrival minimums\nBetter allow for converging and circling approaches, especially for dual and triple\nrunway configurations\nReduce inter-arrival separations\nProvide for independent operations on closely-spaced parallel runways\nProvide for precise noise abatement operations\nRequired Navigation Performance adherence\n4D navigation capability\nOceanic route optimization, spacing, and ownship reporting\nEnhanced path guidance, compliance monitoring, and alerting\nDepiction of terminal, restricted and special use airspace\nDepiction of traffic and weather hazards and resolutions\nMission planning / rehearsal capability\nReduced training requirements\nApproach operations to Type I and non-ILS runways\nVirtual visual self-spacing and station keeping capability\nPiloting aid support (e.g., flare guidance, runway remaining, navigation guidance)\nEnhanced flight management\n\n5. ONGOING RESEARCH EFFORTS\n5.1. Government Research\nThere are several government research efforts to design synthetic vision systems. NASA\nis pursuing research and development for commercial, business, and general aviation\naircraft. The project is funded under the Aviation Safety and Security program, Synthetic\nVision Systems research project principally conducted at the NASA Langley Research\nCenter. Human performance modeling and synthetic vision rotocraft research (joint\nArmy-NASA project) are also conducted at the NASA Ames Research Center. The\nFederal Aviation Administration (FAA) Capstone program focuses on synthetic vision\ntechnology that together with NASA, the Alaskan community and aviation industry\npartners, seeks to reduce Part 91 general aviation accidents. The Air Force Research\nLaboratory Human Effectiveness Directorate is evaluating synthetic vision technology\ndisplays to enable U.S. Air Force aircraft to fly with high situation awareness under\ninstrument meteorological conditions and help prevent CFIT accidents. Finally, there has\nbeen a significant amount of synthetic vision research conducted by international\ngovernment research agencies (e.g., Germany Aerospace Center, National Aerospace\nLaboratory).\n5.2. Industry Research\nIndustry research has partnered with government agencies to pursue development of\nsynthetic vision systems. Rockwell-Collins and BAE Systems have significant research\nefforts toward commercial and military applications of synthetic vision, enhanced vision,\nand sensor fusion technology. Part 23 aircraft are served by several companies most\n\nnotably Universal, Chelton Flight Systems, and RTI International. Universal has\nreceived a FAA technical standard order for the Vision-1 egocentric and exocentric\nsynthetic vision system displays. Chelton Flight Systems was selected for the FAA\nCapstone program and has received Supplemental Type Certification (STC) approval for\ninstallation of synthetic vision EFIS in the Cessna Citation 501, King Air\n90/100/200/300, Conquest I and II, all Cheyenne, all Commander, MU-2, Pilatus PC-12,\nTBM-700, Piaggio Avanti, and hundreds of other aircraft, including helicopters. Finally,\nRTI International has integrated a 3-D virtual display depicting the flight path, a\nworldwide terrain database, weather and traffic information, and GPS technology into a\nsingle cockpit instrument that shows traffic, weather, obstacles, flight path, and\nnavigation information.\n5.3. University Research\nNumerous university researchers have contributed to the growing knowledge of the\nhuman factors of synthetic vision displays. For example, research conducted by\nChristopher Wickens (University of Illinois at Urbana-Champaign), Eric Theunissen\n(Technical University of Delft), Thomas Schnell (University of Iowa), Kevin Corker (San\nJose State University), Jacques Verly (University of Liege), Maarten Uijt De Haag (Ohio\nState University), and Andrew Barrows (Stanford University) are a few of the many who\nhave significantly advanced the understanding of human factors issues.\n6. SELECT HUMAN FACTORS ISSUES\nA Human Factors and Ergonomics conference panel was held at the Human Facotrs and\nErgonomics Annual Meeting in 2004 to debate the human factors of synthetic vision\nsystems. The panel members were Lawrence Prinzel (NASA), Raymond Comstock\n(NASA), Mica Endsley (SA Technologies), Christopher Wickens (UIUC), Kevin Corker\n(San Jose State U.), Tim Etherington (Rockwell-Collins), Guy French (Wright-Patterson\nAFB), and Michael Snow (Boeing). The consensus of the panel was that synthetic vision\nsystems have significant promise in achieving the aforementioned safety and operational\nbenefits. It was acknowledged that significant human factors research has been\nconducted, but a number of human factors issues still remain.\nCorker and Guneratne (2002) categorized the human factors issues into three research\nareas: Image quality, information integration, and operational concepts. Based on a\nliterature review, they developed an extensive list of human factors issues and provided a\nset of research priority recommendations which are presented below.\n6.1. Image Quality\nHuman Factors\nIssue\n\nResearch Recommendation\n\nField-of-View\nDisplay Size\n\nWhat are the effects of display minification? Should field-ofview be automatically or manually determined? Can synthetic\nvision be retrofitted into smaller cockpit display sizes? Should\n\nClutter\n\nIconography\n\nDisplay Contrast\n\nOpacity\n\ndifferent field-of-view options be made available? What are the\nminimum and maximum field-of-view settings for each display\nsize?\nWhat is the minimum number of curves or objects required to\nconvey given information? How can the data be arranged to\nprovide a clear view without obstructing the view? How can\nclutter be quantified on synthetic vision displays? What are the\neffects of non-iconic information and synthetic vision\npresentation on pilot scan of the cockpit and out-the-window\nenvironment?\nWhat are effective symbol sizes for iconic representations of\nobstacles, traffic, guidance cues, etc.? What colors and standards\nshould be used? What are the minimum resolution, brightness,\nand contrast? What conventions (color, size, shape, etc.) can be\ncarried forward to support visual momentum and quick transition\nbetween synthetic vision and traditional instrumentation?\nWhat is the minimum contrast necessary to convey synthetic\nterrain information? Should contrast be automatically adjusted for\nlighting conditions and/or background colors? Should contrast\ncontrol be given to pilots?\nShould HUD symbology and/or synthetic terrain be entirely\nopaque, transparent, or mixed? Should transparency be varied\nwith lighting conditions? What are the effects of weather and\nlighting transitions?\n\n6.2. Information Integration\nHuman Factors\nIssue\nGuidance\n\nTerrain\nPresentation\n\nCognitive\nTunneling\nDisplay Integration\n\nResearch Recommendation\nHow should pathway guidance formats be designed for synthetic\nvision systems? What are the best guidance cues for predictor\nvector information?\nWhat are the best synthetic terrain formats? What level of\nrealism is required for effective synthetic vision systems? Would\nphoto-realism be sufficient for altitude and trend information to\nlead the crew to a false confidence in the system? Should\nwireframe formats and overlays be used? What amount of\ntexturing and object detail is needed to provide adequate depthcueing? What would be the effect of combining display terrain\ntexturing methods?\nWill realistic terrain cause the pilot to focus on the artificial\ndisplay to the exclusion of the outside world and backup\ninstruments? Will synthetic vision displays be compelling and\ninduce complacency?\nWhat is the best way of integrating synthetic vision systems with\nexisting traffic, terrain, and other warning displays?\n\nTrend Information\n\nSkill Retention\n\nWorkload Demand\n\nHow can synthetic vision better impart awareness of trends such\nas shallow climbing, descending, etc.? What is the best mix of\ntrend and guidance information to avoid clutter?\nHow does a synthetic vision system change a pilot\xe2\x80\x99s interaction\nwith tradition instruments? Do pilots retain the skills necessary to\nrevert back to traditional instruments if the system fails?\nWill synthetic vision create a measurable decrease in mental\nworkload? What is the effect of the increase in data information\nafforded by synthetic vision displays in the cockpit?\n\n6.3. Operational Concepts\nHuman Factors\nIssue\n\nResearch Recommendation\n\nWhich transitions will require switching between synthetic vision\nand other instrumentation? How can synthetic vision be designed\nto minimize the effect of the transitions?\nShould synthetic vision be designed to accommodate current\noperational procedures? Should pilot-flying or pilot-not-flying\nCrew Interaction\nhave different displays for their different roles? Or should they\nhave the same displays for cross-checking? How much effort can\nbe taken from aircraft management for display management?\nWhen should the crew be alerted to potential failures? Too many\nalarms may cause an impression that the system is \xe2\x80\x9cbuggy\xe2\x80\x9d;\ndelaying an alert too long may leave the crew too little time to\nFailure Modes\nreact to a dangerous system. What is the best way to alert the\ncrew visually, aurally, or otherwise in a way that is clearly\ndistinguishable from the other cockpit alarms?\nWhat information is absolutely necessary for which phases of\nflight? Should there be distinctly different sets of data for\nEssential\ndifferent phases, as the PFD has different modes? Should these\nInformation\nmodes be automatically set, or should the crew have the\ncapability to determine the mode?\nDoes synthetic vision provide a benefit during both high and low\nEffect at Various\nworkload? Are there problems with low workload over long\nWorkloads\nperiods of time?\nDoes synthetic vision lend itself to overtrust and complacency?\nWhat factors are most important to convincing pilots that it is safe\nto follow synthetic vision display and guidance? What operating\nCrew Confidence in\ncharacteristics are likely to decrease confidence (e.g., minimum\nSystem\nframe rates, power losses, sensor lag)? What is the proper\nbalance of crew confidence in the system and ensuring that crosschecking other instruments is performed?\nResource\nHow much control should pilots have over the synthetic vision\nManagement\nsystem during flight?\nFlight Phase\nTransitions\n\n7. CONCLUSIONS\nCommercial aviation is among the safest modes of transportation. But, the need to fly\nregardless of the weather has led to an accident rate that is far from ideal. Aircraft\naccidents serve as powerful reminders of the risks involved and how much safer flying\ncan and should be. Technology has advanced to allow for the emergence of synthetic\nvision systems that will fundamentally change how aircraft are operated in instrument\nconditions. By creating a virtual visual meteorological condition, synthetic vision holds\nthe promise to eliminate the precursor to many accidents and incidents (limited visibility)\nand substantially improve the safety and operational efficiency of aviation.\n8. ACKNOWLEDGEMENTS\nThe authors gratefully acknowledge the assistance of Randall Bailey and Dan Williams\n(NASA Langley Research Center), R. Michael Norman (Boeing), and Kevin Corker (San\nJose State University).\n9. RECOMMENDED FURTHER READINGS\nCorker, K.M., & Guneratne, E. (2002). Human factors issues and evaluation of\ncommercial and business aircraft synthetic vision systems. NASA Contractor Final\nReport (21-1214-2882).\nParrish, R.V., Baize, D.G., & Lewis, M.S. (2001). Synthetic vision. In C. Spitzer\n(Ed.), The Avionics Handbook (pp. 16-1 \xe2\x80\x93 16-8). CRC Press: Boca Raton\nPrinzel, L.J., Comstock, J.R., Corker, K.M., Endsley, M.R., Etherington, T.,\nFrench, G.A., Snow, M.P., Wicken, C.D. (2004). Human factors of synthetic vision\nsystems. Proceedings of the Annual Meeting of the Human Factors and Ergonomics\nSociety, 48.\nPrinzel, L.J., Comstock, J.R., Glaab, L.J., Kramer, L.J., Arthur, J.J., & Barry, J.S.\n(2004). The efficacy of head-down and head-up synthetic vision display concepts for\nretro- and forward-fit of commercial aircraft. International Journal of Aviation\nPsychology, 14(1), 53-77.\nPrinzel, L.J., Hughes, M.F., Arthur, J.J., Kramer, L.J., Glaab, L.J., Bailey, R.E.,\nParrish, R.V., & Uenking, M.D. (2003). Synthetic Vision CFIT Experiments for GA and\nCommercial Aircraft: \xe2\x80\x9cA Picture Is Worth A Thousand Lives\xe2\x80\x9d. Proceedings of the\nHuman Factors & Ergonomics Society, 47, 164-168.\nPrinzel, L.J., Kramer, L.J., Arthur, J.J., Bailey, R.E., Comstock, J.R. (2004).\nComparison of head-up and head-down \xe2\x80\x9chighway-in-the-sky\xe2\x80\x9d tunnel and guidance\nconcepts for synthetic vision displays. Proceedings of the Annual Meeting of the Human\nFactors and Ergonomics Society, 48.\n\nPrinzel, L.J., Kramer, L.J., Comstock, J.R., Bailey, R.E., Hughes, M.F., & Parrish,\nR.V. (2002). NASA synthetic vision EGE flight test. Proceedings of the Annual Human\nFactors and Ergonomics Meeting, 46, 135-139.\nSchnell, T., Kwon, Y., Merchant, S., & Etherington, T. (2004). Improved flight\ntechnical performance in flight decks equipped with synthetic vision information system\ndisplays. International Journal of Aviation Psychology, 14(1), 79-102.\nSnow, M.P., & French, G.A. (2001). Human factors in head-up synthetic vision\ndisplay. SAE Technical Paper 2001-01-2652. Warrendale, PA: Society of Automotive\nEngineers.\nSnow, M. P., and Reising, J. M. (1999). Effect of pathway-in-the-sky and\nsynthetic terrain imagery on situation awareness in a simulated low-level ingress\nscenario. Proceedings of the 4th Annual Symposium on Situation Awareness in the\nTactical Air Environment (pp. 198-207). Patuxent River, MD: NAWCAD.\nTheunissen, E. (1997). Integrated design of a man-machine interface for 4-D\nnavigation. Netherlands: Delft University Press.\nUijt de Haag, M., Young, S., Sayre, J., Campbell, J., & Vadlamani, A. (2002).\nDEM integrity monitor equipment (DIME) flight test results. In J.G. Verly (Ed.),\nEnhanced and Synthetic Vision 2002 (pp. 72-83). Bellingham, Washington: International\nSociety for Optical Engineering (SPIE).\nWilliams, D., Waller, M., Koelling, J., Burdette, D., Doyle, T., Capron, W.,\nBarry, J., & Gifford, R. (2001). Concept of operations for commercial and business\naircraft synthetic vision systems. NASA Langley Research Center: NASA Technical\nMemorandum TM-2001-211058.\nWickens, C.D., Alexander, A.L., & Hardy, T.J. (2003). The primary flight display\nand Its pathway guidance: Workload, performance, and situation awareness. Final\nTechnical Report AHFD-03-2/NASA-03-1. Savoy, Ill: University of Illinois, Aviation\nResearch Laboratory.\nWickens, C.D., Alexander, A.L., Thomas, L.C., Horrey, W.J., Nunes, A., Hardy,\nT.J., Zheng, S.X. (2004). Traffic and flight guidance depiction on a synthetic vision\nsystem display: The effects of clutter on performance and visual attention allocation.\nFinal Technical Report AHFD-04-10/NASA-04-1. Savoy, Ill: University of Illinois,\nAviation Research Laboratory.\nVerly, J.G. (Ed.). (1997 \xe2\x80\x93 2004), Enhanced and Synthetic Vision (Vols. 1997 \xe2\x80\x93\n2004). Bellingham, WA: International Society of Optical Engineering.\n\n'