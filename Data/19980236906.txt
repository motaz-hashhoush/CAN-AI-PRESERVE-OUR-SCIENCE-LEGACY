b':\xe2\x80\xa2\n\n\xe2\x80\xa2\xe2\x80\xa2\n\n_\n\n_ \xe2\x80\xa2 _\n\ni i: _\n\ni\xe2\x80\xa2\n\ni\n\n:::!_:)\n\ni!i\n\n,\n\nHuman-Centered\n\nDesign\n\nof\nHuman-Computer-Human\n\nDialogs\n\nFinal\nNASA\n\nin Aerospace\n\nReport\n\nAmes Research\nNCC 2-824\n\nCenter\n\n(E 24-X30)\n\nDr. Everett A. Palmer,\nIII\nTechnical\nMonitor\nNASA-Ames\nResearch\nCenter\nMail Stop 262-4\nMoffett Field, CA 94035\n650-604-6073\nepalmer\n\nChristine\nCenter\nSchool\n\n@ mail.arc.nasa.gov\n\nM. Mitchell,\n\nPrincipal\n\nfor Human-Machine\nof Industrial\nGeorgia\nAtlanta,\n\nSystems\n\n& Systems\n\nInstitute\n\n30332-0205\n\ncm @ chmsr.gatech.edu\n\nAugust\n\nReport\n\n1998\n\nResearch\n\nEngineering\n\nof Technology\n\nGeorgia\n\nFinal\n\nInvestigator\n\nSystems\n\n\xe2\x80\xa2i\n\n<,=_\n\n:i\xe2\x80\xa2!i_ii\n\n\xe2\x80\xa2\n\nSummary\nThis grant spanned several projects, completing some and initiating others.\nresearch that comprised the past three years are described below.\n\nThe major components\n\nof\n\nGT-EFIRT\nA series of ongoing research programs at Georgia Tech established a need for a simulation support tool for\naircraft computer-based\naids. This led to the design and development\nof the Georgia Tech Electronic Flight\nInstrument Research Tool (GT-EFIRT).\nGT-EFIRT is a part-task flight simulator specifically\ndesigned to\nstudy aircraft display design and single pilot interaction.\nThe simulator, using commercially\navailable\ngraphics and Unix workstations,\nreplicates to a high level of fidelity the Electronic Flight Instrument\nSystems (EFIS), Flight Management\nComputer (FMC) and Auto Flight Director System (AFDS) of the\nBoeing 757/767 aircraft. The simulator can be configured\nto present information\nusing conventional\nlooking B757/767 displays or next generation Primary Flight Displays (PFD) such as found on the Beech\nStarship and MD- 11.\nThe simulator provides high fidelity representations\nof the interfaces and responses of the\ninstrumentation\nsystems while remaining low-cost, rapidly re-configurable,\nand portable.\noriented design allows new displays to be prototyped quickly and evaluated through flight\ncomplete data logging of pilot and systems performance.\nAll navigation related aural and\nalerts/warnings\nare modeled including the ground proximity warning system (GPWS).\n\nautoflight and\nIts objectscenarios with\nvisual\n\nAs in the figure below the baseline version of GT-EFIRT utilizes two computers and three monitors.\nThe\nright two monitors are touch sensitive and all pilot interactions\ncan be performed using touch input. The\nworkstations\nare connected via a local area network (LAN). A Sun SPARC 2 workstation\nwith a GS\ngraphics accelerator card drives the left most monitor. This monitor and CPU are specifically design for\nthe 3-D flight path and terrain displays associated with the PFD. The UNIX operating system and the Sun\nOpenLook Toolkit provide flexibility in allocating displays among the CPUs and monitors.\nThe typical\nconfiguration\nis identified in the figure, but any combination\nof monitors and display windows can be\nrequested.\nFor example, the simulation\nsupport panel, which is used by the researcher,\ncan be allocated to a\nworkstation\nanywhere on a local area network.\nAir traffic control (ATC) interaction is carried out by the researcher with real-time event logging in the data\ncollection file. Modular design and rapid reconfiguration\nwere the driving factors in designing the structure\nof GT-EFIRT.\nAn object-oriented\narchitecture\nwas chosen which is implemented\nnot only in the source\nprogramming\nlanguage, but also in the selection of Sun PHIGS+ as the graphics support language and the\nSun OpenLook Toolkit for window management.\nThe underlying simulation\nis based on a three degree of\nfreedom point mass model of the B757. This model provides sufficient fidelity of aircraft dynamics since\nno hand flying is implemented.\nAs such, pitch and thrust are the driving forces with no modeling of aircraft\ncontrol surfaces. The control loops for the auto flight system can operate in several different modes,\nranging from simple altitude and heading hold to a full lateral and vertical path guidance based on FMC\nprogrammed\nroutes. Localizer and glideslope tracking modes can be engaged for final approach and\nprovide for complete category III full stop landings including the flare maneuver.\nComputational\nspeed has\nbeen enhanced by parallel processing the simulation task across two CPUs. The flight model, FMC and\nAFDS are allocated to one CPU, while the navigation and moving map are allocated to the other. The two\nCPUs\n\nare synchronized\n\nvia message\n\ntraffic on the local area network.\n\nExtensive data collection capabilities\nare built into GT-EFIRT for both system and pilot monitoring.\nA\ndata log is maintained for each session whose contents are selectable by the researcher.\nEvents which can\nbe monitored include pilot input, auto pilot state changes, aircraft dynamics, and aircraft related alerts (e.g.,\nflap and gear warnings).\nEvents are recorded with a time stamp. GT-EFIRT\nserved as the part-task\nsimulator for all the research described below.\nNote, over the years since GT-EFIRT\nwas first developed,\nit has migrated to increasingly\npowerful Sun\nSPARC Unix workstations\nand currently only one SPARC 10 is required to run the simulation and drive\nthe three graphics\n\nfinal.report.8.98--final\n\nmonitors.\n\n2\n\nTouchSensitive\nCRTs\n\nl\n\n"a\n\n1\nSunSPARC (GSGraphics)\n2\n1\niii _lllllllmllll|lllll_l\n\n[\n\nI _llllllllllllllllllllll\n\nIA\n\nSunSPARC (GXGraphics)\n2\n\nTestMonitor\'s eyboard\nK\n\nCRT1\nPrimarylight\nF\nDisplay\nor\nAttitude\nDirector\nIndicator\nAirspeed\nVertical\nSpeed\nAltimeter\n\nPilot\'s\nKeyboard\n\nI_\n\nCRT2\nMode\nControl\nPanel\nHorizontal\nSituation\nIndicator\nHSIControl anel\nP\nControl\nDisplay\nUnit\n\nCRT3\nAircraftMisc.\nSimulation upport\nS\n\nThe VNAV Tutor: A Flight Management\nSystem Vertical Navigation\nTutor\nVertical navigation capabilities\nof the Flight Mana.gement System (FMS) in modern "glass-cockpit"\naircraft\nare often under-utilized\nor misused by pilots. This can be attributed at least in part to an inadequate\nunderstanding\nby pilots of how the FMS interprets and executes a flight plan, which they have entered.\nThis project combines a unique vertical profile display with a part-task airline transport simulator.\nThe\ndisplay provides an otherwise unavailable\nvisual representation\nof FMS and other vertical navigation\nmodes of the aircraft. A control architecture\nis embedded into the system to allow for the creation of\nroutine flights which the tutor uses as lessons that address key training issues. The tutor controls flight\nscenarios which help the student pilot explore the content of the FMS vertical profile, FMS execution of\nthat profile through use of the VNAV function, interaction between FMS and other vertical navigation\nmodes, and the use of FMS vertical navigation by the pilot for the completion\nof various in-flight\nmaneuvers.\nThis system is being evaluated on-site in the flight training department\nof an U.S. airline. The\nevaluation takes approximately\nsix hours per pilot. The initial session is used to assess the subject\'s\nknowledge regarding FMS and VNAV; a formal questionnaire\nis administered.\nFour training sessions with\nthe VNAV tutor follow. The tutorial environment\nconsists of the two-monitor\n757/767 simulator,\naugmented with voice and text-based ATC and tutorial messages, and a third monitor containing the\nVNAV Profile Display. After the four tutorial sessions, the pilot flies a fifth, and final, evaluation session\nthat does not incorporate the tutor or the Vertical Profile Display. This session has periodic interruptions\nat\npredetermined\npoints in order to allow the experimenter\nto ask the pilot specific questions focusing on\nvertical navigation awareness regarding the state of the FMS and other auto flight equipment.\nThese\nquestions are used to determine the subject\'s understanding\nof the training material. Next, a questionnaire,\nsimilar in content to that used prior to the first session, is administered.\nThe comparison\nof the answers to\nthe two questionnaires\nserves as a primary source of data in the evaluation.\nFinally, the evaluation\nfor a\nparticular subject concludes by soliciting pilot reactions and opinions about the VNAV tutor. Citations for\nthis work follow.\n\nfinal.report.8.98--final\n\n3\n\n20000 ft MSL\n\nIVNAV\n\nI\nI\n\nSPD I\n\nI\nI\n\no__FL170-\n\nECON CRZ _g\nAD\n\n_o_\n\ni\nMCP ALT\n\nII\n\nFL,O0\n\n&\n%\n\n_\n\nALAS\n\n"k_"_\n/\n\nXO_. \xc2\xb0\n\n.......\n\nB_HRR_,\n\nCATrA_\n\n_l_\',,\n\nKBH.Mf:- 0S.\nI\n\nI\n\n3D Primary\n\n,\n\nFlight Display\n\nI\n\n,\n\nwith Terrain\n\n,\n\nI\n\n160 nml\n\nInformation\n\nAn important worldwide aviation safety problem is still the controlled-flight-into-terrain\nor CFIT accident.\nArea navigation and onboard terrain elevation databases offer the potential for improved cockpit displays\nof near by terrain. This project has developed a prototype primary flight display format designed to reenforce the pilot\'s model of both lateral and vertical navigation in near-terrain situations.\nThis new display\nformat is referred to as the Spatial Situation Indicator (SSI). Specific emphasis has been placed on the\nterminal phase of flight with terrain modeling in the vicinity of the departing and destination airport.\nThe unique design incorporated\nperspective symbology\nthat depicts a prediction of the aircraft\'s predicted\nposition and terrain clearance information\nfor up to 75 seconds ahead of the aircraft. Projection of the\nflight path is based on a "fast time" modeling technique described by Grunwald (1985). Traditional\nflight\npaths use the "tunnel in the sky" approach which present no reference to the ground elevation e.g.,\nGrunwald\n(1982). The technique developed for this research utilized roll stabilized vertical lines\n"whiskers" positioned at 15 second intervals out to 75 seconds. The figure illustrates the virtual "whiskers"\nand flight path. The whiskers are displayed in pairs of equal distant widths so that in steady level flight a\nperspective\npath is projected.\nThe whiskers are color coded using green and yellow. The green lower\nportion extends from the predicted aircraft altitude at that interval to the terrain below. Its length therefore\nis a direct representation\nof the terrain clearance at that point in the aircraft\'s path, given there are no\nchanges in aircraft flight path.\nThe display also incorporated\na dynamically\ncolor-coded\nterrain grid. The color-coding\nis based upon\naircraft predicted height and terrain spot elevations.\nThe color-coding\nuses dark green for safe terrain and\ndark red for dangerous terrain. The terrain grid is comprised of a triangular mesh with each triangle having\nsides of 2 nautical miles (NM). Man-made\nobstructions\nsuch as radio towers are also shown on the terrain\ngrid. Information for building the terrain and obstruction\nfiles is obtained from the approach plates for each\nrunway in the scenario.\nAn experimental\nevaluation of the display was conducted on-site at a major U.S. airline. Experimental\nparticipants\nare current glass cockpit flight instructors.\nEach experimental\nsubject, after training to\nfamiliarize him/herself\nwith the part-task aircraft simulator and interface, flies three scenarios based on\nactual controlled flight into or toward terrain as described by Bateman (1991).\nEach experimental\nparticipant uses one of the two displays: the baseline cockpit display, and this display\nwith flight path predictor and ground terrain information.\nA total of eighteen pilots will participate,\nnine\nt\n\nfinal.report.8.98--final\n\nwith each display. Attention diverting tasks are implemented\nto match as closely as possible the scenarios\nas they are described by Bateman.\nATC communications\nare implemented\nusing simple voice\ncommunications\nwithout supporting electronic intercoms.\nThe experimenter\ncarries out the air traffic\ncontroller (ATC) communications.\nThe goal of the experiments\nis to measure how quickly pilots can detect\ndangerous terrain with the three different display formats. Response time of the pilot for corrective action\nis recorded as well as MCP inputs. Analysis of these data is in process. Citations for this work follow.\n\nFixed 2000\n75 seconds\n\nseconds\n\nHeight\nterrain\n\neconds\n\nabove\n\nGT-CATS:\nThe Georgia Tech Crew Activity Tracking Systems\nBillings (1991) states the following requirements for the design of human-centered\nsystems: First, the\nhuman operator must be able to monitor the automated system. Second, the automated system must be able\nto monitor the human operator. And, finally, each of these two elements must have knowledge of the\nother\'s intent. Billings points out that cross monitoring can only be effective if the intentions of the human\nor automated systems are known.\nResearchers at Georgia Tech are exploring one method of meeting this\nrequirement.\nThey are developing\nan activity tracking system that attempts to understand the activities\nperformed by crews of glass cockpit aircraft. The activity tracker focuses specifically\non those activities\nthat affect the mode awareness of the crew, such as autoflight mode selection and engagement,\nand\nassociated planning and monitoring\nactivities.\nThe technology permits the design of systems that can\nprovide crews with context-sensitive\nadvice, reminders,\nand assistance based on its dynamic understanding\nof pilot intent.\nCATS uses a task-analytic\nmodel of crew-automation\ninteractions as its source of knowledge about crew\nactivities.\nThe model of crew activities is structured as a functional decomposition;\neach phase of flight is\ndecomposed\ninto crew functions, which are in turn decomposed\ninto subfunctions,\nautoflight mode\nselections, tasks, subtasks, and, at the lowest level, observable actions. Each activity in the model has an\nassociated\nset of conditions for determining\nthe status of the activity based on the occurrence of a particular\nevent or events. By noting the status of activities in the model (e.g., "active," "pending," "done"), a useful\ndescription\nof the crew\'s current activities is produced.\nThe CATS system analyses real-time data from a\npart-task airline transport simulator.\nCATS accepts aircraft and auto flight system state data, along with\n\nfinai.report.8.98--final\n\n5\n\ndata about actions performed\nexpectations\nand explanations\n\nby the pilots "flying" the simulator.\nabout the activities in real-time.\n\nAn evaluation will be conducted\nconcurrent verbal protocols from\nexpectations\nand explanations\nof\nmethod of Jones et al, to validate\ncorrectly infer operator intent.\n\nThese data are used to generate\n\nin which airline pilots "fly" the part-task simulator.\nThis data will include\nthe pilots to be used in assessing the degree of match between the\nCATS and those of the pilots. This phase of the study will follow the\nempirically the adequacy of a computer-based\nactivity tracking system to\n\nConstraints on\nOperation\n\nCA TS\nDUO\n\n\' "_\n\nInformation\n\nConstraints\non Operation\n\n(LOE)\n\nHuman\nOperators\n\nfinal.report.8.98--final\n\nn\n\nControlled\nSystem\n\nT\n\n[ to training\n\nor aiding\n\n6\n\nsystem\n\n]\n\nCitations\n\nfor Papers\n\nDescribing\n\nthe Research\n\nWilliams, J. A., & Mitchell, C. M. (1993). Effect of integrated\nflight into terrain. Proceedings\nof the 1995 IEEE International\nCybernetics,\nLe Touquet, France, 120-125.\n\nSupported\n\nby this Grant\n\n*\n\nflight and terrain displays on controlled\nConference\non Systems, Man, and\n\nCallantine,\nT. J., & Mitchell, C. M. (1994). A methodology\nfor understanding\nhow operators select and use\nmodes of automation\nto control complex dynamic systems. Proceedings\nof the 1994 IEEE International\nConference\non Systems, Man, and Cybernetics,\nSan Antonio, Texas, 1751-1756.\nCallantine, T. (1996). Tracking operator activities in complex systems. Ph.D. Thesis,\nand Systems Engineering,\nGeorgia Institute of Technology,\nAtlanta, Georgia.\n\nSchool of Industrial\n\nChappell, A. R., & Mitchell, C. M. (1995). Intelligent tutoring systems to support mode awareness\nin the\n\'glass cockpit\'. Proceedings\nof the 6th IFA C/IFIP/IFORS/IEA\nSymposium\non Analysis, Design, and\nEvaluation of Man-Machine\nSystems, Cambridge, MA, 415-420.\nChappell, A. R., & Mitchell, C. M. (1996). Use of visualization\nand contextualization\nin training operators\nof complex systems. Proceedings\nof the Human Factors and Ergonomics\nSociety, 40th Annual Meeting,\nPhiladelphia,\nPA, 264-268.\nChappell, A. R., Crowther, E. G., Mitchell, C. M., & Govindaraj,\nT. (1997). The VNAV Tutor: Addressing\na mode awareness difficulty for pilots of glass cockpit aircraft. IEEE Transactions\non Systems, Man, and\nCybernetics,\n27(3), 327-385.\n\n* For copies of these references please contact Dr. Christine M. Mitchell, Center for Human-Machine\nSystems Research, School of Industrial & Systems Engineering,\nGeorgia Institute of Technology,\nAtlanta,\nGeorgia\n30332-0205,\n+ 1 404 894-4321, + 1 404 894-2301 (fax), cm @chmsr.gatech.edu.\n\nfinal.report.8.98--final\n\n7\n\n'