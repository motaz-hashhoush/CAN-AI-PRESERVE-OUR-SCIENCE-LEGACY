b'Deep Learning-Powered Insight\nfrom Dark Resources\nManil Maskey, Rahul Ramachandran\nRitesh Pradhan, and JJ Miller\nNASA/MSFC - Data Science Informatics Group\nUniversity of Alabama in Huntsville\nAGU Fall Meeting\n\nDecember 16, 2016\n\nOutline\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nMotivation\nWhy Deep Learning?\nApplications\nAnalysis\n\nMotivation\n\xe2\x80\xa2\n\nEarth Science Images\n~70+ million browse images\n-basic metadata\n\n\xe2\x80\xa2\n\nUnder-exploited\n\n\xe2\x80\xa2\n\nCan we use browse imagery\n-to enable discovery of possible new case studies?\n-to perform exploratory analytics?\n\n\xe2\x80\xa2\n\nImage Analytics\n\n\xe2\x80\xa2 Component of \xe2\x80\x9cDark Data\xe2\x80\x9d \xe2\x80\x93 NASA AIST Project\n\nImage-based Analytics\n\xe2\x80\xa2 Goal: Earth science image based tasks:\n\xef\x82\xa7\n\xef\x82\xa7\n\xef\x82\xa7\n\xef\x82\xa7\n\nImage Retrieval\nImage Classification\nObject Recognition\nExploration\n\n\xe2\x80\xa2 Challenge: \xe2\x80\x9csemantic gap\xe2\x80\x9d\nLow-level image pixels and high-level semantic\nconcepts perceived by human\n4\n\nTraditional Image Recognition Approach\n\xe2\x80\xa2 Image features: Color, Texture, Edge\nhistogram, \xe2\x80\xa6\n\xe2\x80\xa2 \xe2\x80\x9cShallow\xe2\x80\x9d architecture\n\xe2\x80\xa2 User defines the feature\n\xe2\x80\xa2 Preliminary study\n\nHand-crafted\nFeature Extractor\n(static)\n\n\xe2\x80\x9cSimple\xe2\x80\x9d\nTrainable Classifier\n(learns)\n\n\xe2\x80\x9cDeep\xe2\x80\x9d Architecture\n\xe2\x80\xa2 Features are key to recognition\n\xe2\x80\xa2 What about learning the features?\n\xe2\x80\xa2 Deep Learning\n\xe2\x80\x93 Hierarchical Learning\n\xe2\x80\x93 Mimics the human brain that is organized in a deep\narchitecture\n\xe2\x80\x93 Processes information through multiple stages of\ntransformation and representation\n\nTrainable\nFeature Extractor\n(learns)\n\nTrainable Classifier\n\n(learns)\n\nConvolutional Neural Network\n\xe2\x80\xa2\n\nConvolutional Neural Network (CNN)\n\xe2\x80\x93 Deep Learning for supervised image feature learning\n\xe2\x80\xa2 Nearby pixel values are correlated\n\n\xe2\x80\x93 Supervised\n\xe2\x80\xa2 Ideal for Image Recognition\n\n\xe2\x80\x93 Feed forward\n\xe2\x80\x93 Convolution\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nWeighted moving sum (window)\nMultiple convolutions (Different Filters)\nDetects multiple motifs at each location\nResults in a 3D array \xe2\x80\x93 each slice: a feature map\n\nTranslation Invariant\nLocal correlation\nGlobal representation\nLittle pre-processing\nNo/little expert feedback for feature extraction\nAvoids overfitting\nHighly scalable\n\nCNN Features\n\xe2\x80\xa2 Local receptive fields\n\xe2\x80\x93 Learns particular local part of the input\n\n\xe2\x80\xa2 Sparse connectivity\n\xe2\x80\x93 Local representation (lower layers)\n\xe2\x80\x93 Larger overview and abstract (higher layers)\n\xe2\x80\x93 Maintains spatial local correlations\n\n\xe2\x80\xa2 Shared weights\n\xe2\x80\x93 Detect exactly same feature at different location\n\xe2\x80\x93 Reduce the number of parameters to be learned\n\n\xe2\x80\xa2 Pre-processing\n\xe2\x80\x93 Input with very little pre-processing\n\nLayers\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nConvolutional Layer\nPooling Layer\nNormalization Layer\nReLU Layer\nFully Connected Layer\nLoss Layer\n\nConvolutional layer\n\xe2\x80\xa2 Convolution\n\nConvolutional Layer\n3D Representation\n\nh\n\nh\nw\n\nw\n\n3 (RGB channels)\n\nh\nh\n\nNumber of filters\n\ndepth\nw\n\nw\n\n(Number of feature maps\n=\nNumber of filters)\n\nConvolutional Layer\n\xe2\x80\xa2 Depth (d)\n\xe2\x80\x93 Number of filters\n\xe2\x80\x93 Different depth slices activates different features\n\xe2\x80\x93 Stacked feature maps from all filters gives 3D output volume\n\nConvolutional input volume (red) and output volume (green)\n\nPooling Layer\n\xe2\x80\xa2 Reduces number of parameter through down sampling\n\xe2\x80\xa2 Max-pooling\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\nSelects maximum activated pixel in pooling region\nSimple\nComputationally Efficient\nPreserves translation invariance\n\nFully Connected Layer\n\xe2\x80\xa2 Similar to regular neural network\n\xe2\x80\xa2 Transition from series of convolutional and pooling layers\n\xe2\x80\xa2 Produces single output vector (w=h=1 output volume)\n\nHyperparameters\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nNumber of convolutional filters\nSize of convolutional filters\nSize of pooling filters\nStride\nPadding\nLocal size for normalization\nDropout ratio\nWeight decay\nLearning rate\nMomentum\n\nApplications\n\xe2\x80\xa2 Improving Forecast Operations\n\xe2\x80\xa2 Searching for Events\n\xe2\x80\xa2 Image signature identification for\nTransverse bands\n\xe2\x80\xa2 Enabling New Science\n\xe2\x80\x93 Dust Climatology\n\n16\n\nApplication:\nImproving Forecast Operations\nCollaboration with Dan Cecil, NASA/MSFC\n\nTropical Cyclone Intensity Estimation\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nHurricane Intensity: based on Maximum Sustained Wind (MSW).\nSaffir-Simpson Hurricane Wind Scale (SSHWS)\n\nIntensity Estimation Techniques\n\xe2\x80\xa2\n\nThe Dvorak technique\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\n\xe2\x80\xa2\n\nVernon Dvorak (1970s)\nSatellite-based method\nCloud system measurements\nDevelopment patterns corresponds to T-number\n\nDeviation-angle variation technique (DAVT)\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\nPi\xc3\xb1eros et al.\nSource: Dvorak, V. F., 1973: A technique for the analysis and forecastingof tropical cyclone intensities from\nVariance for quantification of cyclones\nsatellite pictures. NOAATech. Memo. NESS 45, Washington, DC, 19 pp.\nCalculates using center (eye) pixel\nDirectional gradient statistical analysis of the brightness of images\n\nSource: Elizabeth A. Ritchie, Kimberly M. Wood, Oscar G. Rodriguez-Herrera, Miguel F. Pineros, and J. Scott Tyo.\nSatellite-derived tropical cyclone intensity in the north pacific ocean using the deviation-angle variance technique, 2014.\n\nProblems\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nLack of generalizability\nInconsistency\nSubjective\nComplexity\nSignificant pre-processing\n\nArchitecture\n\nConfigurations\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\n8 layers deep\n5 convolutional layers\n3 fully connected layers\n~37.5 million\nparameters learned\n\nDataset\n\xe2\x80\xa2 Image data\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\nUS Naval Research Laboratory (http://www.nrlmry.navy.mil/tcdat)\n1998 to 2014\n15 minute interval\n98 cyclones (68 Atlantic and 30 Pacific)\n\n\xe2\x80\xa2 Wind speed data\n\xe2\x80\x93 National Hurricane Center (http://www.nhc.noaa.gov) (Best track data: HURDAT and HURDAT2)\n\xe2\x80\x93 Hurricane Research Division (http://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html)\n\xe2\x80\x93 6 hour interval\n\nCyclones\n\nData Augmentation\n\xe2\x80\xa2 Interpolate to increase even more\n\xe2\x80\xa2 NRL images for every 2 hour \xe2\x80\x93 wind speed interpolation\n\xe2\x80\xa2 Image transformation\n\xe2\x80\x93 Original\n\xe2\x80\x93 90 degree rotation\n\xe2\x80\x93 180 degree rotation\n\xe2\x80\x93 270 degree rotation\n\xe2\x80\x93 Other..\nExample image difference: 2hr interval, wind speed interpolation\n\nTraining/Test/Validation split\n\xe2\x80\xa2 (Training + Validation) 70% - 30% (Test)\n\xe2\x80\xa2 (Training) 75% - 25% (Validation)\n\nTraining\n\xe2\x80\xa2 Preprocessing\n\xe2\x80\x93 Resize to 232 x 232 for input\n\xe2\x80\x93 Subtract image mean from training images\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nGRID K520 4GB GPU\nStopped at 90% validation accuracy\n65 epochs in 8 hours\nCaffe framework\n\nVisualization\n\nFeature maps from second convolution\n\nPerformance\n\xe2\x80\xa2 Model with around 90% of validation accuracy\n\xe2\x80\xa2 14,345 test images (Atlantic + Pacific)\n\xe2\x80\xa2 Measures\n\xe2\x80\x93 Confusion Matrix\n\xe2\x80\x93 Classification Report\n\xe2\x80\x93 Accuracy\n\xe2\x80\x93 RMS Intensity Error\n\nConfusion Matrix\n\nClassification Report\n\nRMS Intensity Errors\n\xe2\x80\xa2 Our model\n\xe2\x80\x93 Across Atlantic and Pacific\n\xe2\x80\x93 Achieved RMSE of 9.19kt\n\n\xe2\x80\xa2 North Atlantic\n\xe2\x80\x93 Pi\xc3\xb1eros et al. (2011): 14.7kt\n\xe2\x80\x93 Ritchie et al. (2012): 12.9kt\n\n\xe2\x80\xa2 North Pacific\n\xe2\x80\x93 Ritchie et al. (2014): 14.3kt\n\nCorrect Predictions\n\nIncorrect Predictions\n\nApplication:\nSearching for Events\n\nSearching for Events\n\xe2\x80\xa2 Labeled Data\n\xe2\x80\x93 MODIS Rapid Response\n\n\xe2\x80\xa2 Experts manually labeled ~850 images\n\xe2\x80\xa2 4 classes:\n\xe2\x80\x93 Hurricane, Dust, Smoke/Haze, Other\n\n\xe2\x80\xa2 Final Dataset\n\xe2\x80\x93 images transformation\n\xc2\xbb (flip, transpose, rotate, random patch)\n\xe2\x80\x93 Total ~5000 images\n\xe2\x80\x93 70% for training and validation\n\n\xe2\x80\xa2 Test Data\n\xe2\x80\xa2 30% of Labeled data\n\xe2\x80\xa2 Unseen by CNN trained model\n\n\xe2\x80\x93 Global Browse Image Service (GIBS)\n\xe2\x80\xa2 MODIS_Aqua_CorrectedReflectance_TrueColor tiles for 2012 - classified against\ntrained model\n36\n\nSearching for Events - Results\nOverall Accuracy = 87.88%\n\nConfusion Matrix\n\nHurricane \xe2\x80\x93 True Positive\n\n37\n\nDust \xe2\x80\x93 True Positive\n\nSmoke\xe2\x80\x93 True Positive\n\nSearching for Events - Results\n\nHurricane \xe2\x80\x93 True Positive\n\nDust \xe2\x80\x93 True Positive\n\nSmoke\xe2\x80\x93 True Positive\n\nHurricane \xe2\x80\x93 False Negative\n\nDust \xe2\x80\x93 False Positive\n\nSmoke\xe2\x80\x93 False Positive\n\nApplication:\nImage signature identification for\nTransverse bands\n\nImage signature identification for Transverse\nbands\n\xe2\x80\xa2 Found in association with multiple types of\nphenomena.\n\xe2\x80\xa2\n\nHurricanes, Jet-Streaks, Mesoscale Convective Systems\n(MCS)\n\n\xe2\x80\xa2 Associated with differing levels of aviation\nturbulence\n\xe2\x80\xa2 Problem:\n\xe2\x80\xa2 Identify transverse cirrus bands in MODIS True\nColor imagery.\n\xe2\x80\xa2 Relatively small scale features (1-10 km wide).\n\xe2\x80\xa2\n\n40\n\nMethodology\n\xe2\x80\xa2 Data\n\xe2\x80\x93 5440 images (1 km MODIS RGB)\n\xe2\x80\xa2 1741 with transverse bands\n\xe2\x80\xa2 3699 without transverse bands\n\n\xe2\x80\x93 20% for validation\n\xe2\x80\x93 600 separate images for testing\n\n\xe2\x80\xa2 Architecture\n\xe2\x80\x93 VGG16 architecture\n\n\xe2\x80\x93 Replaced fully connected layers with global average pooling layer\n\xe2\x80\x93 First seven layers frozen (not trained)\n\xe2\x80\x93 Keras (Python)\n\xe2\x80\x93 NVIDIA GTX 960 GPU\n\n\xe2\x80\xa2 Classify 2013 GIBS tiles\n\xe2\x80\xa2 Geolocate transverse cirrus bands\n\nTraining Results\n\xe2\x80\xa2 Model trained for 52 epochs (6 hrs)\n\xe2\x80\xa2 Highest validation accuracy\noccurred at epoch 41 (0.937)\n\xe2\x80\xa2 Testing on the test set:\n\xe2\x80\x93 Accuracy: 94.67%\n\n\xe2\x80\xa2 Class activation maps show that\nthe network is able to identify the\nregions of the image that contain\ntransverse bands.\n\nClassifying 2013 GIBS tiles\n\xe2\x80\xa2 Some interesting areas stand out\n\xe2\x80\x93 Eastern coast of India\n\xe2\x80\x93 Western coast of Mexico/California\n\xe2\x80\x93 Southeastern coast of South America\n\n\xe2\x80\xa2 Jet stream appears to play a\nlarge role\n\xe2\x80\xa2 Eastern and Central US more\nthan likely due to MCSs\n\nApplication:\nEnabling New Science\nDust Climatology\nCollaboration with Sundar Christopher, UAH\n\nEnabling new science\n\xe2\x80\xa2 Dust Climatology\n\xe2\x80\xa2 Dataset\n\xe2\x80\x93 Manually created truthset\n\n\xe2\x80\xa2 Dust/No Dust classification on GIBS tiles\n\nEnabling new science\nConfusion Matrix\nValidation\nAccuracy = 91%\n\n46\n\nAnalysis\n\xe2\x80\xa2 Accuracy outperformed traditional approaches\n\xe2\x80\xa2 Training data\n\xe2\x80\xa2 Automatic validation of images\n\xe2\x80\xa2 Hyperparameters\n\nAcknowledgement\nNASA Earth Science Technology Office\n\xe2\x80\xa2 Advanced Information Systems Technology (AIST)\nprogram Grant number: NNM11AA01A\n\nContact\nManil Maskey\nmanil.maskey@nasa.gov\n\nRahul Ramachandran\nrahul.ramachandran@nasa.gov\n\n'