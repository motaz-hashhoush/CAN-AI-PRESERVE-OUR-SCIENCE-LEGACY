b'NASA/TP-2004-212997\n\nFlight Test Evaluation of Synthetic Vision\nConcepts at a Terrain Challenged Airport\nLynda J. Kramer, Lawrence J. Prinzel III, Randall E. Bailey, Jarvis J. Arthur III,\nand Russell V. Parrish\nLangley Research Center, Hampton, Virginia\n\nFebruary 2004\n\nThe NASA STI Program Office . . . in Profile\n\nSince its founding, NASA has been dedicated to the\nadvancement of aeronautics and space science. The\nNASA Scientific and Technical Information (STI)\nProgram Office plays a key part in helping NASA\nmaintain this important role.\nThe NASA STI Program Office is operated by\nLangley Research Center, the lead center for NASA\xe2\x80\x99s\nscientific and technical information. The NASA STI\nProgram Office provides access to the NASA STI\nDatabase, the largest collection of aeronautical and\nspace science STI in the world. The Program Office is\nalso NASA\xe2\x80\x99s institutional mechanism for\ndisseminating the results of its research and\ndevelopment activities. These results are published by\nNASA in the NASA STI Report Series, which\nincludes the following report types:\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nTECHNICAL PUBLICATION. Reports of\ncompleted research or a major significant phase\nof research that present the results of NASA\nprograms and include extensive data or\ntheoretical analysis. Includes compilations of\nsignificant scientific and technical data and\ninformation deemed to be of continuing\nreference value. NASA counterpart of peerreviewed formal professional papers, but having\nless stringent limitations on manuscript length\nand extent of graphic presentations.\nTECHNICAL MEMORANDUM. Scientific\nand technical findings that are preliminary or of\nspecialized interest, e.g., quick release reports,\nworking papers, and bibliographies that contain\nminimal annotation. Does not contain extensive\nanalysis.\nCONTRACTOR REPORT. Scientific and\ntechnical findings by NASA-sponsored\ncontractors and grantees.\n\n\xe2\x80\xa2\n\nCONFERENCE PUBLICATION. Collected\npapers from scientific and technical\nconferences, symposia, seminars, or other\nmeetings sponsored or co-sponsored by NASA.\n\n\xe2\x80\xa2\n\nSPECIAL PUBLICATION. Scientific,\ntechnical, or historical information from NASA\nprograms, projects, and missions, often\nconcerned with subjects having substantial\npublic interest.\n\n\xe2\x80\xa2\n\nTECHNICAL TRANSLATION. Englishlanguage translations of foreign scientific and\ntechnical material pertinent to NASA\xe2\x80\x99s mission.\n\nSpecialized services that complement the STI\nProgram Office\xe2\x80\x99s diverse offerings include creating\ncustom thesauri, building customized databases,\norganizing and publishing research results ... even\nproviding videos.\nFor more information about the NASA STI Program\nOffice, see the following:\n\xe2\x80\xa2\n\nAccess the NASA STI Program Home Page at\nhttp://www.sti.nasa.gov\n\n\xe2\x80\xa2\n\nE-mail your question via the Internet to\nhelp@sti.nasa.gov\n\n\xe2\x80\xa2\n\nFax your question to the NASA STI Help Desk\nat (301) 621-0134\n\n\xe2\x80\xa2\n\nPhone the NASA STI Help Desk at\n(301) 621-0390\n\n\xe2\x80\xa2\n\nWrite to:\nNASA STI Help Desk\nNASA Center for AeroSpace Information\n7121 Standard Drive\nHanover, MD 21076-1320\n\nNASA/TP-2004-212997\n\nFlight Test Evaluation of Synthetic Vision\nConcepts at a Terrain Challenged Airport\nLynda J. Kramer, Lawrence J. Prinzel III, Randall E. Bailey, Jarvis J. Arthur III,\nand Russell V. Parrish\nLangley Research Center, Hampton, Virginia\n\nNational Aeronautics and\nSpace Administration\nLangley Research Center\nHampton, Virginia 23681-2199\n\nFebruary 2004\n\nThe use of trademarks or names of manufacturers in the report is for accurate reporting and does not\nconstitute an official endorsement, either expressed or implied, of such products or manufacturers by the\nNational Aeronautics and Space Administration.\n\nAvailable from:\nNASA Center for AeroSpace Information (CASI)\n7121 Standard Drive\nHanover, MD 21076-1320\n(301) 621-0390\n\nNational Technical Information Service (NTIS)\n5285 Port Royal Road\nSpringfield, VA 22161-2171\n(703) 605-6000\n\nSymbols & Abbreviations\nAFL\nAGL\nANOVA\nANP\nARIES\nASIST\nATL\nAVL\nAvSP\nCFIT\nCNS/ATM\nCOS\nDEM\nDFW\nDIME\nDME\nDTW\nEADI\nEFIS\nEGE\nEGPWS\nEP\nEVS\nEWR\nFAA\nFANS\nFDRS\nFLIR\nFMS\nFOV\nFSIL\nFTE\nGEOTIFF\nGPS\nGPWS\nHDD\nHGS\nHUD\nHz\nICAO\nIFD\nILS\nIMC\nin\nJFK\nLaRC\nLAX\n\nAbove Field Level\nAbove Ground Level\nAnalysis of Variance\nActual Navigation Performance\nAirborne Research Integrated Experiment System\nAviation Safety Investment Strategy Team\nFAA airport identifier for The William B. Hartsfield Atlanta International Airport\nFAA airport identifier for Asheville Regional Airport\nAviation Safety Program\nControlled Flight Into Terrain\nCommunication Navigation Surveillance/Air Traffic Management\nFAA airport identifier for Colorado Springs, Colorado Airport\nDigital Elevation Model\nFAA airport identifier for Dallas/Fort Worth International Airport\nDatabase Integrity Monitoring Equipment\nDistance Measuring Equipment\nFAA airport identifier for Detroit Metropolitan Wayne County Airport\nElectronic Attitude Direction Indicator\nElectronic Flight Instrumentation System\nFAA airport identifier for Eagle County, Colorado Regional Airport\nEnhanced Ground Proximity Warning System\nEvaluation Pilot\nEnhanced Vision System\nFAA airport identifier for Newark Liberty International Airport\nFederal Aviation Administration\nFuture Air Navigation System\nFlight Deck Research System\nForward-Looking Infra-Red\nFlight Management System\nField of View\nFlight Systems Integration Laboratory\nFlight Technical Error\nGeoreferenced Tagged Image File Format\nGlobal Positioning System\nGround Proximity Warning System\nHead-Down Display\nHead-Up Guidance System\nHead-Up Display\nHertz\nInternational Civil Aviation Organization\nIntegration Flight Deck\nInstrument Landing Systems\nInstrument Meteorological Conditions\ninches\nFAA airport identifier for John F. Kennedy International Airport\nLangley Research Center\nFAA airport identifier for Los Angeles International Airport\n\niii\n\nLDA\nLGA\nMASPS\nMSL\nMSP\nn\nNASA\nND\nNED\nnmi\nORD\nPFD\nRIPS\nRMS\nRNAV\nRNP\nSA\nSA-SWORD\nSEA\nSNK\nSP\nSV\nSVDC\nSVS\nSVS-GE\nSVS-RD\nSXGA\nTAWS\nTOGA\nUSGS\nUTM\nVISTAS\nVMC\nVNAV\nVOR\nVRD\nXGA\n\nLocalizer-DME Approach\nFAA airport identifier for La Guardia Airport\nMinimum Aviation System Performance Standards\nMean Sea Level\nFAA airport identifier for Minneapolis-St Paul International Airport\nnumber of samples\nNational Aeronautics and Space Administration\nNavigation Display\nNational Elevation Dataset\nnautical mile\nFAA airport identifier for Chicago O\'Hare International Airport\nPrimary Flight Display\nRunway Incursion Prevention System\nRoot Mean Square\nRNP Area Navigation\nRequired Navigation Performance\nSituation Awareness\nSituational Awareness \xe2\x80\x93 Subjective Workload Dominance\nFAA airport identifier for Seattle-Tacoma International Airport\nStudent-Newman-Keuls\nSafety Pilot\nSynthetic Vision\nSynthetic Vision Display Concepts\nSynthetic Vision Systems\nSynthetic Vision Systems \xe2\x80\x93 Graphics Engine\nSynthetic Vision Systems \xe2\x80\x93 Research Display\nSuper-eXtended Graphics Array (1280 by 1024 pixels)\nTerrain Awareness and Warning System\nTakeoff/Go-around\nUnited States Geological Survey\nUniversal Transverse Mercator\nVisual Imaging Simulator for Transport Aircraft Systems\nVisual Meteorological Conditions\nVertical navigation\nVery high frequency Omni-direction Radio\nVision Restriction Device\neXtended Graphics Array (1024 by 768 pixels)\n\niv\n\nTable of Contents\nSymbols & Abbreviations ..........................................................................................................iii\nList of Tables.............................................................................................................................vi\nList of Figures...........................................................................................................................vii\nExecutive Summary ....................................................................................................................1\nIntroduction ................................................................................................................................2\nSafety Benefits of SVS............................................................................................................3\nOperational Benefits of SVS ...................................................................................................4\nEconomic Benefits of SVS......................................................................................................5\nChallenges to Synthetic Vision................................................................................................5\nNASA SVS Human Factors Research .....................................................................................6\nCurrent Study..............................................................................................................................7\nGoals and Objectives ..............................................................................................................8\nHypotheses .............................................................................................................................9\nMethod .....................................................................................................................................10\nSubjects ................................................................................................................................10\nSimulator and Flight Test Vehicle .........................................................................................10\nEvaluation Tasks...................................................................................................................13\nExperiment Design................................................................................................................25\nProcedure..............................................................................................................................31\nResults ......................................................................................................................................32\nApproach Path for FMS25 and Visual 07 ..............................................................................32\nFMS25 approach and departure.............................................................................................34\nVisual 07 approach ...............................................................................................................41\nLateral Navigation Bin Analyses...........................................................................................46\nVertical Navigation Bin Analysis ..........................................................................................49\nSubjective Data Analyses......................................................................................................52\nDiscussion ................................................................................................................................58\nPilot Performance..................................................................................................................58\nRequired Navigation Performance.........................................................................................59\nPilot Preferences ...................................................................................................................60\nSituation Awareness..............................................................................................................60\nWorkload ..............................................................................................................................61\nMinification Hypotheses .......................................................................................................62\nConclusions ..............................................................................................................................63\nFuture Directions ......................................................................................................................64\nBibliography.............................................................................................................................66\nAppendix A. Synthetic Vision Systems Project Background ....................................................69\nAppendix B. Theoretical Foundations of Synthetic Vision Systems..........................................71\nAppendix C: Situation Awareness and Workload in Relation to Synthetic Vision Systems.......73\nAppendix D: Required Navigation Performance.......................................................................75\nAppendix E. Planned Run Matrix.............................................................................................78\nAppendix F. Post-Flight Questionnaire Ratings........................................................................80\n\nv\n\nList of Tables\nTable 1.\nTable 2.\nTable 3.\nTable 4.\nTable 5.\nTable 6.\n\nVertical Accuracy Performance Requirements..............................................................4\nPhoto-realistic Image Sources.....................................................................................19\nFinal TerraPage Database Created from Source Data..................................................19\nFlight Segment Definitions and Associated Piloting Tasks .........................................26\nLateral Navigation Performance Bin Definitions ........................................................29\nVertical Navigation Performance Bin Definitions.......................................................29\n\nvi\n\nList of Figures\nFigure 1. SVS-RD installed in ARIES 757 aircraft. ..................................................................11\nFigure 2. Vision Restriction Device in ARIES 757 aircraft.......................................................11\nFigure 3. HUD stroke-on-raster imagery components...............................................................13\nFigure 4. Diagram of Eagle-Vail regional airport. ....................................................................14\nFigure 5. Runway 25 at Eagle-Vail Regional Airport ...............................................................15\nFigure 6. Runway 07 at Eagle-Vail Regional Airport ...............................................................15\nFigure 7. FMS Runway 25 Approach and Cottonwood-2 Departure.........................................17\nFigure 8. Visual Arrival to Runway 07 and KREMM Departure ..............................................17\nFigure 9. Four databases with symbology overlays used for the experiment. ............................18\nFigure 10. Baseline display, EADI with TAWS on ND. ...........................................................21\nFigure 11. Size A with photo-realistic texturing. ......................................................................21\nFigure 12. Size A with generic texturing. .................................................................................22\nFigure 13. Size X with photo-realistic texturing. ......................................................................22\nFigure 14. Size X with generic texturing. .................................................................................23\nFigure 15. Head-Up Display with generic texturing..................................................................23\nFigure 16. Raw data indicators for the Baseline and SVS concepts...........................................24\nFigure 17. Crow\xe2\x80\x99s feet and goal post in the Synthetic Vision tunnel .........................................24\nFigure 18. Ghost aircraft symbol ..............................................................................................25\nFigure 19. Segmentation of FMS Runway 25 Approach and Cottonwood-2 Departure for\nstatistical analyses. ............................................................................................................27\nFigure 20. Segmentation of Visual Arrival to Runway 07 for statistical analyses......................27\nFigure 21. In-flight run questionnaire. ......................................................................................30\nFigure 22. RMS lateral and vertical path error over the entire approach path. ...........................33\nFigure 23. RMS lateral and vertical path error over segment one..............................................35\nFigure 24. Second order interaction of display type and task for RMS vertical path error over\nsegment one. .....................................................................................................................35\nFigure 25. RMS lateral and vertical path error over segment two (initial approach). .................37\nFigure 26. RMS localizer error plot of display type and task interaction over segment two.......38\nFigure 27. RMS localizer error over segment three (FMS25 short final) ...................................39\nFigure 28. RMS lateral path error over segment three (FMS25 final)........................................40\nFigure 29. RMS lateral and vertical path error over segment six (circle entry level off). ...........42\nFigure 30. RMS lateral and vertical path error over segment seven (circle dogleg). ..................44\nFigure 31. RMS lateral and vertical path error over segment eight (circling approach). ............45\nFigure 32. RMS lateral error plot of SVS display type and texture interaction. .........................46\nFigure 33. Lateral FTE distribution for the Baseline EADI concept..........................................47\nFigure 34. Lateral FTE distribution for the Size A SVS concept...............................................48\nFigure 35. Lateral FTE distribution for the Size X SVS concept...............................................48\nFigure 36. Lateral FTE distribution for the HUD SVS concept.................................................49\nFigure 37. Vertical FTE distribution for the Baseline EADI concept ........................................50\nFigure 38. Vertical FTE distribution for the Size A SVS concept .............................................50\nFigure 39. Vertical FTE distribution for the Size X SVS concept .............................................51\nFigure 40. Vertical FTE distribution for the HUD SVS concept ...............................................51\nFigure 41. Post-run mean pilot ratings......................................................................................53\nFigure 42. Mean pilot situation awareness ratings versus display type ......................................54\n\nvii\n\nFigure 43. Mean pilot workload ratings versus display type .....................................................55\nFigure 44. Comparative situation awareness among display concepts.......................................56\n\nviii\n\nExecutive Summary\nLimited visibility is the single most critical factor affecting both the safety and capacity of worldwide\naviation operations. In commercial aviation alone, over 30-percent of all fatal accidents worldwide are\ncategorized as controlled flight into terrain (CFIT), where a mechanically sound and normally functioning\nairplane is inadvertently flown into the ground, water, or an obstacle, principally due to the lack of outside\nvisual reference and situation awareness. The National Aeronautics and Space Administration (NASA)\nAviation Safety Program\xe2\x80\x99s Synthetic Vision Systems (SVS) Project is developing technologies with\npractical applications that will mitigate low visibility conditions as a causal factor to civil aircraft\naccidents, as well as replicate the operational benefits of flight operations in unlimited ceiling and\nvisibility day conditions, regardless of the actual outside weather or lighting condition. The technologies\nwill emphasize the cost-effective use of synthetic/enhanced-vision displays; worldwide navigation,\nterrain, obstruction, and airport databases; and Global Positioning System (GPS)-derived navigation to\nmitigate \xe2\x80\x9cvisibility-induced\xe2\x80\x9d (lack of visibility) errors for all aircraft categories. A major thrust of the\nSVS Project is to develop and demonstrate affordable, certifiable display configurations which provide\nintuitive out-the-window terrain and obstacle information, including guidance information for precision\nnavigation and obstacle/obstruction avoidance for commercial and business aircraft.\nTo date, much of the SVS research has focused on introducing SVS display technology into as many\nexisting aircraft as possible by providing a retrofit approach. This approach employs existing head down\ndisplay (HDD) capabilities for glass cockpits (cockpits already equipped with raster-capable HDDs) and\nhead-up display (HUD) capabilities for the other aircraft. A major NASA flight test at Dallas/Fort Worth\n(DFW) airport and several simulator studies have occurred for assessment and evaluation of the SVS\ndevelopments and the retrofit approach. The HDD objective of these studies was to examine whether an\nSVS display could be retrofitted into an Electronic Flight Instrumentation System (EFIS) Size \xe2\x80\x9cA\xe2\x80\x9d (5.25\nin. wide by 5 in. tall) (e.g., B-757-200) Electronic Attitude Direction Indicator (EADI) and Size \xe2\x80\x9cD\xe2\x80\x9d (6.4\nin. wide by 6.4 in. tall) (e.g., B-777) Primary Flight Display (PFD). A Size \xe2\x80\x9cX\xe2\x80\x9d (9 in. wide by 8 in. tall)\nhead-down display was also tested that may represent the display real estate available on future aircraft.\nThe HUD objective was to examine the feasibility of the concept of retrofitting SVS display technology\nwith HUDs for aircraft without raster-capable HDDs. The feasibility of the concept of retrofitting SVS\ndisplay technology with HUDs was verified for nighttime operations. Two terrain-texturing techniques\nwere also evaluated during the research. One method of terrain texturing, generic texturing, involved the\nselection of terrain color based on absolute altitude. The other method of terrain texturing, photo-realistic\ntexturing, employed full-color ortho-rectified aerial photographs draped over the elevation model. The\nresults of those studies confirmed that an SVS display, with pilot-selectable field of view (FOV), could be\nincorporated as part of an EFIS suite and effectively replace an EADI or PFD. Regardless of HDD\ndisplay size, and for the nighttime HUD application, pilots reported greater situation awareness and had\nlower flight technical error (FTE) while operating with the SVS displays compared to conventional\ndisplays. For both HDD and HUD applications, no significant performance effects were found between\ntexturing techniques, although most of the pilots preferred the photo-realistic terrain texturing technique\nto the generic texturing technique.\nThe results of previous research have documented the unquestionable promise of SVS to enhance\nsituation awareness and improve aviation safety during approaches to terrain and operationally-complex\nairports. The DFW flight test showed that all SVS display concepts provided precise path control and\nsignificantly improved spatial awareness for approaches to the DFW airport under nighttime conditions.\nAlthough the fixed-based simulator results had provided convincing data on the efficacy of SVS for\nterrain-challenged environments, these results had yet to be replicated and validated under operational\nconditions like that conducted at DFW in 2000. In 1999, a flight test / demonstration was conducted\n\n1\n\nusing the SVS technology to make approaches to the Asheville, North Carolina (AVL) airport, but no\nempirical data was collected to substantiate the claims that SVS was effective in terrain-challenged\nenvironments. Therefore, the Aviation Safety program and SVS Project conducted research flight\noperations at Eagle-Vail, CO (EGE) to further examine the utility, capabilities, and potential of SVS to\nenhance situation awareness and improve pilot performance for complex approaches in mountainous\nenvironments.\nThe flight test was conducted to evaluate three SVS display types (Head-up Display, Head-Down Size\nA; Head-Down Size X) and two terrain texture methods (photo-realistic, generic) in comparison to the\nsimulated Baseline Boeing-757 Electronic Attitude Direction Indicator and Navigation / Terrain\nAwareness and Warning System displays. These independent variables were evaluated for path error,\nsituation awareness, and workload while making approaches to Runway 25 and 07 and during simulated\nengine-out Cottonwood 2 and KREMM departures. The results of the experiment showed significantly\nimproved performance, situation awareness, and workload for SVS concepts compared to the Baseline\ndisplays and confirmed the retrofit capability of the Head-Up Display and Size A SVS concepts. The\nresearch also demonstrated that the tunnel guidance display concept used within the SVS concepts\nachieved required navigation performance (RNP) criteria. These findings are a strong verification of the\nSVS retrofit approach. That is, HUD or HDDs of any size or texture method tested were an equally\neffective means of implementing SVS concepts to achieve FTE and RNP benefits. The top-level results\nof the EGE flight test concerning the improved path performance, enhanced situation awareness, and\nlower associated workload provided by all of the SVS (HDD and HUD) concepts, regardless of display\nsize, are highly significant. These results firmly establish the SVS retrofit concept approach as viable.\nThis paper documents the EGE flight test experiment and presents suggestions for research thrusts for\nfurther development of future embodiments of synthetic vision systems.\n\nIntroduction\nThe Synthetic Vision Systems (SVS) element of the National Aeronautics and Space Administration\xe2\x80\x99s\n(NASA) Aviation Safety Program (AvSP) is striving to eliminate poor visibility as a causal factor in\naircraft accidents as well as enhance operational capabilities of all aircraft. To accomplish these safety\nand situation awareness (SA) improvements, the SVS concept is designed to provide the pilot an\nunobstructed view of the world around the aircraft through the display of computer-generated imagery\nderived from an onboard database of terrain, obstacle, and airport information. To accomplish the\noperational enhancements, the SVS concept includes the intuitive display of intended flight path by tunnel\nor pathway-in-the-sky presentations. When coupled with a synthetic or enhanced view of the outside\nworld, the spatially-integrated depiction of the intended aircraft flight path and its relation to the world\nprovides an intuitive, easily interpretable display of flight-critical information for the pilot.\nThe ability of a pilot to ascertain critical information through visual perception of the outside\nenvironment can be limited by various weather phenomena, such as rain, fog, and snow. Since the\nbeginning of flight, the aviation industry has continuously developed various devices to overcome lowvisibility issues, such as attitude indicators, radio navigation, and instrument landing systems. Recent\nadvances include moving map displays, incorporating advances in navigational accuracies from the\nGlobal Positioning System (GPS), and Terrain Awareness and Warning Systems (TAWS), such as\nHoneywell\xe2\x80\x99s Enhanced Ground Proximity Warning System (EGPWS). All of the aircraft information\ndisplay concepts developed to date, however, require the pilot to perform various additional levels of\nmental model development, maintenance, and information decoding in a real-time environment when\noutside visibility is restricted (e.g., Theunissen, 1997).\n\n2\n\nBetter pilot SA during low visibility conditions is potentially offered by SVS displays because of the\nnatural cues provided by a three-dimensional perspective display of the outside world showing unlimited\nceiling and visibility conditions. New technological developments in navigation performance, low-cost\nattitude and heading reference systems, computational capabilities, and display hardware allow for the\nprospect of SVS displays for virtually all aircraft classes. SVS display concepts employ computergenerated terrain imagery, on-board databases, and precise position and navigational accuracy to create a\nthree dimensional perspective presentation of the outside world, with necessary and sufficient information\nand realism, to enable operations equivalent to those of unlimited ceiling and visibility conditions\nregardless of the actual outside weather. The safety outcome of SVS is a display that should help reduce,\nor even prevent, controlled flight into terrain (CFIT), which is the single greatest contributing factor to\nfatal worldwide airline and general aviation accidents (Boeing, 1998). Other safety benefits include\nreduced runway incursions and loss-of-control accidents (Williams et al., 2001). Operational benefits\npotentially include more approach and departure options and lower visibility minimums for SVS\nequipped aircraft. For a more detailed description of the SVS project, please see Appendix A.\n\nSafety Benefits of SVS\nIt is highly unlikely that conventional display concepts can significantly increase safety as new\nfunctionality and new technology cannot simply be layered onto previous design concepts since the\ncurrent system complexities are already too high (Theunissen, 1997). Better human-machine interfaces\nrequire a fundamentally new approach. One such approach applies the fundamental advantage of\nperspective flight path displays relative to conventional displays. Rather than commanding the pilot what\nto do, or at best showing only the error with respect to the desired trajectory, guidance and navigation\ndisplays can now provide information about the margins within which the pilot is allowed to operate.\nThese displays are augmented to show such information as spatial constraints and terrain constraints,\nrather than just showing conventional flight director commands, which only indicate an error, seemingly\nindependent of the actual constraints. These additional display elements provide guidance that does not\nforce the pilot to apply a continuous compensatory control strategy. Only in this way can human\nflexibility be exploited. This is a fundamental difference between current and SVS displays \xe2\x80\x93 that\nsynthetic vision embodies the concept of \xe2\x80\x9chuman-centered\xe2\x80\x9d design by providing natural versus coded\ninformation to the pilot (Theunissen, 1997). Appendix B describes the concept of human-centered design\nand the theoretical foundations for synthetic vision.\nBecause SVS displays are posited to provide both natural and coded information to the pilot, better\npilot spatial situation awareness during low visibility conditions can be achieved. Synthetic vision\ntechnology will allow the issues associated with limited visibility to be solved with a vision-based\nsolution, making every flight the equivalent of a clear daylight operation, which will help improve\nsituation awareness, lower workload, and support proper development of pilots\xe2\x80\x99 mental models (see\nAppendix C). Therefore, SVS can have a most significant impact on improving aviation safety, as limited\nvisibility has often been cited as the single greatest contributing factor in fatal worldwide airline and\ngeneral aviation accidents (Boeing, 1996).\nConsider that one of the major classifications of aviation accidents involving visibility issues is CFIT\nand that CFIT is the greatest cause of aviation fatalities. A CFIT accident is defined as \xe2\x80\x9cone in which an\notherwise-serviceable aircraft, under control of the crew, is flown (unintentionally) into terrain, obstacles\nor water, with no prior awareness on the part of the crew of the impending collision\xe2\x80\x9d (Wiener, 1977).\nEnders, et al., (1996) noted that worldwide, the chances of CFIT accidents are 5 times higher in nonprecision approaches. SVS could have a significant impact in ameliorating the incidence of this accident\ncategory (Arthur et al., 2003). For commercial transport aircraft, instant recognition and correction of\n\n3\n\nvisibility-induced errors may eliminate CFIT. If accurate positioning information of other traffic were\nincorporated into the system, SVS could also help to eliminate runway incursions. For general aviation\naircraft, a lower cost implementation of such a system could help to prevent visibility-induced loss-ofcontrol accidents by providing an intuitive, easy-to-fly visual reference for Visual Meteorological\nConditions (VMC)-like operations in Instrument Meteorological Conditions (IMC). It would also be\nanticipated that SVS technology could serve to increase national airspace system capacity by providing\nthe potential for VMC-like operations more of the time (Hemm, 2000; Hemm, Lee, Stouffer, & Gardner,\n2001).\n\nOperational Benefits of SVS\nAside from the safety benefits accrued from the increased SA with reduced workload provided by the\nnatural information presentation of synthetic vision displays, considerable operational benefits are also\npotentially available through provisions for flight operations in IMC resembling those conducted in\nVMC. These potential benefits could include lower landing minimums, more approach and departure\noptions, more complex path structures to avoid hazardous or restricted (noise, security) areas, reduced\ntraining time, etc. Among these, a significant operational benefit of SVS would include helping to meet\nnew Federal Aviation Administration (FAA) required navigation performance (RNP) criteria.\nRNP is a statement of the navigation performance accuracy necessary for operation within a defined\nairspace. RNP airspace is a generic term referring to airspace, routes, and legs, where minimum\nnavigation performance requirements have been established and aircraft must meet or exceed that\nperformance to fly in that airspace. The system performance requirements for RNP Area Navigation\n(RNAV) is that each aircraft operating in RNP airspace shall have total horizontal system error\ncomponents in the cross-track and along-track directions that are less than the RNP value 95% of the\nflying time. Vertical navigation (VNAV) capability further enhances flight operations by enabling the\nspecification of a flight path vertically for the lateral flight path. The system performance requirements\nfor VNAV are that for at least 99.7% of the time the navigational performance in the vertical plane, or the\ntotal vertical system error, is less than a specified altitude deviation measure based on the airspace being\nflown in (below 5000 feet mean sea level (MSL), 5000-10000 feet MSL, above 10000 feet MSL) and the\ntype of flight operation (level flight/climb/descent or flight along specified vertical profile) being\nperformed (see table 1). For more information about RNP, please see Appendix D.\nTable 1. Vertical Accuracy Performance Requirements\nError Source\n\nLevel Flight Segments\nand Climb/Descent\nIntercept of Clearance\nAltitudes (MSL)\n\nApproach\nalong Specified\nVertical Profile\n(MSL)\n\nAt or Below\n5000 ft\n\n5000 ft to\n10000 ft\n\nAbove\n10000 ft\n\nAt or Below\n5000 ft\n\n5000 ft to\n10000 ft\n\nAbove 10000 ft\n\nAltimetry\n\n90 ft\n\n200 ft\n\n250 ft\n\n140 ft\n\n265 ft\n\n350 ft\n\nRNAV\nEquipment\n\n50 ft\n\n50 ft\n\n50 ft\n\n100 ft\n\n150 ft\n\n220 ft\n\nFlight\nTechnical\n\n150 ft\n\n240 ft\n\n240 ft\n\n200 ft\n\n300 ft\n\n300 ft\n\nTotal RootSum-Square\n(RSS)\n\n190 ft\n\n320 ft\n\n350 ft\n\n265 ft\n\n430 ft\n\n510 ft\n\n4\n\nRNP defines that an aircraft\xe2\x80\x99s actual navigation performance will be required to meet certain\nnavigation precision criteria. Synthetic Vision is postulated to contribute significantly to achieving RNP\nthrough the use of pathway displays and guidance symbology. Research has shown that the use of\npathway displays and predictive guidance can significantly reduce flight technical error (e.g., Haskell &\nWickens, 1993; Wickens & Prevett, 1995; Theunissen, 1997). Therefore, SVS may not only increase\naviation safety but may also have significant operational benefits that, in turn, can result in substantial\neconomic benefits.\n\nEconomic Benefits of SVS\nHemm (2000) and Hemm et al. (2001) did a benefit estimation of SVS technologies and\nconcluded that synthetic vision has significant potential not only for improving aviation safety and\nincreasing navigation precision but can also provide for other considerable economic benefits. The\nanalyses were based on the assumptions that SVS could reduce runway occupancy time in low visibility;\nreduce departure minimums; reduce arrival minimums; better allow for converging and circling\napproaches, especially for dual and triple runway configurations; reduce inter-arrival separations; and\nprovide for independent operations on closely-spaced parallel runways. A cost-benefit analysis, based on\nthose assumptions at 10 airports (DFW, ORD, LAX, ATL, DTW, MSP, EWR, SEA, LGA, JFK),\ncalculated the average cost savings to airlines for the years 2006 to 2015 to be $2.25 billion. Part of the\nrationale for the AvSP SVS Project choosing Dallas/Fort Worth (DFW) (Glaab et al., 2003) and Eagle\nCounty, Colorado Regional (EGE) airport (Kramer et al., 2003) locations to conduct flight test research\nwas to demonstrate that SVS could allow operations into runways (i.e., EGE Runway 07) that normally\nare not used, especially in IMC.\n\nChallenges to Synthetic Vision\nAlthough there is significant potential for SVS to help meet national aviation goals, there are still\nconsiderable research challenges that need to be addressed. To identify these challenges, a workshop\nresulting in a concept of operations for commercial and business aircraft was held in early 2000\n(Williams, et al., 2001). A similar workshop was hosted that focused on general aviation aircraft. The\nfocus of these events was to obtain wide ranging input on the benefits and features which synthetic vision\nmight incorporate. This meeting included representatives from NASA, Department of Defense, FAA,\nindustry, professional organizations, airlines, aircraft and avionics manufacturers, airports, and academic\ninstitutions. The result of the workshop was a \xe2\x80\x9cshopping list\xe2\x80\x9d of research issues that need to be explored\nin developing SVS display concepts. Primary among them, expressed as questions, are:\n\xe2\x80\xa2\n\nHow can an SVS display be retrofitted into an aircraft class that has limited real-estate display\nspace?\n\n\xe2\x80\xa2\n\nWhat are the perceptual issues involved with minification and increased field of views on\nsmaller SVS displays?\n\n\xe2\x80\xa2\n\nWhat is the best way to present synthetic terrain and symbology to enhance situation\nawareness?\n\n\xe2\x80\xa2\n\nCan an SVS display improve SA and reduce workload?\n\n\xe2\x80\xa2\n\nWhat are the cognitive issues that may affect safety of flight when pilots fly a \xe2\x80\x9ccompelling\xe2\x80\x9d\nsynthetic vision scene?\n\n5\n\n\xe2\x80\xa2\n\nWhat is the best way to display the synthetic vision scene and what are the database and\nsensor requirements to ensure the integrity of a synthetic vision system?\n\nThe NASA SVS-Commercial and Business aircraft element is using these issues as guidance in its\nresearch plans and a significant amount of research has been conducted, as discussed in the next section.\n\nNASA SVS Human Factors Research\nNASA SVS Simulator Research Experiments. An important issue for the SVS concept is whether\nuseful and effective SVS displays can be implemented on limited size display spaces as would be required\nto implement this technology on older aircraft with physically smaller instrument spaces. With computer\ngenerated 3-dimensional imagery, SVS display concepts can provide pilot-selectable display Field of\nView (FOV) control to enhance display effectiveness, potentially overcoming size constraint limitations.\nComstock, et al., (2001) conducted a study to examine how approaches using SVS on smaller display\nsizes affect performance and situation awareness. In this study, prototype SVS displays were shown on\nthe following display sizes: (a) ARINC Size A (e.g., 757 Electronic Attitude Direction Indicator), (b)\nARINC Size D (e.g., 777 Primary Flight Display), and (c) new size \xe2\x80\x9cX\xe2\x80\x9d (Rectangular flat-panel,\napproximately 20 x 25 cm). Testing was conducted in the Visual Imaging Simulator for Transport\nAircraft Systems (VISTAS)-I, which is a high-resolution graphics workstation at NASA Langley\nResearch Center. Specific issues under test included the display size and the FOV to be shown on the\ndisplay and, directly related to FOV, the degree of minification of the displayed image or picture. Using\nsimulated approaches to Asheville, NC airport runways (FAA identifier, AVL), no significant lateral or\nvertical performance differences were found for any display size or FOV condition. Preferred FOV based\non performance was determined by using approaches during which pilots could select FOV. Mean\npreference ratings for FOV were in the following order: (1) 30\xc2\xb0, (2) Unity, (3) 60\xc2\xb0, and (4) 90\xc2\xb0, and held\ntrue for all display sizes tested.\nA second study by Stark, et al., (2001) was conducted to further explore issues of display size, FOV,\nand tunnel guidance on pilot performance and SA. Tunnel guidance was expected to improve pilot\nperformance, increase SA, and decrease workload. Results of the study supported these hypotheses.\nBoth horizontal and vertical path error were indeed reduced by tunnel guidance. Pilots were able to stay\non path more accurately with the assistance of the tunnel, and these findings support previous pathway\nresearch (see Doherty & Wickens, 2001 for a review). Pilots also verbally reported \xe2\x80\x9cfeeling\xe2\x80\x9d like they\nwere better able to stay on path when using the tunnel guidance system, and these feelings were\naccompanied by a statistically significant reduction in mental workload measurements. One pilot\ncommented that he was so \xe2\x80\x9cin tune\xe2\x80\x9d with the guidance system that it was almost \xe2\x80\x9ctoo easy\xe2\x80\x9d to fly. The\n\xe2\x80\x9cintuitiveness\xe2\x80\x9d of the tunnel concept contributed to significantly higher situation awareness ratings for the\nsynthetic vision concepts.\nDallas Fort-Worth Flight Test. To introduce SVS display technology into as many existing aircraft\nas possible, a retrofit approach was postulated. That approach proposed using existing head-down display\n(HDD) capabilities for glass cockpits (cockpits already equipped with raster-capable HDDs) and head-up\ndisplay (HUD) capabilities for the other aircraft. This retrofit approach takes advantage of the growing\nnumbers of HUDs being fitted into the commercial fleet due to HUD operational benefits.\nPrevious research in a fixed-based simulator at NASA Langley Research Center (LaRC) (Comstock et\nal., 2001) indicated that an SVS display could significantly enhance SA in both an operationally\nchallenging environment (multiple runways and taxiways at DFW) and a terrain-challenged environment\n(at AVL). The SVS retrofit approach was evaluated and initially validated for typical nighttime airline\n\n6\n\noperations at DFW International Airport in September 2000. Overall, 6 evaluation pilots performed 75\nresearch approaches accumulating 18 hours of flight time evaluating SVS display concepts using the\nNASA Langley Research Center\xe2\x80\x99s Airborne Research Integrated Experimental System (ARIES) Boeing\nB-757-200 aircraft. The SVS HDD concepts evaluated included variations in display size, with pilotselectable FOV, and in methods of terrain texturing. SVS HUD concept evaluations also included\nvariations in the method of terrain texturing. Two types of terrain texturing were employed: photorealistic texturing and elevation-based color-coded texturing (also referred to as generic texturing).\nResults (Glaab et al., 2003) indicated that effective applications of SVS display technology can be\naccomplished in aircraft equipped with HDDs as small as Size A (5.25 in. wide by 5 in. tall) using pilotselectable FOV. All pilots acknowledged the enhanced situation awareness provided by all of the SVS\n(HDD and HUD) concepts. Regardless of display size, pilots selected HDD FOVs of approximately 50\ndegrees, or higher, during initial approach segments, such as on downwind and base legs, and consistently\nreduced the selected FOV to approximately 30 degrees, or less, for low final approach segments. Display\nsize, selected FOV, and minification are correlated. Therefore, the selected FOV/phase-of-flight result\nabove can be expressed in another way - as range to touchdown decreased, the minification factor moved\ntoward unity (i.e., no minification). Also, pilots selected smaller minification factors for the larger-sized\nHDDs regardless of phase-of-flight (as display size increased, the minification factor moved toward\nunity). With these results, pilot-selectable display FOV control became the accepted standard approach to\novercome display size constraint limitations associated with HDDs within the NASA SVS Project.\nThe majority of the pilots participating in the DFW tests preferred the photo-realistic terrain texturing\ntechnique to the generic texturing technique for both HDD and HUD applications. For aircraft without\nraster-capable HDDs, the feasibility of the concept of retrofitting SVS display technology with HUDs was\nverified for nighttime operations by results demonstrating effective SVS presentation on this type of\ndisplay device. Pilots also commented that presentation of SVS imagery on the HUD (with a minification\nfactor of unity - i.e., no minification) was not only acceptable, but actually preferred, over the HDDs. The\ntop-level results of the DFW flight test concerning the enhanced situation awareness provided by all of\nthe SVS (HDD and HUD) concepts, regardless of display size, are highly significant. These results\nfirmly established the SVS retrofit concept approach as viable, at least in the benign terrain environment\nof DFW in nighttime operations.\n\nCurrent Study\nThe results of previous research have documented the unquestionable promise of SVS to enhance\nsituation awareness and improve aviation safety during approaches to terrain- (e.g., 1999 AVL\ndemonstration; Comstock et al., 2001; Stark et al., 2001) and operationally-complex (e.g., 2000 DFW\nflight test) airports. The DFW flight test showed that all SVS display concepts provided precise path\ncontrol and significantly improved spatial awareness for approaches to the DFW airport under nighttime\nconditions. However, although the fixed-based simulator results had provided convincing data on the\nefficacy of SVS for terrain-challenged environments, these results had yet to be replicated and validated\nunder operational conditions like that conducted at DFW in 2000. In 1999, a flight test / demonstration\nwas conducted using the SVS technology to make approaches to AVL airport, but no empirical data was\ncollected to substantiate the claims that SVS was effective in terrain-challenged environments. Therefore,\nthe Aviation Safety Program and SVS Project conducted research flight operations at Vail, CO to further\nexamine the utility, capabilities, and potential of SVS to enhance situation awareness and improve pilot\nperformance for complex approaches in mountainous environments. This paper documents that flight test\nexperiment.\n\n7\n\nGoals and Objectives\nThe goal of the flight test conducted at EGE was to extend the assessment of the SVS retrofit approach\nto operations in a terrain-challenged operational environment with testing in daytime conditions. EGE\nrepresented an ideal location to test the effectiveness of SVS technologies for terrain awareness and\nseparation for approaches and departures that put the aircraft close to mountainous terrain.\nSVS Display Concepts\nSix NASA SVS tactical display configurations were evaluated. These configurations were obtained\nby presenting SVS terrain databases of two terrain texturing types (generic or photo-realistic) on three\ndisplays: a HUD and two HDD sizes (A or X).\nTerrain Texturing Types. Terrain-texturing refers to the method used to fill the polygons that\ncomprise the rendered terrain database. The two texturing concepts tested were elevation-based colorcoding, or generic, and photo-realistic. The generic texturing concept consisted of applying equal-height\ncoloring bands that correspond to different absolute terrain elevation levels, similar to the colors\nemployed for Visual Flight Rules sectional charts. Lower terrain levels were colored with darker colors,\nwhile higher terrain levels were assigned lighter colors. A certain shade of green was set to the field\nelevation. The photo-realistic texturing was derived from full color ortho-rectified aerial photographs.\nThe resulting scene was a highly realistic view due to the photographic imagery employed.\nHUD Concept. As mentioned previously, the NASA SVS Project is investigating the potential of\nHUD technology as a retrofit solution for display of terrain database SVS concepts in non-glass cockpits.\nAs such, the HUD is used in a manner not traditionally employed in commercial aircraft operations. The\nSVS terrain database scene is presented on the HUD as a raster image with stroke symbology overlaid\nupon it. This concept for a SVS-HUD is similar to enhanced vision system (EVS) concepts, which\ntypically use advanced imaging sensors to penetrate weather phenomena such as darkness, fog, haze, rain,\nand/or snow, and the resulting enhanced scene is presented on a HUD, through which the outside real\nworld may be visible. (The FAA has just recently certified an infrared EVS for use on a business\naircraft.) In the SVS-HUD concept, the terrain database scene is displayed instead of the sensor EVS\nimage. Unlike EVS displays, the SVS-HUD concept maintains a \xe2\x80\x9cclear sky\xe2\x80\x9d so there is no obstruction of\nthat area of the display. (This is in contrast to an EVS image which displays a sensor image of the sky.)\nBelow the horizon, the terrain raster image can obstruct the view of the outside real world, just as an EVS\ndisplay can, particularly if the raster brightness is not appropriately controlled by the pilot. Obstruction of\nthe outside real world scene by such a display is a recognized certification issue and a rapid means of\ndecluttering the SVS imagery from the HUD was provided to the evaluation pilot. In addition to the\nraster, nominal flight information symbology characteristic of most airline HUDs was overlaid on the\nHUD imagery.\nHDD Tactical Display Sizes. Two different SVS-HDD configurations were evaluated during this\nflight test to explore retrofit concepts of SVS display technology into existing glass cockpits (cockpits\nalready equipped with raster-capable HDDs). One display configuration, referred to as the SVS Size A\n(5.25 in. wide by 5 in. tall), was similar to a B-757-200 electronic attitude direction indicator (EADI) with\nseparate airspeed, altitude, and vertical speed gauges, with the addition of SVS information. The second\nHDD configuration, referred to as Size X (9 in. wide by 8 in. tall), featured an enlargement of an\nintegrated Primary Flight Display (PFD) to replicate future SVS HDD concepts. Evaluation pilots could\ncontrol the FOV of the HDD EADI and PFD concepts evaluated to enhance display effectiveness. A\nconventional Size A EADI HDD configuration with no SVS information was also provided as a baseline\n\n8\n\nfor comparison purposes. Terrain information was available on the Navigation Display (ND) (4.75 in.\nwide by 6 in. tall) for all of the concepts.\nThe objectives of the flight test were to:\na) Confirm potential of NASA SVS HUD concept as a retrofit solution for display of SVS\nconcepts in non-glass cockpits. Determine potential in both day VMC and in day, lowvisibility operational environments.\nb) Confirm results from piloted simulation experiments and SVS-DFW flight test for operational\nutility and acceptability of various-sized (Size A, X) head-down synthetic vision displays.\nc) Compare operational utility and acceptability of photo-realistic textured with generic textured\nterrain databases within NASA SVS concepts (HUD; head-down Size A, X).\nd) Assess pilot path control performance (flight technical error) during manually flown landing\napproach and go-around maneuvers in a terrain-challenged operational environment, with and\nwithout SVS display concepts.\ne) Determine required navigation performance capabilities of SVS for area navigation.\nf) Confirm the situation awareness and workload benefits of SVS display concepts.\ng) Provide demonstration of economic potential of SVS for approaches that have significant\nrestrictions for current operations.\n\nHypotheses\nThe a priori hypotheses (based on prior SVS research) for the flight test evaluations included:\nObjective Data Hypotheses\na) All SVS display concepts would have lower flight technical error (FTE) compared to a\nBaseline EADI/ND.\nb) Pilots would have lower FTE with the SVS HUD concepts than with the Size X display\nconcepts.\nc) Pilots would have lower FTE with the Size X displays than with the smaller Size A SVS\ndisplays.\nd) Pilots would have lower FTE with the photo-realistic texture concepts.\nSubjective Data Hypotheses\ne) Pilots would prefer all SVS display concepts over the Baseline EADI/ND.\nf) Pilots would prefer the HUD over the Size X display concepts.\ng) Pilots would prefer the Size X display concepts to the smaller Size A SVS display concepts.\nh) All SVS display concepts would be rated higher in situation awareness than the Baseline\nEADI/ND.\ni)\n\nPilots would rate the Size X display concepts significantly higher in terms of situation\nawareness than the Size A SVS display concepts.\n\n9\n\nj)\n\nThere would be an interaction found between display size and texture for situation awareness\nratings. For example, photo-realistic texture would be judged to be much more effective than\ngeneric texturing on the HUD than on Size A, where texturing effects would be much less\nimportant.\n\nk) Pilots would rate the photo-realistic texture concept significantly higher in terms of situation\nawareness than the generic texture concept for both HDD and HUD display concepts.\nl)\n\nWorkload ratings would be significantly lower for all SVS display concepts compared to the\nBaseline EADI/ND.\n\nm) Workload ratings would be significantly lower for the HUD compared to the Size X display\nconcepts.\nn) Workload ratings would be significantly lower for the Size X compared to the Size A SVS\ndisplay concepts.\no) Workload ratings would be significantly lower for the Size A SVS display concepts compared\nto the Baseline EADI/ND.\n\nMethod\nSubjects\nSix evaluation pilots, representing three airlines, FAA and Boeing, flew 12 research flights totaling\n51.6 flight hours. Eighty-four data flight test runs were conducted to evaluate the NASA display concepts\nwith forty-nine being flown to Runway 07 and thirty-five flown to Runway 25. All participants were\nrated B-757 captains with operating experience at EGE. The currency and degree of actual experience at\nEGE prior to the test varied but was not considered to be a significant factor since, prior to deployment,\nall evaluation pilots received a one-day training course (briefing and simulator session) at NASA LaRC.\nThis training was to familiarize them with the SVS display concepts as well as provide sufficient training\nin the approach procedures and tasks to create a consistent level of knowledge and experience for EGE\noperations.\n\nSimulator and Flight Test Vehicle\nAircraft. The flight test was conducted in an operationally realistic, terrain-challenged\nenvironment using the NASA LaRC Boeing 757 (B-757) ARIES aircraft to compare SVS display\nconcepts to a Baseline EADI and navigation display (ND) which included a simulated TAWS. The left\nseat in the Boeing 757 was occupied by the Evaluation Pilot (EP). This position, with its associated\ndisplays and controls, is used for research testing and is known as the Flight Deck Research System\n(FDRS). The right seat was occupied by a NASA Safety Pilot (SP). The left seat included the installation\nof an SVS Research Display (SVS-RD) and an overhead HUD projection unit (see fig. 1). A vision\nrestriction device (VRD) (fig. 2) was placed in the left-seat forward windscreen to block the EP\xe2\x80\x99s forward\nvision and thus simulate IMC when needed experimentally.\n\n10\n\nSVS-RD\n\nFigure 1. SVS-RD installed in ARIES 757 aircraft.\n\nFigure 2. Vision Restriction Device in ARIES 757 aircraft.\n\nSVS-RD. The SVS-RD was a Commercial Off-the-Shelf 18.1 in. diagonal high brightness\nLiquid Crystal Display monitor, modified for installation over the forward instrument panel\ncluster on the left hand side of the ARIES cockpit (see fig. 1). Since the SVS-RD was capable of\ngenerating high resolution, multi-sized displays, this monitor displayed all head-down display\nconcepts for evaluation. The SVS-RD covered the normal Boeing 757 captain\xe2\x80\x99s displays with\nthe exception of the analog standby instruments (attitude direction indicator, airspeed, and\naltitude). The SVS-RD had 1280 vertical x 1024 horizontal pixel resolution (approximately 90\npixels per inch) with 900 nits brightness for reasonable sunlight readability in the Boeing 757\naircraft. Overall, the SVS-RD weighed approximately 16 lbs.\nField of View Control. FOV control for the NASA HDD SVS concepts was available to the\npilot on a four-position wafer switch on a conveniently located center console panel. The FOV options\n\n11\n\nwere: Unity, 30\xc2\xba, 60\xc2\xba, and 90\xc2\xba. The FOV provided at the \xe2\x80\x9dunity\xe2\x80\x9d setting changed depending upon the size\nof the experimental HDD condition being flown.\nSynthetic Vision Systems Graphic Engine (SVS-GE). The NASA SVS display concepts were\ngenerated by two Intergraph Zx10 personal computers using Windows NT \xe2\x84\xa2. The Zx10 used for this\nflight test was a dual 866 MHz Pentium III processor with 1+ Gigabytes of Random Access Memory.\nThe video card used was a 3D Labs, Inc. Wildcat\xe2\x84\xa2 4210 which provided 1280x1024 resolution at 60\nHertz (Hz) anti-aliased (SuperScene \xe2\x84\xa2 enabled) video rendering at real-time (>30 Hz) update rates.\nSymbology was generated using the OpenGL application programming language. SXGA (1280x1024\npixels, 60 Hz non-interlaced) format video output from the Zx10 computer drove the SVS-RD. For the\nHUD raster channel, an XGA (1024x768 pixels) image from the Zx10 was scan converted to RS-343\n(875 line, 30 Hz interlaced) format video via a Folsom 2100 scan conversion unit.\n\xef\xa3\xa8\n\nHead-Up Display. The left-seat, overhead Dassault projection HUD was interfaced with a\nresearch Flight Dynamics Head-Up Guidance System (HGS)-4000 computer. The HGS-4000 was\nmodified by NASA to conduct research on certain HUD configurations. The HGS-4000 could be placed\nin a "Normal" mode, which triggered the HGS-4000 to function with its nominal commercial\nfunctionality, or in a \xe2\x80\x9cResearch\xe2\x80\x9d mode. For this flight test, the HGS-4000 was operated in the \xe2\x80\x9cResearch\xe2\x80\x9d\nmode which triggered the HGS-4000 to include some special purpose symbology, as described below.\n\xef\xa3\xa8\n\nThe HGS-4000 computer is stroke-on-raster capable using an RS-343 raster video format input. The\nHGS-4000 raster input consisted of the synthetic vision (SV) terrain and tunnel symbology while\nretaining high-quality stroke symbology for primary flight information (e.g., airspeed, altitude). The\nHGS-4000 \xe2\x80\x9cPrimary Mode\xe2\x80\x9d stroke symbology set was used in the flight test, albeit with the compass rose\nsymbol set removed when in \xe2\x80\x9cResearch\xe2\x80\x9d mode. The raster image consisted of \xe2\x80\x9clayers\xe2\x80\x9d of imagery and\nsymbology (see fig. 3). Synthetic terrain imagery formed the \xe2\x80\x9cBackground Raster\xe2\x80\x9d. Guidance\nsymbology and tunnel (\xe2\x80\x9cPathway-in-the-Sky\xe2\x80\x9d) symbology were combined to create the \xe2\x80\x9cForeground\nRaster\xe2\x80\x9d. The FOV of the ARIES HUD was measured to be 22o vertical by 28o horizontal. Note that to\nmaintain conformality with the outside world, the FOV for the HUD raster image was fixed and could not\nbe varied by the EP. As the minification/magnification factor was thus unity, the condition was\ncolloquially known as unity FOV.\nBrightness and contrast controls were provided: a) Stroke-only brightness; b) Overall raster image\nbrightness; c) Background raster (synthetic terrain imagery) contrast; d) Background raster brightness;\nand e) Foreground raster (guidance and tunnel symbology) brightness. Although somewhat complex,\nthese controls gave the EP the needed flexibility to tailor the image.\nA HUD declutter button was available on the control yoke. The declutter button cycled the HUD\nsymbology between four modes: 1) No declutter \xe2\x80\x93 All display elements present; 2) Foreground raster\n(raster guidance symbology & tunnel) removed; 3) All HUD raster removed; and, 4) All display elements\n(both stroke and raster) removed.\n\n12\n\nStroke Symbology\n\nStroke-On-Raster HUD\n\nRaster Image\n\nPathway / Tunnel\nRaster Symbology\n(\xe2\x80\x9cForeground Raster\xe2\x80\x9d)\nSynthetic Terrain\n(\xe2\x80\x9cBackgroun d Raster\xe2\x80\x9d)\n\nFigure 3. HUD stroke-on-raster imagery components.\n\nGround-based facilities\nFlight Systems Integration Lab (FSIL). The Flight Systems Integration Lab (FSIL) at NASA\nLaRC was used to validate the experimental systems. By simulating the aircraft systems in flight\nconditions, data passing through the network devices was monitored, verifying that the test system and\ndata collection was functioning properly. Evaluations in the FSIL environment were used to establish\nsatisfactory performance of the HGS-4000 system. Satisfactory performance was defined as the ability to\ndraw flight guidance symbology and raster imagery, provided by the SVS computers and forward-looking\ninfra-red (FLIR) cameras, on the HUD combiner glass.\nIntegration Flight Deck (IFD). The Integration Flight Deck (IFD) at NASA LaRC was used to\ndevelop and evaluate key hardware and software components, as well as provide familiarization and\ntraining for the flight crew prior to the EGE deployment. The IFD is a simulation facility which emulates\nthe ARIES research cockpit. The IFD has the same pilot controls as ARIES. Other significant features of\nthe IFD are the 6-degrees of freedom B-757 simulation model, mode control panel, and realistic\nreplication of the FDRS. It also includes a representative ARIES Boeing 757 Flight Management System\n(FMS), which contains the published routes to EGE (i.e., the FMS approaches, departures, and missed\napproaches), and pilot-FMS interface controls simulation, including autoflight systems.\n\nEvaluation Tasks\nIn general, flight-test operations involved established operational maneuvers employed by airlines\noperating at EGE. The base of operations for deployment was Colorado Springs (COS) municipal airport,\nlocated approximately 115 nm from EGE. COS provided minimal operational restrictions due to air\ntraffic, and easy access to aircraft and personnel support facilities. All of the checkout and research flight\n\n13\n\nactivities occurred at EGE (see fig. 4).\n\nFigure 4. Diagram of Eagle-Vail regional airport.\n\nAlthough EGE has received a \xe2\x80\x9cSpecial Airport\xe2\x80\x9d designation from the FAA, approach and landing\nprocedures are not atypical of many airports constrained by terrain in all quadrants. Precision approach\nlanding aides are not available due to the terrain. EGE is only equipped with an offset localizer with\nDistance Measuring Equipment (DME) (~1 degree offset from the runway heading) to support LocalizerDME Approach (LDA) procedures which includes several altitude step-downs. Visual arrivals to both\nEGE runways (07 and 25) are commenced from the East using an LDA procedure. See figures 5 and 6\nfor photographs of the approach ends of the EGE runways.\n\n14\n\nFigure 5. Runway 25 at Eagle-Vail Regional Airport\n\nFigure 6. Runway 07 at Eagle-Vail Regional Airport\n\nTo facilitate larger commercial airline operations, such as Boeing 757 aircraft, and obtain lower\ninstrument approach minima, FMS-based approach and landing procedures have been developed and\ncertified for EGE. These procedures also specify training and equipment standards that are well above\nthat required for the FAA-published EGE instrument approach and landing procedures.\nThe evaluation tasks were developed by tailoring existing FAA-approved FMS-based approach and\ndeparture procedures for EGE. The tailoring defined procedures and constraints which aided in\n\n15\n\nexperimental data collection and subsequent data analysis. Two approaches and associated departure\ntasks were flown during day VMC. (See figures 7 and 8.)\nFMS Runway 25 Approach and Cottonwood-2 Departure ("FMS25"). The FMS25 task started\non a dogleg to the final approach course, level at 13,100 ft MSL (step C in fig. 7). At the waypoint\nTALIA, approximately 16 nm from the airfield \xe2\x80\x93 the final approach fix \xe2\x80\x93 the turn to the localizer\napproach course was made and the descent into the EGE local operating area was initiated. The initial\ndescent angle from TALIA was nominally 4.43 degrees. Several descent angle changes were commanded\nuntil approximately 1000 ft Above Field Level (AFL), where the guidance directed a 3 degree descent to\nthe runway touchdown zone. A go-around was declared before 200 ft Above Ground Level (AGL) and\nthe NASA SP took over control of the 757 from the EP (step I in fig. 7). The subsequent missed approach\nwas, in fact, tailored to mirror a \xe2\x80\x9cworse-case\xe2\x80\x9d terrain-clearance departure; hence, the wording \xe2\x80\x9cmissed\napproach\xe2\x80\x9d and \xe2\x80\x9cdeparture\xe2\x80\x9d are often interchanged throughout this document, yet they apply to the same\ntask. After the go-around call, the SP performed a level-off, flew at a constant AGL over the runway, and\nreconfigured the aircraft for the climb-out. At approximately mid-field, a left turn (step J in fig. 7) was\nmade to pick up the nominal FMS-departure path (the Cottonwood-2 departure) - well before the\ndeparture end of the runway to ensure clearance from Snow Mountain \xe2\x80\x93 an 1800 ft AFL peak\napproximately two nautical miles (nmi) from EGE. After the departure turn, the EP was given control of\nthe aircraft and flew the Cottonwood-2 departure task. A reduced climb angle departure, loosely\nreplicating the climb of a moderately loaded 757 in a single engine condition, was flown. The simulated\nsingle engine departure provided a worst-case operational scenario but a best-case condition for terrain\nawareness testing. The simulated single-engine Cottonwood-2 departure required a turn at Waypoint\nF219G (step L in fig. 7) to maintain terrain and obstacle clearance along Cottonwood Pass. The departure\nconcluded upon reaching 10,000 ft MSL which typically occurred just prior to Waypoint F204K (step M\nin fig. 7). No departure tunnel was provided, and the EP flew conventional lateral path and speed-onpitch guidance symbology for all display concepts.\nVisual Arrival to Runway 07 and KREMM Departure ("Visual 07"). The Runway 07 approach\ntask started with the same FMS25 approach procedure. At approximately 5.3 nmi DME (step G1 in fig.\n8), a level off at 8100 ft MSL was commanded followed by an approximate 20 degree left turn (step H1)\ninto a modified downwind leg. When about abeam the Runway 07 end, a descending right turn was\nflown for landing. For this flight test, a go-around was declared before 200 ft AGL and executed by the\nNASA SP. After the go-around call (step L1 in fig. 8), the SP took over control of the 757, performed a\nlevel-off and reconfigured the aircraft for the climb-out. Near the departure end of the runway, the task,\nfollowing the published KREMM departure procedure, called for an initial left turn to a 050 heading (step\nM1 in fig. 8). After the departure turn, the EP was given control of the aircraft and flew the remainder of\nthe departure task (where, again, the terminology \xe2\x80\x9cmissed approach\xe2\x80\x9d and \xe2\x80\x9cdeparture\xe2\x80\x9d may be\ninterchanged, yet they relate to this same task). A reduced climb angle departure was again established to\nprovide a best-case testing condition. A 050 heading was held until intercepting the 059 radial from the\nSnow VOR (Very high frequency Omni-direction Radio) beacon. The run ended upon climbing along the\n059 radial through 10,000 ft Mean Sea Level (MSL) (step Q1 in fig. 8). No departure tunnel was\nprovided, and the EP flew conventional lateral path and speed-on-pitch guidance symbology for all\ndisplay concepts.\n\n16\n\nFMS 25 Approach\nCottonwood-2 Departure\n\nFlight Director (F/D) active throughout\n\nA\n\nCottonwood-2\n\nLDA25\n\n(simulated single engine)\n\nA) Prior To Run\nEstablish Experimental Conditions\nSafety-of-Flight Metrics Cross-Check\nB) Outbound RLG on 184\xc2\xba Radial\nB\nNo Data Being Taken\nSim IMC If Used\nRLG\nEP Gets Airplane\nSterile Cockpit Commences\nBegin descent to ensure\nF058R End-Pt Condition\n184\n\xc2\xba\n\n(IAF)\n\nJESIE\n\n13 10\n0\xe2\x80\x99\n\nRW25\nF247A\nSXW\n5\xc2\xba\n21\n\nC\n\nF058R\n\nF222C\nD4.5\xc2\xba\nRW25\n\nSXW\n\nM\n\n251\xc2\xba\n\n(IEGE)\n\nTALIA\n\nF219G\n182\xc2\xba\n\nI) 150 ft AFL\nDeclare Missed Approach\nA/T Disengage\nSP Sets Thrust &\nControls Aircraft\nClimb\n\nF204K\n\nD\n\n182\xc2\xba\n\nM) Before F204K\n>10.0K MSL\n\xe2\x80\x9cRT DIR JESSIE\xe2\x80\x9d\nData Off\nEnd Data Collection\nTurn to Jesie/RLG\nSterile Cockpit Ends\nCommentary/Rating\nData Taken\n\n5\xc2\xba\n21\nF222C\nF219G\n\nI\n\nC) At F058R\nStart of Tunnel, If Used\n190 KIAS\nLevel at 13.1K MSL\nData On\nD) Passing F058R\nConfigure for Landing\nNull F/D Commands\n(Maintain Course)\n(Maintain 13.1K MSL)\n\nF204K\n\nE\nL\n\nJ\n\nL) At F219G D6.4\nIf < 10K ft\nContinue Climb\nTurn left to 182\xc2\xba\n\nG\n\nJ) IEGE D0.2\nTurn left to 215\xc2\xba\n\nK\n\nE) Prior to Talia\nBegin turn to\n251\xc2\xb0\n\nH\n\nK) At F247A\nNull F/D\n(Maintain Course & Climb)\n\nH) 200 Ft AFL\nPath turns left\nto 250\xc2\xba To Align\nwith Runway\n\nG) IEGE D4.5\n\xe2\x80\xa2Safety Pilot CheckPt\nDA (H) Reqrd\nParameters:\n\xe2\x80\xa2Stabilized Approach\n\xe2\x80\xa2V-Path within 100 ft\n\xe2\x80\xa2Loc Dev < 1/3 Dot\n\nF\nF) Passing Talia\nNull F/D Commands\nBegin 4.43\xc2\xb0 descent\n(Maintain Loc, Course &\nDescent)\n\nFigure 7. FMS Runway 25 Approach and Cottonwood-2 Departure\n\nVisual 07\n\nKREMM Departure\nVisual 07 Identical To FMS 25 Through\nPoint F, So Task Details Start at G1\n\nQ1\n\nRLG\n\n71\xc2\xba\nR-171\n\n4.0D IE\n\nGE\n\nR-059\xc2\xba\n\nSXW\n\nSXW\n\nK1\nK1) At 200 ft AFL\n\nH1\n\nJ1\nJ1) Roll-Out On Final\nI1\n\nI1) On Circle\nNull F/D Commands\n(Descending Turning\nPath)\n\nO1\n\nG1 G1) IEGE D5.32\nHalt descent at 8100\xe2\x80\x99\nNull F/D Commands\n(Maintain Altitude &\nPath)\n\nH1) IEGE D4.0\nTurn left to 220\xc2\xba\nNull F/D Commands\n(Maintain Altitude &\nPath)\n\nP1) R-171\xc2\xba RLG\nContinue climb,\nP1 Intercept RLG 171 \xc2\xba radial\nTurn left to RLG\n\nSXW\n050\xc2\xba\nHdg\n\nFL\n\xe2\x80\x99A\n00\n15\n0\xc2\xba\n22\n\nQ1) On R-171\xc2\xba RLG\n>10.0K MSL\nData Off\n\nO1) R-059\xc2\xba SXW\nContinue climb, \xe2\x80\x9cHDG 050 \xe2\x80\x9c\nIntercept 059\xc2\xba SXW radial\n\nL1\nN1\nL1) 150 ft AGL\nN1) On Course\nDeclare Missed Approach\nMaintain Course &\nA/T Disengage\nClimb\nOverfly runway\nM1\nSP Set Thrust\nClimb\nM1) Positive Rate-of-Climb\nNo Tunnel Guidance Avail\n\xe2\x80\x9cCLB 14K, HDG 050\xe2\x80\x9d\nUse >15, <25 deg Bank\nNull F/D Commands\n\nFlight Director (F/D)\nactive throughout\n\nFigure 8. Visual Arrival to Runway 07 and KREMM Departure\n\n17\n\nTerrain Database\nThe terrain databases used for this experiment were 95 nmi by 95 nmi in area, centered at the EGE\nairport. Jeppesen provided the source elevation data for the EGE databases based on United States\nGeological Survey (USGS) National Elevation Dataset (NED). The delivered elevation data was 1arcsecond (30 meter) in Digital Elevation Model (DEM) format, with a Universal Transverse Mercator\n(UTM) WGS84 projection and covered a 100 nmi square geographic area centered about EGE. The\naccuracy of the source data was within 12 meters (90% of data) horizontal and 7 meters (90% of data)\nvertical. From this DEM, four real-time rendering databases were created (see fig. 9): SVS-HDD full\ncolor elevation-based (generic) textured, SVS-HDD full color photo-realistic textured, SVS-HUD\nmonochrome green elevation-based (generic) textured, and SVS-HUD monochrome green photo-realistic\ntextured. The monochrome databases were created because the HUD is monochrome. The monochrome\ndatabases were designed specifically for the monochrome HUD to ensure proper rendering (i.e., no holes\nin database due to lack of green color). Each EGE terrain database was built using the Terrain Experts,\nInc (Terrex) TerraVista Pro\xe2\x84\xa2 software. The SV terrain databases were written to a UTM Terrex\nTerraPage\xe2\x84\xa2 format and rendered using CG2 VTree.\xe2\x84\xa2 An EGE airport model was created using\nMultigen\xe2\x84\xa2 Creator modeling software and placed into the SV database.\n\nColor Photo-realistic\n\nColor Generic\n\nGreen Photo-realistic\n\nGreen Generic\n\nFigure 9. Four databases with symbology overlays used for the experiment.\n\nTo create the full color photo-realistic terrain database, multi-resolution aerial imagery (geotiff ranging\n\n18\n\nfrom 2 to 16 meters/pixel) was overlaid on the DEM database. The source data included three image sets\nof 1, 4, and 16 meter resolution (see table 2). The final TerraPage\xe2\x84\xa2 database was created from the\nsource data (table 3) after a rendering trade off study. The trade off study maximized the amount of\ntexturing to be rendered (most photo-realistic) while maintaining a 30 Hz update frame rate. A significant\neffort was made to color balance the various aerial images to produce a non-tiled, single brightness and\ncontrast database appearance. To create the monochrome green photo-realistic database, full color aerial\nphotographs were converted to a single green color using a freeware image-editing tool, ImageMagick.\nTable 2. Photo-realistic Image Sources\nImage resolution\n\nProvider\n\nFormat\n\n1-meter per pixel\n\nNGS\n\nWGS84 UTM Zone 13\n\n4-meter per pixel\n\nImageLinks\n\ngeotiff WGS84 UTM Zone 13\n\n16-meter per pixel\n\nImageLinks\n\ngeotiff WGS84 UTM Zone 13\n\nArea Coverage\n(centered on EGE)\n17.2 nmi (east/west) by\n6.8 nmi (north/south)\n29.7 nmi (east/west) by\n32 nmi (north/south)\n104.2 nmi (east/west) by\n104.2 nmi (north/south)\n\nTable 3. Final TerraPage Database Created from Source Data\nImage Resolution\n2-meter per pixel\n4-meter per pixel\n16-meter per pixel\n\nCoverage\n2.1 nm by 0.7 nm\n25 nm by 25 nm\n95 nm by 95 nm\n\nTo create the generic textured terrain database, a color mapping technique (i.e., \xe2\x80\x9celevation shading\xe2\x80\x9d)\nwas developed. The color scheme was based on Aeronautical Chart legends with slight modification to\nshow more contrast over the elevation range in the database. The colors ranged from greens at the field\nelevation of EGE, to browns, to light tans, to off-white, with the greens representing the lower elevations\nbands, and the off-white representing the highest elevation band. Twelve bands were used, segmented\ninto 250 meter ranges. To create the monochrome green generic database, shades of green were used to\nrepresent elevation changes. The green color intensities associated with each elevation level varied in an\nincremental fashion from the lowest to highest level. Thus, no two elevation levels had the same green\nvalue. Main cultural features, such as railroads, roads, lakes, and rivers, were placed in the generic\ntextured terrain databases.\nDisplay Concepts\nThe flight test was designed as a comparative study against a baseline condition. The Baseline was\nrepresentative of the current display configuration being flown in regular airline service to EGE \xe2\x80\x93 the\nBoeing 757 EADI format with a TAWS-capability installed on the Navigation Display. The TAWS aural\nalerts were not implemented, as continual aural alert conditions were anticipated. In the actual test\nconditions, even the ship\xe2\x80\x99s conventional Ground Proximity Warning System aural alerts had to be\ndisabled.\nThe Baseline display (fig. 10) was rendered on the SVS-RD. As evident in Figure 10, the Baseline\nEADI was intentionally not a direct replication of the Boeing 757 EADI but instead, was a blue-overbrown representation of the NASA SVS concepts. The intent was to keep the display\xe2\x80\x99s symbolic\ninformation constant (e.g., pitch ladder) in the comparison across display concepts to avoid additional\n\n19\n\nvariability. Also note that the ND is not directly below the EADI. The ND was offset because the control\nyoke blocked the view of the display directly below the EADI. The TAWS ND display format was\nconstant across all concepts.\nSix NASA SVS concept display configurations were evaluated (SVS-HUD, SVS-HDD Size A, and\nSVS-HDD Size X, each with generic and photo-realistic terrain). A comparison of these displays (figs.\n11-15) with Figure 10 \xe2\x80\x93 the Baseline display configuration \xe2\x80\x93 shows the intuitive nature of the SVS\ndisplay portrayal for terrain awareness. The HUD concepts utilized the Baseline concept head down,\nalong with the TAWS ND.\nIn addition to terrain texture differences, several important symbology differences were embedded in\nthe SVS configurations. These symbology differences did not influence the terrain awareness properties\nof the display configuration evaluation but did influence the pilot\xe2\x80\x99s ability to precisely monitor and\ncontrol the aircraft. These differences include the airspeed and altitude format (e.g., \xe2\x80\x9cround-dials\xe2\x80\x9d on the\nBaseline and Size A concepts versus \xe2\x80\x9ctapes\xe2\x80\x9d on the Size X and HUD concepts), the presence (on SVS\nconcepts) or absence (on Baseline) of a flight path marker (also referred to as the velocity vector), and the\npresence (on SVS concepts) or absence (on Baseline) of tunnel or \xe2\x80\x9cpathway-in-the-sky\xe2\x80\x9d information. It\nshould be noted that raw data (path) indicators were provided on the glideslope and localizer deviation\nscales for all the display concepts (Baseline and SVS). These raw data indicators are referred to as\n\xe2\x80\x9cdogbone\xe2\x80\x9d indicators (see fig. 16).\nA tunnel was nominally drawn for approach guidance on the SVS-HUD and SVS-HDD (but not for\nthe Baseline display condition) to increase the pilot\xe2\x80\x99s awareness of the desired aircraft trajectory. The\nobjective was to create path awareness yet not to obscure or occlude the terrain portrayal of the Synthetic\nVision image. With this objective, a \xe2\x80\x9cminimalist\xe2\x80\x9d tunnel was constructed using \xe2\x80\x9ccrow\xe2\x80\x99s feet\xe2\x80\x9d and \xe2\x80\x9cgoal\nposts\xe2\x80\x9d (see fig. 17). The crow\xe2\x80\x99s feet represented the truncated corners of nominally-connected 2dimensional rectangles spaced at 0.2 nm increments along the desired path. The top crow\xe2\x80\x99s feet of the\ntunnel were only displayed up to 1.0 nm in front of the aircraft. The bottom crow\xe2\x80\x99s feet were linearly\ndecreased in brightness so, by 3.0 nm from own-ship, the brightness of the bottom crow\xe2\x80\x99s feet was\nreduced to zero. The goal posts were vertical lines anchored to the ground and were spaced at 1.0 nm\nincrements along the desired path (also decreased in brightness, disappearing by 3.0 nm).\nAdditional guidance information for the SVS display concepts was provided by a ghost airplane\nsymbol (see fig. 18). The ghost airplane was positioned by a modified form of pursuit guidance,\ndocumented in Merrick (1995), to keep the aircraft trajectory tracking the tunnel. Placing the flight path\nmarker on the beacon of the ghost aircraft symbol guided the EP to the desired flight path. During the\nmissed approach tasks, the tunnel and ghost aircraft were removed and a single cue flight director based\non the ship\xe2\x80\x99s FMS was drawn to provide speed-on-pitch and roll steering commands (also presented on\nthe Baseline EADI).\nBecause of difficulties encountered with the ship systems\xe2\x80\x99 FMS and flight director, approach guidance\nfor the Baseline Concept varied according to Task. For the FMS 25 approach task, flight director\nguidance was provided on conventional dual cue flight director needles. For the Visual 07 approach task,\nno flight director guidance was available, and the pilots resorted to the raw lateral and vertical path\ndeviation indicators (dogbones).\n\n20\n\nFigure 10. Baseline display, EADI with TAWS on ND.\n\nFigure 11. Size A with photo-realistic texturing.\n\n21\n\nFigure 12. Size A with generic texturing.\n\nFigure 13. Size X with photo-realistic texturing.\n\n22\n\nFigure 14. Size X with generic texturing.\n\nFigure 15. Head-Up Display with generic texturing\n\n23\n\nVertical path\n(raw data)\nindicator\n\nLateral path (raw data) indicator\nFigure 16. Raw data indicators for the Baseline and SVS concepts.\n\nCrow\xe2\x80\x99s Feet\n\nGoal Post\n\nFigure 17. Crow\xe2\x80\x99s feet and goal post in the Synthetic Vision tunnel\n\n24\n\nFlight Path Marker\n\nGhost aircraft\n\nFigure 18. Ghost aircraft symbol\n\nExperiment Design\nA full-factorial experimental matrix design was established to evaluate the six NASA SVS display\nconcepts (SVS-HUD, SVS-HDD Size A, and SVS-HDD Size X, each with generic and photo-realistic\nterrain) and the Baseline display condition in each of the two approach and departure tasks. Evaluations\nwere flown under simulated instrument meteorological conditions using a VRD.\nIndependent Variables\nFor the full-factorial experiment, the independent variables were display type (HUD, Size A, Size X,\nEADI), terrain texturing method (photo-realistic, generic), and evaluation task (Visual 07, FMS25).\nDependent Measures for the Objective Data Analyses\nEngineering unit data was collected on all evaluations. The approach and departure paths for the\ntwo flying tasks (FMS25 and Visual 07) were analyzed using a flight segment analysis approach (see\ntable 4 and figures 19-20). Flight segments were used since the segments contain well-defined piloting\ntasks in which specific and clear performance expectations were given to the EPs, and control of\nstatistical variability could thus be anticipated. The segment definition and analyses for Segments 1 and 2\nwere identical for both the FMS25 and Visual 07 tasks. The KREMM departure segments out of the\nVisual 07 task were not analyzed because the nature of the task was not conducive to a uniform flight\nconduct. The departure was not path-based (heading-based, rather than ground track) and not all of the\nruns, as actually conducted, used the exact same display configuration and flight director set-up.\nTherefore, analyses of these segments would have been more indicative of these differences than those of\nspecific SVS-design parameters.\n\n25\n\nTable 4. Flight Segment Definitions and Associated Piloting Tasks\nSegment\nNumber\n1\n\nSegment\nDescription\nInbound to\nWaypoint TALIA\n\nAssociated\nFlying Task\nFMS25 &\nVisual 07\n\n2\n\nInitial Approach\n\nFMS25 &\nVisual 07\n\nMaintain a straight course\n(no turns), and intercept\nand maintain the descent\npath\n\n3\n\nFMS25 Final\n\nFMS25\n\nMaintain a straight course\n(no turns) and a 3.0\ndegree descent path\n\n4\n\nCottonwood\nDeparture Initial\nClimbout\nCottonwood\nDeparture Final\nClimbout\nCircle Entry Level\noff\n\nFMS25\n\nNull the flight director for\nthe initial straight\nclimbout\nNull the flight director for\nthe final straight climbout\n\n5\n\n6\n\nFMS25\n\nPiloting Task\n\nGuidance Available\n\nMaintain a straight course\n(no turns) while\nremaining level at an\naltitude of 13,100 feet\nMSL\n\nPath deviation indicators on\nall concepts\nBaseline FMS25: Dual-cue\nflight director\nBaseline Visual 07: No flight\ndirector\nSVS FMS25 & Visual 07:\nTunnel & ghost aircraft\nPath deviation indicators on\nall concepts\nBaseline FMS25: Dual-cue\nflight director\nBaseline Visual 07: No flight\ndirector\nSVS FMS25 & Visual 07:\nTunnel & ghost aircraft\nPath deviation indicators on\nall concepts\nBaseline: Dual-cue flight\ndirector\nSVS: Tunnel & ghost aircraft\nBaseline & SVS: Single-cue\nflight director\n\nVisual 07\n\nLevel off at 8,100 ft MSL\nwhile maintaining a\nstraight course (no turns)\nMaintain altitude while\nexecuting the dogleg left\nturn and then to maintain\na straight and level course\n(no turns)\nIntercept and maintain the\n3.0 degree descent path\nwhile executing the\ncircling right turn to\nrollout on final\n\n7\n\nCircle Dogleg\n\nVisual 07\n\n8\n\nCircling Approach\n\nVisual 07\n\n26\n\nBaseline & SVS: Single-cue\nflight director\nPath deviation indicators on\nall concepts\nBaseline: No flight director\nSVS: Tunnel & ghost aircraft\nPath deviation indicators on\nall concepts\nBaseline: No flight director\nSVS: Tunnel & ghost aircraft\nPath deviation indicators on\nall concepts\nBaseline: No flight director\nSVS: Tunnel & ghost aircraft\n\n184\xc2\xba\n\nF058R\n\nSegment 1\nLevel flight\nat 13,100 feet MSL\n\nSegment 4\n\nD5.32\nIEGE\n\nRW25\n\nInitial Climb\n5\xc2\xba\n21\nF219G\n\nTALIA\n\nSegment 2\nInitial 4.43\xc2\xba descent angle\nfollowed by multiple\ndescent angles\n\nSegment 3\n\n182\xc2\xba\n\nSegment 5\nFinal Climb with\nrun ending\nat 10,000 feet MSL\n\n251\xc2\xba\n\nConstant 3\xc2\xba descent angle\n\nF204K\n\n184\xc2\xba\n\nFigure 19. Segmentation of FMS Runway 25 Approach and Cottonwood-2 Departure for statistical analyses.\n\nSegment 1\n\nSegment 6\n\nRW 07\n\nSegment 8\nDescending turn\n\nF058R\n\nLevel flight\nat 8,100 feet MSL\nD5.32\nIEGE 251\xc2\xba\n\nLevel flight\nat 13,100 feet MSL\n\nTALIA\n\nSegment 2\nInitial 4.43\xc2\xba descent angle\nfollowed by multiple\ndescent angles\n\nSegment 7\n\nLevel flight\nat 8,100 feet MSL\n\nFigure 20. Segmentation of Visual Arrival to Runway 07 for statistical analyses\n\nRoot mean square (RMS) metrics were computed from the measures for vertical and lateral deviations\nof the B-757 from the defined path. The lateral path deviation data for the FMS25 approach runs using\nthe Baseline display condition were not recorded properly. As such, this data were treated as missing\nvariables in the analyses for the lateral path deviation measure. This mis-recording did not affect the\nanalyses for the lateral path deviation for the Visual 07 flying task. Where available, RMS localizer error\nwas also computed. When applicable, RMS flight director roll command and RMS flight director pitch\ncommand were also computed.\n\n27\n\nAnalysis of the quantitative path data (RMS vertical and lateral deviation) were done by Task\nSegments and for the entire Approach. The entire Approach data included more than just the combination\nof the segment data for an approach, as some turns and some glideslope transitions were excluded from\nsome of the segments by definition. The entire Approach data covered all points of the approach, from\nTALIA through to the missed approach point.\nThe data were analyzed by Analysis of Variance (ANOVA) across subject, display type, texture type\n(when appropriate), and flying task. Pilot selectable FOV effects on the quantitative path data for the\nHDDs were not examined for either the individual task segments nor the entire approach task, but rather\nwere accepted as a standard component of the SVS HDD display types. Within the ANOVAs, only main\neffects and second order interactions were tested. Higher order interactions were pooled into the\nexperimental error term. For statistically significant factors revealed by the ANOVAs, Student-NewmanKeuls (SNK) tests (at a 5-percent significance level) of individual means were performed at appropriate\nstages in the analyses.\nFTE computations (which are one component of RNP calculations) were made from the recorded\nquantitative path error data for the Runway 25 and 07 approaches. These data were analyzed over the\nentire approach segment using histogram analyses. For lateral path performance, 27 bins were defined.\nTable 5 provides the bin width definitions used for the lateral path performance. For vertical path\nperformance, 13 bins were defined. Table 6 provides the bin width definitions used for the vertical path\nperformance. The bin values were selected to range across current-generation aircraft RNP values (\xe2\x89\xa5 0.1\nnmi) with finer gradation below these values in case the advance tunnel guidance concepts provided\nmeasurable improvement in FTE. The number of occurrences in each bin was totaled and this total bin\nvalue was divided by the total number of occurrences over the entire approach to determine the\npercentage of occurrences for each bin to form the histograms.\n\n28\n\nTable 5. Lateral Navigation Performance Bin Definitions\nBin\nNumber\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\nLateral Navigation\nPerformance Range Window, x\n(nmi)\nx>2.0\n2.0\xe2\x89\xa5x>1.5\n1.5\xe2\x89\xa5x>1.0\n1.0\xe2\x89\xa5x>5\n.5\xe2\x89\xa5x>.45\n.45\xe2\x89\xa5x>.4\n.4\xe2\x89\xa5x>.35\n.35\xe2\x89\xa5x>.3\n.3\xe2\x89\xa5x>.25\n.25\xe2\x89\xa5x>.2\n.2\xe2\x89\xa5x>.15\n.15\xe2\x89\xa5x>.1\n.1\xe2\x89\xa5x>.05\n.05\xe2\x89\xa5x>-.05\n-0.05\xe2\x89\xa5x>-0.1\n-0.1\xe2\x89\xa5x>-0.15\n-0.15\xe2\x89\xa5x>-0.2\n-.2\xe2\x89\xa5x>-.25\n-.25\xe2\x89\xa5x>-.3\n-.3\xe2\x89\xa5x>-.35\n-.35\xe2\x89\xa5x>-.4\n-.4\xe2\x89\xa5x>-.45\n-.45\xe2\x89\xa5x>-.5\n-.5\xe2\x89\xa5x>-1.0\n-1.0\xe2\x89\xa5x>-1.5\n-1.5\xe2\x89\xa5x>-2.0\n-2.0\xe2\x89\xa5x\n\nTable 6. Vertical Navigation Performance Bin Definitions\nBin\nNumber\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\nVertical Navigation Performance\nAltitude Window, x\n(feet)\nx>300\n300\xe2\x89\xa5x>250\n250\xe2\x89\xa5x>200\n200\xe2\x89\xa5x>150\n150\xe2\x89\xa5x>100\n100\xe2\x89\xa5x>50\n50\xe2\x89\xa5x>-50\n-50\xe2\x89\xa5x>-100\n-100\xe2\x89\xa5x>-150\n-150\xe2\x89\xa5x>-200\n-200\xe2\x89\xa5x>-250\n-250\xe2\x89\xa5x>-300\n-300\xe2\x89\xa5x\n\n29\n\nDependent Measures for the Subjective Data Analyses\nQualitative EP ratings and comments were collected both during the flight and in post-flight\ndebriefings. In-flight pilot comments were recorded via the videotape audio recording channel. A short\nin-flight questionnaire (fig. 21) was provided aurally to the EP to elicit his comments after each run. Inflight comments were obtained between research maneuvers from the EP once aircraft control was\ntransferred to the safety pilot. Post-flight qualitative EP ratings and other comments were obtained during\nextensive debriefings (semi-structured interviews) conducted immediately following a research flight on\nthe ground at COS.\n\nRUN QUESTIONAIRE\nSTRONGLY MODERATELY SLIGHTLY SLIGHTLY MODERATELY STRONGLY\nDISAGREE\nDISAGREE DISAGREE AGREE\nAGREE\nAGREE\n1\n2\n3\n4\n5\n6\n\n1.) IT WAS EASY TO DETERMINE AIRCRAFT POSITION\nWITH RESPECT TO THE TERRAIN:\n\n_________\n\nCOMMENTS: _______________________________________________________\n2.) I WAS CONFIDENT IN THE TERRAIN INFORMATION\nCONVEYED BY THE DISPLAY:\n\n_________\n\nCOMMENTS: _______________________________________________________\n3.) IT WAS DIFFICULT TO INTERPRET THE GUIDANCE CUES:\n\n_________\n\nCOMMENTS: _______________________________________________________\n4.) IT WAS DIFFICULT TO FOLLOW THE GUIDANCE CUES:\n\n_________\n\nCOMMENTS: _______________________________________________________\n5.) THE AMOUNT AND DENSITY OF DISPLAY\nINFORMATION WAS APPROPRIATE TO THE TASK:\n\n_________\n\nCOMMENTS: _______________________________________________________\n6.) I COULD PERFORM THIS TASK WITH EASE AND PRECISION:\n\n_________\n\nCOMMENTS: _______________________________________________________\n7.) AS I PERFORMED THE TASK, THE EFFECTS OF WIND AND\nTURBULENCE WERE INCONSEQUENTIAL TO THE EVALUATION: _________\nCOMMENTS: _______________________________________________________\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\nWERE ANY EVALUATION RATINGS SIGNIFICANTLY DIFFERENT\nBETWEEN THE APPROACH AND DEPARTURE TASKS?\nOTHER COMMENTS / REMARKS / SUGGESTIONS?\n\nFigure 21. In-flight run questionnaire.\n\nIn addition to pilot ratings and comments, the Situational Awareness \xe2\x80\x93 Subjective Workload\nDominance (SA-SWORD) technique (Vidulich & Hughes, 1991) was administered at the conclusion of\nthe EP\xe2\x80\x99s flights during their semi-structured interviews. The SA-SWORD technique uses judgment\nmatrices to assess situation awareness.\n\n30\n\nOrganization of Trials\nApproximately six evaluations per flight were planned. Each evaluation consisted of the approach and\ndeparture task to either Runway 25 or Runway 07. For aircraft performance considerations (fuel weight),\nRunway 07 evaluations were planned for the latter portions of each flight. Because of the desire to ensure\ncollection of HUD flight test data, the HUD runs were always flown first of all the SVS display concepts.\nThe experimental run matrix was developed with these constraints in place. See Appendix E for the\nplanned run matrix.\nGenerally, an EP\xe2\x80\x99s first experimental run used the Baseline concept with no VRD installed. In fact,\nwhenever the Baseline condition was evaluated, the VRD was not installed. The second experimental run\nused the HUD without the VRD installed. After the first two experimental runs were flown, the VRD\nwas installed and used for the remaining display concept evaluations (except for the Baseline condition).\nThe first three runs were always FMS25 runs to ensure some fuel weight reduction before attempting the\nmore challenging Visual 07 runs. The SVS Size A and X concept runs, along with SVS texture type\nvariations, were balanced across pilots in the usual manner to alleviate learning and fatigue effects.\n\nProcedure\nUpon arriving at Colorado Springs, the EP was given a briefing by a Synthetic Vision Display\nConcepts (SVDC) Principal Investigator before flying the ARIES aircraft. The briefing included the\nfollowing elements:\n\xe2\x80\xa2\n\nNASA Synthetic Vision Systems Project overview\n\n\xe2\x80\xa2\n\nSVDC EGE flight test objectives\n\n\xe2\x80\xa2\n\nEGE FMS-based approaches and departures\n\n\xe2\x80\xa2\n\nSVS display concepts\n\n\xe2\x80\xa2\n\nEGE approach procedures\n\n\xe2\x80\xa2\n\nExperimental Equipment\n\n\xe2\x80\xa2\n\nSchedule\n\nThe tests were not conducted in the blind for the EPs. All test conditions were briefed to the EP and\nthe conditions had previously been flown in simulator training. Following the orientation briefing, a pre\nflight briefing was held where weather conditions and general aircraft operating procedures (e.g.,\ncommunications, cockpit protocol, etc.) were discussed. A final general briefing was provided on the\naircraft by the flight test director covering the sequence of maneuvers to be performed and the anticipated\ngeneral schedule. ARIES flights originated at COS and transitioned to EGE for repetitive approach and\ndeparture maneuvers. ARIES transited back to COS at the end of research operations. Each flight was\napproximately four hours.\n\n31\n\nResults\nObjective data results are presented from ANOVAs and histogram analyses, and the subjective data\nresults are presented from ANOVAs, along with any pilot comments that were considered to be\nparticularly meaningful. From the ANOVAs, results for the main factors and second order interactions of\ninterest are presented. Since the main factor of pilot is usually significant in these types of analyses, it is\nnot specifically mentioned in the Results section unless it was found to be not significant. Within the\nANOVAs, only main effects and second order interactions were tested. Higher order interactions were\npooled into the experimental error term. For statistically significant factors revealed by the ANOVAs,\nSNK tests (at a 5-percent significance level) of individual means were performed at appropriate stages in\nthe analyses.\nIn addition, the unavailable lateral path deviation data for the Baseline condition FMS 25 runs were\ntreated as missing variables for the task factor in the ANOVA analyses for this measure. As a result of\nthe desire to eliminate any effects of this missing data for the Baseline Concept from the examination of\nthe SVS displays, two separate ANOVAs were conducted on the quantitative path data for the individual\ntask segments and the entire approach task. The first ANOVA treated display type (Baseline, Size A,\nSize X, HUD), task (FMS25, Visual 07), and pilot as the independent variables, while the second\nANOVA treated SVS display type (Size A, Size X, HUD), texture type (generic, photo-realistic), task\n(FMS25, Visual 07), and pilot as the independent variables. Note that the second analyses are essentially\na subset of the previous ANOVA treatments, but without the Baseline data and with different statistical\ndegrees of freedom and power. Also, the second analyses enabled testing the texture type factor as well.\n\nApproach Path for FMS25 and Visual 07\nThe analyzed approach path began at the end of Segment One (just prior to the turn at Waypoint\nTALIA), included all turns and glideslope changes thereafter, and ended at the point where the SP took\nover control of the aircraft (before 200 ft AGL).\nSix runs (4 HUD, 1 Size A and 1 Baseline) were not included in these analyses due to known data\ncontamination problems (operational restrictions, equipment problems, raster guidance symbology\nlimitations, and cockpit distractions). For example, two HUD runs were excluded due to a low cloud\nceiling of 12,500 feet MSL that prevented the pilot from flying the required altitude of 13,100 feet MSL\nduring the inbound approach to Waypoint TALIA (operational restriction). Another HUD run was\nexcluded due to a pilot\xe2\x80\x99s inability to discern the raster guidance symbology from the raster terrain, which\ncaused him to miss the initial descent at Waypoint TALIA (symbology limitation). This raster clutter\nproblem (which could have been eliminated with a programmable stroke symbology capability) was\novercome once pilots had become familiar with the condition.\nDisplay/Task Analyses. Separate ANOVAs were performed on the RMS lateral path deviation and\nthe RMS vertical path deviation for the entire approach with display type (Baseline, Size A, Size X,\nHUD), task (FMS25, Visual 07), and pilot as the independent variables.\nDisplay type (F(3,61)=102.143, p<.001) was highly significant for the measure of RMS lateral path\nerror during the entire approach (see fig. 22). Post hoc tests (using SNK with \xce\xb1=.05), showed that\nsignificantly worse tracking of the lateral path occurred when using the Baseline Concept (missing data\nfor FMS25; raw data only for Visual 07: mean=818 ft, n=5) than when using the three SVS Concepts,\nwith which the pilots had precision pathway guidance during each task: Size A (mean=61 ft, n=19), Size\nX (mean=51 ft, n=22), HUD (mean=67 ft, n=27). There were no significant differences among the SVS\n\n32\n\nconcepts for this measure. Task, pilot, and the second order interaction of display type and task were not\nsignificant (p>.05) for this measure.\nDisplay type (F(3,65)=18.227, p<.001) was highly significant for the measure of RMS vertical path\nerror during the entire approach. Post hoc tests (using SNK with \xce\xb1=.05) showed that the vertical path\ndeviation when flying with the Baseline Concept (the pilots had differing conventional guidance\ninformation across the two tasks: mean=147 ft, n=10) was significantly worse than when flying with any\nof the three SVS Concepts, with which the pilots had precision pathway guidance: Size A (mean=38 ft,\nn=19), Size X (mean=40 ft, n=22), HUD (mean=32 ft, n=27). There were no significant differences\namong the SVS concepts for this measure. Task, pilot, and the interaction between display type and task\nwere not significant (p>.05) for this measure.\n\nApproach RMS Path Error\n900\n\n818\n\nRMS path error (feet)\n\n800\n\nRMS lateral error\n\n700\n\nRMS vertical error\n\n600\n500\n400\n300\n200\n\n147\n61 38\n\n100\n\n51 40\n\nSize A\n\nSize X\n\n67\n\n32\n\n0\nBaseline\n\nHUD\n\nFigure 22. RMS lateral and vertical path error over the entire approach path.\n\nSVS Display/Texture/Task Analyses. Separate ANOVAs were performed on the RMS lateral path\ndeviation and the RMS vertical path deviation for the entire approach with SVS display type (Size A, Size\nX, HUD), texture type (generic, photo-realistic), task (FMS25, Visual 07), and pilot as the independent\nvariables.\nNeither the main factors nor the second order interaction between SVS display type and texture type\nwere significant (p>.05) for the measure of RMS lateral path error during the entire approach. SVS\ndisplay type (F(2,56)=8.449, p=.001) and task (F(1,56)=12.884, p=.001) were significant for the measure\nof RMS vertical path error during the entire approach. Post hoc tests (using SNK with \xce\xb1=.05) showed\nthat the vertical path deviation (fig. 22) when flying with the HUD SVS concept (mean=32 ft, n=27) was\n\n33\n\nsignificantly better than when flying with the head-down SVS Concepts: Size A (mean=38 ft, n=19) and\nSize X (mean=40 ft, n=22). The pilots had worse tracking of the vertical path during the FMS25\napproach (mean=39 feet) than with the Visual 07 approach (mean=34 feet). Texture type and the second\norder interaction between SVS display type and texture type were not significant (p>.05) for the measure\nof RMS vertical path error during the entire approach.\n\nFMS25 approach and departure\nSegment One: Inbound to Waypoint TALIA\nThis segment was a common path for the FMS25 and Visual 07 approaches. The pilot\xe2\x80\x99s task was to\nassume control of the airplane and maintain a straight course (no turns) while remaining level at an\naltitude of 13,100 feet MSL. Six runs (3 HUD, 2 Size A and 1 Baseline) were not included in these\nanalyses due to known data contamination problems (operational restrictions, equipment problems, raster\nguidance symbology limitations, and cockpit distractions).\nDisplay/Task Analyses. Separate ANOVAs were performed on the RMS lateral path deviation and\nthe RMS vertical path deviation for Segment One with display type (Baseline, Size A, Size X, HUD), task\n(FMS25, Visual 07), and pilot as the independent variables.\nDisplay type (F(3,14)=3.743, p=.036) was significant for the measure of RMS lateral path error (see\nfig. 23). Post hoc tests (using SNK with \xce\xb1=.05) showed that significantly worse tracking of the lateral\npath occurred when using the Baseline concept (missing data for FMS25; raw data only for Visual 07:\nmean=522 ft, n=5) than when using the three SVS Concepts, with which the pilots had precision pathway\nguidance: Size A (mean=116 ft, n=16), Size X (mean=111 ft, n=21), HUD (mean=157 ft, n=25). There\nwere no significant differences among the SVS concepts. Task and the second order interaction of\ndisplay type and task were not significant (p>.05) for this measure.\nDisplay type (see fig. 23), task, and pilot were not significant (p>.05) for the measure of RMS vertical\npath error. The second order interaction between display type and task (F(3,39)=7.904, p<.001) was\nhighly significant for this measure. Examination of the interaction between display type and task (see fig.\n24) revealed poorer vertical tracking when using the Baseline Concept for the Visual 07 task (for which\nthe pilots had only a raw vertical path error indicator) versus for the FMS25 task (for which the pilots had\nflight director guidance), while the task effect for the SVS Concepts (the pilots had precision pathway\nguidance during each task) was diminished and in reverse order (although these differences were not\nstatistically discriminable).\n\n34\n\nSegment One RMS Path Error\n600\n522\nRMS lateral error\n\nRMS path error (feet)\n\n500\n\nRMS vertical error\n\n400\n\n300\n200\n\n157\n116\n\n100\n\n111\n\n70\n31\n\n36\n\nSize A\n\n36\n\nSize X\n\n0\nBaseline\n\nHUD\n\nFigure 23. RMS lateral and vertical path error over segment one.\n\nSegment One Vertical Path Error\n\nRMS vertical path error (feet)\n\n120\nFMS 25\n100\n\n104\n\nCircle 07\n\n80\n60\n40\n\n47\n\n48\n\n26\n\n28\n\n30\n\nSize A\n\nSize X\n\nHUD\n\n38\n28\n\n20\n0\nBaseline\n\nFigure 24. Second order interaction of display type and task for RMS vertical path error over segment one.\n\n35\n\nSVS Display/Texture/Task Analyses. ANOVAs were performed on the RMS lateral path deviation\nand the RMS vertical path deviation for Segment One with SVS display type (Size A, Size X, HUD),\ntexture type (generic, photo-realistic), task (FMS25, Visual 07), and pilot as the independent variables.\nNeither the main factors nor the interaction between SVS display type and texture type were significant\n(p>.05) for the measures of RMS lateral path error and RMS vertical path error during this segment.\nSegment Two: Initial Approach\nThis segment was a common path for the FMS25 and Visual 07 approaches. The pilot\xe2\x80\x99s task was to\nmaintain a straight course (no turns), and intercept and maintain the descent path. Five runs (3 HUD, 1\nSize A and 1 Baseline) were not included in these analyses due to known data contamination problems\n(operational restrictions, equipment problems, raster guidance symbology limitations, and cockpit\ndistractions).\nDisplay/Task Analyses. ANOVAs were performed on the RMS lateral path deviation, the RMS\nlocalizer error, and the RMS vertical path deviation for Segment Two, with display type (Baseline, Size\nA, Size X, HUD), task (FMS25, Visual 07), and pilot as the independent variables.\nFor Segment Two, display type (F(3,14)=15.628, p<.001) was highly significant for the measure of\nRMS lateral path error (see fig. 25). Post hoc tests (using SNK with \xce\xb1=.05), showed that lateral path\ntracking performance using the Baseline concept (missing data for FMS25; raw data only for Visual 07:\nmean=867 ft, n=5) was significantly worse than when using the three SVS Concepts, with which the\npilots had precision pathway guidance: Size A (mean=42 ft, n=19), Size X (mean=29 ft, n=22), HUD\n(mean=52 ft, n=27). There were no significant differences among the SVS concepts for this measure.\nTask, pilot, and the second order interaction between display type and task were not significant (p>.05)\nfor this measure.\nDisplay type (F(3,15)=4.964, p=.014), task (F(1,5)=9.0, p=.03), and the interaction between display\ntype and task (F(3,45)=15.406, p<.001) were significant for the measure of RMS localizer error during\nSegment Two. Post hoc tests (using SNK with \xce\xb1=.05) showed that the localizer tracking when using the\nBaseline concept (the pilots had differing conventional guidance information across the two tasks:\nmean=.349 dots, n=10) was significantly worse than when using the three SVS Concepts, with which the\npilots had precision pathway guidance: Size A (mean=.061 dots, n=19), Size X (mean=.061 dots, n=22),\nHUD (mean=.064 dots, n=27). There were no significant differences among the SVS concepts. Pilots\naccrued less localizer error during the Visual 07 approach (mean=.097 dots) than when flying the FMS25\napproach (mean=.101 dots). Although this result is statistically significant, it was not considered\noperationally meaningful as the difference between the two means was only .004 dots. Examination of\nthe interaction between display type and task (see fig. 26) revealed that task differences for the Baseline\nwere large compared to the differences for the three SVS Concepts. Larger localizer error with the\nBaseline display was obtained during the Visual 07 task (for which the pilots had only a raw localizer\nerror indicator) than during the FMS25 task (for which the pilots had flight director guidance). Note that\nbecause no lateral path error data was available for the Baseline Concept for the FMS25 task (treated as\nmissing data), a comparable statistically significant interaction was not possible for the previous analysis\nof the RMS lateral path error measure (lateral path error is a linear measure and as such is a more\nsensitive measure of path performance than the angular localizer error measure). The remaining main\nfactor, pilot, was not significant (p>.05) for this measure.\nDisplay type (F(3,15)=8.593, p=.014) was highly significant for the measure of RMS vertical path\n\n36\n\nerror during Segment Two (see fig. 25). Post hoc tests (using SNK with \xce\xb1=.05) showed that the vertical\npath tracking performance using the Baseline concept (the pilots had differing conventional guidance\ninformation across the two tasks: mean=185 ft, n=10) was significantly worse than the tracking\nperformance when using the three SVS Concepts, with which the pilots had precision pathway guidance:\nSize A (mean=39 ft, n=19), Size X (mean=42 ft, n=22), HUD (mean=39 ft, n=27). There were no\nsignificant differences among the SVS concepts. Task, pilot, and the second order interaction between\ndisplay type and task were not significant (p>.05) for this measure.\n\nSegment Two RMS Path Error\n1000\n900\n\n867\n\nRMS lateral error\nRMS vertical error\n\nRMS path error (feet)\n\n800\n700\n600\n500\n400\n300\n200\n\n185\n\n100\n\n42\n\n39\n\n29\n\n42\n\n52\n\n39\n\n0\nBaseline\n\nSize A\n\nSize X\n\nHUD\n\nFigure 25. RMS lateral and vertical path error over segment two (initial approach).\n\n37\n\nSe gm e nt Tw o RMS Loca lize r Error\n0.5\n\nRMS localizer error (dots)\n\n0.45\n0.4\n\nFMS 25\n\n0.45\n\nCircle 07\n\n0.35\n0.3\n\n0.25\n\n0.25\n0.2\n0.15\n0.07\n\n0.05\n0\nBaseline\n\n0.07\n\n0.07\n\n0.05\n\n0.1\n\n0.05\n\n0.06\n\nSiz e A\n\nSize X\n\nHUD\n\nFigure 26. RMS localizer error plot of display type and task interaction over segment two.\n\nSVS Display/Texture/Task Analyses. ANOVAs were performed on the RMS lateral path deviation,\nthe RMS localizer deviation, and the RMS vertical path deviation for Segment Two with SVS display\ntype (Size A, Size X, HUD), texture type (generic, photo-realistic), task (FMS25, Visual 07), and pilot as\nthe independent variables.\nNeither the main factors nor the second order interaction between display type and texture type were\nsignificant (p>.05) for the measure of RMS lateral path error or for the measure of RMS vertical path\nerror. For the measure of RMS localizer, SVS display type, texture type, and the interaction between\nSVS display type and texture type were not significant (p>.05), but task was significant (F(1,5)=3.0,\np=.011). Pilots accrued less localizer error during the Visual 07 approach (mean=.054 dots) than when\nflying the FMS25 approach (mean=.073 dots). Although this result is statistically significant, it was not\nconsidered operationally meaningful. The lateral flight plans for the Visual 07 and FMS25 over Segment\nTwo differed by 0.02 degrees, which, at EGE\xe2\x80\x99s scaling of 1.5deg/dot, resulted in a 0.013 dots difference.\nBecause of that slight path definition difference, the RMS localizer is biased by 0.013 dots between the\ntwo tasks. The statistical differences noted above (0.073-0.054=0.019 dots) are thus attributed to this path\nmismatch, rather than to display effects. It should be noted that the path mismatch influences on localizer\nerror just discussed had negligible effect on the results previously presented on the Baseline condition\ntask findings for localizer error, as the task effect was much larger and in the opposite direction there (see\nfig. 26: 0.25-0.45=-0.20 dots).\nSegment Three: FMS25 Final Approach\nThis critical segment was the straight final for the FMS 25 approach.\n\n38\n\nIt typically ended in a\n\ntakeoff/go-around (TOGA) just before the left turn away from the offset localizer course to align with the\nrunway at 200 ft AFL. The pilot\xe2\x80\x99s task was to maintain a straight course (no turns) and a 3.0 degree\ndescent path. Two runs (1 HUD and 1 Baseline) were not included in these analyses due to known data\ncontamination problems caused by equipment problems.\nDisplay Analyses. ANOVAs were performed on the RMS vertical path deviation and the RMS\nlocalizer error for Segment Three with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables. An ANOVA was not performed for the lateral path deviation with display type as\nan independent variable because there was no Baseline FMS25 data available for this measure. However,\nan ANOVA was performed on this measure with SVS display type as an independent variable and that\nanalysis is presented in the next section.\nDisplay type and pilot were not significant (p>.05) for the measure of RMS vertical path deviation.\nDisplay type (F(3,11)=8.182, p=.004) was highly significant for the measure of RMS localizer error (see\nfig. 27), an angular measure, that while less sensitive than the linear lateral path deviation measure,\nprovides related results. Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilot accrued\nsignificantly more localizer error with the Baseline concept (using a conventional flight director,\nmean=.320 dots, n=5) than when using the three SVS Concepts (using precision pathway guidance): Size\nA (mean=.068 dots, n=8), Size X (mean=.070 dots, n=10), HUD (mean=.065 dots, n=11). There were no\nsignificant differences among the SVS concepts. Pilot was not significant (p>.05) for the measure of\nRMS localizer error.\n\nSegment Three RMS Localizer Error\n\nRMS localizer error (dots)\n\n0.35\n\n0.32\n\n0.3\n0.25\n0.2\n0.15\n0.1\n\n0.07\n\n0.068\n\n0.065\n\n0.05\n0\nBaseline\n\nSize A\n\nSize X\n\nHUD\n\nFigure 27. RMS localizer error over segment three (FMS25 short final)\n\n39\n\nSVS Display/Texture Analyses. ANOVAs were performed on the RMS lateral path deviation and\nthe RMS vertical path deviation for Segment Three with SVS display type (Size A, Size X, HUD), texture\ntype (generic, photo-realistic), and pilot as the independent variables.\nSVS display type (F(2,7)=11.959, p=.006) was highly significant for the measure of RMS lateral path\nerror (see fig. 28). Post hoc tests (using SNK with \xce\xb1=.05), showed that the pilot had worse tracking of the\nlateral path with the HUD (mean=36 ft, n=11) concept than when using the other two SVS Concepts: Size\nA (mean=11 ft, n=8) and Size X (mean=12 ft, n=10). One could postulate that the poorer lateral tracking\nwhen using the HUD could be attributed to learning effects with the use of the vision restriction device\n(VRD). In general, the pilots\xe2\x80\x99 first HUD run was always without the VRD (all baseline runs were without\nthe VRD and, for safety considerations, usually preceded the first HUD run to a particular runway end).\nOnce the VRD was installed, the mean for the RMS lateral deviation when using the HUD concept (each\npilot\xe2\x80\x99s second HUD run; mean=55 feet, n=4) increased as compared to using the HUD without the VRD\ninstalled (each pilot\xe2\x80\x99s first HUD run; mean=31 feet, n=4). Again, one could postulate that there was a\nlearning effect as the pilots\xe2\x80\x99 tracking became better as they got used to flying with the VRD installed\n(each pilot\xe2\x80\x99s third HUD run; mean=17 feet, n=3). However, such an effect was not exhibited for the\nvertical error tracking when using the HUD with and without the VRD. The VRD was in place for all the\nSize A and X concept runs, and the Size A and X concept runs, along with texture type runs, were\nbalanced across pilots. Conversely, turbulence effects were greater for the later runs of a sortie, such that\none could argue the Size A and X concept run conditions might have been more difficult than the HUD\nruns. Consequently, no concrete explanation can be offered for the exceptionally good RMS lateral path\ntracking performance obtained over the 3.83 Nmi Segment Three when using the Size A (mean=11 ft,\nn=8) and Size X (mean=12 ft, n=10) concepts. Pilot, texture type and the interaction between SVS\ndisplay type and texture type were not significant (p>.05) for the RMS lateral path error measure.\n\nSegment Three RMS Path Error\n60\nRMS lateral error\n\nRMS path error (feet)\n\n50\n\nRMS vertical error\n\n40\n\n36\n33\n28\n\n30\n22\n\n22\n\n20\n11\n\n12\n\nSize A\n\nSize X\n\n10\n0\nBaseline\n\nHUD\n\nFigure 28. RMS lateral path error over segment three (FMS25 final).\n\n40\n\nSVS display type (see fig. 28), texturing type, pilot, and the interaction between texture type and SVS\ndisplay type were not significant (p>.05) for the measure of RMS vertical path error during the straight\nfinal approach to Runway 25.\nSegment Four: Cottonwood Departure Initial Climbout\nThis segment was the initial straight climbout for the Cottonwood departure of the FMS25 flying task.\nThe pilot\xe2\x80\x99s task was to null the flight director. The flight director commands were based on LNAV and\nSpeed on Pitch.\nDisplay Analyses. ANOVAs were performed on the RMS flight director roll command and the RMS\nflight director pitch command with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables. Display type was not significant (p>.05) for either measure.\nSVS Display/Texture Analyses. ANOVAs were performed on the RMS flight director roll command\nand the RMS flight director pitch command with SVS display type (Size A, Size X, HUD), texture type\n(generic, photo-realistic), and pilot as the independent variables. SVS display type, texture type, pilot,\nand the interaction between SVS display type and texture type were not significant (p>.05) for either\nmeasure.\nSegment Five: Cottonwood Departure Final Climbout\nThis segment was the final straight climbout for the Cottonwood departure of the FMS25 flying task.\nThe pilot\xe2\x80\x99s task was to null the flight director. The flight director commands were based on LNAV and\nSpeed on Pitch.\nDisplay Analyses. ANOVAs were performed on the RMS flight director roll command and the RMS\nflight director pitch command with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables. Display type was not significant (p>.05) for either measure and pilot was not\nsignificant (p>.05) for the flight director pitch command measure.\nSVS Display/Texture Analyses. ANOVAs were performed on the RMS flight director roll command\nand the RMS flight director pitch command with SVS display type (Size A, Size X, HUD), texture type\n(generic, photo-realistic), and pilot as the independent variables. SVS display type, texture type, pilot,\nand the interaction between SVS display type and texture type were not significant (p>.05) for either\nmeasure.\n\nVisual 07 approach\nSegments one and two of this approach were covered in the section entitled FMS25 Approach and\nDeparture, as these two segments were common to both flying tasks.\nSegment Six: Circle Entry Level off\nThis segment was the level off before the circling approach to runway 07. The pilot\xe2\x80\x99s task was to\nlevel off at 8,100 ft MSL while maintaining a straight course (no turns).\nDisplay Analyses. ANOVAs were performed on the RMS lateral path deviation and the RMS vertical\n\n41\n\npath deviation for Segment Six with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables.\nDisplay type (F(3,14)=5.350, p=.012) was highly significant for the measure of RMS lateral path error\n(see fig. 29). Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilots had worse tracking of the\nlateral path with the Baseline concept (for which the pilots had only a raw lateral path error indicator:\nmean=203 ft, n=5) than when using the three SVS concepts, with which the pilots had precision pathway\nguidance: HUD (mean=46 ft, n=19), Size X (mean=18 ft, n=12) and Size A (mean=28 feet, n=12)\nconcept. There were no significant differences among the SVS concepts. The pilot factor was not\nsignificant (p>.05) for the RMS lateral path error measure.\nDisplay type (F(3,14)=12.953, p<.001) was highly significant for the measure of RMS vertical path\nerror during Segment Six (see fig. 29). Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilot had\nworse tracking of the vertical path with the Baseline concept (for which the pilots had only a raw vertical\npath error indicator: mean=122 ft, n=5) than when using the three SVS Concepts, with which the pilots\nhad precision pathway guidance: Size A (mean=59 ft, n=12), Size X (mean=50 ft, n=13), HUD (mean=38\nft, n=19). Also, tracking with the HUD concept was significantly better than with the Size A concept but\nperformance with the HUD could not be discriminated from that of the Size X concept. The Size X\nconcept performance could also not be discriminated from that of the Size A concept. The pilot factor\nwas not significant (p>.05) for the RMS vertical path error measure.\n\nSegment Six RMS Path Error\n250\nRMS lateral error\nRMS vertical error\n\n203\nRMS path error (feet)\n\n200\n\n150\n122\n100\n59\n50\n\n50\n\n28\n\n46\n\n38\n\n18\n\n0\nBaseline\n\nSize A\n\nSize X\n\nHUD\n\nFigure 29. RMS lateral and vertical path error over segment six (circle entry level off).\n\nSVS Display Type/Texture Analyses. ANOVAs were performed on the RMS lateral path deviation\nand the RMS vertical path deviation for Segment Six with SVS display type (Size A, Size X, HUD),\ntexture type (generic, photo-realistic), and pilot as the independent variables. SVS display type\n\n42\n\n(F(2,10)=5.425, p=.025) was significant for the measure of RMS lateral path error. However, post hoc\ntests (using SNK with \xce\xb1=.05) could not discriminate between the three SVS concepts for this measure.\nThe SNK uses a different statistical model than the ANOVA and in this case had less power to\ndiscriminate between the means. (See Display Analyses section above and fig. 29 for the means.)\nTexture type, pilot and the interaction between SVS display type and texture type were not significant\n(p>.05) for the RMS lateral path deviation measure.\nSVS display type, texture type, the interaction between SVS display type and texture type, and pilot\nwere not significant (p>.05) for the measure of RMS vertical path error.\nSegment Seven: Circle Dogleg\nThis segment was the level dogleg left turn prior to the right circling approach to runway 07. The\npilot\xe2\x80\x99s task was to maintain altitude while executing the turn and then to maintain a straight and level\ncourse (no turns).\nDisplay Analyses. ANOVAs were performed on the RMS lateral path deviation and the RMS vertical\npath deviation for Segment Seven with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables.\nDisplay type (F(3,14)=19.133, p<.001) was highly significant for the measure of RMS lateral path\nerror (see fig. 30). Post hoc tests (using SNK with \xce\xb1=.05) showed that lateral path control using the\nBaseline concept (for which the pilots had only a raw lateral path error indicator: mean=522 ft, n=5)\nconcept was significantly worse than when using the three SVS Concepts, with which the pilots had\nprecision pathway guidance: Size A (mean=35 ft, n=12), Size X (mean=39 ft, n=12), HUD (mean=50 ft,\nn=19). There were no significant differences among the SVS concepts for the RMS lateral path deviation\nmeasure. The pilot factor was not significant (p>.05) for the RMS lateral path error measure.\nDisplay type (F(3,14)=21.063, p<.001) was also highly significant for the measure of RMS vertical\npath error during Segment Seven (see fig. 30). Post hoc tests (using SNK with \xce\xb1=.05) showed that the\npilots had worse tracking of the vertical path with the Baseline concept (for which the pilots had only a\nraw vertical path error indicator: mean=86 ft, n=5) than with any of the three SVS Concepts, with which\nthe pilots had precision pathway guidance: Size A (mean=19 ft, n=12), Size X (mean=18 ft, n=12), HUD\n(mean=11 ft, n=19). There were no significant differences among the SVS concepts. The pilot factor\nwas not significant (p>.05) for the RMS vertical path error measure.\n\n43\n\nSegment Sev en RMS Path Error\n600\n522\n\nRMS lateral error\n\nRMS path error (feet)\n\n500\n\nRMS vertical error\n\n400\n300\n200\n100\n\n86\n35\n\n39\n\n19\n\n50\n18\n\n11\n\n0\nBaseline\n\nSize A\n\nSize X\n\nHUD\n\nFigure 30. RMS lateral and vertical path error over segment seven (circle dogleg).\n\nSVS Display/Texture Analyses. ANOVAs were performed on the RMS lateral path deviation and\nthe RMS vertical path deviation for Segment Seven with SVS display type (Size A, Size X, HUD),\ntexture type (generic, photo-realistic), and pilot as the independent variables. SVS display type, texture\ntype, the interaction between these 2 main factors, and pilot were not significant (p>.05) for either\nmeasure.\nSegment Eight: Circling Approach\nThis segment was the circling, descending approach to runway 07 with a rollout on short final at about\n350 ft AFL. The pilot\xe2\x80\x99s task was to intercept and maintain the 3.0 degree descent path while executing\nthe circling right turn to rollout on final. This critical segment typically ended in a TOGA just before 200\nft AFL.\nDisplay Analyses. ANOVAs were performed on the RMS lateral path deviation and the vertical path\ndeviation for Segment Eight with display type (Baseline, Size A, Size X, HUD) and pilot as the\nindependent variables.\nDisplay type (F(3,14)=17.627, p<.001) was highly significant for the measure of RMS lateral path\nerror (see fig. 31). Post hoc tests (using SNK with \xce\xb1=.05), showed that the pilot had worse tracking of the\nlateral path with the Baseline concept (for which the pilots had only a raw lateral path error indicator:\nmean=685 ft, n=5) than when using the three SVS Concepts, with which the pilots had precision pathway\nguidance: Size A (mean=83 ft, n=12), Size X (mean=100 ft, n=12), and HUD (mean=55 ft, n=19). Also,\ntracking with the HUD concept was significantly better than with the Size X concept but performance\n\n44\n\nwith the HUD could not be discriminated from that of the Size A concept. The Size A concept\nperformance could also not be discriminated from that of the Size X concept. The pilot factor was not\nsignificant (p>.05) for the RMS lateral path deviation measure.\nDisplay type (F(3,14)= 5.610, p=.010) was also highly significant for the measure of RMS vertical\npath error during Segment Eight (see fig. 31). Post hoc tests (using SNK with \xce\xb1=.05) showed that\nvertical path control was worse when using the Baseline concept (for which the pilots had only a raw\nvertical path error indicator: mean=78 ft, n=5) than when using the three SVS Concepts, with which the\npilots had precision pathway guidance: Size A (mean=40 ft, n=12), Size X (mean=38 ft, n=12), and HUD\n(mean=20 ft, n=19). Also, tracking with the HUD concept was significantly better than with the Size A\nconcept but performance with the HUD could not be discriminated from that of the Size X concept. The\nSize X concept performance could also not be discriminated from that of the Size A concept. The pilot\nfactor was not significant (p>.05) for the RMS vertical path deviation measure.\n\nSegment Eight RMS Path Error\n800\nRMS path error (feet)\n\n700\n\n685\n\nRMS lateral error\nRMS vertical error\n\n600\n500\n400\n300\n200\n100\n\n78\n\n83\n\n100\n40\n\n38\n\nSize A\n\nSize X\n\n55\n\n20\n\n0\nBaseline\n\nHUD\n\nFigure 31. RMS lateral and vertical path error over segment eight (circling approach).\n\nSVS Display Type/Texture Analyses. ANOVAs were performed on the RMS lateral path deviation\nand the RMS vertical path deviation for Segment Eight with SVS display type (Size A, Size X, HUD),\ntexture type (generic, photo-realistic), and pilot as the independent variables.\nThe SVS-only display type analysis for the measure of RMS lateral path error is essentially a subset of\nthe previous ANOVA treatment, but without the Baseline data and with different statistical degrees of\nfreedom and power. Post hoc tests (using SNK with \xce\xb1=.05), showed that tracking with the HUD concept\n\n45\n\n(mean=55 ft, n=19) was significantly better than with the Size X concept (mean=100 ft, n=12), but\nperformance with the HUD could not be discriminated from that of the Size A concept (mean=83 ft,\nn=12). The Size A concept performance could also not be discriminated from that of the Size X concept.\nThe interaction between SVS display type and texture type (F(2,17)=3.854, p=.042) was significant for\nthe measure of RMS lateral path error. Examination of the interaction between SVS display type and\ntexture (see fig. 32) revealed poorer lateral tracking using the Size X Photo-realistic concept than when\nusing the Size X Generic Concept, while the texture effect for the Size A and HUD SVS Concepts was\ndiminished and in reverse order (although not statistically discriminable). Texture type and pilot were not\nsignificant (p>.05) for the measure of RMS lateral path error.\nSVS display type (F(2,10)=10.139, p=.004) was highly significant for the measure of RMS vertical\npath error. Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilots had better tracking of the\nvertical path with the HUD concept (mean=20 ft, n=19) than when using the Head-down SVS Concepts:\nSize A (mean=40 ft, n=12) and Size X (mean=38 ft, n=12). There were no differences among the headdown concepts for this measure. Texture type and the interaction between SVS display type and texture\ntype were not significant (p>.05) for the measure of RMS vertical path error.\n\nSegment Eight Lateral Path Error\n\nRMS lateral path error (feet)\n\n140\nGeneric\n\n120\n100\n\n124\n95\n\nPhoto-realistic\n\n75\n\n80\n\n61\n60\n\n71\n48\n\n40\n20\n0\nSize A\n\nSize X\n\nHUD\n\nFigure 32. RMS lateral error plot of SVS display type and texture interaction.\n\nLateral Navigation Bin Analyses\nThe system performance requirements for RNAV is that each aircraft operating in RNP airspace shall\nhave total (lateral) system error components in the cross-track and along-track directions that are less than\nthe RNP value 95% of the flying time (see Appendix D). For the reasons cited previously in the\nApproach Path for FMS25 and Visual 07 section, six runs were excluded from the Lateral Navigation\nanalyses. Figures 33-36 show the horizontal FTE distribution for the display concepts using the bin width\n\n46\n\ndefinitions provided in table 5. The path steering error component of the RNP calculation includes both\nFTE and display error. For this analysis, it was assumed that display error was negligible, so FTE was the\nonly component of path steering error. It was also assumed that the other two components (path\ndefinition error and position estimation error) of the RNP calculation would be equivalent across the\ndisplay concepts evaluated.\nWith these assumptions, the SVS concepts yielded a horizontal FTE navigational accuracy of 0.05 nmi\nat least 95% of the time; while the Baseline concept was only able to yield a horizontal FTE navigational\naccuracy of 0.25 nmi at least 95% of the time. As such, based on the FTE distributions shown in figures\n33-36, the SVS concepts with precision pathway information (Size A, Size X, HUD) would enable\nhorizontal RNP-type operations that were five times smaller than those that would be allowed with the\nBaseline EADI concept.\n\n68.47\n\nLateral FTE - Approach\nBaseline\n\n70\n60\n50\n\n95.6 percent\n\n40\n\nLateral Bins, nmi\n\nFigure 33. Lateral FTE distribution for the Baseline EADI concept\n\n47\n\nx<-2.0\n\n-1.5>x>-2\n\n-.5>x> -1\n\n-1>x>-1.5\n\n-.45>x>-.5\n\n-.4>x>-.45\n\n-.35>x>-.4\n\n-.3>x>-.35\n\n-.25>x>-.3\n\n-.2>x>-.25\n\n-0.15>x>-0.2\n\n-0.1>x>-0.15\n\n.05>x>-.05\n\n.1>x>.05\n\n.15>x>.1\n\n.2>x>.15\n\n.25>x>.2\n\n.3>x>.25\n\n.35>x>.3\n\n.4>x>.35\n\n.45>x>.4\n\n.5>x>.45\n\n1.0>x>.5\n\n2>x>1.5\n\n0\n\n1.5>x>1.0\n\n10\n\n0.00\n0.00\n0.94\n0.11\n0.49\n0.57\n0.46\n0.44\n0.44\n0.69\n3.16\n4.09\n\n20\n\n-0.05>x>-0.1\n\n10.61\n4.48\n1.92\n1.75\n0.38\n0.44\n0.37\n0.19\n0.00\n0.00\n0.00\n0.00\n0.00\n\n30\n\nx>2.0 nmi 0.00\n\nPercentage of Occurrences\n\n80\n\nPercentage of Occurrences\n\n48\n\nLateral Bins, nmi\n\nFigure 35. Lateral FTE distribution for the Size X SVS concept\nx<-2.0\n\n-1.5>x>-2\n\n-1>x>-1.5\n\n-.5>x> -1\n\n-.45>x>-.5\n\n-.4>x>-.45\n\n-.35>x>-.4\n\n-.3>x>-.35\n\n-.25>x>-.3\n\n-.2>x>-.25\n\n-0.15>x>-0.2\n\n-0.1>x>-0.15\n\n-0.05>x>-0.1\n\n.05>x>-.05\n\n.1>x>.05\n\n.15>x>.1\n\n.2>x>.15\n\n.25>x>.2\n\n.3>x>.25\n\n.35>x>.3\n\n.4>x>.35\n\n.45>x>.4\n\n.5>x>.45\n\n1.0>x>.5\n\n1.5>x>1.0\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.44\n\nLateral FTE - Approach\nSize X\n\n99.56\n\n100\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\n2>x>1.5\n\nx<-2.0\n\n-1.5>x>-2\n\n-1>x>-1.5\n\n-.5>x> -1\n\n-.45>x>-.5\n\n-.4>x>-.45\n\n-.35>x>-.4\n\n-.3>x>-.35\n\n-.25>x>-.3\n\n-.2>x>-.25\n\n-0.15>x>-0.2\n\n-0.1>x>-0.15\n\n-0.05>x>-0.1\n\n.05>x>-.05\n\n.1>x>.05\n\n.15>x>.1\n\n.2>x>.15\n\n.25>x>.2\n\n.3>x>.25\n\n.35>x>.3\n\n.4>x>.35\n\n.45>x>.4\n\n.5>x>.45\n\n1.0>x>.5\n\n1.5>x>1.0\n\n2>x>1.5\n\n0.21\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.11\n0.28\n\nx>2.0 nmi 0.00\n\n99.40\n\n100\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\nx>2.0 nmi 0.00\n\nPercentage of Occurrences\n\nLateral FTE - Approach\nSize A\n\nLateral Bins, nmi\n\nFigure 34. Lateral FTE distribution for the Size A SVS concept\n\n99.47\n\nx<-2.0\n\n-1.5>x>-2\n\n-.5>x> -1\n\n-1>x>-1.5\n\n-.45>x>-.5\n\n-.4>x>-.45\n\n-.35>x>-.4\n\n-.3>x>-.35\n\n-.25>x>-.3\n\n-.2>x>-.25\n\n-0.15>x>-0.2\n\n-0.1>x>-0.15\n\n0.13\n0.16\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n.05>x>-.05\n\n-0.05>x>-0.1\n\n.1>x>.05\n\n.15>x>.1\n\n.2>x>.15\n\n.25>x>.2\n\n.3>x>.25\n\n.35>x>.3\n\n.4>x>.35\n\n.45>x>.4\n\n.5>x>.45\n\n1.0>x>.5\n\n1.5>x>1.0\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.25\n2>x>1.5\n\n100\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\nx>2.0 nmi\n\nNumber of occurrences\n\nLateral FTE - Approach\nHUD\n\nLateral Bins, nmi\n\nFigure 36. Lateral FTE distribution for the HUD SVS concept\n\nVertical Navigation Bin Analysis\nThe system performance requirements for VNAV are that for at least 99.7% of the time the\nnavigational performance in the vertical plane, or the total vertical system error, is less than a specified\naltitude deviation measure (see Appendix D). For the reasons cited previously in the Approach Path for\nFMS25 and Visual 07 section, six runs were excluded from the Vertical Navigation analyses. Figures 3740 show the vertical FTE distribution for the display concepts using the bin width definitions provided in\ntable 6. The vertical path steering error component of the VNAV performance calculation includes both\nFTE and display error. For this analysis, it was assumed that display error was negligible so FTE was the\nonly component of vertical path steering error. It was also assumed that the other three components\n(altimetry system error, vertical path definition error, and horizontal coupling error) of the VNAV\nperformance calculation would be equivalent across the display concepts evaluated. In addition, it was\nassumed that the pilot was flying a specified vertical profile so that the required vertical navigation\nperformance accuracy was 300 feet (see table 1).\nThe HDD SVS concepts (Size A, Size X) yielded a vertical FTE navigational accuracy of 150 feet at\nleast 99.7% of the time and the HUD SVS concept yielded a vertical FTE navigational accuracy of 100\nfeet at least 99.7% of the time. The Baseline concept was unable to yield a vertical FTE navigational\naccuracy of 300 feet for at least 99.7% of the time. As such, based on the FTE distributions shown in\nfigures 37-40, the SVS concepts with precision pathway information (Size A, Size X, HUD) would\nenable RNP-type operations along a specified vertical profile of 300 feet and the Baseline EADI concept\nwould not. Thus, the SVS concepts enhance flight operations by enabling the specification of a flight\npath vertically for a given lateral flight path.\n\n49\n\nPercentage of Occurrences\n\n0.05\n0.41\n\n200>x>150\n\n150>x>100\n\n50\n\nx<-300\n\nVerical Bins, nmi\n\nFigure 38. Vertical FTE distribution for the Size A SVS concept\n5.38\nx<-300\n\n-250>x>-300\n\n0.00\n\n-200>x>-250\n\n0.26\n\n0.00\n\n-150>x>-200\n\n-250>x>-300\n\n0.00\n\n-100>x>-150\n\n0.00\n\n3.87\n\n0.41\n\n-50>x>-100\n\n9.87\n\n-200>x>-250\n\n99.95 percent\n\n0.93\n\nVertical FTE - Approach\nSize A\n-150>x>-200\n\nFigure 37. Vertical FTE distribution for the Baseline EADI concept\n1.91\n\nVerical Bins, nmi\n-100>x>-150\n\n0.17\n\n18.51\n\n50>x>-50\n\n100>x>50\n\n6.77\n\n150>x>100\n\n54.51\n\n60\n\n-50>x>-100\n\n80.33\n\n6.09\n\n200>x>150\n\n2.15\n\n250>x>200\n\n70\n\n50>x>-50\n\n0.54\n\n0.00\n\n250>x>200\n\n2.28\n\n0\n300>x>250\n\n5.57\n\n40\n\n100>x>50\n\n0.00\n\n100\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\n300>x>250\n\nx>300\n\n10\n\n0.00\n\n20\n\nx>300\n\nPercentage of Occurrences\n\nVertical FTE - Approach\nBaseline\n\n100\n90\n\n80\n\n50\n\n89.0 percent\n\n30\n\n0.00\n0.00\n\n200>x>150\n\n150>x>100\n\n20\n\n51\n\n0.00\n0.00\n0.04\n\n250>x>200\n200>x>150\n150>x>100\n\nx<-300\n\n0.00\n\nx<-300\n\n-150>x>-200\n\n-100>x>-150\n\n-50>x>-100\n\n50>x>-50\n\nVertical Bins, nmi\n\nFigure 40. Vertical FTE distribution for the HUD SVS concept\n0.00\n\n0.00\n\n0.00\n\n0.00\n\n0.32\n\n1.69\n\n0.00\n\n300>x>250\n\n100>x>50\n\n0.00\n\nx>300\n\n-250>x>-300\n\n99.8 percent\n\n0.00\n\n40\n\n-250>x>-300\n\n60\n-200>x>-250\n\n70\n\n0.00\n\n80\n\n-200>x>-250\n\n90\n\n0.05\n\nVertical FTE - Approach\nHUD\n\n-150>x>-200\n\nFigure 39. Vertical FTE distribution for the Size X SVS concept\n\n0.16\n\nVerical Bins, nmi\n\n-100>x>-150\n\n10.53\n\n30\n\n-50>x>-100\n\n88.64\n\n100\n\n50>x>-50\n\n0.62\n\n0.00\n\n250>x>200\n\n50\n\n100>x>50\n\n0.00\n\n0\n\n300>x>250\n\n10\n\n0.00\n\nPercentage of Occurrences\n\n22.58\n\n75.36\n\n100\n90\n80\n70\n60\n50\n40\n30\n20\n10\n0\n\nx>300\n\nNumber of occurrences\n\nVertical FTE - Approach\nSize X\n\n100.0 percent\n\nSubjective Data Analyses\nPost-Run Ratings\nSeven post-run questions (see fig. 21) were asked of each evaluation pilot to help assess specific\nsubjects of interest to researchers while flying the approaches with the display concepts. Only those\nquestions of particular interest with regard to terrain awareness and pilot workload are discussed here\n(questions # 1, 2, and 6). An ANOVA was performed on the mean rating (1 = \xe2\x80\x9cstrongly disagree\xe2\x80\x9d; 6 =\n\xe2\x80\x9cstrongly agree\xe2\x80\x9d) for each of those post-run questions with display type (seven levels: Baseline; and Size\nA, Size X, and HUD, each with generic and photo-realistic terrain) and pilot as the independent variables.\nThe pilot factor is not specifically mentioned unless it was found not to be significant.\nTerrain Awareness. Post-run question # 1, \xe2\x80\x9cIt was easy to determine aircraft position with respect to\nthe terrain\xe2\x80\x9d, was asked of each EP to help assess his terrain awareness when flying the different display\nconcepts. Display type (F(6,73)=2.82, p=.016) was highly significant for the measure of the mean terrain\nawareness rating (see fig. 41). Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilots felt that their\nterrain awareness while using the Size A Photo-realistic, Size X Generic, and Size X Photo-realistic\nconcepts was significantly better than when using the Baseline EADI/TAWS ND concept. No other\ndifferences could be discriminated.\nPost-run question # 2, \xe2\x80\x9cI was confident in the terrain information conveyed by the display\xe2\x80\x9d, was asked\nof each EP to help assess his confidence in the terrain information when flying the different display\nconcepts. Display type (F(6,73)=3.30, p=.006) was highly significant for the measure of the mean terrain\nconfidence rating (see fig. 41). Post hoc tests (using SNK with \xce\xb1=.05) showed that the pilots felt\nsignificantly more confident in the terrain information provided by the Size X Generic and Size X Photorealistic concepts than that of the Baseline concept. No other differences could be discriminated.\nWorkload. Post-run question # 6, \xe2\x80\x9cI could perform this task with ease and precision\xe2\x80\x9d, was asked of\neach EP to help assess his workload when flying the different display concepts. Display type\n(F(6,73)=5.594, p<.000) was highly significant for the measure of the mean workload rating (see fig. 41).\nPost hoc tests (using SNK with \xce\xb1=.05), showed that use of the Baseline concept (mean=4.1) imposed\nsignificantly more workload on the pilots than the use of any of the SVS concepts: Size A Generic\n(mean=5.2), Size A Photo-realistic (mean=5.7), Size X Generic (mean=5.7), Size X Photo-realistic\n(mean=5.4), HUD Generic (mean=5.5), and HUD Photo-realistic (mean=5.7). There were no significant\ndifferences among the SVS concepts for this measure.\n\n52\n\nIn-Flight Questionnaire Ratings\nTerrain Awareness\n\nstrongly\nagree\n\n6\n\n5.6 5.7\n\nConfidence in Terrain\n\n5.7 5.7 5.7\n\n5.9 5.8\n\n5.7 5.8 5.8\n\n5.5\n\n5.4\n\n5.2\n5\n\nWorkload\n\n5.1\n\n5.7\n5.3 5.3\n\n4.8\n\n4.5 4.6\n\nRating\n\n4.1\n4\n\n3\n\n2\n\nHUD Photo\n\nHUD Generic\n\nSize X Photo\n\nSize X Generic\n\nSize A Photo\n\nSize A Generic\n\n1\n\nBaseline\n\nstrongly\ndisagree\n\nDisplay Type\n\nFigure 41. Post-run mean pilot ratings\n\nDisplay Questionnaire Ratings\nAppendix F documents the mean and standard deviations for each of the 70 post-flight questionnaire\nratings on specific subjects of interest to researchers. Those of particular interest with regard to pilot SA\n(questions 11-14, 43-46, and 67-70) and pilot workload (questions 8-9, 39-42, and 63-66) using SVS\ndisplay concepts are presented here. Due to an omission in the questionnaire, the pilots were not asked to\nrate the workload for the HUD Photo-realistic concept. Mean pilot ratings of situation awareness and\nworkload (see figures 42 and 43, respectively) for both the head-up and head-down SVS display concepts\ntested indicated that all of these concepts provided enhanced situation awareness while imposing low\nworkload for the pilot. Statistical analyses of these results were not conducted.\n\n53\n\n6.915\n\n7.33\n\n7.415\n\nHUD\nGeneric\n\nSize X\nPhotorealistic\n\nSize X\nGeneric\n\nSize A\nPhotorealistic\n\n6.415\n\n6.745\n\nHUD\nPhotorealistic\n\n7.83\n\nSize A\nGeneric\n\nSituation Awareness Level\n\n9\n8\n7\n6\n5\n4\n3\n2\n1\n\nDisplay Type\n\n1\n2\nVery Low\n\nSituation Awareness Scale\n3\n4\n5\n6\n7\nSomewhat Low\nSomewhat High\n\n8\n\nFigure 42. Mean pilot situation awareness ratings versus display type\n\n54\n\n9\nVery High\n\n6.33\n\n6.08\n\nSize A\nPhotorealistic\n\nSize X\nGeneric\n\nSize X\nPhotorealistic\n\n6.165\n\nHUD\nPhotorealistic\n\n6.08\n\nHUD\nGeneric\n\n5.835\n\nSize A\nGeneric\n\nWorkload Rating\n\n9\n8\n7\n6\n5\n4\n3\n2\n1\n\nDisplay Type\n\n1\n2\nVery High\n\n3\n\nWorkload Scale\n4\n5\n6\n7\nSomewhat High\nSomewhat Low\n\n8\n\n9\nVery Low\n\nFigure 43. Mean pilot workload ratings versus display type\n\nSA-SWORD Ratings\nPilots were asked to complete a paired-comparison SA-SWORD (Vidulich & Hughes, 1991). The\nSA-SWORD for this experiment was designed to allow a statistical analysis of the pilot\xe2\x80\x99s subjective\nassessment of the situation awareness for each of the display configurations (Baseline, Size A Generic,\nSize A Photo-realistic, Size X Generic, Size X Photo-realistic, HUD Generic and HUD Photo-realistic).\nFor this exercise, SA was defined as: The pilot\xe2\x80\x99s awareness and understanding of all factors that will\ncontribute to the safe flying of their aircraft under normal and non-normal conditions.\nThe responses were averaged and the overall rank order was: Size X Photo-realistic, Size X Generic,\nHUD Photo-realistic, Size A Photo-realistic, Size A Generic, HUD Generic, and Baseline. An ANOVA\nwas performed on the mean rankings with display type and pilot as the independent variables. Display\ntype (F(6,18)=6.968, p<.001) was highly significant for this measure. Post hoc tests (using SNK with\n\xce\xb1=.05) showed that the Size X Photo-realistic had significantly higher SA-SWORD ratings than all other\nSVS display concepts except for Size X Generic. Three distinct, overlapping subsets (see fig. 44) were\nformed: 1) Size X Photo-realistic & Size X Generic; 2) Size X Generic & HUD Photo-realistic; and 3)\nHUD Photo-realistic, Size A Photo-realistic, Size A Generic, HUD Generic, & Baseline.\n\n55\n\nHigher SA\n\nSize X Photo\n\nSize X Generic\n\nLower SA\n\nHUD Photo\n\nSize A Photo\n\nSize A Generic\n\nHUD Generic\n\nBaseline\n\nNote: Any two concepts not underscored by the same line are significantly different.\nFigure 44. Comparative situation awareness among display concepts.\n\nPilot Comments\nVideo and audio recordings of each pilot were taken while they flew the two approaches and\ndepartures. In addition, each pilot\xe2\x80\x99s post-flight debriefing was recorded on audiotapes.\nThere were numerous comments on elements of the tunnel symbology but they will not be discussed\nhere as the emphasis of this flight test was on the presentation of terrain information. In summarizing\nthese pilot comments, the following themes emerged.\n1. All but one pilot felt that the NASA SVS HUD concepts were viable for presenting terrain\ninformation to the pilot. One pilot commented that it gave a significant improvement in\nsituation awareness over the Baseline EADI concept because of the terrain. Two of the pilots\nstated they would like the ability to toggle the terrain information on and off. The one\ndiffering pilot felt that a wireframe terrain HUD concept would be an improvement over the\nNASA HUD concepts because there are occasions when you want to see through the HUD\nraster image.\n2. For the HDDs, all pilots overwhelming preferred the larger size display (Size X). In fact,\nthree of the pilots commented that the Size X photo-realistic textured SVS concept provided\nthe most enhanced situation awareness of the concepts evaluated. The pilots also stated that\nsize (larger is better) is more important than the texturing method for the SVS concepts\nevaluated.\n3. For the HDDs, each pilot agreed that workload, situation awareness, and pilot interpretation of\nperformance parameters (e.g., airspeed, vertical speed information, etc.) was not affected by\nthe type of texturing, photo-realistic or generic, employed on the SVS concept. However, four\nof the pilots said that they would choose photo-realistic over generic texturing for each of the\nHDDs evaluated.\n4. Two of the pilots suggested that using both generic and photo-realistic texturing within one\ndatabase would have merit as each has its advantages. Photo-realistic texturing gives a pilot\nan excellent view of cultural features (hills, roads, vegetation) and would be useful near the\nairport during approaches and departures. Generic texturing shows a pilot the angular\nrelationship to the view of the terrain, thus enhancing the elevation cues, and would be useful\nwhen flying enroute segments.\n\n56\n\n5. Two of the pilots suggested placing waypoints with altitude information on the SVS primary\nflight displays. Then they could crosscheck with the Navigation Display when passing the\nwaypoints.\nOf particular interest was a comment made by one pilot after completing a Visual 07 approach with\nthe Size A Photo-realistic concept in simulated IMC:\n\xe2\x80\x9cI often commented to people over the years that I never ever flew a circling approach in the 141 that\nI was ever comfortable with, particularly at night. It always demanded a lot of attention. This was the\nfirst time I ever had an occasion of circling an approach with the kind of information I would love to have\nin a circling approach. Keeping me safe, I could see the terrain, taking me where I want to go, getting me\nall types of information in terms to where I am relative to the end of the runway. I mean it\xe2\x80\x99s the best of\nall possible worlds in terms of safety.\xe2\x80\x9c\n\n57\n\nDiscussion\nThe NASA AvSP SVS Project has been focused on developing new technologies that will mitigate, or\neven eliminate, visibility-induced accidents through the cost-effective use of synthetic vision displays.\nAdditionally, Synthetic Vision has been forecast to reduce FTE, increase RNP capabilities, and provide\nother significant economic benefits. Therefore, SVS has many rewards associated with its development\nand implementation. To achieve such considerable potential, research is needed to deliver products which\nfulfill these technology objectives. Moreover, the introduction of such an innovative display concept may\nhave unforeseen risks which requires data to safeguard the position that SVS supports \xe2\x80\x9chuman-centered\xe2\x80\x9d\ndesign. Past research has consistently demonstrated that SVS is a substantial improvement over current\ncockpit instrumentation, and no human factors shortcomings have been uncovered. However, because\none major objective of SVS is to enhance safety and operational capabilities in terrain environments,\ntesting at a terrain-challenged location - in this case, Eagle-Vail, Colorado - was warranted.\nThe NASA flight test had several objectives to demonstrate the potential of SVS technology. The\nobjectives of the research were:\na) Confirm the potential of the NASA SVS HUD concept as a retrofit solution for display of SVS\nconcepts in non-glass cockpits. Determine the potential in both day VMC and in day, lowvisibility operational environments.\nb) Confirm results from piloted simulation experiments and the SVS-DFW flight test for\noperational utility and acceptability of various-sized (Size A, X) head-down synthetic vision\ndisplays.\nc) Compare the operational utility and acceptability of photo-realistic textured with generic\ntextured terrain databases within the NASA SVS concepts (HUD; head-down Size A, X).\nd) Assess pilot path control performance (flight technical error) during manually flown landing\napproach and go-around maneuvers in a terrain-challenged operational environment, with and\nwithout SVS display concepts.\ne) Determine required navigation performance capabilities with SVS display concepts for area\nnavigation.\nf) Confirm the situation awareness and workload benefits of SVS display concepts.\ng) Provide demonstration of the economic potential of SVS for approaches that have significant\nrestrictions for current operations.\nThe NASA 757 ARIES experiment was designed to achieve these objectives. Six evaluation pilots\nflew eighty-four flight test runs to Runway 25 and Runway 07 at the EGE airport. Each of the pilots\nexperienced combinations of SVS display (HUD, HDD Size A, HDD Size X) and terrain texture (generic\nphoto-realistic) configurations, and was asked to compare these display concepts to Baseline displays\n(i.e., EADI with TAWS/ND). Overall, the results confirm most of a priori hypotheses (the exceptions are\nindicated as well), and the significant findings of the flight test are discussed in the following sections.\n\nPilot Performance\nIt was hypothesized that flight technical error (in terms of RMS path performance, rather than RNP\npercentiles) would be lower for the SVS display concepts compared to the Baseline because of increased\nsituation awareness and path control guidance afforded by using a flight path marker in conjunction with\n\n58\n\na pathway presentation (tunnel and guidance symbol). The significant main effects for both lateral and\nvertical path control showed that pilots performed the approaches with significantly lower RMS error\nusing the SVS displays compared to the Baseline display. On average, the Baseline lateral RMS error\nwas 818 feet and was significantly larger than the Size A (61 ft.), Size X (51 ft.) and HUD display\nconcepts (67 ft.). A similar result was found for vertical RMS error. Post-hoc analyses confirmed that\nthe Baseline vertical RMS error (147 ft.) was significantly larger than the SVS displays (~37 ft.). For\nboth lateral and vertical RMS error, post-hoc analyses did not find any significant differences across the\nSVS display concepts. Additionally, no significant differences were found for texture type or the\ninteraction between display size and texture type.\nAnalyses of RMS path performance for the individual segments, particularly for the critical final\napproach segments (segments 3 and 8), produced similar results. The most plausible reason for the\nfindings are that the manually-flown approaches using the Baseline display relied on raw path error (i.e.,\n\xe2\x80\x9cdogbone\xe2\x80\x9d) indicators and in some cases a dual cue flight director (only with the FMS25 approaches),\nwhile the SVS display concepts (in addition to the raw path error indicators) had a flight path marker and\na pathway presentation (tunnel and guidance symbol) that provided the pilot with additional path\nguidance feedback.\nThe pilot performance results described above confirm previous research (e.g., Comstock et al., 2001;\nGlaab et al., 2003) that SVS with precision guidance information can significantly reduce flight technical\nerror. Similar results have also been reported in numerous pathway research studies (e.g., Williams,\n2002) confirming the advantage of making manual approaches using a tunnel because of the added\nbenefits of (a) tunnel or commanded display, (b) flight path marker (i.e., velocity vector), (c) 3-D\nperspective along the pilot\xe2\x80\x99s forward viewing axis, and (d) guidance (e.g., \xe2\x80\x9cghost aircraft symbol\xe2\x80\x9d).\nResearch has long established the benefits of prediction and preview (e.g., Lintern, Roscoe, & Sivier,\n1990) and presentation of this information in a 3-D perspective (Haskell & Wickens, 1993; Parrish et al.,\n1994; Wickens & Prevett, 1995; Theunissen, 1997). Therefore, the finding that the SVS concepts, with\ntunnel information, yielded significantly improved pilot path performance compared to a Baseline\nconcept with no tunnel was not surprising. This result suggests the use of a \xe2\x80\x9cpathway-in-the-sky\xe2\x80\x9d as a\nbeneficial element in a synthetic vision system, and confirms the potential of these SVS concepts as\nretrofit candidates for replacing current displays with synthetic vision technology.\nThe other objective data hypotheses dealt with anticipated FTE differences between SVS display\nfeatures. It was anticipated that FTE performance would be directly related to the minification factor,\nwith better performance being achieved as minification approached unity (i.e., performance with the HUD\nwould be better than with Size X, which would be better than with Size A). While the results tend to\nsupport those hypotheses in the majority of cases, statistical significance was rarely obtained. Certainly\nno meaningful differences in terms of operational significance were found. The final objective data\nhypothesis dealt with texture effects, and it also was not supported by the results. Either method of\ntexturing produced equivalent FTE performance, regardless of HUD or HDD implementation. The\nrejection of these hypotheses is a verification of the SVS retrofit approach. That is, HUD or HDDs of any\nsize or texture method tested were equally effective means of implementing SVS concepts to achieve FTE\nbenefits.\n\nRequired Navigation Performance\nThe International Civil Aviation Organization (ICAO) Special Committee of Future Air Navigation\nSystem (FANS) developed a new concept based in terms of communication, navigation, surveillance, and\nair traffic management (CNS/ATM). Critical to achieving the benefits of CNS/ATM concept, aircraft\n\n59\n\nwill need to be able to achieve accurate, predictable, and repeatable navigation performance; this is\ntermed RNP. Minimum Aviation System Performance Standards (MASPS) have been established for\narea navigation in an RNP environment, and an important objective of the EGE flight test was to establish\nactual navigation performance and compare it to RNP MASPS (RTCA, 2000).\nIt was anticipated that the increased path precision provided by the tunnel presentation would enable\npilots to make manual approaches within RNP accuracies that normally require RNAV capabilities. The\nlateral navigation analyses confirmed that flight technical error for all the SVS display concepts achieved\nan accuracy of 0.05 nmi for at least 95% of the approach compared to just 0.25 nmi for the Baseline\ncondition. The vertical navigation analyses for the head-down (Size A, Size X) and head-up SVS\nconcepts paralleled these results in that those concepts achieved a vertical accuracy of 150 feet and 100\nfeet, respectively, at least 99.7% of the time which is better than the required vertical accuracy of 300\nfeet. Vertical path control with the Baseline EADI concept (which met required accuracy 89.0% of time)\nwas outside RNP permissible limits. Based on these results, therefore, synthetic vision would enable\nmanual RNP operations that are one-fifth as large for lateral RNP and within required vertical\nperformance accuracy values than similar operations with current 757 instruments. The outcome would\nbe an increase of RNP operations to runways that otherwise would not meet current MASPS, resulting in\na significant economic advantage to airlines employing SVS technology (Hemm, 2000; Hemm et al.,\n2001).\n\nPilot Preferences\nIt was hypothesized that pilots would prefer all SVS display concepts over the Baseline\nEADI/Navigation Display, and that, between SVS display concepts, pilot preferences would be directly\nrelated to the minification factor, with preference favoring minifications approaching unity (i.e., the HUD\npreferred over Size X, which would be preferred over Size A). The only formal assessment of pilot\npreferences utilized during the flight test was the SA-SWORD, which was actually a subjective\nassessment of the situation awareness for each of the display configurations. That assessment, which is\ndiscussed in detail in the next section, ranked the Size X concepts ahead of the HUD and Size A concepts,\nwith the Baseline concept ranked last. Informal pilot comments also ranked the Size X concepts as the\npreferred concept, and all SVS concepts were preferred over the Baseline. Thus the hypothesis\nconcerning preference favoring minifications approaching unity must be rejected.\n\nSituation Awareness\nTo achieve the national aviation objective of reducing visibility-induced accidents, perhaps the most\nimportant construct that needs to be examined with SVS is how it impacts the SA of the pilot. Therefore,\nseveral measures of situation awareness were gathered, in addition to pilot comments. Because of the\nnature of a flight test, there are limitations on the types of measures that may be employed. Objective\nmeasures of SA, such as SAGAT (Endsley, 1987), do not lend themselves well to the flight research\nenvironment. As a consequence, subjective measures of situation awareness were used in this flight test\nincluding the SA-SWORD pair-comparison technique (Vidulich & Hughes, 1991) and SA run questions.\nAfter each test run, evaluation pilots were asked to complete a post-run questionnaire that included\nseveral questions about terrain awareness while flying the approaches. In general, the results suggest that\nthe SVS display provided for greater terrain awareness than the Baseline EADI. Furthermore, the Size A\nphoto-realistic, Size X generic, and Size X photo-realistic display concepts were rated higher in terrain\nawareness than the other SVS display concepts. Therefore, although synthetic vision was significantly\nbetter for pilots with regard to knowledge of terrain and aircraft position, Size A generic and the HUD\n\n60\n\nconcepts did not afford the same level of terrain awareness. However, during the semi-structured\ninterview, follow-up questions about situation awareness resulted in a non-significant finding across SVS\ndisplay concepts. The ratings of SA (0 to 9) ranged from 6.415 (HUD generic) to 7.83 (Size A, photorealistic), but were not significantly different statistically from one another. Despite representing the\nsame trend in responses as the post-run questionnaire, the post-experimental debriefings showed that all\npilots felt that each of the SVS display concepts provided adequate situation awareness and, in all cases,\nwas better than the Baseline condition.\nIn addition to the post-run and post-experiment questionnaires, each evaluation pilot completed the\nSA-SWORD that allows for paired comparison of each display concept for situation awareness. There\nwas a significant effect found and the ranked order of the displays were: Size X Photo-realistic, Size X\nGeneric, HUD Photo-realistic, Size A Photo-realistic, Size A Generic, HUD Generic, and Baseline. The\npost-hoc analyses revealed that pilots rated the Size X photo-realistic to provide greater situation\nawareness than all other SVS and Baseline concepts with the exception of Size X generic. Therefore,\ndisplay size seems to be the primary factor determining the SA rankings, although the photo-realistic\ntexture was consistently ranked higher within each display concept. Pilot comments would support this\nconclusion as many of the pilots felt that the Size X photo-realistic display concept provided the greatest\nsituation awareness, but that Size X generic provided an almost equal degree of SA enhancement. All\npilots agreed that size was more important than the texturing method although four of the pilots noted\nthey would chose photo-realistic if given a choice. However, while most of the evaluation pilots did not\ndiscern a considerable advantage of either texture method, several pilots noted that each of the two\ntexturing methods provided different information. For example, the photo-realistic texturing gave pilots\nexcellent information about cultural features and was helpful for approach and departure segments.\nGeneric texturing, on the other hand, showed pilots the angular relationship to the view of the terrain and\nwas postulated to be useful for enroute segments. Two of the six pilots suggested that photo-realistic and\ngeneric should be combined into one database to take advantage of the benefits provided by both.\nThe above discussion provides the validation of all of the stated a priori hypotheses concerning the\nsituation awareness properties associated with size and texturing methods of the SVS concepts. More\nimportantly, the hypothesis that all SVS display concepts would be rated higher in situation awareness\nthan the Baseline EADI/Navigation Display is clearly upheld.\n\nWorkload\nAnother objective of synthetic vision is to reduce mental workload of the pilot. Because SVS presents\nboth natural and coded information to the pilot, it is postulated that it will both increase situation\nawareness and also reduce pilot workload by integrating often disparate pieces of information. Once\nagain, the a priori hypotheses concerning workload included both that workload ratings would be\nsignificantly lower for all SVS display concepts compared to the Baseline EADI/Navigation Display, and\nthat, within the SVS concepts, workload ratings would be directly related to the minification factor, with\nlower workload associated with minifications approaching unity (i.e., the HUD lower than Size X lower\nthan Size A).\nAfter each test run, evaluation pilots were asked to complete a post-run questionnaire that included a\nquestion assessing workload experienced while flying the approaches. The results were a significant\nmain effect for display type, and pilots rated the Baseline condition to be significantly higher in mental\nworkload compared to the SVS concepts. No significant differences were found for either display size or\ntexture type and, therefore, pilots rated the workload equally across the SVS concepts. The post-run\nquestionnaire results paralleled those found for the post-flight results. Thus the hypothesis concerning\n\n61\n\nworkload being directly related to minification factor must be rejected, while the overall SVS hypothesis\nis fully supported.\nAll pilots ranked the Baseline condition to be significantly higher in workload and lower in SA than\nthe SVS concepts, which were all given low workload and moderate to high SA ratings. These results\nconfirm previous research (e.g., Comstock et al., 2001; Glaab et al., 2003; Stark et al., 2001) documenting\nthat synthetic vision has the potential to significantly reduce workload demands and, consequently,\nincrease both the safety and efficiency of aircraft operations. In addition, these results appear to indicate\nthat the SVS displays evaluated are approaching the goal of true human-centered design, which is high\nsituation awareness and low workload for the pilot.\n\nMinification Hypotheses\nPrior testing at DFW had thoroughly examined pilot selectable FOV and display size effects for\nHDDs, finding that as range to touchdown decreased, the minification factor moved toward unity (i.e., no\nminification) and that as display size increased, the minification factor also moved toward unity.\nCombining those results with the facts that the SVS HUD concept (with unity minification) had provided\nequal, if not superior, pilot/vehicle tracking performance, and superior subjective ratings, compared to the\nHDDs, led to the postulation of the hypotheses concerning enhanced performance being directly related to\nminification factor (with improvements in FTE, Pilot Preference, and Workload favoring minifications\napproaching unity). In contrast to those results obtained in nighttime testing at DFW, where the\nevaluation pilots stated that they preferred the HUD to the HDD concepts, and on which the a priori\nhypotheses concerning enhanced performance being directly related to minification factor were based, the\nEGE results rejected those hypotheses (FTE, Pilot Preference, and Workload). The rejections were based\non HUD ratings in daylight operations.\nAs at DFW, the SV-HUD concept was, for all intents, just a monochromatic green representation of\nthe full-color, head-down display SV concept, using an RS-343 video format. No effort was expended to\nexamine graphical light source or other terrain shading issues. In addition to the terrain presentation, the\npathway guidance symbology was also presented in raster format (stroke presentation would have been\npreferred, but programmable stroke symbology was not available).\nAs a result, two significant deficiencies were encountered: illegible display renditions under some\ndirect sunlight conditions and some reported terrain depiction illusions. These deficiencies are discussed\nbelow.\nPilot comments from the EGE flight trials indicated that there were instances where the sun angle\nwashed out the SV HUD image and rendered the SV image unusable. To achieve the benefits of SV\nusing the HUD, the SV raster image must be legible and useable in all foreseeable ambient background\nconditions. A "useable display" can be defined using many different figures of merit, but in the case of\nthe raster HUD, contrast ratio has been specified as the figure of merit. Bailey (2002) specifies that the\nHUD contrast ratio requirement for a generic or photo-realistic terrain textured SVS raster HUD\nimplementation to be on the order of 5.5. This contrast ratio value was achieved only when the ambient\nbrightness was below 750 ft-L. In higher ambient lighting situations, the contrast ratios were less than\nthis requirement (given the finite maximum HUD brightness capability) and some raster scene details\nwere washed out by the ambient light.\nSome pilots in the EGE flight test reported an occasional inversion illusion with the synthetic terrain\nHUD image, in that, at one particular point, they would interpret a valley as a ridge, and a ridge as a\n\n62\n\nvalley. Post-flight image evaluations and experimentation with graphic light source sun angles while\ngenerating the monochrome terrain database appeared to eliminate the problem as discussed in Bailey\n(2002).\nThese two deficiencies were not apparent at DFW, and appear to have significantly affected the EGE\nresults for FTE, Pilot Preference, and Workload. The FTE effects are attributed to occasional loss of\nguidance symbology, while the subjective data effects are attributed to both deficiencies. In spite of these\ndeficiencies, the SVS HUD concepts performed as well as the HDD concepts all of which was vastly\nsuperior to present-day cockpit display technology.\n\nConclusions\nThe NASA Synthetic Vision Eagle-Vail flight test provided a considerable amount of valuable\nresearch data that have enabled crew systems researchers to significantly improve upon SVS display\nconcepts. The SVS Project of Aviation Safety Program is striving to eliminate poor visibility as a causal\nfactor in aircraft accidents as well as enhance operational capabilities of all aircraft through the display of\ncomputer generated imagery derived from an onboard database of terrain, obstacle, and airport\ninformation. The goal of the flight test conducted at EGE was to extend the assessment of the SVS\nretrofit approach to operations in a terrain-challenged operational environment with testing in daytime\nconditions. EGE represented an ideal location to test the effectiveness of SVS technologies for terrain\nawareness and separation for approaches and departures that put the aircraft close to mountainous terrain.\nAll of the aforementioned flight test objectives were successfully achieved. The flight test was\nconducted to evaluate three SVS display types (Head-up Display, Head-Down Size A; Head-Down Size\nX) and two terrain texture methods (photo-realistic, generic) in comparison to the simulated Baseline\nBoeing-757 Electronic Attitude Direction Indicator and Navigation / Terrain Awareness and Warning\nSystem displays. These independent variables were evaluated for path error, situation awareness, and\nworkload while making approaches to Runway 25 and 07 and during simulated engine-out Cottonwood 2\nand KREMM departures. The results of the experiment showed significantly improved performance,\nsituation awareness, and workload for SVS concepts compared to the Baseline displays and confirmed the\nretrofit capability of the Head-Up Display and Size A SVS concepts. The research also demonstrated that\nthe tunnel guidance display concept used within the SVS concepts achieved RNP criteria.\nSpecific results of the study using objective data were:\n1. FTE performance, both laterally and vertically, was significantly lower when using the SVS\ndisplays compared to the Baseline display.\n2. Within the SVS concepts, FTE performance was not directly related to the minification factor,\nwith better performance being achieved as minification approached unity (i.e., performance\nwith the HUD would be better than with Size X, which would be better than with Size A).\nWhile the results tended to support that hypothesis in the majority of cases, statistical\nsignificance was rarely obtained. Certainly no meaningful differences in terms of operational\nsignificance were found.\n3. No significant texture effects were found within the objective data. Either method of texturing\nproduced equivalent FTE performance, regardless of HUD or HDD implementation.\n4. The actual navigation performance results showed that synthetic vision (HUD or HDD) would\nenable manual RNP operations that are five times smaller for lateral RNP and within required\nvertical performance accuracy values than similar operations with current 757 instruments.\n\n63\n\nThe outcome would be an increase of RNP operations to runways that otherwise would not\nmeet current MASPS, resulting in a significant economic advantage to airlines employing\nSVS technology.\nThese objective data findings are a strong verification of the SVS retrofit approach. That is, HUD or\nHDDs of any size or texture method tested were an equally effective means of implementing SVS\nconcepts to achieve FTE and RNP benefits.\nSpecific results of the study using subjective data were:\n5. All pilots ranked the Baseline condition to be significantly higher in workload and lower in\nSA than the SVS concepts, which were all given low workload and moderate to high SA\nratings.\n6. While larger display sizes were preferred, effective applications of SVS display technology\ncan be accomplished in aircraft equipped with HDDs as small as Size-A (5.25 in. wide by 5 in.\ntall) with selectable FOV techniques.\n7. In contrast to the results obtained in nighttime testing at DFW, the EGE evaluation pilots\nstated that they preferred the HDD concepts to the HUD concept. Also the a priori hypotheses\nconcerning enhanced performance being directly related to minification factor (with\nimprovement favoring minifications approaching unity), which were based on the DFW\nresults, were rejected by the EGE results. The rejections were based on HUD ratings in\ndaylight operations. Two specific HUD deficiencies were identified, and proposed solutions\nto each have been presented.\nThese subjective data results indicate that the SVS displays evaluated are approaching the goal of true\nhuman-centered design, which is high situation awareness and low workload for the pilot.\nThe top-level results of the EGE flight test concerning the improved path performance, enhanced\nsituation awareness, and lower associated workload provided by all of the SVS (HDD and HUD)\nconcepts, regardless of display size, are highly significant. These results firmly establish the SVS retrofit\nconcept approach as viable.\n\nFuture Directions\nThe NASA Synthetic Vision Eagle-Vail flight test provided a considerable amount of valuable\nresearch data that have enabled crew systems researchers to significantly improve upon SVS display\nconcepts. To date, several findings of the flight test have been incorporated into development of future\nembodiments of synthetic vision. For example, several pilots suggested that photo-realistic and generic\ntexturing should be combined together to achieve the best that each method has to offer, and the SVS\nProject has developed a new hybrid texture method that meets that goal. Also, the research uncovered\nseveral issues that were unknown before research commenced. These include the usability of raster on\nthe HUD and the presentation of the \xe2\x80\x9ccrow\xe2\x80\x99s feet\xe2\x80\x9d minimal tunnel symbology set that was leveraged from\nearlier High-Speed Civil Transport research at NASA LaRC. Several changes have been made to resolve\nthese issues, such as development of several new tunnel concepts and modifications to the HUD to render\nall symbology in stroke and render the terrain in the raster channel.\nRockwell-Collins, a NASA industry partner, is employing a fish-net (grid) presentation of the terrain for\ntheir Synthetic Vision HUD concepts. The fish-net or grid presentation is a high-contrast raster image\nwhich should be legible throughout all ambient background luminance ranges since it mimics strokewritten symbology. Rockwell-Collins testing has also developed methods to ameliorate one of the past\n\n64\n\nproblems with fish-net type displays \xe2\x88\x92 the annoying and distracting bright area caused by the confluence\nof edgelines in valleys or vanishing points. The United States Air Force has found an Air Force pilot\npreference for the fish-net or grid format (Snow, 2001), especially when used in combination with an\nEVS image (Rate, 1984).\nDirect comparisons between a fish-net and synthetic terrain HUD format were not conducted, but\nfuture NASA efforts are being directed at evaluating a fish-net terrain overlay embedded within Synthetic\nVision terrain renditions. This approach is analogous to a fish-net synthetic terrain image combined with\nEVS. The theory is that the high contrast fish-net depiction will be noticeable and readable during all\nambient lighting conditions, yet in lower ambient lighting conditions, the Synthetic Vision terrain\ndepiction will be viewable to provide a high fidelity, unambiguous scene for terrain and obstacle\nawareness.\nDespite the progress made to address human factors research issues, research is still needed to ensure a\n\xe2\x80\x9chuman-centered\xe2\x80\x9d synthetic vision system. In addition to the efforts described above, crew systems\nresearchers have been actively involved in improving upon and developing new concepts. These are part\nof a suite of R&D activities that form the future directions that the SVS Project is taking.\nPrevious flight tests of SVS have primarily focused on the general use and usefulness of SVS for\nproviding flight critical guidance and improved situational awareness. The research objectives of these\nprevious flight tests were focused on the SVS display (e.g., size, content, and format) and on SVS\nenabling technologies (e.g., Runway Incursion Prevention Systems (RIPS), Enhanced Vision Systems\n(EVS), and Database Integrity Monitoring Equipment (DIME)). While differential GPS and on-board\ndatabases can provide the primary framework for an operational SVS, many in the aviation community\nbelieve that independent integrity monitors for both surveillance and navigational functions will be\nrequired to meet certification and safety requirements. This functionality will rely heavily on existing onboard sensors (e.g., weather radars, high quality radar altimeters) to provide real-time integrity monitoring\nfor the databases. Specifically, on-board integrity sensors will provide independent air-to-air, air-toground, ground-to-ground, and ground-to-air traffic and object surveillance, a runway incursion monitor\nand a confirmation of database integrity and registration (navigational position confirmation via terrain\nfeature extraction). Additionally, the requirements for augmenting SVS concepts with the independent\ncapabilities of weather-penetrating, enhanced vision imaging sensors during low visibility landing and\nsurface operations conditions should be explored. These technologies form the basis for monitoring the\ndynamic flight environment and thereby supplement the synthetic world with real-time, direct\nmeasurement of the surrounding terrain and air/ground traffic.\nA flight test evaluation is anticipated in 2004 by the NASA/LaRC under NASA\xe2\x80\x99s Aviation Safety,\nSynthetic Vision System Project to examine a synthetic vision system that integrates the enabling\ntechnologies (RIPS, EVS and DIME) of SVS. The research will focus on the integration of runway\nincursion prevention technologies, surface map displays, integrity monitoring, enhanced sensors,\nsynthetic vision navigation displays, and enhanced synthetic vision primary flight and HUD displays.\nTogether, such a synthetic vision system may considerably help meet national aeronautic goals to \xe2\x80\x9creduce\nthe fatal accident rate by a factor of 5\xe2\x80\x9d and to \xe2\x80\x9cdouble the capacity of the aviation system\xe2\x80\x9d both within 10\nyears (NASA, 2001).\n\n65\n\nBibliography\nArthur, J.J., Prinzel, L.J., Kramer, L.J., Bailey, R.E., and Parrish, R.V. (2003). CFIT Prevention\nUsing Synthetic Vision. SPIE. In Proceedings of SPIE, Enhanced and Synthetic Vision 2003, Editor:\nJacuqes G. Verly, Volume 5018 paper 16 Apr.\nBailey, R.E., Parrish, R.V., Kramer, L.J., Harrah, S., & Arthur, J.J. (2002). Technical Challenges\nin the Development of a NASA Synthetic Vision System Concept. Proceedings of the North Atlantic\nTreaty Organization (NATO) Symposium on Enhanced and Synthetic Vision Systems, Ottawa, Ontario:\nCanada.\nBillings, C.E. (1997). Aviation Automation: The Search for a Human-Centered Approach.\nMahway, NJ: Lawrence Erlbaum Associates\nBoeing (1996). Statistical summary of commercial jet aircraft accidents, Worldwide Operations,\n1959-1995. Seattle, WA: Airplane Safety Engineering, Boeing Commercial Airplane Group.\nBoeing (1998). Statistical summary of commercial jet aircraft accidents, Worldwide Operations,\n1959-1997. Seattle, WA: Airplane Safety Engineering, Boeing Commercial Airplane Group.\nComstock, J.R, Glaab L.J., Prinzel, L.J., & Elliot, D.M. (2001). Can effective synthetic vision\nsystem display be implemented on limited size display spaces. International Symposium on Aviation\nPsychology.\nDavis, R. (1957). The human operator as a single-channel information system. Quarterly Journal\nof Experimental Psychology, 9, 119-129.\nDepartment of Transportation (1997). White House Commission on Aviation Safety and\nSecurity: Final Report to President Clinton Washington, DC: DOT.\nDoherty, S.M., & Wickens, C.D. (2001). Effects of preview, prediction, frame of reference, and\ndisplay gain in the tunnel-in-the-sky displays. Proceedings of the 11th International Symposium on\nAviation Psychology. Columbus, OH: Ohio State University.\nEnders, J.H., Dodd, R., Tarrel, R., Khatwa, R., Roelen, A.L.C., & Karwal, A.K. (1996). Airport\nsafety: A study of accidents and available approach-and-landing aids. Flight Safety Digest, 1996(3), 136.\nEndsley, M.R. (1987). SAGAT: A methodology for the measurement of situation awareness\n(NOR DOC 87-83). Hawthorne, CA: Northrop.\nEndsley, M. (1988). Design and evaluation for situation awareness enhancement. Proceedings of\nthe Human Factors Society, 32, 97-101.\nGlaab, L.J., Kramer, L.J., Arthur, T., & Barry, J.S. (2003). Flight test comparison of synthetic\nvision display concepts at Dallas/Fort Worth International airport. NASA Langley Research Center:\nNASA Technical Paper TP-2003-212177.\nGopher, D., & Donchin, E. (1986). Workload: An examination of the concept. In K. Boff, L.\nKaufman, & J. Thomas (Eds.), Handbook of Perception and Human Performance (pp. 41-1 \xe2\x80\x93 41-48) New\nYork: Wiley.\nHaskell, I.D. and Christopher D. Wickens. Twoand Three-Dimensional Displays for Aviation: A\nTheoretical and Empirical Comparison. International Journal of Aviation Psychology 3, 2 (1993), 87-109.\nHemm, R.V. (2000). Benefit estimates of synthetic vision technology. Logistics Management\nInstitute Report NS002S1.\n\n66\n\nHemm, R.V., Lee, D., Stouffer, V., & Gardner, A. (2001). Additional benefit estimates of\nsynthetic vision technology. Logistics Management Institute Report NS014S1.\nJensen, R.S. (1995). Pilot judgment and crew resource management. Brookfield, VT: Ashgate\nPublishing.\nKlein, G.A. (1993). Sources of error in naturalistic decision making. Proceedings of the Human\nFactors Society, 37, 368-371.\nKramer, L.J., Prinzel, L.J., Bailey, R.E., & Arthur, J.J. (2003). Synthetic vision enhances\nsituation awareness and RNP capabilities for terrain-challenged approaches. Proceedings of the\nAmerican Institute of Aeronautics and Astronautics Third Aviation Technology, Integration, and\nOperations Technical Forum, AIAA 2003-6814, 1-11.\nLadkin, P. B. (1997). Risks of technological remedy. Communications of the ACM, 40, 160.\nLintern, G., Roscoe, S.N., & Sivier, J.E. (1990). Display principles, control dynamics, and\nenvironmental factors in pilot training and transfer. Human Factors, 32, 299-317.\nMerrick, V.K. & Jeske, J.A. (1995). Flightpath synthesis and HUD scaling for V/STOL terminal\narea operations. NASA Langley Research Center: NASA Technical Memorandum TM-1995-110348.\nMiller, G.A. (1956). The magical number seven, plus or minus two: Some limits on our capacity\nfor processing information. Psychological Bulletin, 63, 81-97.\nMoroze, M. and Snow, M. (1999). Causes and remedies of controlled flight into terrain in\nmilitary and civil aviation. 10th International Aviation Psychology Symposium, Columbus, OH, Ohio\nState University.\nNational Aeronautics and Space Administration (2001). Aerospace Technology Enterprise.\nWashington, D.C.: NASA.\nNorman, R.M. (2001). Synthetic Vision Systems (SVS) description of candidate concepts\ndocument. NASA Contract Report for NAS1-20342. Long Beach, CA: Boeing Company.\nParasuraman, R., & Riley, V. (1997). Humans and automation: Use, misuse, disuse, and abuse.\nHuman Factors, 39, 230-253.\nParasuraman, R., Sheridan, T.B., K& Wickens, C.D. (2000). A model for types and levels of\nhuman interaction with automation. IEEE Transactions on Systems, Man, and Cybernetics \xe2\x80\x93 Part A:\nSystems and Humans, 30(3), 286-297.\nParrish, R.V., Busquets, A.M., Williams, S.P. & Nold, D.E. (1994). Spatial Awareness\nComparisons Between Large-Screen, Integrated Pictorial Displays and Conventional EFIS Displays\nDuring Simulated Landing Approaches. NASA Technical Paper 3467. Hampton, VA: NASA Langley\nResearch Center.\nRate, C., Probert, A., Wright, D., Corwin, W.H., & Royer, R. (1984). Subjective Results of a\nSimulator Evaluation Using Synthetic Terrain Imagery Presented on a Helmet-Mounted Display. SPIE\nProceedings Helmet- and Head-Mounted Display and Symbology Design Requirements, Vol. 2218, 306315.\nRTCA (2000). Minimum Aviation System Performance Standards: Required Navigation\nPerformance for Area Navigation (RTCA DO-236A). Washington, D.C.: RTCA, Incorporated.\nSarter, N.B., & Woods, D.D. (1991). Situation awareness: A critical bull ill-defined\nphenomenon. International Journal of Aviation Psychology, 1, 45-57.\nSnow, M. P., & French, G. A. (2001) Human Factors In Head-Up Synthetic Vision Displays,\nProceedings of the 2001 World Aviation Safety Conference, Society of Automotive Engineers, 26412652.\n\n67\n\nSnow, M.P., & Reising, J.M. (1999). Effect of pathway-in-the-sky and synthetic terrain imagery\non situation awareness in a simulated low-level ingress scenario. Wright-Pattern Air Force Base: Air\nForce Research Laboratory,\nStark, J., Comstock, J.R., Prinzel, L.J., Burdette, D, & Scerbo, M.W. (2001). A preliminary\nexamination of situation awareness and pilot performance in a synthetic vision environment. Proceedings\nof the Human Factors & Ergonomics Society, 45, 40-43.\nTheunissen, E. (1997). Integrated design of a man-machine interface for 4-D navigation.\nNetherlands: Delft University Press.\nVidulich, M.A & Hughes, E.R. (1991). Testing a subjective metric of situation awareness.\nProceedings of the Human Factors & Ergonomics Society 35th Annual Meeting, 1307-1311.\nVidulich, M. (1994). Cognitive and performance components of situation awareness: SAINT\nteam task one report. In M. Vidulich, C. Dominquez, E. Vogel, & G. McMillian (Eds.), Situation\nawareness: Papers and annotated bibliography (AL/CF-TR-1994-0085; pp. 17-28). Wright-Patterson Air\nForce Base, OH: Armstrong Laboratory.\nWickens, C.D., and Prevett, T. (1995). Exploring Dimension of Egocentricity in Aircraft\nNavigation Display: Influence on Local Guidance and Global Situation Awareness. Journal of\nExperimental Psychology: Applied, 1, 110-135.\nWiener, E. L. (1977). Controlled flight into terrain accidents: System-induced errors. Human\nFactors, 19, 171-181.\nWilliams, D., Waller, M., Koelling, J., Burdette, D., Doyle, T., Capron, W., Barry, J., & Gifford,\nR. (2001). Concept of operations for commercial and business aircraft synthetic vision systems. NASA\nLangley Research Center: NASA Technical Memorandum TM-2001-211058.\nWilliams, K.W. (2002). Impact of aviation highway-in-the-sky displays on pilot situation\nawareness. Human Factors, 44, 18-27.\n\n68\n\nAppendix A. Synthetic Vision Systems Project Background\nBackground\nIn August 1996, following the wake of several commercial transport accidents that raised the level of\npublic awareness, a White House Commission on Aviation Safety and Security was established to study\nmatters involving these pertinent issues. The Commission\xe2\x80\x99s findings (Department of Transportation,\n1997) concluded that although the worldwide commercial aviation major accident rate is low and has\nbeen nearly constant over the past two decades, increasing traffic over the years has resulted in an\nincrease in the absolute number of accidents. The demand for air travel is expected to increase over the\ncoming two decades, more than doubling by 2017. Without an improvement in the accident rate, such an\nincrease in traffic volume would lead to a projected 50 or more major accidents a year worldwide - a near\nweekly occurrence. Given the very tragic, and damaging effects of a single major accident, this situation\ncould become an unacceptable blow to the public\xe2\x80\x99s confidence in the aviation system. As a result, the\nanticipated growth of the commercial air-travel market would not reach its full potential. In February\n1997, in response to the Commission\xe2\x80\x99s recommendations, President Clinton set a national goal to reduce\nthe aviation fatal accident rate by 80% within ten years.\n\nNASA Agency Role\nA high priority national challenge is to ensure U.S. leadership in aviation in the face of growing air\ntraffic volume, new safety requirements, and increasingly stringent noise and emissions standards. NASA\nhas a successful history of leading the development of aggressive high payoff technology in high-risk\nareas, ensuring a proactive approach is taken to developing technology that will both be required for\nmeeting anticipated future requirements, and for providing the technical basis to guide policy by\ndetermining feasible technical limits. Therefore, NASA created the Aviation Safety Program (AvSP) to\naddress the President\xe2\x80\x99s national aviation safety goal. NASA sponsored a major program planning effort\nto gather input from the aviation community regarding the appropriate research to be conducted by the\nAgency. The NASA Aviation Safety Investment Strategy Team (ASIST) held four industry- and\ngovernment-wide workshops to define and recommend research areas which would have the greatest\npotential impact for reducing the fatal accident rate. NASA then redirected existing research and\ntechnology efforts and formulated new ones to address the safety needs defined by ASIST (Norman,\n2001).\nOne of the significant recommendations from ASIST was to establish a project to eliminate visibilityinduced errors for all aircraft through the cost-effective use of synthetic/enhanced vision displays,\nworldwide terrain databases, and global positioning system (GPS) navigation. Therefore, the Associate\nAdministrator for Aerospace Technology, Spence Armstrong, signed the Project Formulation\nAuthorization for the Synthetic Vision Systems Project.\n\nNASA Synthetic Vision Research Project\nNASA stepped up to the challenge of eliminating visibility-induced accidents by forming the AvSP\nSynthetic Vision Systems (SVS) Project. Limited visibility is the single most critical factor affecting both\nthe safety and capacity of worldwide aviation operations. In commercial aviation alone, over 30-percent\nof all fatal accidents worldwide (Boeing, 1996) are categorized as controlled flight into terrain (CFIT),\nwhere a mechanically sound and normally functioning airplane is inadvertently flown into the ground,\nwater, or an obstacle, principally due to the lack of outside visual reference and situation awareness (SA).\nAnother type of accident involving restricted visibility combined with compromised situational awareness\n\n69\n\nis runway incursions. The AvSP SVS Project is developing technologies with practical applications that\nwill eliminate low visibility conditions as a causal factor to civil aircraft accidents, as well as replicate the\noperational benefits of flight operations in unlimited ceiling and visibility day conditions, regardless of\nthe actual outside weather or lighting condition. The technologies will emphasize the cost-effective use\nof synthetic/enhanced-vision displays; worldwide navigation, terrain, obstruction, and airport databases;\nand GPS-derived navigation to eliminate \xe2\x80\x9cvisibility-induced\xe2\x80\x9d (lack of visibility) errors for all aircraft\ncategories. A major thrust of the SVS Project is to develop and demonstrate affordable, certifiable\ndisplay configurations which provide intuitive out-the-window terrain and obstacle information, including\nguidance information for precision navigation and obstacle/obstruction avoidance for commercial and\nbusiness aircraft.\nThe ultimate goal of the SVS Project is to eliminate low visibility as a causal factor of civil aircraft\naccidents as recommended by the ASIST team, which would significantly help achieve national aviation\nsafety goals. In addition, SVS may increase the efficiency of the National Airspace System by allowing\nprecision Instrument Meteorological Conditions (IMC) operations, which presently require extensive\nground infra-structure, such as Instrument Landing Systems (ILS), to many more runways than are\npermitted today by providing safer operations and lower weather minimums (i.e., Category I, II, IIIa, IIIb)\nfor landing at non-ILS-equipped airports.\nThe SVS Project is taking the approach of employing a visual-based solution to overcome reduced\npilot situation awareness caused by limited outside visibility. As a part of the SVS Project, the Synthetic\nVision Display Concepts (SVDC) group focuses on SVS applications for commercial and business\naircraft by designing, developing and implementing SVS display concepts for flight test and simulation\nevaluations and by conducting subsequent research activities. These SVS displays will provide the pilot\nwith a clear view of the outside world through the application of sensors, such as Forward-Looking InfraRed (FLIR), Radar, and Millimeter-Wave technologies; navigation and terrain databases; and\ncomputational subsystem components, such as image object detection and symbology generation.\n\n70\n\nAppendix B. Theoretical Foundations of Synthetic Vision Systems\nIt is highly unlikely that conventional display concepts can significantly increase safety as new\nfunctionality and new technology cannot simply be layered onto previous design concepts since the\ncurrent system complexities are already too high (Theunissen, 1997). Better human-machine interfaces\nrequire a fundamentally new approach. One such approach applies the fundamental advantage of\nperspective flight path displays relative to conventional displays. Rather than commanding the pilot what\nto do, or at best showing only the error with respect to the desired trajectory, guidance and navigation\ndisplays can now provide information about the margins within which the pilot is allowed to operate.\nThese displays are augmented to show such information as spatial constraints and terrain constraints,\nrather than just showing conventional flight director commands, which only indicate an error, seemingly\nindependent of the actual constraints. These additional display elements provide guidance that does not\nforce the pilot to apply a continuous compensatory control strategy. Only in this way can human\nflexibility be exploited. This is a fundamental difference between current and synthetic vision systems\n(SVS) displays \xe2\x80\x93 that synthetic vision embodies the concept of \xe2\x80\x9chuman-centered\xe2\x80\x9d design by providing\nnatural versus coded information to the pilot (Theunissen, 1997).\nHuman-Centered SVS Displays. The term, \xe2\x80\x9chuman-centered\xe2\x80\x9d, is used to define an approach that\ndesigns to accommodate the human user in contrast to the more common \xe2\x80\x9ctechnology-centered\xe2\x80\x9d\napproach. The rapid advance of technology in the cockpit has had an unintended consequence of\nisolating the pilots and decreasing their situation awareness by increasing systems complexity, reducing\ncrew-vehicle coupling, enhancing system autonomy, and reducing systems feedback (Billings, 1997).\nEssentially, layers of technology have removed the pilots from aircraft control, leading to the \xe2\x80\x9cout-of-theloop\xe2\x80\x9d problem. A number of researchers have proposed a set of principles of human-centered design.\nBillings (1997) offered the following that are relevant to SVS:\nPremise:\nAxiom:\nCorollaries:\n\nThe pilot bears the responsibility for safety of flight\nPilots must remain in command of their flights\nPilots must be actively involved\nPilots must be adequately informed\nPilots must be able to monitor the system assisting them\n\nThe use of the human-centered design perspective has important implications for the reduction of\nvisibility-induced accidents. Past technologies have been developed with the intended purpose of\nprevention of several accident categories attributed to low-visibility. For example, the Ground Proximity\nWarning System (GPWS) was introduced in 1973 and, despite initial problems with a high false alarm\nrate, the 10-30 second \xe2\x80\x9clook ahead\xe2\x80\x9d capability of the system has significantly improved the situation\nawareness (SA) of flightcrews. However, numerous accidents, such as the A-300 Thai Airlines (1992)\nand B-757 American Airlines (1995) accidents, show that the GPWS is not the final solution. The\nintroduction of the Enhanced GPWS (EGPWS) has mitigated some of the \xe2\x80\x9cmisuse\xe2\x80\x9d and \xe2\x80\x9cdisuse\xe2\x80\x9d\n(Parasuraman & Riley, 1997) issues that confront GPWS. It provides for more warning time \xe2\x80\x93 up to 60\nseconds \xe2\x80\x93 and takes advantage of a worldwide digital terrain database and a color-coded display of the\nsurrounding terrain. Ladkin (1997) asserted that there is near unanimity of the acceptance that EGPWS\nhas improved aviation safety and reduced the incidences of controlled flight into terrain (CFIT).\nHowever, the use of technology generally follows the \xe2\x80\x9cwarn-act\xe2\x80\x9d model and, therefore, requires the\nflightcrew to be reactive rather than proactive. The technology provides a warning when theoretically the\nflightcrew has already lost spatial and situation awareness and must then perform an escape maneuver.\nAs Moroze et al. (1999) describe, the strategy may not be optimal given the reaction times required to\ninitiate the escape maneuver and the cognitive and naturalistic decision making constraints required to\n\n71\n\nadequately encode and assess the situation (i.e., situation assessment and action implementation;\nParasuraman, Sheridan, & Wickens, 2000). Essentially, then, EGPWS is a \xe2\x80\x9cwarning system\xe2\x80\x9d and doesn\xe2\x80\x99t\nsupport a human-centered design philosophy in the objective of reduction of CFIT accidents. Snow et al.\n(1999) declared that what is needed is an intuitive system that improves pilot situation awareness with\nrespect to spatial orientation in terms of terrain and flight path, and does not require the pilot to divert\nvisual attention and cognitive resources away from possible external events and primary flight reference;\nthat is, to provide a human-centered technology that can help prevent rather than just inform the\nflightcrews of a potential collision with terrain. The approach requires an understanding and exploitation\nof the unique information processing capability of flight crews and a design of the technology and\ninterface to accommodate perceptual and cognitive capabilities of the pilots \xe2\x80\x93 the difference between a\n\xe2\x80\x9cnatural\xe2\x80\x9d and a \xe2\x80\x9ccoded\xe2\x80\x9d display.\nTheunissen (1997) discussed the concept of natural versus coded information. Natural information\nimplies that the method of information acquisition by the pilot is similar to that experienced in Visual\nMeteorological Conditions (VMC) by looking out the window. Visual altitude judgment is an example of\nnatural information acquisition. Coded information implies some type of information presentation to the\npilot that requires interpretation to comprehend the actual value. An example of coded information is\ndigital radio altitude. Theunissen noted that it is very important to give the pilot information required to\nmaintain SA in low-visibility conditions and that natural information presentation is intuitive and able to\nbe perceived in a much more rapid manner than coded information. SVS displays provide a natural\npresentation of the outside world with information that is intuitive and easy to process.\n\n72\n\nAppendix C: Situation Awareness and Workload in Relation to Synthetic\nVision Systems\nSituation Awareness and SVS. There are numerous definitions of situation awareness (SA) and what\nit best represents. Sarter and Woods (1991) defined it as, \xe2\x80\x9caccessibility of a comprehensive and coherent\nsituation representation which is continuously being updated in accordance with the results of the\nrecurrent situation assessments.\xe2\x80\x9d Vidulich (1994) defined SA as, \xe2\x80\x9cthe capability to appropriately assess\nyourself, your system, and your environment in order to make the right decision at the right time.\xe2\x80\x9d\nEndsley (1988), in contrast, stated that SA is comprised of three levels: \xe2\x80\x9cthe perception of the elements of\nthe environment within a volume of time and space [Level 1], the comprehension of their meaning [Level\n2], and the projection of their status in the near future [Level 3].\xe2\x80\x9d Because there are so many definitions\nof what SA is, Wickens (1995) offered up a consensus definition which he proposes as: \xe2\x80\x9cSituation\nawareness is the continuous extraction of environmental information about a system or environment, the\nintegration of the information with previous knowledge to form a coherent mental picture, and the use of\nthat picture in directing further perception, anticipating and responding to future events.\xe2\x80\x9d A synthetic\nvision system, therefore, has significant potential to improve situation awareness by fostering and\ndeveloping a \xe2\x80\x9cpicture\xe2\x80\x9d, both figuratively and literally, of the environment and presenting that picture so\nthat a pilot could \xe2\x80\x9cstay ahead\xe2\x80\x9d of the aircraft and maintain an accurate mental model.\nWorkload and SVS. Workload and situation awareness are related but are distinct psychological\nconstructs and, therefore, have different theoretical implications for the design of a synthetic vision\nsystems (SVS) display. Endsley (1988) noted that SA and workload could be differentiated through the\neffects on the pilot due to variations in task, system operation, or individual differences. She described\nthat there are four extremes in which there is a \xe2\x80\x9cdissociation\xe2\x80\x9d between the two measures:\nlow SA and low workload can arise because of inattentiveness and low motivation;\nlow SA and high workload can lead to a loss of SA because the volume of information and\ntask demands tax the ability of the pilot to keep up with the current information and properly\nanalyze data significance;\nhigh SA and high workload often confronts flight crews wherein the task demands are great\nbut the pilots work hard to manage the task situation; and\nhigh SA and low workload wherein flight crews are provided with the right information at the\nright time and in the right amount \xe2\x80\x93 the goal of true human-centered design and one that an\nSVS display as part of a human factored system could engender.\nDefinitions of workload are as numerous as definitions of situation awareness. Davis (1957) stated\nthat, "paying attention to an object or an activity is regarded as imposing a measurable cost upon limited\ninformation processing resources which varies with the amount of attention paid, or the degree of\n\xe2\x80\x98intensive\xe2\x80\x99 attention. The processing of attention by the nervous system depends first upon the quality of\nthe stimulus input, second upon the availability of mental structures to perform the mental operations\nnecessary for processing the input, and third upon a supply of mental resources or capacity which\nprovides the energy required for those operations to be carried out." There are a number of theories (e.g.,\nconfusion theory, single undifferentiated capacity theory, multiple resource theory) and measurement\ntechniques (i.e., primary, secondary, physiological, and subjective) of workload.\nThe difference between the amount of cognitive resources available to perform a task and the\n\n73\n\ndifficulty of the task determines how much mental workload the pilot or flight crew experiences. Gopher\net al. (1986) stated that, \xe2\x80\x9cMental workload may be viewed as the difference between the capacities of the\ninformation processing system that are required for task performance to satisfy performance expectations\nand the capacity available at a given time.\xe2\x80\x9d The construct of mental workload, therefore, is partly\n\xe2\x80\x9chardware\xe2\x80\x9d (e.g., channel capacity) and partly \xe2\x80\x9csoftware\xe2\x80\x9d (e.g., situational cognitive appraisal). Pilots are\nconstantly confronted with new information that they have to recognize, encode, synthesize, decide upon\nproper course of actions to take, and then implement the action sequence to effectuate the activated\ndecision node. Miller (1956) and information theory literature show that the channel bandwidth is limited\nto 5 \xe2\x80\x93 9 \xe2\x80\x9cchunks\xe2\x80\x9d of information. There are considerable individual differences amongst pilots in\nstrategies used, experiences, skills, motivations, responsiveness, and cognitive and resource management\nabilities. These differences can determine what constitutes a "chunk" (e.g., Miller, 1956) and whether the\ncollective resources of the flight crew will be taxed, leading to increased mental workload. As the pilots\xe2\x80\x99\ncapabilities to manage the task situation are exceeded, the mental workload induced can lead to\nperformance deficits. Furthermore, research has shown that as mental workload increases, task\nsaturation, peripheralization, tunneling, and other outcomes significantly hinder a flight crews\xe2\x80\x99 ability to\nadequately do situation assessment, cross-checking, and hypothesis generation. Flight crews, confronted\nwith high mental workload situations, often get \xe2\x80\x9cbottled in\xe2\x80\x9d to a single solution and fail to be able to \xe2\x80\x9cstay\nahead of the aircraft\xe2\x80\x9d (i.e., Level III situation awareness; see Endsley, 1987) and perform projective\nmanagement of the requirements to aviate, navigate, and communicate (Endsley, 1988; Klein, 1993;\nJensen, 1995). Often, the flight crews get \xe2\x80\x9cled down the garden path\xe2\x80\x9d and get further and further behind\nthe aircraft until they can no longer manage the task environment and understand state events, putting the\naircraft into a dangerous and sometimes unrecoverable situation. SVS, therefore, could significantly\nmitigate a high workload situation by providing information in a natural, intuitive format that doesn\xe2\x80\x99t tax\nthe pilots in the requirement to integrate disparate pieces of flight / state data to develop and update their\nmental model. Presentation of precision guidance that is overlaid on a perspective, 3-D SVS display\ncould significantly enhance situation awareness and free the cognitive resources of the flight crew to\nmanage the non-normal or emergency events, compared to having to synthesize information from the\nspeed and altitude tapes, flight director, terrain depiction / color codes on the navigation display, flight\npath and constraints, aircraft performance capabilities, Mode Control Panel settings, etc.\n\n74\n\nAppendix D: Required Navigation Performance\nRequired navigation performance (RNP) is a statement of the navigation performance accuracy\nnecessary for operation within a defined airspace. RNP airspace is a generic term referring to airspace,\nroutes, and legs, where minimum navigation performance requirements have been established and aircraft\nmust meet or exceed that performance to fly in that airspace. The system performance requirements for\nRNP Area Navigation (RNAV) is that each aircraft operating in RNP airspace shall have total system\nerror components in the cross-track and along-track directions that are less than the RNP value 95% of the\nflying time. RNP type is a designator according to navigational performance accuracy in the horizontal\nplane (lateral and longitudinal position fixing). This designator invokes all of the navigation performance\nrequirements associated with the applicable RNP number, which is a containment value. For example,\nRNP-1 means that for at least 95% of the time the navigational performance in the horizontal plane, or the\ntotal horizontal system error, is less than 1.0 nautical mile (nmi). In addition to requiring 95% positioning\naccuracy for RNP operations, these types of procedures also require integrity of the positioning accuracy\nat 99.999% at 2 x RNP number. In our example above with an RNP-1, the position accuracy within 2.0\nnmi of the ownship (2 x RNP value of 1.0 nmi) would have to be guaranteed to be correct 99.999% of the\ntime to enable RNP-1 operations.\nThere are three lateral components of navigation error: path definition error, path steering error, and\nposition estimation error (RTCA, 2000). These errors, defined in the following, represent the total\nhorizontal system error of the airplane and are the difference between the aircraft\xe2\x80\x99s true position and\ndesired position (see fig. D1):\nThe path definition error is the difference between the defined path and the desired path at a\nspecific point.\nThe path steering error is the distance from the estimated position to the defined path. It\nincludes both the flight technical error (FTE) and display error. FTE is the accuracy with\nwhich the aircraft is controlled as measured by the indicated aircraft position with respect to\nthe indicated command or desired position.\nThe position estimation error, also referred to as the ship\xe2\x80\x99s actual navigation performance\n(ANP), is the difference between the true position and the estimated position.\nDesired Path\nPath Definition Error\nDefined Path\n\nEstimated Position\n\nPath Steering Error (FTE+Display Error) Total Horizontal\n\nSystem Error\n\nPosition Estimation Error\nTrue Position\n\nFigure D1. Lateral components of navigation error terms\n\n75\n\nVertical navigation (VNAV) capability further enhances flight operations by enabling the specification\nof a flight path vertically for the lateral flight path. The system performance requirements for VNAV are\nthat for at least 99.7% of the time the navigational performance in the vertical plane, or the total vertical\nsystem error, is less than a specified altitude deviation measure based on the airspace being flown in\n(below 5000 feet MSL, 5000-10000 feet MSL, above 10000 feet MSL) and the type of flight operation\n(level flight/climb/descent or flight along specified vertical profile) being performed (see table D1).\nThere are four vertical components of navigation error: altimetry system error, vertical path steering\nerror, vertical path definition error, and horizontal coupling error (RTCA, 2000). These errors, defined in\nthe following, represent the total vertical system error of the airplane and are the difference between the\naircraft\xe2\x80\x99s true vertical position and desired vertical position at the true lateral position (see fig. D2):\nAltimetry system error is the error attributable to the aircraft altimetry installation, including\nposition effects resulting from normal aircraft flight attitudes.\nThe vertical path steering error is the distance from the estimated vertical position to the\ndefined path. It includes both FTE and display error.\nThe vertical path definition error is the vertical difference between the defined path and the\ndesired path at the estimated lateral position.\nThe horizontal coupling error is the vertical error resulting from horizontal along track\nposition estimation error coupling through the desired path.\nTable D1. Vertical Accuracy Performance Requirements\nError Source\n\nLevel Flight Segments\nand Climb/Descent\nIntercept of Clearance\nAltitudes (MSL)\n\nApproach\nalong Specified\nVertical Profile\n(MSL)\n\nAt or Below\n5000 ft\n\n5000 ft to\n10000 ft\n\nAbove\n10000 ft\n\nAt or Below\n5000 ft\n\n5000 ft to\n10000 ft\n\nAbove 10000 ft\n\nAltimetry\n\n90 ft\n\n200 ft\n\n250 ft\n\n140 ft\n\n265 ft\n\n350 ft\n\nRNAV\nEquipment\n\n50 ft\n\n50 ft\n\n50 ft\n\n100 ft\n\n150 ft\n\n220 ft\n\nFlight\nTechnical\n\n150 ft\n\n240 ft\n\n240 ft\n\n200 ft\n\n300 ft\n\n300 ft\n\nTotal RootSum-Square\n(RSS)\n\n190 ft\n\n320 ft\n\n350 ft\n\n265 ft\n\n430 ft\n\n510 ft\n\n76\n\nTrue Position\n\nEstimated Position\nAltimetry System Error\n\nDefined Path\n\nVertical Path Steering Error (FTE+Display Error)\nDesired Path\n\nTotal Vertical\nSystem Error\nVertical Path Definition Error\n\nHorizontal Coupling Error\n\nFigure D2. Vertical components of navigation error terms\n\n77\n\nAppendix E. Planned Run Matrix\nThe following tables show the planned run matrix / configurations by pilot for the 12 sorties (data\ncollection flights).\n\nPilot #\n\nSortie #\n\nRun #\n\nRunway\n\nVision\nRestriction\nDevice\n\n1\n\n1\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Photo-texture\nHUD, Photo-texture\nHUD, Generic-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize A, Generic-texture\nSize A, Photo-texture\nHUD, Photo-texture\nSize A, Photo-texture\nSize X, Generic-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Generic-texture\nHUD, Generic-texture\nHUD, Photo-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize A, Photo-texture\nSize A, Generic-texture\nHUD, Photo-texture\nSize X, Photo-texture\nSize A, Generic-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Photo-texture\nHUD, Photo-texture\nHUD, Generic-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize X, Generic-texture\nSize X, Photo-texture\nHUD, Generic-texture\nSize A, Generic-texture\nSize X, Photo-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n2\n\n2\n\n1\n\n2\n\n3\n\n1\n\n2\n\n78\n\nDisplay\nCondition\n\nPathway\n\nPilot #\n\nSortie #\n\nRun #\n\nRunway\n\nVision\nRestriction\nDevice\n\n4\n\n1\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Generic-texture\nHUD, Generic-texture\nHUD, Photo-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize X, Photo-texture\nSize X, Generic-texture\nHUD, Generic-texture\nSize X, Generic-texture\nSize A, Photo-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Photo-texture\nHUD, Photo-texture\nHUD, Generic-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize A, Photo-texture\nSize A, Generic-texture\nHUD, Photo-texture\nSize A, Generic-texture\nSize X, Photo-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n1\n2\n3\n4\n5\n6\n1\n2\n3\n4\n5\n6\n\n25\n25\n25\n25\n7\n7\n25\n25\n25\n7\n7\n7\n\nnone\nnone\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\nBaseline with flight director\nHUD, Generic-texture\nHUD, Generic-texture\nHUD, Photo-texture\nBaseline with flight director\nIndustry Partner\nIndustry Partner\nSize X, Generic-texture\nSize X, Photo-texture\nHUD, Generic-texture\nSize X, Generic-texture\nSize A, Photo-texture\n\nnone\nyes\nyes\nyes\nnone\nyes\nyes\nyes\nyes\nyes\nyes\nyes\n\n2\n\n5\n\n1\n\n2\n\n6\n\n1\n\n2\n\n79\n\nDisplay\nCondition\n\nPathway\n\nAppendix F. Post-Flight Questionnaire Ratings\nIn the text below, the symbol, \xcf\x87, represents the mean and the symbol, \xcf\x83, represents one standard\ndeviation. These two symbols are highlighted, italicized, and in bold font, for each question that\nwas analyzed and presented in the Results/Subjective Data Analyses section of this paper.\nBaseline EADI w/ flight director\n1. Please rate the ease of performing the approach to rwy. 25 using the traditional EADI with\nflight director\nEASE OF USE TO RWY. 25 USING EADI\n1\n2\n3\n4\n5\nVery Hard\nSomewhat Hard\n\n6\n7\nSomewhat Easy\n\nPilot 1: 5\nPilot 2: 7\nPilot 3: 9\n\n8\n\n9\nVery Easy\n\xcf\x87 = 6.16\n\xcf\x83 = 2.04\n\nPilot 4: 3\nPilot 5: 7\nPilot 6: 6\n\n2. Please rate the ease of performing the approach to rwy. 7 using the traditional EADI with flight\ndirector\nEASE OF USE TO RWY. 7 USING EADI\n1\n2\n3\n4\n5\nVery Hard\nSomewhat Hard\nPilot 1: 5\nPilot 2: 7\nPilot 3: 9\n\n6\n7\nSomewhat Easy\n\n8\n\n9\nVery Easy\n\xcf\x87 = 5.16\n\xcf\x83 = 2.71\n\nPilot 4: 1\nPilot 5: 4\nPilot 6: 5\n\nNASA SVS HUD\n3. Evaluate the ease of using the HUD photo-texture during the approach to rwy. 25\nEASE OF USE OF HUD PHOTO TO RWY. 25\n1\n2\n3\n4\n5\n6\n7\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 7\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 7\n\n80\n\n8\n\n9\nVery Easy\n\xcf\x87 = 7.5\n\xcf\x83 = 0.83\n\n4. Evaluate the ease of using the HUD generic-texture during the approach to rwy. 25\nEASE OF USE OF HUD GENERIC TO RWY. 25\n1\n2\n3\n4\n5\n6\n7\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 5\nPilot 2: 8\nPilot 3: 9\n\n8\n\n9\nVery Easy\n\xcf\x87 = 6.66\n\xcf\x83 = 1.86\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 4\n\n5. Evaluate the ease of using the HUD photo-texture during the approach to rwy. 7\nEASE OF USE OF HUD PHOTO TO RWY. 7\n1\n2\n3\n4\n5\nVery Hard\nSomewhat Hard\nPilot 1: 3\nPilot 2: 8\nPilot 3: 9\n\n6\n7\nSomewhat Easy\n\n8\n\n9\nVery Easy\n\xcf\x87 = 6.83\n\xcf\x83 = 2.04\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 7\n\n6. Evaluate the ease of using the HUD generic-texture during the approach to rwy. 7\nEASE OF USE OF HUD GENERIC TO RWY. 7\n1\n2\n3\n4\n5\n6\n7\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\n8\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 4\n\n9\nVery Easy\n\xcf\x87 = 6.83\n\xcf\x83 = 1.72\n\n7. Evaluate the ease of performing a missed approach to rwy. 25 using the HUD generic-texture\ndisplay concept\nEASE OF USE OF HUD GENERIC TO MISSED APPROACH RWY. 25\n3\n4\n5\n6\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 4\n\n81\n\nVery Easy\n\xcf\x87 = 6.5\n\xcf\x83 = 1.76\n\nYou responded that the ease of using the HUD generic-texture during the approach to rwy 7 was\n_________ during your first day of flight evaluation. Please comment on the perceived\ndifferences (in rating if there is one) between using the generic-texture HUD to rwy. 7 and rwy.\n25.\nPilot 1: No differences\nPilot 2: No differences\nPilot 3: No differences\nPilot 4: No differences\nPilot 5: No differences\nPilot 6: Generic harder\n8. Please rate the workload associated between the two different approaches. We can define\nworkload as: \xe2\x80\x9cthe degree of cognitive processing capacity required to perform the flight task\napproach adequately\xe2\x80\x9d. Please rate the workload in using the HUD generic-texture during the\napproach to rwy. 7\nWORKLOAD TO RWY. 7 USING HUDGENERIC\n1\n2\n3\n4\n5\n6\n7\nVery High\nSomewhat High\nSomewhat Low\nPilot 1: 5\nPilot 2: 7\nPilot 3: 6\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.33\n\xcf\x83 = 1.03\n\nPilot 4: 8\nPilot 5: 6\nPilot 6: 6\n\n9. Please rate the workload in using the HUD generic-texture during the approach to rwy. 25\nWORKLOAD TO RWY. 25 USING HUD GENERIC\n1\n2\n3\n4\n5\n6\n7\nVery High\nSomewhat High\nSomewhat Low\nPilot 1: 5\nPilot 2: 7\nPilot 3: 6\n\nPilot 4: 7\nPilot 5: 5\nPilot 6: 6\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.0\n\xcf\x83 = 0.89\n\n10. Please rate the missed approach, rwy. 7 or rwy. 25, which was lower in workload with using\nthe HUD generic-texture. _____________ rwy. 7 ___________ rwy. 25\nPilot 1: Equal\nPilot 2: Equal\nPilot 3: Equal\nPilot 4: Equal\nPilot 5: Equal\nPilot 6: Equal\n\n82\n\n11. Please evaluate your situation awareness during the two different approaches to rwy. 25 using\nthe NASA SV HUD generic-texture display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the\npilot has an integrated understanding of the factors that will contribute to the safe flying of the\naircraft under normal or non-normal conditions.\xe2\x80\x9d\nSA TO RWY. 25 USING HUD GENERIC\n1\n2\n3\n4\n5\nVery Low\nSomewhat Low\nPilot 1: 5\nPilot 2: 8\nPilot 3: 8\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 6.5\n\xcf\x83 = 1.74\n\nPilot 4: 8\nPilot 5: 6\nPilot 6: 4\n\n12. Please evaluate your situation awareness during the two different approaches to rwy. 7 using\nthe NASA SV HUD generic-texture display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the\npilot has an integrated understanding of the factors that will contribute to the safe flying of the\naircraft under normal or non-normal conditions.\xe2\x80\x9d\nSA TO RWY. 7 USING HUD GENERIC\n1\n2\n3\n4\n5\nVery Low\nSomewhat Low\nPilot 1: 5\nPilot 2: 8\nPilot 3: 8\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 6.33\n\xcf\x83 = 1.86\n\nPilot 4: 8\nPilot 5: 5\nPilot 6: 4\n\n13. Please evaluate your situation awareness during the approach to rwy. 25 using the NASA SV\nHUD photo-texture display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an\nintegrated understanding of the factors that will contribute to the safe flying of the aircraft under\nnormal or non-normal conditions.\xe2\x80\x9d\nSA TO RWY. 25 USING HUD PHOTO\n1\n2\n3\n4\n5\nVery Low\nSomewhat Low\nPilot 1: 6\nPilot 2: 8\nPilot 3: 8\n\n6\n7\nSomewhat High\nPilot 4: 8\nPilot 5: 5\nPilot 6: 6\n\n83\n\n8\n\n9\nVery High\n\n\xcf\x87 = 6.83\n\xcf\x83 = 1.33\n\n14. Please evaluate your situation awareness during the approach to rwy. 7 using the NASA SV\nHUD photo-texture display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an\nintegrated understanding of the factors that will contribute to the safe flying of the aircraft under\nnormal or non-normal conditions.\xe2\x80\x9d\nSA TO RWY. 7 USING HUD PHOTO\n1\n2\n3\n4\n5\nVery Low\nSomewhat Low\nPilot 1: 6\nPilot 2: 8\nPilot 3: 8\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 6.66\n\xcf\x83 = 1.50\n\nPilot 4: 8\nPilot 5: 5\nPilot 6: 5\n\n15. Did the use of the NASA HUD significantly improve your situation awareness beyond the use\nof the EADI w/ flight director for approach to rwy. 25? Please rate how much more your level of\nsituation awareness was enhanced.\nSA IMPROVEMENT USING HUD OVER EADI Rwy. 25\n1\n2\n3\n4\n5\n6\n7\nNone\nA Little\nSomewhat\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\n8\n\n9\nSignificantly\n\xcf\x87 = 7.83\n\xcf\x83 = 1.33\n\nPilot 4: 9\nPilot 5: 7\nPilot 6: 9\n\n16. Did the use of the NASA HUD significantly improve your situation awareness beyond the use\nof the EADI w/ flight director for approach to rwy. 7? Please rate how much more your level of\nsituation awareness was enhanced.\nSA IMPROVEMENT USING HUD OVER EADI Rwy. 7\n1\n2\n3\n4\n5\n6\n7\nNone\nA Little\nSomewhat\nPilot 1: 5\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 9\nPilot 5: 7\nPilot 6: 9\n\n84\n\n8\n\n9\nSignificantly\n\xcf\x87 = 7.83\n\xcf\x83 = 1.60\n\n17. Evaluate the ease of using the HUD generic-texture during the missed approach to rwy. 7\nEASE OF USE OF HUD GENERIC TO MISSED APPROACH RWY. 7\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 9\n\n9\nVery Easy\n\xcf\x87 = 6.5\n\xcf\x83 = 1.76\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 4\n\n18. Evaluate the ease of performing a missed approach to rwy. 7 using the HUD photo-texture\ndisplay concept\nEASE OF USE OF HUD PHOTO TO MISSED APPROACH RWY. 7\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 9\n\n9\nVery Easy\n\xcf\x87 = 6.5\n\xcf\x83 = 1.76\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 4\n\n19. Please rate which NASA HUD display concept (e.g., generic) provided the best level of\nsituation awareness in performing the missed approach to rwy. 7 (situation awareness defined as:\n\xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated understanding of the factors that will contribute to the safe flying of\nthe aircraft under normal or non-normal conditions.\xe2\x80\x9d).\nPilot 1: Neither\nPilot 2: Photo\nPilot 3: Photo\nPilot 4: Photo\nPilot 5: Photo\nPilot 6: Photo\nNASA HUD Symbology\n20. Evaluate the ease of predicting flight path using the \xe2\x80\x9cfollow-me aircraft\xe2\x80\x9d:\nEASE OF PREDICTING FLIGHT PATH\n1\n2\n3\n4\n5\nVery Hard\nSomewhat Hard\nPilot 1: 7\nPilot 2: 7\nPilot 3: 6\n\n6\n7\nSomewhat Easy\nPilot 4: 8\nPilot 5: 8\nPilot 6: 7\n\n85\n\n8\n\n9\nVery Easy\n\xcf\x87 = 7.16\n\xcf\x83 = 0.75\n\n21. Evaluate the ease of using the tunnel for vertical flight path guidance\nEASE OF TUNNEL FOR VERTICAL FLIGHT PATH GUIDANCE\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 7\nPilot 2: 7\nPilot 3: 9\n\n9\nVery Easy\n\xcf\x87 = 7.16\n\xcf\x83 = 1.33\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 5\n\n22. Evaluate the ease of using the tunnel for lateral flight path guidance\nEASE OF TUNNEL FOR LATERAL FLIGHT PATH GUIDANCE\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 7\nPilot 2: 7\nPilot 3: 9\n\n9\nVery Easy\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 5\n\n\xcf\x87 = 7.0\n\xcf\x83 = 1.26\n\nSize A Evaluation\n23. Evaluate the ease of interpreting airspeed information for Size A photo:\nEASE OF INTERPRETING AIRSPEED INFORMATION SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 9\nPilot 3: 6\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 6\n\n\xcf\x87 = 7.66\n\xcf\x83 = 1.36\n\n24. Evaluate the ease of interpreting airspeed information for Size A generic:\nEASE OF INTERPRETING AIRSPEED INFORMATION SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 9\nPilot 3: 8\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 6\n\n86\n\n\xcf\x87 = 8.0\n\xcf\x83 = 1.09\n\n25. Evaluate the ease of interpreting flight path vectors for Size A photo:\nEASE OF INTERPRETING FLIGHT PATH VECTORS SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 8\n\n9\nVery Easy\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 8\n\n\xcf\x87 = 8.16\n\xcf\x83 = 0.41\n\n26. Evaluate the ease of interpreting flight path vectors for Size A generic:\nEASE OF INTERPRETING FLIGHT PATH VECTORS SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 8\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 5\n\n\xcf\x87 = 7.67\n\xcf\x83 = 1.36\n\n27. Evaluate the ease of interpreting altitude information for Size A photo:\nEASE OF INTERPRETING ALTITUDE INFORMATION SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 9\nPilot 3: 6\n\nPilot 4: 8\nPilot 5: 8\nPilot 6: 5\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.51\n\n28. Evaluate the ease of interpreting altitude information for Size A generic:\nEASE OF INTERPRETING ALTITUDE INFORMATION SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 9\nPilot 3: 6\n\nPilot 4: 8\nPilot 5: 8\nPilot 6: 5\n\n87\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.51\n\n29. Evaluate the ease of interpreting vertical speed information for Size A photo:\nEASE OF INTERPRETING VERTICAL SPEED INFORMATION SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 6\n\nPilot 4: 8\nPilot 5: 7\nPilot 6: 5\n\n\xcf\x87 = 7.0\n\xcf\x83 = 1.26\n\n30. Evaluate the ease of interpreting vertical speed information for Size A generic:\nEASE OF INTERPRETING VERTICAL SPEED INFORMATION SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 6\n\nPilot 4: 8\nPilot 5: 7\nPilot 6: 5\n\n\xcf\x87 = 7.0\n\xcf\x83 = 1.26\n\n31. Evaluate the ease of interpreting the ILS/Precision approach deviation indicators for Size A\nphoto\nEASE OF INTERPRETING ILS/PRECISION APPROACH INDICATORS SIZE A\nPHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 7\n\n\xcf\x87 = 7.83\n\xcf\x83 = 0.75\n\n32. Evaluate the ease of interpreting the ILS/Precision approach deviation indicators Size A\ngeneric\nEASE OF INTERPRETING ILS/PRECISION APPROACH INDICATORS SIZE A\nGENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 8\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 7\n\n88\n\n\xcf\x87 = 7.83\n\xcf\x83 = 0.75\n\n33. Evaluate the ease of predicting flight path using the \xe2\x80\x9cfollow-me aircraft\xe2\x80\x9d for Size A photo:\nEASE OF PREDICTING FLIGHT PATH INFORMATION SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 7\nPilot 6: 7\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.03\n\n34. Evaluate the ease of predicting flight path using the \xe2\x80\x9cfollow-me aircraft\xe2\x80\x9d for Size A generic:\nEASE OF PREDICTING FLIGHT PATH INFORMATION SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 7\nPilot 6: 7\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.03\n\n35. Evaluate the ease of using the tunnel for vertical flight path guidance for Size A photo:\nEASE OF USING TUNNEL FOR VERTICAL PATH GUIDANCE SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 4\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 6\n\n\xcf\x87 = 6.16\n\xcf\x83 = 1.47\n\n36. Evaluate the ease of using the tunnel for vertical flight path guidance for Size A generic:\nEASE OF USING TUNNEL FOR VERTICAL PATH GUIDANCE SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 5\n\nPilot 4: 6\nPilot 5: 8\nPilot 6: 7\n\n89\n\n\xcf\x87 = 6.33\n\xcf\x83 = 1.21\n\n37. Evaluate the ease of using the tunnel for lateral flight path guidance for Size A photo:\nEASE OF USING TUNNEL FOR LATERAL PATH GUIDANCE SIZE A PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 4\n\n\xcf\x87 = 6.0\n\xcf\x83 = 1.26\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 6\n\n38. Evaluate the ease of using the tunnel for lateral flight path guidance for Size A generic:\nEASE OF USING TUNNEL FOR LATERAL PATH GUIDANCE SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 5\nPilot 2: 7\nPilot 3: 5\n\n\xcf\x87 = 6.16\n\xcf\x83 = 0.98\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 6\n\n39. Please rate the workload associated between the two different missed approaches using the\nNASA Size A photo-texture display concept. We can define workload as: \xe2\x80\x9cthe degree of\ncognitive processing capacity required to perform the flight task approach adequately\xe2\x80\x9d. Runway\n25:\nWORKLOAD TO RWY. 25 SIZE A PHOTO\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 3\nPilot 3: 5\n\n6\n7\nSomewhat Low\n\n8\n\n9\nVery Low\n\xcf\x87 = 6.16\n\xcf\x83 = 2.22\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 7\n\n40. Please rate the workload associated between the two different missed approaches using the\nNASA Size A photo-texture display concept. We can define workload as: \xe2\x80\x9cthe degree of\ncognitive processing capacity required to perform the flight task approach adequately\xe2\x80\x9d. Runway\n7:\nWORKLOAD TO RWY. 7 SIZE A PHOTO\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 3\nPilot 3: 7\n\n6\n7\nSomewhat Low\nPilot 4: 6\nPilot 5: 9\nPilot 6: 6\n\n90\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.0\n\xcf\x83 = 2.0\n\n41.Please rate the workload associated between the two different missed approaches using the\nNASA Size A generic-texture display concept. Runway 25:\nWORKLOAD TO RWY. 25 SIZE A GENERIC\n1\n2\n3\n4\n5\n6\n7\nVery High\nSomewhat High\nSomewhat Low\nPilot 1: 5\nPilot 2: 3\nPilot 3: 7\n\n8\n\n9\nVery Low\n\xcf\x87 = 6.0\n\xcf\x83 = 2.0\n\nPilot 4: 8\nPilot 5: 8\nPilot 6: 5\n\n42. Please rate the workload associated between the two different missed approaches using the\nNASA Size A generic-texture display concept. Runway 7:\nWORKLOAD TO RWY. 7 SIZE A GENERIC\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 3\nPilot 3: 7\n\n6\n7\nSomewhat Low\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 5.67\n\xcf\x83 = 1.75\n\nPilot 4: 6\nPilot 5: 8\nPilot 6: 5\n\n43. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 25 for Size A photo. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d\nSA TO RWY 25 SIZE A PHOTO\n1\n2\n3\n4\nVery Low\nSomewhat Low\nPilot 1: 7\nPilot 2: 8\nPilot 3: 7\n\n5\n\n6\n7\nSomewhat High\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n91\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.83\n\xcf\x83 = 0.98\n\n44. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 25 for Size A generic. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d\nSA TO RWY. 25 SIZE A GENERIC\n1\n2\n3\n4\nVery Low\nSomewhat Low\n\n5\n\nPilot 1: 5\nPilot 2: 8\nPilot 3: 7\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 6.83\n\xcf\x83 = 1.16\n\nPilot 4: 8\nPilot 5: 6\nPilot 6: 7\n\n45. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 7 for Size A photo. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d\nSA TO RWY 7 SIZE A PHOTO\n1\n2\n3\n4\nVery Low\nSomewhat Low\n\n5\n\nPilot 1: 7\nPilot 2: 8\nPilot 3: 7\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.83\n\xcf\x83 = 0.98\n\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n46. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 7 for Size A generic. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d\nSA TO RWY. 7 SIZE A GENERIC\n1\n2\n3\n4\nVery Low\nSomewhat Low\nPilot 1: 6\nPilot 2: 8\nPilot 3: 7\n\n5\n\n6\n7\nSomewhat High\nPilot 4: 8\nPilot 5: 6\nPilot 6: 7\n\n92\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.0\n\xcf\x83 = 0.89\n\nSize X Display Concept Evaluation\n47. Evaluate the ease of interpreting airspeed information for Size X photo:\nEASE OF INTERPRETING AIRSPEED INFORMATION SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\n\xcf\x87 = 8.0\n\xcf\x83 = 1.26\n\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n48. Evaluate the ease of interpreting airspeed information for Size X generic:\nEASE OF INTERPRETING AIRSPEED INFORMATION SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n\xcf\x87 = 8.0\n\xcf\x83 = 1.26\n\n49. Evaluate the ease of interpreting flight path vectors for Size X photo:\nEASE OF INTERPRETING FLIGHT PATH VECTORS SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\nVery Hard\nSomewhat Hard\nSomewhat Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 9\nPilot 6: 7\n\n9\nVery Easy\n\xcf\x87 = 7.66\n\xcf\x83 = 1.21\n\n50. Evaluate the ease of interpreting flight path vectors for Size X generic:\nEASE OF INTERPRETING FLIGHT PATH VECTORS SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 7\nPilot 5: 9\nPilot 6: 7\n\n93\n\n\xcf\x87 = 7.5\n\xcf\x83 = 1.22\n\n51. Evaluate the ease of interpreting altitude information for Size X photo:\nEASE OF INTERPRETING ALTITUDE INFORMATION SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 8\n\n\xcf\x87 = 7.83\n\xcf\x83 = 1.17\n\n52. Evaluate the ease of interpreting altitude information for Size X generic:\nEASE OF INTERPRETING ALTITUDE INFORMATION SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 8\n\n\xcf\x87 = 8.0\n\xcf\x83 = 1.09\n\n53. Evaluate the ease of interpreting vertical speed information for Size X photo:\nEASE OF INTERPRETING VERTICAL SPEED INFORMATION SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 7\n\n\xcf\x87 = 7.66\n\xcf\x83 = 1.21\n\n54. Evaluate the ease of interpreting vertical speed information for Size X generic:\nEASE OF INTERPRETING VERTICAL SPEED INFORMATION SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 7\n\n94\n\n\xcf\x87 = 7.83\n\xcf\x83 = 1.17\n\n55. Evaluate the ease of interpreting the ILS/Precision approach deviation indicators for Size X\nphoto\nEASE OF INTERPRETING ILS/PRECISION APPROACH INDICATORS SIZE X\nPHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 7\n\n\xcf\x87 = 7.83\n\xcf\x83 = 1.17\n\n56. Evaluate the ease of interpreting the ILS/Precision approach deviation indicators Size X\ngeneric\nEASE OF INTERPRETING ILS/PRECISION APPROACH INDICATORS SIZE X\nGENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 8\nPilot 3: 9\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 7\n\n\xcf\x87 = 7.83\n\xcf\x83 = 1.17\n\n57. Evaluate the ease of predicting flight path using the \xe2\x80\x9cfollow-me aircraft\xe2\x80\x9d for Size X photo:\nEASE OF PREDICTING FLIGHT PATH INFORMATION SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 7\nPilot 2: 7\nPilot 3: 4\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 8\n\n\xcf\x87 = 5.83\n\xcf\x83 = 2.79\n\n58. Evaluate the ease of predicting flight path using the \xe2\x80\x9cfollow-me aircraft\xe2\x80\x9d for Size X generic:\nEASE OF PREDICTING FLIGHT PATH INFORMATION SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 7\nPilot 2: 7\nPilot 3: 4\n\nPilot 4: 7\nPilot 5: 8\nPilot 6: 8\n\n95\n\n\xcf\x87 = 6.83\n\xcf\x83 = 1.47\n\n59. Evaluate the ease of using the tunnel for vertical flight path guidance for Size X photo:\nEASE OF USING TUNNEL FOR VERTICAL PATH GUIDANCE SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 7\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 8\n\n\xcf\x87 = 6.67\n\xcf\x83 = 2.50\n\n60. Evaluate the ease of using the tunnel for vertical flight path guidance for Size X generic:\nEASE OF USING TUNNEL FOR VERTICAL PATH GUIDANCE SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 7\n\nPilot 4: 9\nPilot 5: 8\nPilot 6: 8\n\n\xcf\x87 = 6.67\n\xcf\x83 = 2.50\n\n61. Evaluate the ease of using the tunnel for lateral flight path guidance for Size X photo:\nEASE OF USING TUNNEL FOR LATERAL PATH GUIDANCE SIZE X PHOTO\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 7\n\nPilot 4: 9\nPilot 5: 7\nPilot 6: 8\n\n\xcf\x87 = 6.5\n\xcf\x83 = 2.43\n\n62. Evaluate the ease of using the tunnel for lateral flight path guidance for Size X generic:\nEASE OF USING TUNNEL FOR LATERAL PATH GUIDANCE SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\n8\n9\nVery Hard\nSomewhat Hard\nSomewhat Easy\nVery Easy\nPilot 1: 6\nPilot 2: 7\nPilot 3: 7\n\nPilot 4: 9\nPilot 5: 7\nPilot 6: 8\n\n96\n\n\xcf\x87 = 6.0\n\xcf\x83 = 2.60\n\n63. Please rate the workload associated between the two different missed approaches using the\nNASA Size X photo-texture display concept. We can define workload as: \xe2\x80\x9cthe degree of\ncognitive processing capacity required to perform the flight task approach adequately\xe2\x80\x9d Runway\n25:\nWORKLOAD TO RWY. 25 SIZE X PHOTO\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 4\nPilot 3: 7\n\n6\n7\nSomewhat Low\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.0\n\xcf\x83 = 1.54\n\nPilot 4: 8\nPilot 5: 7\nPilot 6: 7\n\n64. Please rate the workload associated between the two different missed approaches using the\nNASA Size X photo-texture display concept. We can define workload as: \xe2\x80\x9cthe degree of\ncognitive processing capacity required to perform the flight task approach adequately\xe2\x80\x9d Runway 7:\nWORKLOAD TO RWY. 7 SIZE X PHOTO\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 4\nPilot 3: 7\n\n6\n7\nSomewhat Low\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.16\n\xcf\x83 = 1.33\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 7\n\n65. Please rate the workload associated between the two different missed approaches using the\nNASA Size X generic-texture display concept. Runway 25:\nWORKLOAD TO RWY. 25 SIZE X GENERIC\n1\n2\n3\n4\n5\n6\n7\nVery High\nSomewhat High\nSomewhat Low\nPilot 1: 5\nPilot 2: 5\nPilot 3: 7\n\nPilot 4: 8\nPilot 5: 6\nPilot 6: 7\n\n97\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.33\n\xcf\x83 = 1.21\n\n66. Please rate the workload associated between the two different missed approaches using the\nNASA Size X generic-texture display concept. Runway 7:\nWORKLOAD TO RWY. 7 SIZE X GENERIC\n1\n2\n3\n4\n5\nVery High\nSomewhat High\nPilot 1: 5\nPilot 2: 5\nPilot 3: 7\n\n6\n7\nSomewhat Low\n\n8\n\n9\nVery Low\n\n\xcf\x87 = 6.33\n\xcf\x83 = 1.03\n\nPilot 4: 7\nPilot 5: 7\nPilot 6: 7\n\n67. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 25 for each display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d Size X Photo-texture:\nSA TO RWY 25 SIZE X PHOTO\n1\n2\n3\n4\nVery Low\nSomewhat Low\n\n5\n\nPilot 1: 3\nPilot 2: 8\nPilot 3: 9\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.5\n\xcf\x83 = 2.34\n\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n68. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 25 for each display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d Size X Generic-texture:\nSA TO RWY. 25 SIZE X GENERIC\n1\n2\n3\n4\nVery Low\nSomewhat Low\nPilot 1: 4\nPilot 2: 8\nPilot 3: 9\n\n5\n\n6\n7\nSomewhat High\nPilot 4: 8\nPilot 5: 9\nPilot 6: 6\n\n98\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.97\n\n69. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 7 for each display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d Size X Photo-texture:\nSA TO RWY 7 SIZE X PHOTO\n1\n2\n3\n4\nVery Low\nSomewhat Low\n\n5\n\nPilot 1: 3\nPilot 2: 7\nPilot 3: 9\n\n6\n7\nSomewhat High\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.33\n\xcf\x83 = 2.33\n\nPilot 4: 9\nPilot 5: 9\nPilot 6: 7\n\n70. Please evaluate the level of situation awareness experienced during the missed approach to\nrwy. 7 for each display concept. We define situation awareness as: \xe2\x80\x9c\xe2\x80\xa6the pilot has an integrated\nunderstanding of the factors that will contribute to the safe flying of the aircraft under normal or\nnon-normal conditions.\xe2\x80\x9d Size X Generic-texture:\nSA TO RWY. 7 SIZE X GENERIC\n1\n2\n3\n4\nVery Low\nSomewhat Low\n\n5\n\n6\n7\nSomewhat High\n\nPilot 1: 4\nPilot 2: 7\nPilot 3: 9\n\nPilot 4: 8\nPilot 5: 9\nPilot 6: 7\n\n99\n\n8\n\n9\nVery High\n\n\xcf\x87 = 7.33\n\xcf\x83 = 1.86\n\nForm Approved\nOMB No. 0704-0188\n\nREPORT DOCUMENTATION PAGE\n\nThe public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources,\ngathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this\ncollection of information, including suggestions for reducing this burden, to Department of Defense, Washington Headquarters Services, Directorate for Information Operations and\nReports (0704-0188), 1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person\nshall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number.\nPLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.\n\n1. REPORT DATE (DD-MM-YYYY)\n\n01- 02 - 2004\n\n2. REPORT TYPE\n\n3. DATES COVERED (From - To)\n\nTechnical Publication\n\n4. TITLE AND SUBTITLE\n\n5a. CONTRACT NUMBER\n\nFlight Test Evaluation of Synthetic Vision Concepts at a Terrain\nChallenged Airport\n\n5b. GRANT NUMBER\n5c. PROGRAM ELEMENT NUMBER\n\n6. AUTHOR(S)\n\n5d. PROJECT NUMBER\n\nKramer, Lynda J.; Prinzel, Lawrence J., III; Bailey, Randall E.; Arthur,\nJarvis J., III; and Parrish, Russell V.\n\n5e. TASK NUMBER\n5f. WORK UNIT NUMBER\n\n23-728-60-10\n7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)\n\n8. PERFORMING ORGANIZATION\nREPORT NUMBER\n\nNASA Langley Research Center\nHampton, VA 23681-2199\n\nL-18360\n9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)\n\n10. SPONSOR/MONITOR\'S ACRONYM(S)\n\nNational Aeronautics and Space Administration\nWashington, DC 20546-0001\n\nNASA\n11. SPONSOR/MONITOR\'S REPORT\nNUMBER(S)\n\nNASA/TP-2004-212997\n12. DISTRIBUTION/AVAILABILITY STATEMENT\n\nUnclassified - Unlimited\nSubject Category 03\nAvailability: NASA CASI (301) 621-0390\n\nDistribution: Standard\n\n13. SUPPLEMENTARY NOTES\n\nAn electronic version can be found at http://techreports.larc.nasa.gov/ltrs/ or http://ntrs.nasa.gov\n14. ABSTRACT\n\nNASA\'s Synthetic Vision Systems (SVS) Project is striving to eliminate poor visibility as a causal factor in aircraft accidents as well as\nenhance operational capabilities of all aircraft through the display of computer generated imagery derived from an onboard database of\nterrain, obstacle, and airport information. To achieve these objectives, NASA 757 flight test research was conducted at the Eagle-Vail,\nColorado airport to evaluate three SVS display types (Head-up Display, Head-Down Size A, Head-Down Size X) and two terrain texture\nmethods (photo-realistic, generic) in comparison to the simulated Baseline Boeing-757 Electronic Attitude Direction Indicator and\nNavigation / Terrain Awareness and Warning System displays. The results of the experiment showed significantly improved situation\nawareness, performance, and workload for SVS concepts compared to the Baseline displays and confirmed the retrofit capability of the\nHead-Up Display and Size A SVS concepts. The research also demonstrated that the tunnel guidance display concept used within the SVS\nconcepts achieved required navigation performance (RNP) criteria.\n15. SUBJECT TERMS\n\nSynthetic vision systems; Advanced displays; Flight testing; Terrain awareness; CFIT\n\n16. SECURITY CLASSIFICATION OF:\na. REPORT\n\nU\n\nb. ABSTRACT c. THIS PAGE\n\nU\n\nU\n\n17. LIMITATION OF\nABSTRACT\n\nUU\n\n18. NUMBER 19a. NAME OF RESPONSIBLE PERSON\nOF\nSTI Help Desk (email: help@sti.nasa.gov)\nPAGES\n19b. TELEPHONE NUMBER (Include area code)\n\n110\n\n(301) 621-0390\nStandard Form 298 (Rev. 8-98)\nPrescribed by ANSI Std. Z39.18\n\n'