b'IT&E FT3 FTP-01\nDRAFT--BASELINE\n\n1\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nSIGNATURES\nPrepared By:\n\n_____________________________________________________\nMike Marston, IT&E Operations Engineer, AFRC\n\nConcur:\n\n_____________________________________________________\nMaria Consiglio, SSI Project Engineer, LaRC\n\n_____________________________________________________\nJim Griner, Communications Project Engineer, GRC\n\n_____________________________________________________\nConfesor Santiago, SSI Project Engineer, ARC\n\n_____________________________________________________\nJay Shively, HSI Project Engineer, ARC\n\nApprove:\n____________________________________________________\nSam Kim, IT&E Project Engineer, AFRC\n\n____________________________________________________\nJim Murphy, IT&E Project Engineer, ARC\n\n____________________________________________________\nHeather Maliska, IT&E DPMf, AFRC\n\n2\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n____________________________________________________\nAmy Jankovsky, DPMf GRC\n\n_____________________________________________________\nMatt Knudson, DPMf ARC\n\n____________________________________________________\nVince Schultz, DPMf LaRC\n\n____________________________________________________\nMauricio Rivas, PM Ikhana, AFRC\n\n____________________________________________________\nPeggy S. Hayes, Deputy Chief Systems Engineer\n\n3\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nREVISION SHEET\n\nREV\n\nDATE\n\nBaseline\n\nMarch 2015\n\nREVISION SUMMARY\nBaseline final draft (rev D). Incorporated CCB\ncomments on 3/6/2015 based on review of\nbaseline draft rev C.\n\nPAGE\n17, 20-22,\n& 37\n\n4\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nTable of Contents\n1\n\nINTRODUCTION ..........................................................................................................................9\n1.1\nPURPOSE .................................................................................................................. 9\n1.2\nSTAKEHOLDERS, PARTICIPANTS, AND RESPONSIBILITIES ................................................... 11\n1.3\nREQUIREMENTS FLOW & DOCUMENTATION ................................................................. 12\n\n2\n\nFT3 CONOPS ............................................................................................................................. 12\n2.1\nPAIRWISE ENCOUNTERS (FLIGHT TEST CONFIGURATION 1) .............................................. 14\n2.2\nFULL MISSION ENCOUNTERS (FLIGHT TEST CONFIGURATION 2) ....................................... 15\n2.3\nGOALS AND OBJECTIVES ............................................................................................ 15\n2.3.1 Flight Test 3 Goals ...................................................................................................... 16\n2.3.2 Flight Test 3 Objectives ............................................................................................... 16\n\n3\n\nFLIGHT TEST SYSTEMS AND ARCHITECTURE ............................................................................... 19\n3.1\nFLIGHT TEST MANAGEMENT....................................................................................... 22\n3.1.1 Success Criteria ........................................................................................................... 22\n3.1.2 Vehicle Configurations ................................................................................................ 22\n3.1.3 Flight Test Systems Roles and Responsibilities ........................................................... 24\n3.1.4 Flight Test Planning .................................................................................................... 25\n3.2\nFLIGHT TEST RESOURCES ........................................................................................... 25\n3.2.1 Live Resources............................................................................................................. 25\n3.2.2 Virtual Resources ........................................................................................................ 29\n3.2.3 Test Facilities .............................................................................................................. 35\n3.2.4 Test Area..................................................................................................................... 36\n3.2.5 Spectrum Management .............................................................................................. 36\n3.2.6 Communication Resources ......................................................................................... 36\n3.2.7 Test Support Resources .............................................................................................. 38\n3.2.8 Instrumentation and Data Collection Resources ........................................................ 38\n3.2.9 LVC Test Setup Architecture ....................................................................................... 38\n3.2.10 Simulation Resources.................................................................................................. 41\n3.3\nFLIGHT TEST EQUIPMENT ........................................................................................... 41\n3.3.1 Aircraft Required Systems .......................................................................................... 41\n3.4\nSECURITY REQUIREMENTS .......................................................................................... 43\n3.4.1 General Security ......................................................................................................... 44\n3.4.2 Operations Security .................................................................................................... 44\n3.4.3 Communications Security ........................................................................................... 44\n3.4.4 IT Security ................................................................................................................... 44\n3.4.5 Data Security .............................................................................................................. 44\n3.5\nFLIGHT TEST LIMITATIONS .......................................................................................... 44\n\n4\n\nFLIGHT TEST EXECUTION ........................................................................................................... 45\n4.1\nMISSION BRIEFINGS .................................................................................................. 45\n4.1.1 Preflight Brief.............................................................................................................. 46\n4.1.2 Post-Flight Brief .......................................................................................................... 46\n4.2\nSTANDARD AIR NAVIGATION PROCEDURES ................................................................... 46\n4.2.1 Air Traffic Control ....................................................................................................... 46\n4.2.2 Visual Flight Rules ....................................................................................................... 46\n4.2.3 Weather ...................................................................................................................... 46\n4.2.4 Aircraft Calibration Procedures .................................................................................. 47\n5\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.3\n4.3.1\n4.4\n4.4.1\n4.4.2\n4.4.3\n4.4.4\n4.5\n4.5.1\n4.5.2\n4.5.3\n4.5.4\n4.5.5\n4.6\n4.6.1\n4.6.2\n4.6.3\n4.6.4\n4.6.5\n4.6.6\n4.6.7\n\nFLIGHT TEST COORDINATION ...................................................................................... 47\nFlight Test Roles and Responsibilities ......................................................................... 47\nFLIGHT TEST SAFETY.................................................................................................. 48\nFlight Safety Process ................................................................................................... 48\nMission Rules .............................................................................................................. 48\nGo / No-Go.................................................................................................................. 49\nAbort Procedures ........................................................................................................ 49\nPAIRWISE FLIGHT TEST ENCOUNTERS (CONFIGURATION 1) .............................................. 49\nOwnship Requirements............................................................................................... 51\nIntruder Requirements................................................................................................ 51\nMinimum Separation .................................................................................................. 51\nTest Flow..................................................................................................................... 52\nMinimum Success Criteria .......................................................................................... 55\nFULL MISSION FLIGHT TEST ENCOUNTERS (CONFIGURATION 2) ....................................... 56\nMission Plan ............................................................................................................... 56\nTest Encounters .......................................................................................................... 58\nOwnship Requirements............................................................................................... 59\nIntruder Requirements................................................................................................ 59\nVirtual Aircraft Requirements ..................................................................................... 59\nMinimum Separation .................................................................................................. 60\nMinimum Success Criteria .......................................................................................... 60\n\n5\n\nTEST REPORTING ...................................................................................................................... 62\n5.1\nDEFICIENCY REPORT .................................................................................................. 62\n5.2\nPROGRESS REPORT ................................................................................................... 62\n5.3\nTEST AND PRELIMINARY RESULTS REPORT .................................................................... 62\n5.4\nANALYSIS REPORTS ................................................................................................... 62\n5.5\nFLIGHT TEST REPORT................................................................................................. 62\n\n6\n\nDATA COLLECTION.................................................................................................................... 62\n6.1\nSUMMARY OF DATA SOURCES FROM FLIGHT TEST AIRCRAFT ........................................... 63\n\n7\n\nAPPENDICES ............................................................................................................................. 63\nAPPENDIX A REFERENCE DOCUMENTS ............................................................................................. 64\nAPPENDIX B ACRONYMS ............................................................................................................... 65\nAPPENDIX C DEFINITION OF TERMS ................................................................................................. 69\n\n6\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nList of Figures\nFigure 1-1. UAS-NAS IT&E Document Tree. ................................................................................................ 12\nFigure 2-1. Collision Avoidance, Sense and Avoid, and Separation Assurance Interoperability. ............... 13\nFigure 2-2. UAS in the NAS ConOps Overview. ........................................................................................... 14\nFigure 2-3. FT-3 Primary Technical Goals and Objectives ........................................................................... 16\nFigure 3-1. FT3 Baseline Configuration 1A (Pairwise Encounters at AFRC) ................................................ 20\nFigure 3-2. FT3 Baseline Configuration 1B (Pairwise Encounters at AFRC) ................................................ 21\nFigure 3-3. FT3 Baseline Configuration 2 (Full Mission Flights at AFRC)..................................................... 22\nFigure 3-4. Self-Separation Flight Systems.................................................................................................. 23\nFigure 3-5. NASA AFRC, MQ-9 Predator B (Ikhana), T/N 870, Ownship Aircraft ........................................ 26\nFigure 3-6. NASA GRC, T-34C Mentor, T/N N608NA, UAS Surrogate Aircraft ............................................ 27\nFigure 3-7. NASA GRC, S-3, Viking, T/N N601NA, High Speed Ownship/Intruder Aircraft ......................... 28\nFigure 3-8. Honeywell, Beech C90, T/N N3GC, Intruder Aircraft ................................................................ 29\nFigure 3-9. Multi-Aircraft Control System (MACS) Air Traffic Control displays .......................................... 30\nFigure 3-10. MACS Ground Control Station displays. ................................................................................. 31\nFigure 3-11. Vigilant Spirit Control System (VSCS) ...................................................................................... 32\nFigure 3-12. GA-ASI Conflict Prediction and Display System (CPSD) .......................................................... 33\nFigure 3-13. Research Ground Control Station layout. ............................................................................... 34\nFigure 3-14. Multi-Aircraft Control System (MACS) pseudo pilot displays. ................................................ 35\nFigure 3-15. Southern California R-2508 Range Complex........................................................................... 36\nFigure 3-16. Full Mission Voice Comm Architecture at AFRC. .................................................................... 37\nFigure 3-17. FT3 Configuration 1 & 2 Communications Matrices ............................................................... 38\nFigure 3-18. FT3 LVC system with components for the Pairwise Encounters of Live Aircraft Test\nConfiguration (including observer positions).............................................................................................. 39\nFigure 3-19. FT3 LVC system with components for the Pilot Acceptability of SAA Maneuvers Full Mission\nFlight test setup (including observer positions).......................................................................................... 40\nFigure 4-1. R-2515 Areas for Pairwise Encounters...................................................................................... 50\nFigure 4-2. Example of a Self - Separation Encounter. ............................................................................... 51\nFigure 4-3. Configuration 1 Flight Test 3 Combined Encounters ................................................................ 54\nFigure 4-4. Configuration 1 (Pairwise) Test Encounter Geometries ........................................................... 55\nFigure 4-5. Example of a Full Mission flight flown in R-2508 Complex ....................................................... 57\nFigure 4-6. Example of a Full Mission Track with Encounter Points ........................................................... 58\nFigure 6-1. FT3 Data Collection Sources ..................................................................................................... 63\n\n7\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nList of Tables\nTable 1. List of FT3 Facilities. ...................................................................................................................... 35\n\n8\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n1\n\nIntroduction\n\nThe desire and ability to fly Unmanned Aircraft Systems (UAS) in the National Airspace System\n(NAS) is of increasing urgency. The application of unmanned aircraft to perform national\nsecurity, defense, scientific, and emergency management are driving the critical need for less\nrestrictive access by UAS to the NAS. UAS represent a new capability that will provide a variety\nof services in the government (public) and commercial (civil) aviation sectors. The growth of\nthis potential industry has not yet been realized due to the lack of a common understanding of\nwhat is required to safely operate UAS in the NAS.\nNASA\xe2\x80\x99s UAS Integration into the NAS Project is conducting research in the areas of Separation\nAssurance/Sense and Avoid Interoperability, Human Systems Integration (HSI), and\nCommunication to support reducing the barriers of UAS access to the NAS. This research is\nbroken into two research themes namely, UAS Integration and Test Infrastructure. UAS\nIntegration focuses on airspace integration procedures and performance standards to enable UAS\nintegration in the air transportation system, covering Sense and Avoid (SAA) performance\nstandards, command and control performance standards, and human systems integration. The\nfocus of Test Infrastructure is to enable development and validation of airspace integration\nprocedures and performance standards, including the integrated test and evaluation. In support of\nthe integrated test and evaluation efforts, the Project will develop an adaptable, scalable, and\nschedulable relevant test environment capable of evaluating concepts and technologies for\nunmanned aircraft systems to safely operate in the NAS.\nTo accomplish this task, the Project will conduct a series of Human-in-the-Loop and Flight Test\nactivities that integrate key concepts, technologies and/or procedures in a relevant air traffic\nenvironment. Each of the integrated events will build on the technical achievements, fidelity and\ncomplexity of the previous tests and technical simulations, resulting in research findings that\nsupport the development of regulations governing the access of UAS into the NAS.\n\n1.1\n\nPurpose\n\nThe integrated Flight Test 3 (FT3) will gather data for the UAS researchers or their development\nand evaluation of Communication system, Sense and Avoid (referred to as Detect and Avoid in\nthe RTCA SC 228 ToR) algorithms and pilot displays for candidate UAS systems in a relevant\nenvironment. The technical goals of FT3 are to: 1) perform end to end traffic encounter test of\npilot guidance generated by Self Separation algorithms (aircraft sensor to wind, TCAS II, and\nlatency uncertainties to Ground Control Station (GCS) display); and 2) conduct flight test of\nprototype Communication system as part of an integrated DAA system; 3) collect data to inform\nthe preliminary draft of the Methods of Performance Standards (MOPS) for Detect and Avoid\nand C2, to include display and human performance standards in both MOPS. The completion of\nFT3 will provide valuable data to the Separation Assurance/Sense and Avoid Interoperability\n(SSI), Communication (Comm) and Human Systems Integration (HSI) research as well as reduce\nthe risks associated with building a relevant flight test environment moving towards the final\nflight tests (FT4).\nFT3 objectives and test infrastructure builds from previous UAS project simulations and flight\ntests. The basic test infrastructure has been used during the Integrated Human in the Loop\n(IHITL) simulation, Part Task 4, (PT4) Part Task 5 (PT5), UAS Controller Acceptability Study\n(UAS-CAS 1), and GRC Comm prototype CNPC system ground and flight tests. NASA Ames\n9\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n(ARC), NASA Armstrong (AFRC), NASA Glenn (GRC), and NASA Langley (LaRC) Research\nCenters will share responsibility for conducting the tests, each providing a test lab and critical\nfunctionality. UAS-NAS project support and participation on the 2014 flight test of ACAS Xu\nand Self Separation (SS) significantly contributed to building up infrastructure and procedures\nfor FT3 as well. The experiment will be divided into two distinct test configurations each\nfocusing on different aspects of the primary technical goals. The first is a four-week study\n(described as Pairwise Encounters) looking at the SS algorithm alerting times to support the\ndefinition of well-clear. The second is a four-week study (described as Full Mission (FM)\nflights) focusing on UAS pilot response times to, and acceptability of, the same SAA alerts,\nresolutions, and GCS displays under real world uncertainties, including real voice comm delays.\nThe two test planned baseline configurations will be conducted in two phases. The Pairwise\nEncounters (also called Configuration 1) will be conducted out of NASA Armstrong over a fourweek period beginning in June 2015. The Full Mission flights (also called Configuration 2) will\nstart data collection in July 2015 and continue over a four-week period, run out of NASA\nArmstrong. NASA Glenn (along with the Communication system under test) and NASA\nArmstrong will provide the live aircraft. At least one aircraft from NASA Glenn will support the\ntest as a UAS surrogate. Over the course of FT3, data will be collected from a total of 10 pilot\nsubjects and evaluated over fifty aircraft encounters. Additional test dates are available to\naccount for make-up data collection opportunities, if needed.\nTest facilities are Government owned, managed, leased or under agreement and fall into two\ncategories:\nDevelopment Facilities:\nDistributed System Research Laboratory (DSRL) at NASA Ames\nFlight Deck Display Research Laboratory (FDDRL) at NASA Ames\nResearch Aircraft Integration Facility (RAIF) at NASA Armstrong\nUAS Sense and Avoid Research Lab at Stinger Gaffarian Technologies (SGT, outside of\nNASA Langley)\nGA-ASI Grey Butte Flight Test Facility\nGA-ASI System Integration Lab\nTest Facilities:\nCrew Vehicle Simulation Research Facility (CVSRF) at NASA Ames\nDistributed System Research Laboratory (DSRL) at NASA Ames\nResearch Aircraft Integration Facility (RAIF) at NASA Armstrong\nGryden Aeronautical Test Range (DATR) at NASA Armstrong\nStand Alone Facility (SAF) at NASA Armstrong\nThe Radio Frequency (RF) Communications facility at NASA Armstrong\nEdwards R-2508 Complex\n\n10\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n1.2\n\nStakeholders, Participants, and Responsibilities\n\nNASA Integrated Aviation Systems Program (IASP) provides direction for the UAS in the NAS\nproject. The project office has overall responsibility for FT3 flight test. NASA Ames, NASA\nArmstrong, NASA Glenn, NASA Langley, GA-ASI and Honeywell support the project and are\nparticipants in the FT3 activity. The following is a brief description of responsibilities:\nNASA Ames Research Center (ARC): NASA Ames is responsible for providing the\nHSI research requirements for subject pilot evaluation based on performance during\nscenario events. Subject pilots will perform scenario tests from the Research Ground\nControl Station (RGCS) located at NASA Armstrong. ARC will provide one of the Self\nSeparation algorithms to be used during pairwise and full mission flight test.\nNASA Armstrong Flight Research Center (AFRC): NASA Armstrong is the\nresponsible test organization for all test missions flown from AFRC. AFRC is responsible\nfor providing the RGCS to be used for subject pilot evaluation. Further AFRC is\nresponsible for hosting and supporting the Live Virtual Constructive (LVC) infrastructure\nfor hosting data distribution between NASA Ames, Glenn and Langley. AFRC is also\nresponsible for providing the live unmanned aircraft to be used during pairwise\nencounters. Ikhana will provide the unmanned aircraft ownship platform to support\npairwise encounters within R-2515 airspace. In addition to providing the UAS ownship\naircraft, AFRC will also provide intruder aircraft (T-34 / King Air) as required.\nNASA Glenn Research Center (GRC): NASA Glenn is the participating test\norganization for all test missions flown from GRC or AFRC. GRC is responsible for\nproviding communication and control system interface, the high speed ownship during\nsome pairwise encounters, the UAS Surrogate ownship aircraft and a manned high speed\nintruder aircraft to be used during Full Mission flights.\nNASA Langley Research Center (LaRC): NASA Langley is responsible for providing\na Self Separation algorithm (Stratway +) that will be displayed and evaluated by subject\npilots during flight encounters.\nGeneral Atomics Aeronautical Systems Inc. (GA-ASI): Is responsible for providing\nhardware, software and integration support on the NASA Ikhana UAS. GA-ASI will\nprovide pairwise encounter requirements for autonomous aircraft response maneuvers.\nGA-ASI\xe2\x80\x99s CPDS will be used to gather data during both configurations of FT3.\nHoneywell: Honeywell is providing the software for the Surveillance Tracking Module\n(STM) prototype that contains the Honeywell Fusion Tracker. Honeywell will also\nprovide a second Traffic Alert and Collision Avoidance System (TCAS) II equipped\nintruder aircraft to support pairwise flight test encounters and may support full mission\nflights as well. The Honeywell intruder aircraft is capable of onboard TCAS data\nrecording.\n\n11\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n1.3\n\nRequirements Flow & Documentation\n\nFigure 1-1. UAS-NAS IT&E Document Tree.\nDetails for this section are TBD.\n\n2\n\nFT3 ConOps\n\nThe UAS in the NAS Project has ongoing research efforts focusing on the investigation of the\ninteroperability of SAA algorithms with Collision Avoidance (CA) and Separation Assurance\n(SA) concepts. Figure 2-1 shows the overlap of these concepts. Primary counterparts to this\nresearch are the display and interaction with the outputs of these systems by pilots and\ncontrollers, as well as additional response delays observed due to an unmanned aircraft\xe2\x80\x99s\ndistributed communication system.\n\n12\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 2-1. Collision Avoidance, Sense and Avoid, and Separation Assurance\nInteroperability.\nAs such, the Project is conducting a series of integrated human in the loop simulations and flight\ntests in order to evaluate pilot performance in response to SAA alerting and guidance, as well as\npilot and controller acceptance of the usability, display, and timeliness of the alerting and\nguidance (see Figure 2-2). FT3 will utilize the distributed Live, Virtual, Constructive (LVC)\nenvironment developed by the Project to provide the core infrastructure and supporting\nsimulation software components, to integrate a real UAS flying under nominal (noncontingency) operations, interacting with air traffic control (ATC) and virtual and live manned\naircraft during Configuration 2 full mission flights. An instance of the LVC environment will be\nexplicitly configured to meet the requirements for each of FT3 test configurations, providing the\nappropriate level of functionality, fidelity and security as needed. LVC software test components\ninclude a research prototype GCS and live aircraft at NASA Armstrong, constructive aircraft\ntarget generators at NASA Ames, and virtual ATC workstations at NASA Ames.\nJava Architecture for DAA Extensibility and Modeling (JADEM) provides an Application\nProgramming Interface for modeling DAA functions in simulation and flight test environments.\nFor this flight test, there are six DAA sub-functions: detect, track, evaluate, prioritize, declare,\nand determine. The detect and track function\xe2\x80\x94or surveillance system\xe2\x80\x94 models the process to\nwhich sensors on-board UAS detect other aircraft, and provide track data for each intruder within\nthe sensors\' field of regard to be displays on the UAS pilot\'s traffic display. Perfect, sensor errors,\nand configurable range and field of regard can be modeled in JADEM. Since this flight test\nutilizes an operational surveillance system onboard the UAS, JADEM\'s surveillance model is\nsimply a pass-through. The evaluate, prioritize, and declare functions are responsible for\nevaluating each intruder detected by the surveillance system and determine whether to provide\nan alert to the pilot and the severity of the alert. The alerting logic used for this flight test is\n13\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nbased on alerting requirements in the draft DAA MOPS. The determine function provides\nguidance to the pilot to aid in the pilot executing a maneuver to remain well clear. There are two\nmain algorithms within JADEM\'s guidance: (i) Autoresolver, and (ii) OmniBands. The\nAutoresolver provides directive guidance, i.e. a specific resolution maneuver, for the pilot to\nexecute to remain well clear. OmniBands is an algorithm that provides suggestive guidance, i.e.,\nranges of heading and altitude "bands" to which the pilot could execute in order to remain well\nclear.\nThe FT3 test environment builds upon the LVC test environment used during IHITL and the\nACAS Xu flight test. Prior to discussing the specific test setups, a description of the high-level\nsystem configurations is in order. Note this describes the system level requirements for FT3 in\nthe abstract sense, specific hardware and software components that comprise the implemented\nsystem are described later in this document.\n\nFigure 2-2. UAS in the NAS ConOps Overview.\n\n2.1\n\nPairwise Encounters (Flight Test Configuration 1)\n\nThis test configuration investigates the advisories generated by the Self Separation and Collision\nAvoidance Algorithms fed by data from live aircraft during flight. Flight Test Configuration 1 is\nfurther defined into two distinct groups (Configuration 1A and 1B). Configuration 1A involves\nflight test encounters using a low-speed, unmanned ownship aircraft. Configuration 1B involves\nflight test encounters using a high-speed manned ownship aircraft. In these tests a UAS or highspeed manned ownship aircraft will be flown with either one or two manned intruder aircraft,\n14\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nunder scripted flight paths to induce alerting and in some cases maneuvering based on specific\ngeometry encounters. Three SS algorithms will be evaluated: Three SS algorithms will be\nevaluated: 1.) Stratway+ (now called Detect & AvoID Alerting Logic for Uncrewed Systems or\nDAIDALUS), originally developed to support tactical resolution advisories for manned aircraft;\n2.) AutoResolver, first developed to support air traffic controllers with advisories to maneuver\naircraft in the en route and Terminal airspace based on predicted Loss of Separation (LOS). This\nalgorithm has been modified to work with pilots to receive and evaluate intruder TCAS\nmessages, support Resolution Alerts and CA maneuvers in response to Loss of Well Clear\npredictions and includes a model of an airborne sensor that applies a filter to restrict the inputs to\nthe AutoResolver; and 3.) CPDS developed by GA-ASI and TU Delft for Human Factors and\nuser display research. This study seeks to exercise the SS concepts alerting guidance and\nexamine the timing and utility of the alerts under real world flight conditions.\n\n2.2\n\nFull Mission Encounters (Flight Test Configuration 2)\n\nThe experimental goal of this study is to continue the evaluation of the display of self-separation\nalerts and guidance information to the UAS pilot, based on IHITL and Part Task 5 results, and\nlessons learned. The UAS Surrogate aircraft is flown on a visual flight rules (VFR) flight plan\nwith scenarios containing a mix of two live and several virtual manned instrument flight rules\n(IFR) and VFR (squawking) aircraft. Voice Communication and data messages between the\nUAS Surrogate aircraft and the Ground Control station will utilize the UAS Project\xe2\x80\x99s prototype\nUAS Communication system. In this setup, controllers act as confederates, allowing for (and\nensuring) interaction between the manned and UAS aircraft. An SS algorithm provides alerts and\nadvisories for display to the pilot on the GCS-TD. The pilot uses the display information to\nnegotiate maneuvers to avoid the traffic with ATC. The Full Mission test configuration is\ndesigned to connect virtual air traffic control (ATC) and constructive aircraft processes running\nat NASA Ames with a live manned aircraft and a UAS surrogate controlled by the research GCS.\nThe framework for the simulation environment will be supplied by the LVC via the High Level\nArchitecture (HLA) messaging infrastructure. The research GCS will control the UAS surrogate\nvia the Vigilant Spirit Control Station (VSCS) and also provide a traffic display (GCS-TD) used\nto present SS advisories to the pilot. The components send and receive data through a gateway\nconnected to the HLA network. The constructive manned aircraft and ATC workstations\ncommunicate directly via a local gateway and communicate to the other components via that\ngateway and the HLA. The constructive manned aircraft generators provide the required\nbackground traffic supporting a more realistic environment. The prototype UAS Communication\nSystem will be integrated into the surrogate aircraft and used to send voice and data messages to\nand from the GCS.\n\n2.3 Goals and Objectives\n\n15\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 2-3. FT-3 Primary Technical Goals and Objectives\n2.3.1 Flight Test 3 Goals\nFlight Test 3 serves as the mechanism to test two primary technical goals and one programmatic\ngoal:\nPairwise Encounter Goal:\nValidate results previously collected during project simulations with live data\nEvaluate TCAS II / SS interoperability\nFull Mission Goal:\nTest fully integrated system in a relevant live test environment\nProject Goal:\nInform final DAA and C2 MOPS\nReduce risk for Flight Test Series 4\n2.3.2 Flight Test 3 Objectives\nThe Flight Test 3 Series objectives for Pairwise Encounters (Configuration 1):\n1.) Validate CPA prediction accuracy and self-separation alerting logic in realistic flight\nconditions\n16\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n2.) Validate self-separation trajectory model including maneuvers\n3.) Validate sensor and tracking models\n4.) Evaluate TCAS/self-separation interoperability\n\xe2\x80\x93 Ownship CA/SS interaction\n\xe2\x80\x93 Compatibility with intruder\xe2\x80\x99s TCAS\n5.) Evaluate DAA performance in multi-threat encounters\n6.) Evaluate TCAS II as installed performance on a UAS\n7.) Qualitatively evaluate pilot impression of self-separation advisories\n8.) Inform final MOPS\nSpecific Flight Test 3 requirements for Pairwise Encounters (Configuration 1):\nFlight Test 3 Pairwise Encounters (Configuration 1) shall:\n1.) Evaluate the SAA aircraft and trajectory models in flight with real world uncertainties\n\xe2\x80\x93 Measurements/Metrics\nClimb rates, descent rates, turn radius, along /cross track trajectory error,\naltitude trajectory error, winds, CPA error\n2.) Evaluate the SAA pilot models in flight with real world uncertainties\n\xe2\x80\x93 Measurements/Metrics\nPilot reaction times (evaluation time, maneuver time)\n3.) Measure the Self separation alert threshold using cooperative sensors in flight with real\nworld uncertainties\n\xe2\x80\x93 Measurements/Metrics\nSS alert time, distance, CPA, resolution maneuver type, etc.\n4.) Measure the Self separation alert threshold using non-cooperative sensors in flight with\nreal world uncertainties\n\xe2\x80\x93 Measurements/Metrics\nSS alert time, distance, CPA, resolution maneuver type, etc.\n5.) Measure the surveillance data accuracy of non-cooperative sensor\n\xe2\x80\x93 Measurements/Metrics\nGet measurement list from Honeywell\nData fusion evaluation, if applicable\n6.) Evaluate whether the intruder pilot(s) thought that well clear was maintained throughout\nthe encounter where the ownship maneuvered in response to a self separation alert.\n\xe2\x80\x93 Measurements/Metrics\nSubjective feedback from pilot(s) on manned Intruder\n7.) Evaluate alert threshold interoperability between CA (i.e., TCAS) and SS\n\xe2\x80\x93 Measurements/Metrics\nCompare Intruder TCAS TA time vs. SS alert time\nCompare Intruder TCAS RA vs. SS maneuver\n17\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nCompare Ownship TCAS TA time vs. SS alert time\nCompare Ownship TCAS RA vs. SS maneuver\nThe Flight Test 3 Series objectives for Full Mission Flight Encounters (Configuration 2):\n1.) Evaluation of integrated Self Separation algorithms, GCS Traffic displays, and prototype\nCNPC systems in a realistic environment\n2.) Evaluate the effect of Self Separation alerting and guidance information on pilots\' ability\nto maintain well clear\n3.) Gather objective and subjective pilot data to evaluate/validate Well-clear definition\n4.) Analyze the performance of fourth generation CNPC systems\nSpecific Flight Test 3 requirements for Full Mission Flight Encounters (Configuration 2):\nFlight Test 3 Full Mission Flight Encounters (Configuration 2) shall:\n1.) Measure the UAS pilot response time to detect potential conflicts and maintain well clear\nfor each DAA display\n\xe2\x80\x93 Measurements/Metrics\nResponse Time (RT) to detect conflict\nRT to contact ATC\nRT to initiate resolution maneuver\nRT to upload maneuver\nRT for A/C to maneuver\nRT to clear conflict\n2.) Evaluate the performance of UAS pilots to maintain well clear for each DAA display\n\xe2\x80\x93 Measurements/Metrics\nNumber of well clear violations\nNumber of NMACs\nMinimum horizontal and vertical distances\n3.) Evaluate UAS pilot workload while operating with each DAA display\n\xe2\x80\x93 Measurements/Metrics\nNASA TLX\n4.) Evaluate UAS pilot subjective assessment of each DAA display\n\xe2\x80\x93 Measurements/Metrics\nPreference\nEase of Use/Learning\nUsability\nSelf-ratings of ability to maintain well clear\n5.) Evaluate the impact of real world atmospheric, sensor, and communication latency\nuncertainties on SS alerts and advisories\n\xe2\x80\x93 Measurements/Metrics\n18\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nPreference\nEase of Use/Learning\nUsability\nSelf-ratings of ability to maintain well clear\n6.) Measure the CNPC system in real world conditions\n\xe2\x80\x93 Measurements/Metrics\nAmount /Duration of voice communications Pilot/ATC\nLatency of voice communications Pilot/ATC\nNumber of targets ADS-B & Radar\nLatency of target information Air/Ground\nLatency of commands to aircraft\nLatency of telemetry from aircraft\nPercentage of telemetry information successfully received from aircraft\n\n3\n\nFlight Test Systems and Architecture\n\nNASA Armstrong will provide facilities, infrastructure and systems required to perform the\nbaseline FT3 pairwise and full mission test encounters within the Edwards Complex. Figures 31, 3-2 & 3-3 (respectively) depict the architecture that comprise the flight test systems required\nto support the flight test activity.\n\n19\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-1. FT3 Baseline Configuration 1A (Pairwise Encounters at AFRC)\nUAS Ownship vs Manned Intruder.\nConfiguration 1A flight test encounters include pairwise encounters between a low speed\nownship aircraft that will be performed by Ikhana configured with the GA-ASI prototype TCASSelf Separation system.\n\n20\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-2. FT3 Baseline Configuration 1B (Pairwise Encounters at AFRC)\nHigh Speed Ownship vs Manned Intruder.\nConfiguration 1B flight test encounters include pairwise encounters between a high speed\nownship aircraft that will be performed by GRC S-3B configured with CNPC and ADS-B\nsystem.\n\n21\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-3. FT3 Baseline Configuration 2 (Full Mission Flights at AFRC)\nUAS Surrogate Ownship vs Manned Intruder.\nConfiguration 2 Full Mission flight test encounters include pairwise encounters between a low\nspeed ownship UAS Surrogate aircraft that will be performed by GRC T-34C configured with\nthe CNPC and ADS-B.\n\n3.1\n\nFlight Test Management\n\nThe integrated team approach to supporting FT3 operations includes personnel from NASA\nArmstrong, NASA Ames, NASA Glenn, NASA Langley, Honeywell, and GA-ASI. The\nArmstrong DPMf and the AFRC and Ames Integrated Test and Evaluation (IT&E) Co-PE\xe2\x80\x99s lead\nthe test management decisions with inputs from subject matter experts within the aforementioned\norganizations assigned to the UAS-NAS project. SSI, HSI and Collaboration PE\xe2\x80\x99s lead the\nresearch decisions. A Test Conductor, as assigned from the IT&E subproject, has the\nresponsibility to develop the flight test plan and has decision authority during actual flight test\noperations.\n3.1.1 Success Criteria\nSuccess criteria for pairwise and full mission flight encounters is described in section 4 of this\ndocument.\n3.1.2 Vehicle Configurations\nFigure 3-4 gives a high level overview of the systems involved in the flight test.\n\n22\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-4. Self-Separation Flight Systems\nThe aircraft elements include the following required subsystems to execute the flight test and\nachieve all data collection objectives:\n3.1.2.1 Ikhana Predator B (Ownship)\nHoneywell Tracking Software\nNon-Cooperative Sensor System (GA-ASI Air-To-Air Radar)\nGround Control Stations (GCS) and Support crew\nGCS Displays and Architectures\nGCS Software to accommodate TCAS II\nConflict Prediction and Display System (CPDS)\nSSI Stratway+ (Incorporated into VSCS Display)\nVigilant Spirit Control Station (VSCS)+AutoResolver\nAvionics Packages for TCAS II, ADS-B, and Transponders\nData recording equipment\n3.1.2.2 Intruders\nAvionics Packages for TCAS II (as req), ADS-B, and Transponders\n23\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nNavigation system that use Global Positioning System (GPS) derived position\n\n3.1.3 Flight Test Systems Roles and Responsibilities\nThis section describes the roles and responsibilities for test systems provided by the various\nparticipating organizations participating in Flight Test 3. Flight systems include: aircraft, aircraft\nsupport systems (i.e. GCS), communication, IT, simulation, networking, and other systems and\nsubject matters experts to support these systems that contribute directly to executing flight\noperations.\n3.1.3.1 NASA Armstrong\nNASA Armstrong IT&E subproject will provide several of the systems required for executing\nthe flight test within the Edwards Complex including the RGCS, LVC, SAF, DATR and Ikhana\nGCS. These systems will be staffed and managed by IT&E personnel assigned to support the\nUAS-NAS project. Each major system (RGCS, LVC, and Ikhana GCS) has a lead who is\nresponsible for preparing these systems for the flight test. Armstrong will also provide the Ikhana\nMQ-9 UAS aircraft with qualified aircrew in support of the flight test pairwise encounters.\n3.1.3.2 NASA Ames\nNASA Ames will provide several of the systems required for executing the full mission flight\ntest including virtual ATC, constructive air traffic, and LVC. ARC personnel will provide flight\ntest support serving as confederate ATC controllers, ghost controllers and pseudo pilots for\nsimulated aircraft that are required to create a realistic virtual traffic environment for the subject\npilot under test, simulating mission operations within Oakland Center airspace. Ames personnel\nare also responsible for staffing and supporting pairwise and full mission flight activity by\nproviding subject matter expertise for the ARC developed SSI algorithm while under test. HSI\nSMEs will be responsible for managing the research on human system interface between subject\npilots operating the RGCS at Armstrong while performing the full mission flight profile using\nspecific mission display interfaces.\n3.1.3.3 NASA Glenn\nNASA Glenn personnel are responsible for staffing and supporting flight test missions with\nsubject matter expertise for the GRC developed CNPC radio system. GRC is responsible for\nproviding a UAS Surrogate aircraft (T-34C) and high speed ownship/intruder aircraft (S-3B) in\nsupport of the flight test.\n3.1.3.4 NASA Langley\nNASA Langley personnel are responsible for staffing and supporting flight test missions with\nsubject matter expertise for the LaRC developed SSI algorithm while under test.\n3.1.3.5 Honeywell\nHoneywell is responsible for providing subject matter expertise for the company-developed\nfusion software used on Ikhana during flight test. Honeywell is also responsible for flight test\n\n24\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nsupport providing their instrumented C90 aircraft as a TCAS equipped intruder aircraft along\nwith qualified aircrew.\n3.1.3.6 GA-ASI\nGeneral Atomics (GA-ASI) is responsible for providing subject matter and technical expertise\nfor the company-developed hardware and software installed on Ikhana during flight test. GAASI is responsible for providing recommended Engineering Development Module (EDM) radar\ntest objectives and test encounter scenarios for testing the radar in a relevant environment. GAASI will contribute technical expertise related to SAA, including with CPDS.\n3.1.4 Flight Test Planning\nAFRC is responsible for developing the flight test plan for FT3. Support from ARC, GRC,\nLaRC, HW and GA-ASI is required in order to develop a comprehensive test plan. The baseline\nfor the plan is pairwise and full mission flight encounters conducted within the R-2508/2515\nairspace complex located at Edwards AFB, CA. Indianapolis Center airspace located in southern\nOhio has been identified as an alternate location for performing the high speed pairwise and full\nmission encounters.\n\n3.2\n\nFlight Test Resources\n\nResources from all organizations involved with the flight test are described and identified in the\nfollowing sections.\n3.2.1 Live Resources\nThe flight test will require various mixtures of manned and unmanned aircraft types with\ndifferent subsystem requirements. The following aircraft are planned to be available for use in\nthe flight test:\nAircraft\nPredator B \xe2\x80\x9cIkhana\xe2\x80\x9d\nT-34C\nS-3B\nKing Air (N3GC)\nT-34C\nKing Air\n\nProvider\nNASA AFRC\nNASA GRC\nNASA GRC\nHoneywell\nNASA AFRC\nNASA AFRC\n\nRole\nUAS/Ownship\nUAS Surrogate/Ownship\nHigh Speed Ownship/Intruder\nTCAS Threat/Intruder\nSecond/Backup Low Speed Intruder\nSecond/Backup Low Speed Intruder\n\n3.2.1.1 Unmanned Aircraft (Ownship)\nAn \xe2\x80\x98ownship\xe2\x80\x99 is the aircraft that hosts the systems (hardware and software) under test. Reference\nOwnship and Intruder Equipage and Performance SRD (OIEP SRD-01) for detailed information.\n\n25\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n3.2.1.1.1 Predator B (Ikhana)\nAFRC will provide the Ikhana Predator B unmanned aircraft (Figure 3-5) to support FT3 as the\nownship for all pairwise encounters except encounters that require operations by the ownship\nthat exceeds 180 KGS.\n\nFigure 3-5. NASA AFRC, MQ-9 Predator B (Ikhana), T/N 870, Ownship Aircraft\nThe NASA AFRC Predator B (Ikhana) is a turbo-prop single engine unmanned aircraft built by\nGA-ASI. Ikhana has been configured with the GA-ASI prototype Sense and Avoid (SSA) system\nthat includes integrated hardware and software components enabling the aircraft to perform pilot\nenabled and autonomous response to collision conflict resolution. The system is dependent upon\nSAA sensors. The SAA cooperative sensors in the aircraft include an Automatic Dependent\nSurveillance-Broadcast (ADS-B) In/Out compatible Identification Friend-or-Foe (IFF), and a\nTraffic Alert and Collision Avoidance System (TCAS). An Active Electronically Scanned Array\n(AESA) Air-To-Air Radar (ATAR) is installed to detect all airborne targets. The Ikhana will\nsupport the test mission as the UAS ownship during most of the pairwise encounters flown at\nEdwards AFB.\nGeneral Performance Characteristics\nWeight:\nSpeed:\nCeiling:\nEndurance:\n\n10,500 lb\n200 kt\n40,000 ft\n24 hr\n\n3.2.1.2 Manned Aircraft (Ownship or Intruder)\nAn \xe2\x80\x98ownship\xe2\x80\x99 is the aircraft that hosts the systems (hardware and software) under test. An\n\xe2\x80\x98intruder\xe2\x80\x99 is an aircraft that supports the flight test to permit the live data collection requirements\nto be met. Intruder aircraft must be properly equipped to support the flight test. Reference\nOwnship and Intruder Equipage and Performance SRD (OIEP SRD-01) for detailed information.\n26\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n3.2.1.1.2 T-34C Mentor\n\nFigure 3-6. NASA GRC, T-34C Mentor, T/N N608NA, UAS Surrogate Aircraft\nThe NASA GRC T-34C Mentor (Figure 3-6) is a turbo-prop single engine aircraft that seats two\npilots in tandem. The T-34C will support the test mission as an ADS-B equipped UAS surrogate\naircraft during full mission encounters. The aircraft is configured as a UAS surrogate using a 2axis S-TEC autopilot that when coupled to the onboard flight navigation computer provides\nautomatic maneuvering for heading and a cueing system to the front seat pilot for speed and\nvertical control. The surrogate is equipped with a CNPC radio that is a system under test for the\nComm subproject. The T-34C can also support test missions as a non-cooperative intruder\naircraft.\nGeneral Performance Characteristics\nWeight:\nSpeed:\nCeiling:\nEndurance:\n\n4,300 lb\n214 kt\n30,000 ft\n4 hr\n\n3.2.1.1.3 S-3B Viking\n\n27\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-7. NASA GRC, S-3, Viking, T/N N601NA, High Speed Ownship/Intruder Aircraft\nThe NASA GRC S-3B Viking (Figure 3-7) is a four-seat, twin engine turbofan-powered high\nperformance jet aircraft. The aircraft is ADS-B equipped and will support test missions as a high\nspeed ownship/intruder aircraft for pairwise and can serve as an intruder for full mission\nencounters. During FT4, the S-3B will be capable of operating as an ADS-B and ATAR\nequipped UAS surrogate aircraft that will have 2-axis autopilot control for UAS autonomous\noperations.\nGeneral Performance Characteristics\nWeight:\nSpeed:\nCeiling:\nEndurance:\n\n32,000 lb\n429 kt\n40,000 ft\n10 hr\n\n3.2.1.1.4 Beech C90\n\n28\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-8. Honeywell, Beech C90, T/N N3GC, Intruder Aircraft\nThe Honeywell Beech C90 (Figure 3-8) is a twin engine turbo-prop, eight seat aircraft modified\nwith an onboard TCAS system recording. The C90 supports test missions as an ADS-B and\nTCAS II equipped intruder aircraft primarily for pairwise encounters but can also support full\nmission operations as required.\nGeneral Performance Characteristics\nWeight:\nSpeed:\nCeiling:\nEndurance:\n\n10,100 lb\n247 kt\n30,000 ft\n4.5 hr\n\n3.2.2 Virtual Resources\n3.2.2.1 Multi-Aircraft Control System (MACS)\nThe Multi-Aircraft Control System (MACS) program provides a virtual ATC display\nfunctionality and generates the constructive air traffic that provides a realistic environment for\nthe subject under test during full mission flights. A separate instance of MACS will be used for\neach function supporting flight test, including an ATC sector position a Ghost Controller, Ghost\nPilot, two Pseudo Pilots, and a Pseudo Pilot Manager. An emulation of the En Route Automation\nModernization (ERAM) environment replicating Oakland Center\xe2\x80\x99s ZOA 40/41 sectors will be\nused for the full mission test. Figure 3-9 shows MACS configured as an ERAM sector display.\n\n29\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-9. Multi-Aircraft Control System (MACS) Air Traffic Control displays\nMACS also runs as a standalone Pilot Station with built-in UAS characteristics providing a\nvirtual GCS, called the MACS GCS (Figure 3-10). This version of MACS hase the NASA\nLangley Stratway+ SAA system integrated into its software. The RGCS will be used for Test\nSetup 3 and will provide the position updates for the primary UAS aircraft of interest in each\nscenario. The MACS GCS will be used at NASA Langley during Test Setup 3.\n\n30\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-10. MACS Ground Control Station displays.\n3.2.2.2 Vigilant Spirit Control Station (VSCS)\nAFRL\'s Vigilant Spirit Control Station (VSCS) UAS simulator provides the ground control\nstation capability as well as modeling of a UAS aircraft in simulation mode (Figure 3-11). It\nconnects to the LVC and the rest of the simulation environment via the HLA, providing position\nupdates based on flight plan and state data provided by the Vigilant Spirit Simulator or a live\naircraft. The Traffic Display shows Self-Separation conflict advisories and alerts in addition to\nintruder information such as call sign (if available), relative altitude, vertical velocity, and\nground speed. The VSCS Traffic display can also show resolution maneuvers and support\n\xe2\x80\x9cvector-planning\xe2\x80\x9d. Vector-planning allows the pilot to test various horizontal or vertical vectors\nto help determine appropriate trajectories to avoid potential conflicts. Maneuver resolutions and\nvector-planning are facilitated by the SAA system, which is derived from the AutoResolver\ntechnologies developed by NASA Ames to support resolution advisories for manned aircraft. It\nwill connect via the LVC Gateway, receiving data from VSCS and MACS SimMgr, and sending\nadvisories back to the LVC, which are then sent to the VSCS and presented on the Traffic\nDisplay.\n\n31\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-11. Vigilant Spirit Control System (VSCS)\nIntegrated Traffic and Tactical Situation Display.\n3.2.2.3 Conflict Prediction and Display System (CPDS)\nFigure 3-12 shows a screen shot of the Conflict Prediction and Display System (CPDS)\ndeveloped by General Atomics, which provides GCS-TD functionality. It shows the ownship\naircraft with proximal surrounding traffic. During the FT3 the CPDS will provide the UAS pilot\nwith situation awareness and SS advisories.\nA key feature of the CPDS is to keep the pilot involved in conflict resolution before collision\navoidance is necessary. The CPDS is a display that helps the pilot obtain sufficient situational\nawareness to anticipate and resolve potential conflicts before they become time-critical through\nthe implementation of Conflict Probes [6].\n\n32\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-12. GA-ASI Conflict Prediction and Display System (CPSD)\n3.2.2.4 Research Ground Control Station (RGCS)\nThe UAS Ground Control Station (GCS) capability will be provided by the RGCS at NASA\nArmstrong for Configuration 2 (Full Mission). The RGCS is a hardware test-bed for UAS GCS\ninformation display and human factors concepts. It contains the monitors and computer systems\nthat run the display systems under test. A graphical representation of the RGCS is depicted in\nFigure 3-13.\n\n33\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-13. Research Ground Control Station layout.\n3.2.2.5 Multi-Aircraft Control System Programs\nThe MACS SimMgr and MACS Pseudo Pilot programs provide constructive aircraft targets\nduring testing (Figure 3-14). For the purposes of the IHITL, PT5 and FT3, constructive aircraft\nare defined as background traffic that fly a prescribed flight path. A subset of the constructive\ntraffic are designated as encounters which interact with the subject aircraft. Other MACS traffic\nare not the primary aircraft of interest in the scenario, but lend fidelity to the ATC environment.\nThe MACS SimMgr reads the initial conditions and flight path from an input scenario file.\nAircraft are then assigned to the MACS Pseudo Pilot stations where the aircraft position updates\nare generated and sent into the LVC system based on the flight paths and aircraft model data.\nMACS uses a four degree of freedom trajectory engine to update the location of the aircraft on a\none second frequency (emulating ADS-B). The constructive targets can emulate IFR or VFR\naircraft.\n\n34\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-14. Multi-Aircraft Control System (MACS) pseudo pilot displays.\nTwo instances of MACS ERAM will be used to automate the Air Traffic Control environment.\nThe "Controller" display will emulate ZOA sector 40/41 airspace shown in Figure 3-14. The\nGhost position will duplicate the controller\'s ERAM display and act as the surrounding the ATC\npositions. The Controller and Ghost will perform ATC duties compliant with FAA orders and\nprocedures specific to ZOA sector 40/41.\n3.2.3 Test Facilities\nTable 1 presents a list of the test facilities to be used for FT3 and their purpose. Testing will be\nconducted at three primary facilities: the DSRL and CVSRF labs at NASA Ames and the RAIF\nlab at NASA Armstrong. The DSRL lab at NASA Ames will be the virtual control center for the\nas well as contain the core LVC interface components, including HLA, HLA Toolboxes and the\nLVC Gateways. CVSRF is also located at NASA Ames and will run the instances of MACS\nERAM and MACS SimMgr. The RAIF at NASA Armstrong contains two work areas, the\nRGCS/UAV Simulation Development Lab and the LVC Distributed Environment Lab. The first\ncontains the RGCS, which connects to the HLA via an LVC Gateway. The second contains the\nLVC Gateway and simulation monitoring displays. The LVC lab also serves as a viewing area\nfor project VIPs.\nTable 1. List of FT3 Facilities.\nFacility\nCrew Vehicle Simulation\nResearch Facility (CVSRF)\nDistributed System Research\nLaboratory (DSRL)\nResearch Aircraft Integration\nFacility (RAIF) UAV SIM\nDevelopment Lab\n\nLocation\nNASA Ames\n\nLVC Component\nMACS ERAM, MACS SimMgr\n\nNASA Ames\n\nHLA\n\nNASA Armstrong\n\nRGCS, LVC\nTest Support\n\n35\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n3.2.4 Test Area\n\nFigure 3-15. Southern California R-2508 Range Complex.\nThe baseline IT&E CONOPS describes pairwise and full mission encounters being flown at\nEdwards AFB within the R-2508/2515 airspace complex (Figure 3-15). NASA Armstrong is\nproperly equipped to fully support the planned flight test missions using the DATR with some\nsupport provided by the Air Force. The HW C90 will operate out of the Van Nays Airport.\n3.2.5 Spectrum Management\nSpectrum requirements for new RF systems (CNPC and EDM radar) must be vetted through the\nNASA AFRC SMO for operations that occur within the R-2508/2515 airspace complex.\n3.2.6 Communication Resources\nBoth pairwise and full mission encounters requires voice communications to meet mission\neffectiveness and ATC requirements (Figure 3-16). All voice communications are planned for\nusing VHF two-way aviation radio frequencies. A minimum of 2 VHF radios are required as\nmission discreet channels to meet minimum test objectives. One VHF radio will be used to\nperform actual test mission tasks (TC/SPORT Net) and one VHF radio will be used for\nperforming the mission under test (Virtual ATC Net). As depicted in the baseline Voice\nCommunication Architecture Figures 2-23/24, the Control and Non-Payload Communications\n(CNPC) radio will support the voice comm requirements for the UAS Surrogate aircraft. The test\nconductor will primarily use TC/SPORT net to conduct the actual flight test mission\ncommunicating mission-related information to all airborne test aircraft on that channel. For\nmissions flown within the Edwards complex, an assigned, dedicated SPORT controller will\nmonitor TC/SPORT net and provide real-time traffic and airspace calls as required. The Virtual\n36\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nATC net is used by the pilot under test who is positioned at the RGCS pilot station. Virtual ATC\nprovides a representative virtual ATC environment within Class E airspace in Oakland ARTCC\nairspace (ZOA).\n\nFigure 3-16. Full Mission Voice Comm Architecture at AFRC.\nVirtual ATC net is used to support the comm requirements for performing the mission under test\nduring full mission encounters. Subject pilots positioned at the RGCS will communicate to ATC\non the Virtual ATC net. From the subject pilot\xe2\x80\x99s perspective, he/she is flying their UAS within\nOakland ARTCC airspace and they are communicating with Oakland Center controllers. Since\nthe UAS Surrogate aircraft is a required participant of the virtual element during full mission\nencounters, the surrogate must also have a dedicated radio assigned to Virtual ATC. Figure 3-17\ndepicts a basic communication plan for Configuration 1 and 2 missions.\nAll actual (live) aircraft participating in the test must be able to communicate with real ATC\nresponsible for the airspace where the test is being conducted hence there may be periods of time\nwhere a VHF radio must be available and channelized to local ATC. For the Edwards complex,\nJoshua is the local airspace controlling agency when SPORT is not operational.\nGhost net is an IP link between the Test Conductor and Ghost Controller used to coordinate test\nencounters during full mission sorties. Variations to the planned virtual and actual test\nencounters are expected and the Test Conductor and Ghost Controller will need to communicate\nreal-time in order to ensure mission success.\n\n37\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 3-17. FT3 Configuration 1 & 2 Communications Matrices\n(Note: Net Users & Frequencies are notional in this diagram\xe2\x80\x94need to update)\n3.2.7 Test Support Resources\nIn order to conduct actual and virtual flight test encounters in a geographically diverse physical\nand virtual test environment, dedicated test support resources are required. Additional details for\nthis section are TBD.\n3.2.8 Instrumentation and Data Collection Resources\nDetails for this section are TBD.\n3.2.9 LVC Test Setup Architecture\n3.2.9.1 Pairwise Encounters of Live Aircraft (Test Configuration 1)\nThe experimental goal of this study is to gather data to help determine the effectiveness of the\nself-separation maneuver to remain well clear without violating the intruders Collision\nAvoidance threshold volume. Metrics to determine the impact of coordinating (or not) well clear\nmaneuvers will include whether maneuver within and outside encounter was noted and its type,\ngross workload measured post-scenario, the amount of time spent performing the avoidance\nmaneuvers, and acceptability assessment questionnaire administered at the end of each collection\nrun.\nFigure 3-18 shows the LVC design for the Pairwise Encounters of Live Aircraft test\nconfiguration. In this simplified data collection effort, there are no subjects, only engineering and\npilot participants running preplanned flight plans for the unmanned and intruder aircraft. For the\ntests the unmanned aircraft will be provided by the Ikhana MQ-9. The GRC S-3B will provide\nhigh speed ownship encounter support. Ikhana will be outfitted with an air surveillance radar\nsystem, TCAS II and ADS-B. The intruder aircraft will be equipped with ADS-B and TCAS.\nThe sensor onboard the unmanned aircraft will receive data from the intruder aircraft and feed\n\n38\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nthat data to the onboard data fusion algorithm. This data will be sent do to the GCS where it will\nbe sent to the LVC via the LVC Gateway and then on to the Self Separation algorithms.\n\nFigure 3-18. FT3 LVC system with components for the Pairwise Encounters of Live\nAircraft Test Configuration (including observer positions)\nNote: Need to update diagram to remove reference to ACAS Xu and add CPDS.\n\n3.2.9.2 Full Mission of Live Aircraft Encounters (Test Configuration 2)\nThe experimental goal of this study is to continue the evaluation of candidate SAA information\ndisplays and systems with respect to self-separation, based on previous simulation results and\nlessons learned. Focus is on the effect of:\n-\n\nAdvanced traffic display elements and tools on pilots\xe2\x80\x99 ability to remain well clear\nDifferent sensor ranges for intruder aircraft on pilots\xe2\x80\x99 ability to remain well clear?\n\nFigure 3-19 shows the LVC design for the Full Mission test configuration. The core LVC\ninfrastructure will be provided by the HLA messaging system running at the DSRL lab at NASA\nAmes. The UAS pilot subject will utilize the RGCS functionality at NASA Armstrong\xe2\x80\x99s RGCS\nlab. The UAS Surrogate control will be provided by the VSCS instantiated in the RGCS. The\nintegrated SAA display provides situation awareness of the surrounding air traffic and SAA\n39\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nadvisories, alerts, and guidance information to the pilot. The SAA system is derived from the\nAutoResolver and Stratway+ technologies for Self-Separation resolution advisories, which are\nconnected to the RGCS via a Gateway. The MACS SimMgr Pseudo Pilots running out of the\nCVSRF provides virtual and constructive manned background aircraft. Two live manned intruder\naircraft will be used to evaluate the SSA system under real world conditions. MACS ATC\nprovides the virtual ATC environment and will also be run out of the CVSRF at NASA Ames.\nNote for this test setup, the controllers and pseudo pilots are co-located in order to allow for\neasier collaboration against the UAS pilot subject. The MACS processes communicate to each\nother and the rest of the LVC processes via the ADRS, which in turn connects to HLA.\n\nFigure 3-19. FT3 LVC system with components for the Pilot Acceptability of SAA\nManeuvers Full Mission Flight test setup (including observer positions)\nNote: Need to update diagram to remove reference to ACAS Xu and add CPDS.\n\n40\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n3.2.10 Simulation Resources\nDetails for this section are TBD.\n3.2.10.1\n\nHigh Level Architecture (HLA) and LVC Gateway\n\nAs stated previously, the framework for the simulation environment will be supplied by the LVC\nvia the High Level Architecture (HLA) messaging infrastructure. The LVC uses a version of the\nIEEE 1516 standard Pitch portable Real Time Infrastructure HLA and Federation Object Model\n(FOM) middleware, modified at NASA Ames, to exchange information about the air traffic\nenvironment (aircraft state, flight plans, digital messaging) among the participants operating\nfrom distributed facilities. The HLA utilizes Toolboxes to convert data from simulation\ncomponents (e.g. flight simulator, or air traffic control display) into its expected format. The\nLVC Gateway was developed to enable passing of messages within a facility (without the need\nto distribute them to HLA), for those messages that are then required to be sent to a distributed\nfacility, the gateway connects to HLA via a toolbox.\n3.2.10.2\n\nRemote User Monitoring System (RUMS)\n\nIn order to facilitate the monitoring of the data collection, the Remote User Monitoring System\n(RUMS) software processes connects to the LVC Gateway process and provides an ability to\naccess and display data being collected via a web browser. The RUMS server connects to the\nLVC Gateway and handles the web browser data requests.\n3.2.10.3\n\nFlight Test Environment\n\nThe test environment for performing pairwise encounters requires sterile airspace to perform the\nencounters with 1,000 ft vertical buffers below the lowest participating aircraft and 1,000 ft\nabove the highest participating aircraft. Ideally these encounters will be flown within the R-2515\nin scheduled airspace that omits other users during the period scheduled. Due to limitations to the\nsize of the scheduled airspace, at times intruder aircraft may maneuver outside of the schedule\nwith concurrence by the assigned SPORT controller.\nFull mission flight encounters are also planned for the R-2508 Complex which includes the use\nof Military Operating Areas (MOAs) adjacent to R-2515 airspace. These missions will not have\nvertical buffers since all participating live aircraft will be manned and see and avoid applies to all\nairspace users.\n\n3.3 Flight Test Equipment\n3.3.1 Aircraft Required Systems\nAll participating aircraft require the following minimum equipment:\n\xe2\x97\x8f ADS-B Out\n\xe2\x97\x8f Mode 3/C Transponder\n\xe2\x97\x8f GPS\n\xe2\x97\x8f VHF Voice Comm Radio (2)\n\xe2\x97\x8f CNPC (UAS Surrogate aircraft only)\n41\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nIn addition to the minimum equipment some participating aircraft require to be properly\nequipped for flight test as described in 3.3.1.1-3.3.1.4:\n3.3.1.1 Navigation Systems\nAircraft in this flight test are equipped with navigation systems that use Global Positioning\nSystem (GPS) derived position. Due to strict timing and position requirements for safety, aircraft\nshall not use any mode of navigation that does not use GPS as the primary source for navigation.\nIn addition, if aircraft have a Wide Area Augmentation System (WAAS), this will be disabled so\nthat all participating aircraft are functioning with the same atmospheric and ephemeris errors.\n3.3.1.2 Certified Systems\nA manned intruder aircraft equipped with TCAS II version 7.1, for the purpose of demonstrating\nlegacy TCAS interoperability, the reception of and compliance with 1030 MHz. The TCAS\ntraffic display on manned intruder aircraft will be the primary means by which those aircrews\nmaintain situational awareness for safety during the Configuration 1 flight test. The Honeywell\nC90 (N3GC) is planned to support this requirement.\nFor the purpose of situational awareness on the ground, interoperability demonstration, and data\ncollection, all aircraft will be equipped with ADS-B.\n3.3.1.3 Prototype Systems\nEngineering Development Model Due Regard Radar (Air-to-Air Radar):\nEDM is a radar system which supports an airborne SAA architecture for the Predator B UAS.\nThe EDM ATAR is an advanced prototype developmental radar system that has increased\nsurveillance volume and is intended to be installed in the NASA AFRC Ikhana as part of a SAA\nsystem that senses both cooperative and non-cooperative aircraft, fuses the sensor data, generates\nalarms.\nHoneywell Tracker:\nThe Honeywell Tracker fuses all sensor data that is available for a given target. For cooperative\ntargets, ADS-B, TCAS, and EDM measurements (when available) may be fused. For noncooperative targets, only EDM measurements are available.\n3.3.1.4 Software Systems\nDetails for this section are TBD.\n3.3.1.5 Ground Required Data Systems\nAll flight test operations require the following test support ground systems to be operational for\nmission success:\nLive Virtual Constructive (LVC) Distributed Environment (DE) \xe2\x80\x93 The LVC-DE will provide the\ncapability to emulate the Air Traffic Control (ATC) environment, simulate constructive\nbackground traffic and incorporate virtual Unmanned Aircraft (UA) simulations, live UA, and\nlive surrogate UA test vehicles as well as live background air traffic. The LVC-DE will need to\n\n42\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nsupport currently envisioned UAS-NAS IT&E efforts as well as provide the flexibility to support\nfuture activity and expand the LVC-DE to include nodes at other Centers or Facilities.\nDryden Aeronautical Test Range (DATR) \xe2\x80\x93 The DATR supports the actual flight test\nenvironment with telemetry, communication and data processing systems.\nDATR telemetry tracking systems consist of multiple fixed antennas at Armstrong and a\nfleet of mobile systems for deployment to specified locations. The antennas are capable\nof supporting down-linked telemetry and video signals in C-, L-, and S-bands while\nsending up-linked commands in either L- or S-bands. The antennas track targets from\nhorizon to horizon and are certified as having full on-orbit capability for low earth\norbiting spacecraft. Down-linked telemetry may be received in either analog or digital\nformat. Mobile operations can provide telemetry tracking for test missions operating\noutside local airspace boundaries.\nThe Radio Frequency (RF) Communications facility provides more than 40 ultra-high\nfrequency (UHF), very high frequency (VHF), and high frequency (HF) transmitter\nreceivers, and a UHF flight termination system (FTS). An extensive range\nintercommunication system consists of trunk lines, communication panels, public\naddress systems, commercial telephone systems, and military ground communication\nnetworks. An integrated network of communication, fiber optic, and satellite systems is\nalso used to relay telemetry, radar, audio, and video data between Armstrong facilities,\nNASA centers, other government agencies, and industry partners\nData processing systems acquire and merge data from multiple sources in various\nformats to a single, time-correlated, composite stream for processing, distribution, realtime display, and storage archival. Segments of post-mission data is available on portable\nmedia immediately following the test mission.\nADS-B Receiver Data Source \xe2\x80\x93 Details for this section are TBD.\n3.3.1.6 Control Room Required Systems\nStand Alone Facility (SAF) \xe2\x80\x93 The SAF, located at NASA AFRC in building 4800, will be used\nby the test conductor and test director to coordinate, manage, and execute the flight test. The\nroom has three workstations, one dedicated to UAS-NAS operations, each configured with\nDICES III voice comm systems and several display monitors (including ZEUS, Quick Look,\nTECCS, Ikhana video camera sources, and VS traffic displays) providing situational awareness\nand two-way voice capability for test execution.\n3.3.1.7 Support Systems\nDetails for this section are TBD.\n\n3.4 Security Requirements\nDetails for this section are TBD.\n\n43\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n3.4.1 General Security\nNo General Security issues. The tests will involve and be conducted by NASA civil servants and\ncontractors; specific partner agreements for external partners for these tests are in place and on\nfile.\n3.4.2 Operations Security\nThere is no sensitivity to the data collected during the tests. All participants are diligent to\npotential comm radio spoofing/interference that sometimes occur on VHF nets.\n3.4.3 Communications Security\nVoice communications will be conducted via actual RF radios transmitting in free space or with\ncomm links over an encrypted VPN. The specific IT security plans are on file and under access\ncontrol.\n3.4.4 IT Security\nAll transmissions between distributed facilities are encrypted. The specific IT security plans are\non file and under access control.\n3.4.5 Data Security\nThere is no sensitivity to the data collected during the tests. The Data Analysis Plan contains the\ndetails regarding handling and storage of the data.\n\n3.5 Flight Test Limitations\nThe following limitations apply to this flight test:\n\xe2\x97\x8f FT3 will use various simulators to emulate a realistic test environment. These simulators have\nvarying degrees of fidelity (i.e. ability to match their real counterparts). MACS uses a set of\naircraft models in order to generate aircraft position updates. Similarly, the MACS ERAM\nemulates an ATC en route environment, though not all ERAM functionalities will be available\nfor the IHITL. Though the MACS aircraft and ATC emulation are not perfect reproductions, they\nhave been used to model aircraft flight and air traffic control display capabilities for many\nsimulations.\n\xe2\x97\x8f The Engineering Development Model (EDM) Due Regard Radar has a field of regard of \xc2\xb1110\xc2\xb0\nin the horizontal direction and \xc2\xb115\xc2\xb0 in the vertical direction. EDM range is expected to exceed\n10nm. Additionally, the Prototype DRR has a field of regard of \xc2\xb145\xc2\xb0 in the horizontal direction\nand \xc2\xb115\xc2\xb0 in the vertical direction. DRR has a range to detect targets between 5-15 miles\ndepending on aircraft size and could detect larger aircraft out to 30 miles.\n\xe2\x97\x8f During FT3 scenarios that coordinate with TCAS, the intruder aircraft may be expected to\nmaneuver when an alert is given during certain encounters. At other times, the intruder will not\nrespond to TCAS alerts which will ensure that the ownship aircraft receives an alert and has an\nopportunity to act on it. This, however, does not preclude the TCAS equipped intruder aircraft\n\n44\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nfrom responding to TCAS alerts for non-participatory aircraft since these alerts would be\nunplanned and are to be considered a real-world safety of flight threats.\n\xe2\x97\x8f Pairwise encounters are planned to occur in R-2515 within scheduled work areas that includes\nMercury Spin, East/West Range, Four Corners and Buckhorn MOA. ATC expects all\nparticipating aircraft to remain within the scheduled/assigned airspace boundaries at all times\nunless prior coordination/permission is provided by ATC.\n\xe2\x97\x8f ATC expects all participating aircraft to remain within the scheduled/assigned airspace\nboundaries at all times unless prior coordination/permission is provided by ATC for Full Mission\nFlight test encounters that are planned to occur within the R-2508 Complex.\n\n4\n\nFlight Test Execution\n\nExecution of all flight test encounters will follow a buildup approach and employ best practices\nused by the flight test communities located at Edwards AFB, CA. The NASA Armstrong\nairworthiness and flight safety review process will apply to all encounters flown out of AFRC.\nThis section identifies general and specific operational processes and procedures that will be\nused to execute the flight test. Flight test is divided between Pairwise (or Configuration 1)\nencounters and Full Mission Flight (or Configuration 2) test encounters. Flight safety is essential\nto all test encounters and aircrew are expected to use good judgment at all times. Pairwise flight\ntest encounters will be performed using a safety buildup approach which means that test cards\nwith encounters that have the greatest vertical separation will normally start first followed by\nencounters where the vertical separation is decreased. Once a particular test encounter geometry\nhas been cleared at a specific vertical separation, same encounters performed on subsequent test\ndays do not require a repeat of the test buildup task.\nAll flight test encounters that have <500 ft vertical separation require an altimeter calibration\nprior to performing these encounters. Further, the intruder pilot performing test encounters of\n<500 ft vertical separation require visual identification (VID) of the ownship aircraft at least 1\nnm prior to intruder aircraft based on TCAS display. The intruder pilot is expected to establish\nand maintain the visual throughout every encounter (regardless of vertical separation) from 1\nnmi prior to ownship aircraft (based on TCAS display) through the CPA unless the test is\nconcluded prior to the CPA due to alert maneuvering or situations where VID is expected to be\nlost during the encounter. Once VID is established on the ownship aircraft, the intruder pilot will\ncallout the visual on the TC/SPORT net. When encounters are flown with manned aircraft\n(Configuration 1B and 2), the visual requirement applies to both ownship and intruder aircraft.\nSections 4.1 through 4.5 cover procedures and tasks required for every test day unless otherwise\nnoted (altimeter calibration procedures). Sections 4.5 and 4.6 cover specific requirements,\nprocedures, and tasks for pairwise (Configuration 1) and full mission flight (Configuration 2)\nencounters (respectively).\n\n4.1 Mission Briefings\nFlight test operations will typically be preceded by two briefings using the NASA Armstrong\nstandard processes.\n45\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.1.1 Preflight Brief\nThe first prebrief is called a T-1 briefing which is normally performed the day prior to a mission.\nAll flight test participants are required to participate in the T-1 briefing. The T-1 briefing covers\nnumerous topics that include the following: Roll Call, Time Hack, Mission Summary (Overview\n& Objectives), Mission Timeline, Weather & NOTAMS, Aircraft/GCS/Airfield Status, Comm\nData, Mission Information (Mission Rules, Go/No-Go, and Flight Safety), Test Overview &\nProcedures, Test Card Review.\nDay of Flight brief typically occurs a few hours prior to the flight and is used to discuss current\nweather, cover any changes, and generally to focus the team on the test.\n4.1.2 Post-Flight Brief\nThe post flight debrief is used to review the mission in terms of timeline (i.e. what occurred), test\nresults, aircraft squawks, lessons learned, issues, and future planning.\n\n4.2 Standard Air Navigation Procedures\nPilots will comply with all standard flight rules as described within applicable FARs (14 CFR)\nand local guidelines as appropriate. The standard requirement to \xe2\x80\x98see and avoid\xe2\x80\x99 other aircraft\n(14 CFR Part 91.113) applies. The exception is Ikhana when operating within special use\nairspace where other mitigations (i.e. mission rules, SOPs, etc.) apply in order to help ensure safe\nflight operations.\n4.2.1 Air Traffic Control\nAll airborne participants shall comply with local ATC rules as they apply in the execution of the\nflight test encounters. Within the Edwards Complex (R-2515), SPORT has ATC authority except\nduring periods of time when operational control is assumed by Joshua Approach Control. For\nFM test encounters, the project is planning to coordinate with Joshua Approach Control for\npermission to use SPORT as the dedicated controller while operating in R-2508 airspace.\n4.2.2 Visual Flight Rules\nAll flight test encounters shall be performed using visual flight rules (VFR) as described in 14\nCFR Part 91.151, 153, 155 and 159 as they apply to operations within Class E airspace, except\nwhere organizational guidelines (NPR, company FOM, for example) take precedence (if more\nrestrictive). Operations within the R-2508 Complex must comply with guidance provided by the\nR-2508 Complex Users Handbook, EAFBI 13-100, and the aforementioned sections of 14 CFR\nPart 91. This does not preclude the use of Ikhana, which has procedural means for fulfilling these\nrules in Restricted Airspace.\n4.2.3 Weather\nWeather considerations are based on operating in Visual Meteorological Conditions (VMC) at all\ntimes during flight test encounters. VMC, or clear of clouds, requires aircrew to operate with\ncloud ceilings exceeding 1,000 feet above or below the designated altitude block (as described\non the test card) and visibility exceeding 5 statute miles (at or above 10,000 ft MSL) are\nrequired. Any other potentially prohibiting flight conditions such as wind, turbulence, and/or\n46\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nprecipitation that exceed established criteria for launch or recovery cancels or delays tests until\nconditions are within tolerance. Any other conditions that interfere with successful flight test\noutcomes are taken under consideration by the team. Before each scheduled flight, the test team\nconfers via Telecon (during the day of flight brief) to make a final \xe2\x80\x9cgo/no-go\xe2\x80\x9d decision based\nupon the current and forecast weather or any other last minute changes in operational\nrestrictions.\n4.2.4 Aircraft Calibration Procedures\nAll participating aircraft are expected to have a current altimeter calibration in accordance with\nairworthiness certification requirements based on the type of FAA aircraft certificate held. Pilots\nare expected to perform an altimeter check prior to flight operations to determine whether the\naltimeter is within normal limits (\xc2\xb175 ft). For flight test operations that are planned to be \xe2\x89\xa5500 ft\nvertical separation, no airborne altimeter calibration check is planned. Pairwise self-separation\nencounters flown in the Edward Complex shall use 29.92 Hg altimeter setting.\nAll participating aircraft shall monitor GPS navigation error reporting and inform the test\nconductor if the navigation system reports lateral errors greater than 0.1 nmi (600 ft). Aircrew\nwill monitor the reported GPS position quality (figure of merit) periodically during test runs to\nensure that the reported error does not exceed test limits.\nAll participating aircrew will manage encounter timing based on GMT based on the clock\nlocated in the SAF. The test conductor, test director or project pilot will provide a time hack at\nthe flight prebrief. In general aircrew will plan to meet mission timing (CPA) within \xc2\xb18 sec.\nTiming tolerances for a given encounter will be identified on the respective encounter test card.\nAn airborne altimeter calibration check will be performed for all Pairwise and FM encounters\nthat are planned to result in <500 ft vertical separation. An altitude calibration check test card\nwill be developed and provide to aircrew prior to performing altimeter calibration checks. No\nairborne navigation calibration checks are planned.\n\n4.3 Flight Test Coordination\nSuccessful flight test requires a team effort executing a flight test plan that meets test objectives\nin a safe and efficient manner.\n4.3.1 Flight Test Roles and Responsibilities\nThe test team has several members who support the test and this section will describe the key\nroles and responsibilities for conducting the test.\nTest Conductor (TC) \xe2\x80\x93 The Test Conductor has overall responsibility for test execution and\nmission success. The TC coordinates flight test scenarios with the aircrew to ensure that flight\ntest objectives are met. The TC is collocated with and interfaces with the Test Director to\nmaintain an overall picture of the test activity. The TC communicates directly via two-way radio\nwith the participating aircrew and local ATC on a mission discrete channel. The TC workstation\nis located in the SAF.\n\n47\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nTest Director (TD) \xe2\x80\x93 The Test Director has the overall responsibility for mission safety. The TD\nis collocated with and interfaces directly with the TC and coordinates with other test team\nmembers on back channel nets as required in order to feed the TC with information to help\nmaintain an overall test picture. The TD interfaces with the NASA Senior Ops Representative\n(SOR) to ensure their understanding of flight test activities. The TD workstation is located in the\nSAF.\nMission Director/Flight Test Engineer(s) \xe2\x80\x93 A Mission Director is assigned to each aircraft to help\naircrew in the coordination and execution of the test scenarios and to ensure that mission rules\nare followed. For the unmanned aircraft, the Mission Director is located within the Ground\nControl Station and communicates with the aircrew to help in coordination and execution of test\nscenarios. A Flight Test Engineer flies in the jump-seat for manned aircraft and performs the role\nof Mission Director in assisting the aircrew in coordination and execution of test scenarios.\nAircrew \xe2\x80\x93 The aircrew consists of a pilot and a copilot. The aircrew flies test procedures outlined\nin this document adhering to navigation/timing constraints and abort procedures given for each\nflight test card. Aircrew also ensures that the aircraft stays within the vertical and lateral\nboundaries of the airspace that they have been cleared into. The aircrew coordinates test\nactivities directly with the TC and local ATC to execute the test activity.\n\n4.4 Flight Test Safety\nFlight safety is foremost to all flight test planning and essential to executing responsible flight\noperations. NASA Armstrong has flight safety responsibility for flight test operations performed\nat AFRC. NASA Glenn has flight safety responsibility for operations performed out of GRC.\nEffective hazard analysis is the responsibility of all team members and are a required element to\nenabling the airworthiness and flight safety review board to make flight release decisions.\nEncounters that are separated vertically by 500 ft or greater are considered inherently safe based\non the premise that standard acceptable NAS operations allow for IFR and VHR traffic to\noperate within the same airspace with 500 ft vertical separation. See and avoid requirements\nalways remain in effect regardless of what flight rules a given pilot is operating under.\n4.4.1 Flight Safety Process\nAFRC will lead the development of the hazard analysis and follow processes described in DCPS-001 and DCP-S-002. GRC is responsible for complying with center-required flight safety and\nairworthiness processes for their aircraft. All participants of FT3 are expected to support and\ncontribute to the flight safety process for the flight test activities.\n4.4.2 Mission Rules\nMission rules are mandatory operational procedures specific to the planned flight test and are\ndesigned to support safe flight operations. These rules apply to every flight unless specific\nexceptions are identified within a given rule. Mission rules typically cover standard weather\nlimitations, mission specific constraints to ensure flight safety, and other pertinent operational\nprocedures not covered by the flight manual or other established guidance.\n\n48\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.4.3 Go / No-Go\nA Go /No-Go list is a mandatory set of decision guidelines used to determine whether a mission\ncan be accomplished if required equipment, systems, or personnel are functional, operational\nand/or available and ready for the intended flight activity.\n4.4.4 Abort Procedures\nAbort procedures are specific to each scenario flown and are annotated on the flight test cards.\nAn abort is announced over the radio and all test participants must acknowledge including the\nTC.\nSpecific conditions which require an abort are outlined in the mission rules, but general guidance\nis that an abort is mandatory for the following circumstances:\nUnmanned aircraft goes Lost Link, or loses LOS Link (reverts to SATCOM)\nTiming constraints cannot be met within an acceptable tolerance as identified\non flight test card\n\xe2\x80\x9cNo Visual\xe2\x80\x9d after a specified distance between ownship and intruder aircraft\nAn aircraft begins a maneuver in unplanned vertical direction\nWhen test participant observes an aircraft is in the wrong position or profile\n(executing the wrong test card)\nJudgment determines that the run cannot be continued safely\nThe general procedures for an abort are as follows:\n1. Ownship Abort Procedure:\nShall maintain present heading, through and past the CPA, and change altitude as\nspecified on the flight test card.\n2. Intruder Abort Procedure:\nIf the intruder aircrew has a visual on the ownship aircraft then the intruder aircraft can\nmaneuver to remain well clear; otherwise, the intruder shall initiate a turn and begin a\nvertical maneuver as specified on the flight test card.\nIf the intruder pilot has a corrective TCAS RA advisory before or during an abort, the\npilot follows the abort procedure.\n\n4.5 Pairwise Flight Test Encounters (Configuration 1)\nPairwise encounters, also identified as Configuration 1 (more specifically Configuration 1A and\n1B), are self-separation flight encounters involving a single ownship aircraft (manned or\nunmanned) and one (or more) intruder aircraft performing flight maneuvers that are\ngeometrically paired and segregated geospatially either vertically or horizontally (or both).\nPairwise encounters involving the NASA AFRC Ikhana aircraft are Configuration 1A or\nPairwise, Low Speed encounters. These encounters are flown entirely within restricted airspace\nin the Edwards Complex (R-2515). Pairwise encounters that require a high speed ownship\naircraft (>180 KGS), such as the S-3B, are Configuration 1B or Pairwise, High Speed\nencounters. These encounters will be flown either within the Edwards Complex (R-2515).\n49\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nPairwise encounters conducted within the Edwards Complex will be planned to use scheduled\nairspace that will be reserved for aircraft participating in the flight test. The following areas\nwithin R-2515 will be reserved for project use: Mercury Spin Area, East/West Ranges (PIRA),\nFour Corners and Buckhorn MOA (Figure 4-1).\n\nEntry\nEdwards AFB\n\nExit\n\nGray Butte\n\nVictorville\n\nFigure 4-1. R-2515 Areas for Pairwise Encounters.\nPairwise encounters are planned in FalconView and are depicted as navigation legs between two\nor three waypoints depending upon whether a lateral blunder maneuver is intended. Figure 4-2\ndepicts an example of a typical pairwise self-separation encounter. Both the ownship and\nintruder begins the encounter at a designed initial point (IP) and the encounter terminates at the\nclosest point of approach (CPA). Only intruder aircraft are planned to perform lateral blunder\nmaneuvers; therefore on some encounters, an additional waypoint is planned between the IP and\nCPA. Vertical maneuvering is also planned for either the ownship or intruder aircraft on some\nencounters. At no time will encounters include both aircraft maneuvering vertically (reducing\nseparation) prior to an alert. Test cards will be developed for each planned encounter and will be\nprovided to the aircrews performing the test. Some SS encounters are planned with multiple\nintruders. Based on past experience, 15-20 encounters per flight day are expected.\n\n50\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 4-2. Example of a Self - Separation Encounter.\n4.5.1 Ownship Requirements\nThe NASA AFRC MQ-9 Ikhana aircraft is planned for Flight Test 3 ownship low speed pairwise\nencounters (Configuration 1A). Ikhana will be equipped with the GA-ASI EDM radar, ADS-B,\nTCAS II, SAA Avionics, and GPS. Some pairwise encounters require a high speed ownship\n(Configuration 1B). The plan is to use the NASA GRC S-3B for those encounters. Air\nsurveillance radar is desired for the high speed ownship aircraft although ADS-B is required for\nall high speed ownship aircraft. Ownship aircraft must be available to support the planned flight\nschedule.\n4.5.2 Intruder Requirements\nIntruder aircraft require ADS-B, and GPS. TCAS II with onboard data recording is desired for\nsome pairwise encounters. Further, a small number of planned encounters require a high speed\nintruder aircraft. Some pairwise encounters require two intruder aircraft (one of which must be\nhigh speed capable).\n4.5.3 Minimum Separation\nThe minimum geospatial offsets planned are 300 ft vertically and 0 ft horizontally. Test\nencounters will include an acceptable lateral offset of 3000 ft (0.5 nmi) which allows for some\nbuilt-in lateral offset that still meets well clear volume requirements and test data collection\nobjectives.\nAll participating aircraft will ensure that the aircraft altimeter system meets manufacturer\ncalibration specifications and requirements for normal operation in the NAS.\nA maximum of 600 ft (0.1 nmi) navigation error (GPS derived position) is allowed for each\naircraft based on the system\xe2\x80\x99s built-in navigation accuracy readout.\n\n51\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.5.4 Test Flow\nFigure 4-3 and 4-4 depicts the Pairwise self-separation encounters required by NASA ARC and\nLaRC (respectively) self-separation researchers. The pairwise encounters are further divided into\nthe following flight test groupings:\n\xe2\x80\xa2\n\nPairwise, low speed\xe2\x88\x92low speed encounters that requires Ikhana ownship versus a low\nspeed intruder aircraft (C90 or T-34C) [Configuration 1A];\n\n\xe2\x80\xa2\n\nPairwise, low speed\xe2\x88\x92high speed encounters that requires Ikhana ownship versus S-3B (or\nG3) [Configuration 1A];\n\n\xe2\x80\xa2\n\nPairwise, low speed\xe2\x88\x92low/high speed encounters that requires Ikhana ownship versus\nmulti-intruder aircraft (one low speed intruder (T-34C or C90) and one high speed\nintruder (S-3B or G3)) [Configuration 1A];\n\n\xe2\x80\xa2\n\nPairwise, high speed\xe2\x88\x92low speed encounters that requires S-3B ownship versus a low\nspeed intruder (T-34C or C90) [Configuration 1B].\n\nPriority for test sequence will be driven by UAS-NAS PE requirements, test aircraft availability,\nweather conditions, airspace constraints, and test execution considerations (i.e. encounter repeat\nruns such as aborts, resets, system performance issues, etc.).\nThe test conductor will design a flight test order of cards prior to each flight test day that outlines\nthe test card flow for that flight test period. Typically 20 test cards will make up the card order\nwith potentially 5-10 additional cards placed in the card deck as backup or nice to have\nencounters that have the lowest priority for that day.\nOn a given test day, the order of cards will be executed based on the sequence briefed during the\nT-1 briefing. The order of cards with the assigned card numbers will be covered during the\nprebrief plus any red line changes to the cards that were not previously briefed will be discussed.\nThe ownship aircraft will depart Edwards AFB (EAFB) main runway and proceed to the test area\nlocated within R-2515. The intruder aircraft will depart from either EAFB (T-34C or S-3B) or\nVan Nuys Airport (C90) and proceed to the test location. If a calibration run is required, that card\nwill be run first before any test encounters are accomplished. After the calibration run is\ncompleted (if required) the encounters will be performed in accordance with the briefed test\nsequence.\nIn general each participating aircraft is expected to maneuver within the assigned airspace to be\non conditions to arrive at the CPA within \xc2\xb18 sec (or as identified on the applicable test card) of\nthe briefed CPA time for that run. The test conductor will announce the CPA time over the\nTC/SPORT net (VHF). Each pilot performing the run will acknowledge the CPA time and offer\nalibies (if any). Aircrew are expected to be on conditions at the IP for each encounter; therefore,\nany adjustments to timing must be made prior to departing the IP. On condition is defined as on\nairspeed (ground speed), on course, on altitude at the IP in order to make good the CPA time.\nThe IP to CPA leg will be approximately 3 minutes in length.\nOnce the run has commenced, aircrew will manage airspeed, altitude, cross track and timing to\narrive at the CPA within the timing constraints. For runs with \xe2\x89\xa4500 ft vertical separation,\n52\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nmanned participating aircraft are required to call out visual at least 1 nmi prior to CPA. The test\nrun will continue until test objectives are met (alert maneuver or aircraft have reached CPA), at\nwhich point, the Test Conductor will call \xe2\x80\x9cend of run\xe2\x80\x9d signifying that the completion of that run.\nWhen well clear, aircrew will maneuver to their assigned altitude to be in position at the IP for\nthe next test encounter as called out by the TC.\nAll participating aircraft will comply with any abort calls by following the abort procedure\nlocated on the applicable test card being flown. If an abort is called, all participating aircraft and\nthe TC will acknowledge the abort call. The TC will announce the next test card to be run. If an\nabort is called, the team will normally transition to the next card unless there is a priority placed\non rerunning the aborted test run.\n\n53\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\nFlight Test 3 Pairwise Combined Encounter Matrix & Flight Test Cards\n1\n\nRadar Runs for GA\n\nHigh Speed Level Encounters 0/45/90/135/180\n\n135\xc2\xb0 Overtaking\nLevel/Ascending\n/Descending Leftto-Right\n\n90\xc2\xb0 / 110\xc2\xb0 Crossing\nLevel/Ascending/Descending Left-toRight\n\n45\xc2\xb0 Crossing Level/Ascending\n/Descending Left-to-Right\n\nHead-On Level/Ascending/Descending\n\nScenario # Scenario Name\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n\nScenario PW1\nScenario PW2\nScenario PW3\nScenario PW4\nScenario PW5\nScenario PW6\nScenario PW7\nScenario PW8\nScenario PW9\nScenario U/D 211\nScenario U/D 311\nScenario U/D 411\nScenario U/D 511\nScenario T111\nScenario T112\nScenario T113\nScenario PW10\nScenario PW11\nScenario PW12\nScenario PW13\nScenario PW14\nScenario PW15\nScenario PW16\nScenario PW17\nScenario T121\nScenario T122\nScenario T123\nScenario U/D 221\nScenario U/D 321\nScenario U/D 421\nScenario U/D 521\nScenario U/D 161\nScenario PW18\nScenario PW19\nScenario PW20\nScenario PW21\nScenario PW22\nScenario PW23\nScenario PW24\nScenario T131\nScenario T132\nScenario T133\nScenario U/D 231\nScenario U/D 331\nScenario U/D 431\nScenario U/D 531\nScenario U/D 141\nScenario U/D 171\nScenario PW25\nScenario PW26\nScenario PW27\nScenario PW28\nScenario PW29\nScenario PW30\nScenario PW31\nScenario PW32\nScenario PW33\nScenario PW34\nScenario PW35\nScenario PW36\nScenario PW37\nScenario PW38\nScenario PW39\nScenario U/D 111\nScenario U/D 112\nScenario U/D 113\nScenario U/D 114\nScenario U/D 121\nScenario U/D 122\nScenario U/D 123\nScenario U/D 124\nScenario U/D 131\nScenario U/D 132\nScenario U/D 133\nScenario U/D 134\nScenario U/D 151\nScenario U/D 152\nScenario GA1\nScenario GA2\nScenario GA3\nScenario GA4\nScenario GA5\nScenario GA6\nScenario GA7\nScenario GA8\nScenario GA9\n\n2\n\n3\n\n4\n\nLateral\nAngle\nOffset GS OWN\nInto\n(ft)\n0\n3000.0\n150\n20\n3000.0\n150\n0\n3000.0\n130\n20\n3000.0\n130\n0\n3000.0\n130\n20\n3000.0\n130\n0\n3000.0\n130\n0\n0 / 3000\n150\n20/-20\n0.0\n150\n0\n0.0\n150\n0\n0.0\n150\n0\n0.0\n120\n0\n0.0\n120\n0\n0.0\n150\n0\n0.0\n150\n0\n0.0\n150\n45\n3000.0\n150\n45\n3000.0\n130\n45\n3000.0\n130\n45\n3000.0\n130\n45\n3000.0\n150\n45\n3000.0\n150\n0/45\n3000.0\n150\n45/90\n0.0\n150\n45\n0.0\n150\n45\n0.0\n150\n45\n0.0\n150\n45\n0.0\n150\n45\n0.0\n150\n45\n0.0\n120\n45\n0.0\n120\nTurning 45 0.0\n150\n90\n3000.0\n150\n90\n3000.0\n130\n90\n3000.0\n130\n90\n3000.0\n130\n90\n3000.0\n150\n90\n3000.0\n150\n0/90\n3000.0\n150\n90\n0.0\n150\n90\n0.0\n150\n90\n0.0\n150\n90\n0.0\n150\n90\n0.0\n150\n90\n0.0\n120\n90\n0.0\n120\n110\n0.0\n150\nTurning 90 0.0\n150\n135\n3000.0\n150\n135\n3000.0\n130\n135\n3000.0\n130\n135\n3000.0\n130\n135\n3000.0\n150\n135\n3000.0\n150\n0/135\n3000.0\n150\n90/135\n0.0\n150\n0\n3000.0\n150\n45\n3000.0\n150\n90\n3000.0\n150\n135\n3000.0\n150\n0/45\n3000.0\n150\n0/90\n3000.0\n150\n0/135\n3000.0\n150\n0\n0.0\n130\n0\n0.0\n130\n0\n0.0\n210\n0\n0.0\n250\n45\n0.0\n130\n45\n0.0\n130\n45\n0.0\n210\n45\n0.0\n250\n90\n0.0\n130\n90\n0.0\n130\n90\n0.0\n210\n90\n0.0\n250\n180\n0.0\n210\n180\n0.0\n250\n0\n3000.0\n150\n45\n3000.0\n150\n90\n3000.0\n150\n0\n3000.0\n150\n45\n3000.0\n150\n90\n3000.0\n150\n0\n3000.0\n150\n45\n3000.0\n150\n90\n3000.0\n150\n\n5\n\nGS INT1\n\nGS INT2\n\n180\n180\n180\n180\n180\n180\n180\n180\n180\n120\n130\n150\n150\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n120\n130\n150\n150\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n120\n130\n150\n150\n180\n180\n180\n180\n180\n180\n180\n180\n180\n180\n300\n300\n300\n300\n300\n300\n300\n210\n250\n130\n130\n210\n250\n130\n130\n210\n250\n130\n130\n130\n130\n180\n180\n180\n180\n180\n180\n180\n180\n180\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n150\n150\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n150\n150\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n150\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n150\n150\nNA\nNA\nNA\nNA\n150\n150\n150\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n6\n7\n8\n9\n10\nGeneral Scenario Setup\nOwnship Ownship Ownship Intruder 1 Intruder 1\nInitial\nVertical\nInitial\nVertical\nFinal\nAltitude Velocity Altitude\nAltitude\nVelocity\n12000\n0\n12000\n12400\n0\n12000\n0\n12000\n12400\n0\n12000\n1000\n14000\n14500\n0\n12000\n1000\n14000\n14500\n0\n15000\n-1000\n13000\n12500\n0\n15000\n-1000\n13000\n12500\n0\n12000\n1000\n14000\n16500\n-1000\n13000\n0\n13000\n13500\n0\n13000\n0\n13000\n13500\n0\n16500\n0\n16500\n12000\n1000\n12000\n0\n12000\n16500\n-1000\n12000\n1000\n14500\n16500\n0\n16500\n-1000\n14000\n12000\n0\n12000\n0\n12000\n13000\n0\n12000\n0\n12000\n12500\n0\n12000\n0\n12000\n12300\n0\n12000\n0\n12000\n12400\n0\n12000\n1000\n14000\n14500\n0\n15000\n-1000\n13000\n12500\n0\n12000\n1000\n14000\n16500\n-1000\n14500\n0\n14500\n12000\n1000\n12000\n0\n12000\n14500\n-1000\n13000\n0\n13000\n13500\n0\n13000\n0\n13000\n13500\n0\n12000\n0\n12000\n13000\n0\n12000\n0\n12000\n12500\n0\n12000\n0\n12000\n12300\n0\n16500\n0\n16500\n12000\n1000\n12000\n0\n12000\n16500\n-1000\n12000\n1000\n14500\n16500\n0\n16500\n-1000\n14000\n12000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n12400\n0\n12000\n1000\n14000\n14500\n0\n15000\n-1000\n13000\n12500\n0\n12000\n1000\n14000\n16500\n-1000\n14500\n0\n14500\n12000\n1000\n12000\n0\n12000\n14500\n-1000\n13000\n0\n13000\n13500\n0\n12000\n0\n12000\n13000\n0\n12000\n0\n12000\n12500\n0\n12000\n0\n12000\n12300\n0\n16500\n0\n16500\n12000\n1000\n12000\n0\n12000\n16500\n-1000\n12000\n1000\n14500\n16500\n0\n16500\n-1000\n14000\n12000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n12400\n0\n12000\n1000\n14000\n14500\n0\n15000\n-1000\n13000\n12500\n0\n12000\n1000\n14000\n16500\n-1000\n14500\n0\n14500\n12000\n1000\n12000\n0\n12000\n14500\n-1000\n13000\n0\n13000\n13500\n0\n13000\n0\n13000\n13500\n0\n12000\n0\n12000\n12400\n0\n12000\n0\n12000\n12400\n0\n12000\n0\n12000\n12400\n0\n12000\n0\n12000\n12400\n0\n13000\n0\n13000\n13500\n0\n13000\n0\n13000\n13500\n0\n13000\n0\n13000\n13500\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\n12000\n0\n12000\n14000\n0\nMSA\n0\nMSA\nMSA + 500\n0\nMSA\n0\nMSA\nMSA + 500\n0\nMSA\n0\nMSA\nMSA + 500\n0\nMSA + 2000\n0\nMSA\nMSA + 2500\n0\nMSA + 2000\n0\nMSA\nMSA + 2500\n0\nMSA + 2000\n0\nMSA\nMSA + 2500\n0\nMSA + 4000\n0\nMSA\nMSA + 4500\n0\nMSA + 4000\n0\nMSA\nMSA + 4500\n0\nMSA + 4000\n0\nMSA\nMSA + 4500\n0\n\n11\nIntruder 1 Intruder 2\nFinal\nInitial\nAltitude\nAltitude\n12400\nNA\n12400\nNA\n14500\nNA\n14500\nNA\n12500\nNA\n12500\nNA\n14500\nNA\n13500\n12500\n13500\n12500\n14500\nNA\n14000\nNA\n16500\nNA\n12000\nNA\n13000\nNA\n12500\nNA\n12300\nNA\n12400\nNA\n14500\nNA\n12500\nNA\n14500\nNA\n14000\nNA\n12500\nNA\n13500\n12500\n13500\n12500\n13000\nNA\n12500\nNA\n12300\nNA\n14500\nNA\n14000\nNA\n16500\nNA\n12000\nNA\n14000\nNA\n12400\nNA\n14500\nNA\n12500\nNA\n14500\nNA\n14000\nNA\n12500\nNA\n13500\n12500\n13000\nNA\n12500\nNA\n12300\nNA\n14500\nNA\n14000\nNA\n16500\nNA\n12000\nNA\n14000\nNA\n14000\nNA\n12400\nNA\n14500\nNA\n12500\nNA\n14500\nNA\n14000\nNA\n12500\nNA\n13500\n12500\n13500\n12500\n12400\nNA\n12400\nNA\n12400\nNA\n12400\nNA\n13500\n12500\n13500\n12500\n13500\n12500\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\n14000\nNA\nMSA + 500\nNA\nMSA + 500\nNA\nMSA + 500\nNA\nMSA + 2500\nNA\nMSA + 2500\nNA\nMSA + 2500\nNA\nMSA + 4500\nNA\nMSA + 4500\nNA\nMSA + 4500\nNA\n\nIntruder 2\nVertical\nVelocity\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0\n0\nNA\nNA\nNA\nNA\n0\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nIntruder 2\nFinal\nAltitude\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n12500\n12500\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n12500\n12500\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n12500\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n12500\n12500\nNA\nNA\nNA\nNA\n12500\n12500\n12500\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\nFigure 4-3. Configuration 1 Flight Test 3 Combined Encounters\n54\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nDetails for this section are TBD.\n\nFigure 4-4. Configuration 1 (Pairwise) Test Encounter Geometries\nDetails for this section are TBD.\n4.5.5 Minimum Success Criteria\nComplete highest priority flight test encounters according to the priority set by project\nPEs.\nMeet minimum established target CPA tolerances required by project PEs.\nRecord sufficient self-separation data to evaluate CPA prediction accuracy, selfseparation alerting logic, and self-separation trajectory models for ownship aircraft.\nCollect sufficient data to evaluate TCAS/self-separation interoperability.\nCollect sufficient data to inform non-cooperative aircraft predictive models using a radar\nsensor\n\n55\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.6 Full Mission Flight Test Encounters (Configuration 2)\nFull Mission (FM) flight encounters, also identified as Configuration 2, (Figure 3-4) follow a\npreplanned flight plan that represents a fictitious fire line mission flown in Oakland Center Class\nE airspace that has been previously used for IHITL and Full Mission simulation exercises. These\nmissions involve a single ownship aircraft (UAS Surrogate) navigating a flight plan and one (or\nmore) intruder aircraft performing flight encounters that are generally scripted but has flexibility\nin execution to accommodate real-time changes that may occur during the test runs.\nThe baseline plan is to perform these missions entirely within The R-2508 Complex operating\nout of Edwards AFB. Due to the length of the Full Mission flight plan, several areas within the\ncomplex will be scheduled including: R-2515; plus Isabella, Bakersfield and Porterville MOAs.\nIntruder aircraft will be preposition at staging points within the test area to facilitate 4 live flight\nencounters.\n4.6.1 Mission Plan\nFM flights are planned for approximately 40 minutes of flight duration with an additional 20\nminutes required (if flown completely) to reset the mission and to fly subsequent test runs. At\nleast three complete runs are planned each test day. Missions are planned to be flown at 12-15Kft\nMSL. At least one delay for UAS surrogate and low speed intruder refueling may be required\nduring a test day that will require at least a one hour delay between test runs to complete the fuel\nstop.\n\n56\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 4-5. Example of a Full Mission flight flown in R-2508 Complex\n\n57\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nFigure 4-6. Example of a Full Mission Track with Encounter Points\n\n4.6.2 Test Encounters\nFull mission flight encounters are planned for 4 live intruder aircraft encounters and 6 virtual\naircraft test encounters. The subject pilot will operate the UAS surrogate while positioned at the\nRGCS using three different self-separation displays under test. Each mission will be run in its\nentirety starting at the northwestern waypoint proceeding southeast, then proceeding northeast\nand then turning northwest essentially reversing the original course along a flight plan that\nrepresents a fire line mission within Class E airspace (Figure 4-6). To the subject pilot, the fire\nline scenario is being flown in Oakland Center airspace (ZOA).\nDue to the complexity of system architecture required to perform UAS surrogate operations, a\ncomplete understanding of normal and abnormal conditions, flight operations procedures and\nflight safety analysis is expected by all participating aircrew and support elements of the flight\ntest. The following is a brief CONOPS of how the RGCS pilot, who is the subject pilot under\n58\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\ntest, performs his/her task and what is involved by the UAS Surrogate aircrew and other\nparticipating mission positions.\nThe RGCS pilot will fly the mission from the RGCS station using VSCS as his/her primary user\ninterface. The RGCS pilot will \xe2\x80\x98fly\xe2\x80\x99 the fire line mission as if the mission is being flown within\nOakland ARTCC (ZOA) airspace. The RGCS pilot will \xe2\x80\x98command\xe2\x80\x99 the \xe2\x80\x98autonomous\xe2\x80\x99 UAS\nSurrogate through keyboard and mouse interface in order to navigate a preplanned mission plan\n(fire line route). Self-separation alerts will be depicted on either the VSCS display or a\nstandalone display. The RGCS pilot will respond to alerts as appropriate while adhering to\nmission constraints (such as airspace boundaries, ATC directions, aircraft performance\nlimitations, etc.). The RGCS pilot will communicate with ATC (virtual) via CPNC link. This\ncomm link keys a VHF radio onboard the T-34C that transmits RF signals on the Virtual ATC\nNet via local and distant connectivity links to a controller located at Ames. When the RGCS pilot\nreceives an alert and needs to communicate with ATC (virtual), he/she is expected to request\npermission to respond to the alert prior to actually issuing the command using VSCS. When a\ncommand is issued by the RGCS pilot, the UAS Surrogate aircrew will receive these commands\nvia the CNPC link and respond accordingly. The T-34C UAS Surrogate aircraft is capable of\nautonomous lateral (heading) control; therefore, when the RGCS pilot issues a heading change,\nthe T-34C UAS Surrogate aircraft autopilot will automatically respond to the heading change\ncommand. Pitch, directional, and speed commands will be displayed to the T-34C pilot who will,\nin turn, consent or manually perform the appropriate control inputs to effect the maneuver\nexpected by the RGCS pilot. The Test Conductor via mission net (separate VHF radio) will\ncommunicate with the T-34C aircrew and participating intruder aircraft to facilitate actual\nmission coordination. A dedicated SPORT controller is expected to support the mission on\nMission Net and provide traffic callouts and other coordination calls as required.\nThe Test Conductor will coordinate with the Ghost Controller via the Ghost Net to ensure that\nreal and virtual intruder aircraft encounters are managed appropriately to ensure that the subject\npilot meets HSI test objectives (Figure 2-5). Encounter geometries and timing are important\nelements of the test therefore the Test Conductor and Ghost Controller will need to ensure that\nany variability to the real world trajectory of the UAS Surrogate are managed behind the scene in\norder to provide the subject pilot with the realism and consistency desired by the HSI\nresearchers.\n4.6.3 Ownship Requirements\nThe NASA GRC T-34C UAS Surrogate aircraft is planned for Flight Test 3 ownship full mission\nflight encounters. The T-34C will be equipped with the CNPC, ADS-B, and GPS. Ownship\naircraft must be available to support the planned flight schedule.\n4.6.4 Intruder Requirements\nIntruder aircraft require ADS-B, and GPS. Intruder aircraft may be sourced from NASA AFRC,\nNASA GRC and Honeywell.\n4.6.5 Virtual Aircraft Requirements\nVirtual aircraft are manned IFR and VFR (squawking) aircraft generated by simulation sources\ndeveloped by NASA ARC.\n59\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n4.6.6 Minimum Separation\nThe minimum geospatial offsets planned are 500 ft vertically and 0 ft horizontally.\nAll participating aircraft will ensure that the aircraft altimeter system meets manufacturer\ncalibration specifications and requirements for normal operation in the NAS.\nA maximum of 600 ft (0.1 nmi) navigation error (GPS derived position) is allowed for each\naircraft based on the system\xe2\x80\x99s built-in navigation accuracy readout.\n4.6.7 Minimum Success Criteria\nComplete 3 runs using different displays for each of 10 subject pilots as required by\nproject PEs.\nValidate self-separation display performance in a relevant environment.\nCollect sufficient data to evaluate objective and subjective pilot data to determine display\nacceptability as a self-separation decision-making tool.\nCollect sufficient data to inform self-separation MOPS.\nCollect sufficient data to inform communication MOPS.\n\n60\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nPlaceholder page for FT3 Configuration 1A, 1B and 2 Overview Table\n\n61\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n5\n\nTest Reporting\n\nSeveral reports shall be developed by specific members of the test team and distributed as\ndescribed in this section.\n\n5.1 Deficiency Report\nDuring testing any deficiencies that are found in the system or any component of the system will\nbe reported to the Test Conductor. The circumstance of the testing during the deficiency will be\nnoted. At the discretion of the Test Conductor the test may continue, or be terminated. During\nthe Post-test Brief, any deficiency reports will be reviewed. The Test Conductor and Project\nEngineers will determine whether any steps need to be taken to mitigate the deficiency before\ncontinuing with the next set of tests\n\n5.2 Progress Report\nThe IT&E sub-project will deliver preliminary test results to the UAS-NAS Project Office during\ntesting on a per request basis. After each debrief, the AFRC IT&E PE will compile and submit a\ndaily test run sheet to the Project Office including runs/events planned versus successfully\naccomplished on that day, a summary of deficiencies identified during the day, and a brief\nstatement of the next test period/day\xe2\x80\x99s planned runs.\n\n5.3 Test and Preliminary Results Report\nThis report documents the tests that were conducted along with a report of the data collected.\nThis report does not provide analysis of the data, but documents the compilation of the daily data\nruns form the daily debrief report and a summary of the data collection.\n\n5.4 Analysis Reports\nThe formal Analysis Reports are detailed reports that present analyses, evaluation, results, and\nthe conclusions and recommendations of the research under test. Each subproject involved in the\ntest will produce an Analysis Report.\n\n5.5 Flight Test Report\nAfter completion of Flight Test 3, the IT&E Ops lead will develop a report that details the flight\ntest execution and results to be submitted to the UAS-NAS Project Office.\n\n6\n\nData Collection\n\nThe IT&E Data Management Plan, IT&E DMP-001, documents the following data management\nactivities required for FT-3:\nPurpose of data collection;\nSources and types of data to be collected by each flight test participant;\n62\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nQuick-Look at data on day-of-flight;\nReception and archival in a central data repository; and\nProviding data from the central data repository to test participants.\nEach participating organization captures data relevant to the FT-3 flights received by its aircraft\nor generated by that aircraft, including surveillance and tracking data (both ownship and other\naircraft), inter-aircraft data communications, air-ground data communications, as well as data\nprovided to and actions produced by the on-board TCAS.\nA \xe2\x80\x9cquick-look\xe2\x80\x9d on each day of FT3 test flights will be performed to assess the prospects of\nsuccessful flight tests both during the flights and immediately post-flight. Refer to IT&E DMP001 for a description of roles and responsibilities related data analysis pertaining to \xe2\x80\x9cquick-look\xe2\x80\x9d\nactivities and post-flight data analysis.\n\n6.1 Summary of Data Sources from Flight Test Aircraft\n\nFigure 6-1. FT3 Data Collection Sources\nDetails for this section are TBD.\n\n7\n\nAppendices\n\nDetails for this section are TBD.\n63\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nAppendix A\n\nReference Documents\n\nDocument Number\n\nDocument Title\n\nOIEP SRD-01\n\nOwnship and Intruder Equipage and Performance SRD\n\n14 CFR Part 91\n\nGeneral Operating and Flight Rules\n\nEAFBI 13-100\n\nEdward AFB Instruction Flying and Airfield Operations\n\nDetails for this section are TBD.\n\n64\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nAppendix B\n\nAcronyms\n\nACAS\n\nAirborne Collision Avoidance System\n\nACE\nADRS\nADS-B\nAESA\n\nActive Coordination Emulation\nAeronautical Data Link and Radar Simulator\nAutomatic Dependent Surveillance-Broadcast\nActive Electronically Scanned Array\n\nAFRC\nAFRL\nAFSR\n\nArmstrong Flight Research Center\nAir Force Research Laboratory\nAirworthiness and Flight Safety Review\n\nAFTC\n\nAir Force Test Center\n\nAPL\nARC\n\nApplied Physics Laboratory\nAmes Research Center\n\nARTCC\nATAR\nATC\n\nAir Route Traffic Control Center\nAir-To-Air-Radar\nAir Traffic Control\n\nC2\nCA\n\nCommand and Control\nCollision Avoidance\n\nCAS\nCDTI\nCFR\n\nCollision Avoidance Systems\nCockpit Display Of Traffic Information\nCivil Flight Regulations\n\nCOA\nCOMM\nCONOPS\n\nCertificate of Authorization\nCommunications\nConcept of Operations\n\nCoPE\nCNPC\nCPA\n\nCo-Project Engineers\nControl and Non-Payload Communications\nClosest Point of Approach\n\nCPDS\nCV\nCVSRF\n\nConflict Prediction and Display System\nCollision Volume\nCrew Vehicle Simulation Research Facility\n\nDAA\n\nDetect and Avoid\n\nDAIDALUS\nDATR\n\nDetect & AvoID Alerting Logic for Uncrewed Systems\nDryden Aeronautical Test Range\n\nDCP\nDHS\nDO\n\nDryden Centerwide Procedure\nDepartment of Homeland Security\nDirector of Operations\n65\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nDPMf\n\nDeputy Program Manager for\n\nDRR\nDSRL\n\nDue Regard Radar\nDistributed System Research Laboratory\n\nEAFBI\nEC\nEDM\n\nEdwards Air Force Base Instruction\nExperimental Certificate\nEngineering Development Module\n\nEP\nERAM\nFAA\nFAR\n\nEntry Point\nEn Route Automation Modernization\nFederal Aviation Administration\nFederal Aviation Regulations\n\nFBO\nFDDRL\n\nFixed Base Operator\nFlight Deck Display Research Laboratory\n\nFM\nFOM\nFP\n\nFull Mission\nFigure of Merit\nFlight Prototype\n\nFRR\nFT3\nFTP\n\nFlight Readiness Review\nFlight Test 3\nFlight Test Plan\n\nGA-ASI\nGCS\n\nGeneral Atomics Aeronautical Systems Inc\nGround Control Station\n\nGPS\n\nGlobal Positioning System\n\nGRC\nHSI\n\nGlenn Research Center\nHuman Systems Integration\n\nHITL\nHLA\nIFR\n\nHuman In The Loop\nHigh Level Architecture\nInstrument Flight Rules\n\nIP\nIT&E\nITAR\nJADEM\n\nInitial Point\nIntegrated Test and Evaluation\nInternational Traffic In Arms Regulations\nJava Architecture for DAA Extensibility and Modeling\n\nKGS\n\nKilograms\n\nLaRC\nLOS\nLVC\nMACS\n\nLangley Research Center\nLoss of Separation or Line of Sight\nLive Virtual Constructive\nMulti Aircraft Control System\n\nMD\n\nMission Director\n66\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nMHz\n\nMega Hertz\n\nMOA\nMOPS\n\nMilitary Operating Area\nMethods of Performance Standards\n\nNAS\nNASA\nNOTAMS\n\nNational Airspace System\nNational Air and Space Administration\nNotice To Airmen\n\nNPR\nPE s\nPT4\nRAIF\n\nNASA Procedural Requirements\nProject Engineers\nPart Task Four\nResearch Aircraft Integration Facility\n\nRGCS\nRTCA\n\nResearch Ground Control Station\nRadio Technical Commission for Aeronautics\n\nRUMS\nSAA\nSAF\n\nRemote User Monitoring System\nSense and Avoid\nStand Alone Facility\n\nSATCOM\nSGT\nSimMgr\n\nSatellite Communication\nStinger Gaffarian Technologies\nSimulator Manager\n\nSMO\nSPORT\n\nSpectrum Management Office\nCall Sign for AFFTC Radar Control Facility\n\nSS\n\nSelf-Separation\n\nSSI\nSTARS\n\nSeparation Assurance/Sense and Avoid Interoperability\nStandard Terminal Automation Replacement System\n\nSTM\nTBD\nTC\n\nSurveillance Tracking Module\nTo Be Determined\nTest Conductor\n\nTCAS\nTD\nToR\nTRM\n\nTraffic Alert And Collision Avoidance System\nTest Director\nTerms of Reference\nThreat Resolution Module\n\nUAS\n\nUnmanned Aircraft Systems\n\nVFR\nVHF\nVSCS\nWAAS\n\nVisual Flight Rules\nVery High Frequency\nVigilant Spirit Control Station\nWide Area Augmentation System\n\nZOA\n\nOakland Air Route Traffic Control Center\n67\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\n68\n\nIT&E FT3 FTP-01\nDRAFT--BASELINE\n\nAppendix C\n\nDefinition of Terms\n\nDetails for this section are TBD.\n\n69\n\n'