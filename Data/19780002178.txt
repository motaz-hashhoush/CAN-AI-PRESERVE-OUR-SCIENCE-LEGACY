b'General Disclaimer\nOne or more of the Following Statements may affect this Document\n\nThis document has been reproduced from the best copy furnished by the\norganizational source. It is being released in the interest of making available as\nmuch information as possible.\n\nThis document may contain data, which exceeds the sheet parameters. It was\nfurnished in this condition by the organizational source and is the best copy\navailable.\n\nThis document may contain tone-on-tone or color graphs, charts and/or pictures,\nwhich have been reproduced in black and white.\n\nThis document is paginated as submitted by the original source.\n\nPortions of this document are not fully legible due to the historical nature of some\nof the material. However, it is the best reproduction available from the original\nsubmission.\n\nProduced by the NASA Center for Aerospace Information (CASI)\n\n^\t\n\n^c\t\n\n^\t\n\nI\t\n\n\xe2\x80\xa2 .\t\n\nI\t\n\n1\n\nr\t\n\n--r.\n\t\n\nC. (Z - ^ S zo Lo\n\nUNCLASSIFIED\n\nFINAL REPORT\nNUMERICAL AERODYNAMIC SIMULATION FACILITY\nPRELIMINARY STL:nY\n\nOP. i\n\nOctober 1977\n\nDistribution of this report is provided in the interest of informatiol\nexchange Responsibillty for the contents resides\nin the author or organization that prepared it.\n\nI\n\nEXECUTIVE SUMMARY\n\n1\nPrepared under Contract No. NAS2 9456 by\nBurroughs Corporation\nPaoli, Pa.\nfor\n\nN,\t .;01\n(NASA\t\n\n-\'\n\nAMES RESEARCH CENTER\nAERONAUTICS AND SPACE ADMINISTRATION\n10 r,\t\n\nI\t\n\nNU:\n\n-\n\nJD\'i NAMIC\n\nSIMULA110% FACILITY\t Ph- LlMiNAFY\t STUDY:\nEXFCCTIV6\nCorp.)\t\n\n25\n\nSTTIDY\t\np HC\t\n\nFind hep ,)rt\t\n\nAl2/MF\n\nAC, l\t\n\n(burrouyhs\nCSCL\n\n14p\n\nT\xe2\x96\xba nclas\nG3/09\n\n52511\nHA S\n\nUNCLASSIFIED\n\n^,fE`VEa\n\nI\t\n\nUNCLASSIFIED\n\nFINAL REPORT\nNUMERICAL AERODYNAMIC SIMULATION FACILITY\nPRELIMINARY STUDY\n\nOctober 1977\n\nDistribution of this report is provided in the interest of information\nexchange. Responsibility for the contents resides\nin the author or organization that prepared it.\n\nEXECUTIVE SUMMARY\n\nPrepared under Contract No. NAS2 9456 by\nBurroughs Corporation\nPaoli, Pa.\nfor\nAMES RESEARCH CENTER\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n\nUNCLASSIFIED\n\ni\n\nt\n\nR`\n4\n\nT\nORIGNAL PA()F\' lb\nOF PUOA QU kL"TY\n\n6\n\nNAVIE R-STOKES SOLVER\n\nINTRODUCTION\nBurroughs Corporation is pleased to Submit this executive summary of the findings of the Numerical\nAerodynamic Simulation Facility (NASF) Preliminary Study. This report presents a unique solution to the\nproblem of numeric aerodynamic simulation. The solution consists of a com p uting system designed to meet\nthe stated objective of providing an effective throughput of one billion floating point operations per second\nfor three dimensional Navier-Stokes codes. Burroughs p resents this design with full confidence that it is\nfeasible to complete the detailed design and construction of this machine within the required time frame.\nThis high level of confidence is based on Burroughs\' extensive and continuing experience in the design and\ndevelopment of very high performance computer systems, It is Burroughs\' belief that the computer indus\ntry will riot produce a commercial general purpose machine with the required performance by the early\n1980\'s. Consequently, we feel that the design and cc istruction of a relatively specialized system is not\nonly feasible, but necessary to the achievement of NASF objectives.\nThis view is based on two business judgements. First, projections of both computing power and cost of\nperformance of commercial computers for the 1980 to 1985 time frame do not include a machine of this\ncapacity or price. That is, a generation gap will exist between any NASF implementation arid concurrent\ncommercial products. Second, market trends indicate that an insufficient market exists to sustain develop\nment of a machine with two orders of magnitude speed ^ncrease on a commercial basis.\nIn summary, we believe that the sy ,item presented in this report constitutes the best approach to meeting\nthe NASF goals in a timely and cost effective manner, and that NASA has an opportunity to maintain a\n"forefront" position in the scientific community while achieving these goals.\nThe results of this study have produced a unique solution to the problem of numerical aerodynamic sirnu\nlation of three-dimensional Navier Stokes equations. In order to fully appreciate the design, its features,\nand subtleties, the methodology of the study which evolved this solution must be understood. This execu\ntive summary is intended to explain that methodology. First, the problem and solution, in brief, will be\npresented, then basics of the study approach will be expla ; ned. Next, a description of each of three sub\nstudies follows with emphasis on specifically what was examined and why. Finally, the results of the substudies are merged to highlight their im \xe2\x80\x9e ,act on the processor architecture evolution, and show how the\n"baseline design\xe2\x80\x9d for NASF was selected. The final report chapters will discuss details of that design.\n\nMEMORIES\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\nFILE\nSTORAGE\nCENTRAL\nPROCESSORS\n\nPERIPHERALS\n\nV^.\t\nP^\n\nc\n\nG\'r\t\xe2\x80\xa2\n\nAND\n\nI/O\nPROCESSOR\n\nARCIitVE\nSTORAGE\n8\n\nLOCAL USER TERMINALS\nAND\n\nINTERACTIVE\nGRAPHIC TERMINAL\n\n(50)\n\nREMOTE\nTERMINALS\n(50)\n\nSUB SYSTEMS\n(2)\n\nDISPLAYS\n\nFigure 1\t\n\nNASF Syvem Block Diagram\n\nI\n\n2\n\nE\n\nSTUDY OBJECTIVES\nThe Numerical Aerodynamic Simulation Facility Preliminary Study Objectives were to determine the\nfeasibility of desiyniny a system delivering one billion floating point operations per second effective through\nput for three dimensional Navier Stokes codes by 1982. If feasible, a processor architecture and functional\ndesr-In definition were to be developed, supporting that assertion. with attendant requirements of power,\nsize, cost, schedule, etc.\n\nNASF OVERVIEW\nThe basic structure of the candidate baseline NASF system is shown in Fig. 1. The major elements are: \t\n\ndp\xe2\x80\x9e\n\n\xe2\x80\xa2 The Host, a Burroughs B7800 multiprocessing system\n\xe2\x80\xa2 The Navier Stokes Solver (NSS) ... the high throughput work horse of the system\n\xe2\x80\xa2 File Memory\n\xe2\x80\xa2 An Archival Storaqe system.\nTHE HOST COMPUTER\nThe Host, a Burroughs 87800 system, acts as the system manager and support facility. It provides the\nuser interface, schedules and dispatches NSS tasks, and executes supporting functions such as compilation,\ndata reduction, and output generation.\nTHE NAVIER STOKES SOLVER (NSS)\nThe NSS is the high throughput computational element. It is a highly parallel processing array, designed\nto provide the required computational throughput on three dimensional Navier Stokes programs. The\nData Base Memory (DBM) of the NSS provides the interface between the NSS and other system elements.\nThe program and data files are loaded to the DBM by the Host. The NSS with the DBM constitute a high\nspeed "computational envelope," allowing the NSS to run at maximum speed essentially without outside interruption or dependence until job completion.\nTHE ARCHIVE MEMORY\nThe Archive provides a very large storage capability for long term retention of programs and data bases.\nIt consists of a commercially available mass memory system, which is managed by the Host.\nTHE FILE MEMORY (FM)\nThe FM provides for short term file retentior , staging and buffering between the Host, the Archive, and the\nDBM. It consists of a standard disk pack sub system, and is also managed by the Host.\n\n3\n\n\t\n\n1\n\nEM\t I\t\n\n2 X 10 8 B T;i SEC\n\nEXTENDED\t\nMEMORY\t\n\nEM 2\t\n\nEM 52 I\n\n111,75 X 10\'\' BITS/SEC.\n\nTRANSPOSITION NETWORK\n(521/512 PATHS)\nl\n\n;. 75 X 10" BITS/SEC PEAK\n\nPROC. I\n\nLM\nPE\nPE\nFROG.\nMEM.\n\n4\n\nMAJOR ELEMENTS OF THE NAVIER STOKES SOLVER\nThe principal innovation in the NASF system is the NSS. The organization of the NSS is shown in Figure 2,\nand its characteristics are summarized in Table 1 The mayor features of this processing array areHighly Parallel Architecture\nThe NSS consists of 512 computational processors, each with its own local 6ata program memories.\nThese are coordinated by a single control unit, and connected via a transposi t ion network to 521\nmodules of extended memory.\n\xe2\x80\xa2 Synchronizable Operation\nr\n\nThis feature of the NSS suggests the name we have given to the computational array, the Synchro\t\nnizable Array Machine, or SAM Previous processor arrays have operated in "LOCKSTEP," essen\ntially synchronizing o , every instruction cycle. The computational array of the NSS is synchro \t\n\n1\n\nnized explicitly by the code stream only when necessary. Between synchronization points, the\nindividual processing elements may operate asynchronously, allowing them a degree of freedom\nin scheduling instruction sequences.\n\xe2\x80\xa2 Conflict Free Memory Access\nThe transposition network between the processing elements and extended memory allows conflict\nfree access to vectors in any dimension at full memory bandwidth. This eliminates the non produc\ntive time which would otherwise be consumed by reordering or transposition of data before pro\ncessing.\n\xe2\x80\xa2 Large Second Level Store\nThe Data Base Memory (DBM) in the NSS provides an interface between NSS and Host that allows\neach to process independently of the ether. NSS processing need ne^\'er be held up waiting for\nsome response from the Host.\n\xe2\x80\xa2 System Balance\nAll transfer rates and execution speeds are tuned to one another in concert with the requirements\nof the application. This provides for high efficiency by balancing the utilization of system elements.\n\xe2\x80\xa2 Ease of Use\nA high level user language, complemented by 3n instruction set oriented to efficient implementation\nof high level language programs, allows reaclv access to the computational power of the NSS, without encumbering the user with assembly language programming or implementation details.\n\n5\n\nTABLE 1 NSS CHARACTERISTICS\nComputational Capacity (On instruction mix) \t\n\n1.7 x 10 9 floetirn \xe2\x80\xa2 operations /sec.\n\nNumber of Processing Elements \t\n\n512\n\nNumber of Extended Memory Modules \t\n\n521\n\nMemory capacities (total)\n\t\nExtended memory\n\n34 million words \t\n\t\n\nf- 1\n\n8 million words\n\nProcessing element memories\n\t\n\n4 million words\n\nProcessing element program memories\n\nper path\t\n\nTransfer rates (bits/sec)\n\ntotal\n\nno. paths\n\n,\n\n512\n\n2.5 x 1011\n\n512\n\n2.5 x 1011\n\n109\n\n512\n\n5 x 1011\n\nstreaming mode\n\n4 x 108\n\n512\t\n\n2 x 1011\n\n1 word/transfer\n\n1 x 108\n\n512\t\n\n5.5 x 1010\n\n49U x 106\n\nPE - PEM\n\ni\nI\n\nPE\t\n\nPEPM\n\nPE\t\n\n(PEM+PEPM)\n\nEM\t\n\nvia TN\t\n\n490 x 106\n\n^\n\nPEM\n\nI A x 108\nEM\n\nDBM\n\n4 x 108 per PE\n\nProgram loading to all PE\'s snnultaneously\n\t\nClock, synchronous throughout the NSS\n\n50 MHz minor cycles\n25 MHz major cycles\n\nTotal No. of IC packages, including memory\n\n(almost all LSI) \t\n\n200,000\n\nWord Size:\t\n\n48 Bits\n\n6\n\nI\t\n\nI\t\n\nI\t\n\n^\t\n\n^\n\nr\nt\n\nSTUDY METHODOLOGY\nExperience in the design and manutdcture of data processing) equipment, es<)ecially very high performance\ncomputer systems, leaves many lessons behind. In addition to knowing what a design team should do, there\nare some IesSJnS about what should not he clone.\nThe Burroughs study team took care to avoid a serious prol , n that often traps those aiming at maximum\nspeed - namely pushing the state of the art on too many frontiers. One could rely on significant advances in\n\xe2\x80\xa2 Architecture,\n\xe2\x80\xa2 Hardware Technology, or\n\xe2\x80\xa2 Software Technology.\nFor increased performance Burroughs chose Advanced Architecture taking care to build on mature or\ndeveloped software whenever possible. In addition hardware implernentatioo, will be conservative, consis\ntent with performance goals, and will not rely on imposing inordinate speed requirements or new, untried\ntechnologies.\nSelecting architectural elegance as the new frontier, the study concentrated on matching the architecture to\nthe problem, Existing computer structures were not integrated to force fit a "super structure" of these\nunits to the problem. The reasons were:\n\xe2\x80\xa2 Lack of Architectural Flexibility\n\xe2\x80\xa2 Inefficient and Not-Cost-Effective.\nAlthough performance requirements may be met in this fashion, the lack of architectural freerforn with the\nstructures implies that many hardware an(] software elements are not utilized, others must be customized,\nresultiny in a machine that has sortie "dead wood."\nThe NASF system presented here was developed by evolution from careful analysis of the problem charac\nteristics to insure a genuine fit, Top-down design fundamentals were practiced so that on each of the\nseveral design iterations, results could be traced to assumptions. Traceability of this sort allows bottlenecks\nor errors found to be identified at their origin where viable alter natives could be reexarnioed.\nSUB STUDIES\nSpecifically, three Lib studies were executed simultaneously as required by the original contract statement\nof work,\n\xe2\x80\xa2 THE TECHNOLOGY STUDY developed a data base of logic and memory technologies by literature searches, vendor interviews and conferences, etc. Trends of critical issues and parameters of\nthese technologies were studied and a technology forecast developed for the 1980 1985 time-frame.\n\xe2\x80\xa2 THE MATCHING STUDY analysed the flow models and their characteristics and matched them\nagainst candidate processor architectures.\n\xe2\x80\xa2 THE FACILITY STUDY established metrics for the !otal facility and, at a more detailed level, the\nfacility issues addressing the "buildability" of the final system.\nEach sub study was executed with two objective as shown in Figure 3.\n\xe2\x80\xa2 How do results affect processor architecture choice?\n\xe2\x80\xa2 How do results affect specific design choices in the baseline design?\n\n7\n\nr T-1\n\nFigure 3\t\n\nNASF Study Approach\n\nT I I ^\n\n--\n\nT\n\n- \'\n\nT-T-I\n\nThat is, first a processor architecture ..as evolved as a result of the sub-:"Jdies, then a second iteration of\nthe studies supported a more detailerl design to the functional design level referred to as the Baseline Design.\nThe result is an NASF definition that directly addresses the salient issues of the problem itself. \' p his NASF\n.Iefinition meets or exceeds all requirements and cdn be boil! wah d high degree of confidence an assertion\nof , ;-eat significance fur such an ambitious task\n\nTECHNOLOGY STUDY OVERVIEW\nThe objective of this phase ^)f the study was to establish a technology forecast for the NASF time frame\nand assess which logic and me roory technologies are most appropriate for the design of such a facility.\nThe approach taken consisted of tiv? following four tasks:\n\xe2\x80\xa2 Data Gatiieriny\n\xe2\x80\xa2 Establish Critical Issues\n\xe2\x80\xa2 F xarnine Technuioyies & Trends\n\xe2\x80\xa2 Extrapolate 1980 85 Forecast.\nData gathering consisted of a three phase effort a comprehensive literature search, trade conferences and\nworkshops, and interviews with vendors and suppliers such as Motorola, Fairchild, National Semiconductor,\nIntel,\n\nSignetics, and Texas Instruments.\n\nThe critical issues which were established were of two tyues \xe2\x80\xa2 those affecting performance and those affecting development,\nPERFORMANCE\n\xe2\x80\xa2 speed\n\n\xe2\x80\xa2 density\n\xe2\x80\xa2 reliability\n\xe2\x80\xa2 power\n\nDEVEt_OPP.1ENT\n\xe2\x80\xa2 cost\n\xe2\x80\xa2 maturity\n\xe2\x80\xa2 extensiveness\n\xe2\x80\xa2 availability\nMetrics for judgement of these issues and clarifications of their importance were then developed and used\nas criteria in the architecture/design process.\nUnder 1erformance issues, speed of a logic family may be judged by propagation delay times, while with\nmemory the key figures are read/write times. Density refers to the avercge number of gates or memory cells\nper chip. Reliability is largely a function of density since failures frequently occur at the substrate to pin\nconnection, and as the number of pin connections decreases per given function, the reliability increases.\nPower consumption is a measure of the energy costs and reliability associated with a device. A smaller\nspeed-power product indicates better system performance per kilowatt.\nAs to developmental issues, cost should be considered in the light of performance per doilar, as well as\nabsolute cost. Maturity is determined by field verification of manufacturer\'s specification. Another\n9\n\nconsideration in selecting d technology is the availability of the devices. In addition, multiple sources for\nall componentry are essential. These factors are important consufei ttions in the selection of a technology\nfamily.\nThe technology survey provided inputs to the study riot only in the obvious area of surveying the imple\nrnentat \xe2\x96\xba on of digital logic, but also in some areas of packaging, random access and serial memories, and\narchives.\nFrom the many technolo;:es used to implement digital logic, thre,^ are of sufficient interest to report here;\n\xe2\x80\xa2 ECL has been the technology of choice in implementing high speed digital computers for over ten\nyears. The speed power product, aril hence thN amount of processing that can be done per watt of\npower, has been continually improved, and in the last year some LSI has been available in ECL.\nECL is a mature but still developing technology, exemplified by Fairchild\'s "100K" ECL family,\nThis farnily could be used as a star my point for a baseline design.\n\xe2\x80\xa2 1 2 L has much better speed power product than\n\nECL, allowing far more functions per watt. It is\n\ncurrently too slow for the NASF requirement but both speed and availability of standard parts are\nimprovirq each year. 1 2 L would cons::me considerably less power than ECL and is currently utilized\ninternally in LSI chw -here the speed is tolerable.\n\xe2\x80\xa2 MESFETs pror- another improvement, by an order of magnitude, in the speed rower product as\nco \xe2\x80\x94 pared to 1 2 L. They are also very fast; however, they are still in early development. Years of\ndevelopment will be required before the MESFET\'s technology becomLs mature.\nFrom this study we conclude that ECL is the most feasible current technology for implenientation of an\nNASF design, and the base line design will begin with ECL as a starting point.\nMemory technology represents an area of low risk for the (NSS). 16K bit dynamic RAM\'s (Random Access\nMemory) ;ire currently available. 16K-bit static RAMS and 64K bit dynamic RAMS are on the drawing\nboard.\nCCD shift register memory is currently available in pilot quantities in the 64K hits size. Another factor\nof four in storage size (256K bits) is expected by 1980.\nManufacturers reported the occurrence of spontaneous errors in CCD memories. This leads to a requirement\nfor continuously monitoring the contents of a CCD memory and rewriting it correctly when bit Prrors\noccur.\nPresent bubble memories put severe complexities into the controlling and driving circuitry, making them\nvery difficult to use.\nSufficient information about the magnetic storages available for the archive was obtained to indicate that\nthere are several commercially available contenders for the archive storage. No effort was mad- to deter\nmine which of today\'s contenders were likely to be withdrawn from the market in the next two years, nor\nto uncover the new contenders which are undoubtedly under development.\n\n10\n\nT iT ;I^TI\n-\n\n-\n\nPROCESSOR - FLOW MODEL MATCHING STUDY OVERVIEW\nThe key sub study in this effort was the Matzhing Study. Certainly, it had the most profound effect on the\nevolution of SAM as the ch-)sen processor architecture as well as some design details. This sub study was\nbroken into several t asks prior to the aLtual matching or evolving process itself,\n\xe2\x80\xa2 Cataloging and examination of pertinent generic architectures for consideration to be ; sed as a\nstarting point.\n\xe2\x80\xa2 Establishment and discussion with NASA Ames of critical issues and basic requirements and caps\nbilities imposed on the architecture by the problem definition.\n\xe2\x80\xa2 Research and discussion of the fundamental characteristics of the flow models which affect the\nprocessor architecture.\nFollowing these tasks, the res-ilts were merged with those of the other two sub studies the total implica\n\n40-\n\ntions of which determined the final architecture.\nGeneric Architectures considered as starting points were:\n\xe2\x80\xa2 Hybrid system composed of analog computation devices with digital control and storage\n\xe2\x80\xa2 Parallel array architectures with replil-ated arithmetic units executing the same program on different\ndata achieving performance as a multip l e of the number of arithmetic units.\n- Type 1\t\n\nLock Step synchronous arrays with clock by clock tight coupling of arithmetic units\n\n- Type 2 Non Lock-Step arrays with coupling at predetermined synchronization points rather\nthan every clock\n\xe2\x80\xa2 Pipeline architectures where operations are streamed through different stages with performance as a\nmultiple of the number of states.\nA complete discussion of these generic architectures is found in Appendix L of the final report.\nCritical issues, basic requirements and capabilities were jointly developed between the study team and\nNASA Ames personnel. Topics excmined were:\n\xe2\x80\xa2 Navier s tokes Solver t. \xc2\xad abilities\n\xe2\x80\xa2 Programming\n\n\xe2\x80\xa2 NSS - 110\nNSS CAPABILITIES\nThe ability to solve the three-dimensional Reynolds averaged Navier Stokes equations, using both exp,.cit/\nimplicit and totally implicit, dimension ally-split, finite-difference methods.\nThe ability to compute, at high efficiency, problems containing a variety of boundary conditions which\ninclude the independent variables, their derivatives, and other auxilliary variables, a variety of internal and\nexternal geometries and a variety of turbulence models ranging from algebraic to seven differential equation\ndescriptions.\nThe ag ility to compute solutions for up to one million grid points. This implies a data base range to 14\nmillion words for:\n5 conservation variables at 2 time levels\n1 turbulence variable\n\n11\n\n3 grid coordinates\nto 40 million words for:\n5 conservation variables at 2 time levels.\n7 turbulence variables at 2 time levels.\n3 grid coordinates\n12 metrics (including time)\n1 Jacobian\nThe ability f- obtain steady state solutions for one million grid points in 10 minutes of CPU time for 3 D\nproblems using algebraic turbulence models. At present this must be measured using 2 D explicit/implicit\nand implicit codes as performance metrics.\nTwo examples of typical programs and their computational requirements are given below:\nExplicit code (MacCo r mack) status: A 2 D airfoil steady state solution was obtained in ; minutes on CDC\n7600 for 2100 grid points. The steady state was reached after 13 chord lengths of travel by computing\ninviscid solution for 7 chords and viscous solution fir remaining 6 chords. Effective computing steed on\n7600 is about 2 MF LOPS. Assuming twice the :omputational effort at each grid point for the 3 D case, this\nimplies that to compute 13 chords i n 10 minut,.s for one million grid points requires an effective computing\nspeed of 1.4 gigaflops. Greater efficiencies by 1980 can be expected.\nImplicit (Lomax, Ste(jer) code status: A 2 D airfoil steady state (12 chords traveled) was obtained in 10\nminutes on CDC 7600 for 2300 grid points all calculations were viscous. The effective computing speed on\n7600 is about 2 megeflops. This code implies that an effective computing speed of 2 gigaflops will be\nneeded for a 3\xe2\x80\xa2D calculation over one million grid points. However, researchers working on the implicit\ncode are confident that improvements in the treatment of boundary conditions and other strategies can\nimprove the speed of the method by a factor of 2 which implies that at least one gigaflop effective rate\nwi be needed.\nIt is concluded that the minimum effective computing rate needed for the Navier Stokes problem is one\ngigaf lop.\nA precision of 10 decimal digits is required.\nPROGRAMMING\nA high level programming language consistent with ease of mapping the solution methods onto the machine,\noptimum machine performance and the available language development time is necessary.\nDesirable programmability features of the Navier-Stokes machine are as fellows:\nA FORTRAN like high level language with extensions necessary for efficient problem mapping. As well as\nthe following features.\n\xe2\x80\xa2 a stable optimizing compiler\n\xe2\x80\xa2 good compiler diagnostics\n\xe2\x80\xa2 warning from the compiler of possible run-time inefficiencies\n\xe2\x80\xa2 ability to give good run-time diagnostics and statistics\n\xe2\x80\xa2 vector length independence\n\xe2\x80\xa2 freedom from the need to do explicit-mode vector manipulation\n\xe2\x80\xa2 ease in specifying data allocation.\n12\n\ni\t\n\n1\n\nNSS 1/0\nThe primary 1/0 activities of the machine are the input of initial problem parar.reters, restart from stored\ndata, and the output of snapshots and restart dumps. Another important activity is the output of debug\ndumps. Two basic types of Navier Stokes solutions are desired\xe2\x80\x94steady and unsteady (or more correctly\nquasi steady). Steady cases are characterized by the appearance of a solution that does riot vary with time\nafter some large number of time steps or large number of characteristic body lengths travelled. Unstuddy\ncases are characterized by the appearance of a solution that is periodic in time after some large number of\ntime steps. In order to analyze the unsteady or periodic nature of these solutions more time steps (on the\norder of six times that of steady cases) are required. Additional data outp ut is also required in these cases. It is\nestimated that 75% of the time will be used to solve the steady flow case and the remaining 25% the unsteady. \t\n\nY!\n\nThe following output capabilities for these cases are desired.\n\xe2\x80\xa2 Snap Shots\na. Integrated quantities such as drag, lift and moments approximately every 15 30 seconds.\nb. Surface quantities such as pressure and skin friction. If the grid moves with time, the grid coordinates must also be output. A given quantity such as pressure, plus the coordinates could\ntotal up to approximately 60,000 words of output every 15-30 - :onds.\nc, Flow quantities in the field such as pressure or Mach number. For a grid of 1,000,000 points an\nentire field of, say, Mach numbers plus coordinates would be 4,000,000 words. However, it is\nanticipated that only selected grid points need to be output and this would be about one hundreth\nof the about to 40,000 words every 30 seconds. These snapshots require the heaviest output and\nfor 60 minute runs would accumulate up to 5,000,000 words for the unsteady cases.\n\xe2\x80\xa2 Hestart Dumps\n\xe2\x80\xa2 Debug Dumps\n\xe2\x80\xa2 Formatted 1/O\nFLOW MODEL CODE CHARACTERIZATION AND ANALYSIS\nCodes supplied by NASA Ames were analyzed statically and dynamically to determine what the specific\ncharacteristics of the Flow Model problems are and how do they impact computer architecture. The codes\nstudied were written for two specific computers. Features in each code that were specific to its target\nmachine were stripped ativay to find the basic issues. The areas that were examined group themselves\nnaturally into those issues which address processor requirements, rnernory requirements, or communications\nrequirements, and are outlined below.\nMemory Requirements\n\xe2\x80\xa2 Data Base Size - (The actual input/output variables)\n\xe2\x80\xa2 Program Size\n\xe2\x80\xa2 Workspace Size (Those variables never outputted in normal production code \xe2\x80\xa2 the temporaries)\n\xe2\x80\xa2 Access Patterns (dimensionality of problems, subarray structure, indexing patterns)\nCommunications between Processors & Memories\n\xe2\x80\xa2 Number of Computations per Data Base Access\n\xe2\x80\xa2 Interaction of Problem Variables\n\xe2\x80\xa2 Data Dependency\n\xe2\x80\xa2 Control Structures\n\xe2\x80\xa2 Access Patterns (planes, rows, columns, etc.)\n\n13\n\nProcessor Requirements\n\xe2\x80\xa2 Word Size and Format\n\n\xe2\x80\xa2 Scalar operations\n\n\xe2\x80\xa2 Relative frequency of operations\n\n\xe2\x80\xa2 Frequency of intrinsics\n\n\xe2\x80\xa2 Index computations\n\n\xe2\x80\xa2 Program structure\n\n\xe2\x80\xa2 Number of input operands per output operands\n\nEach of these issues were examined in detail and the results are 1-ted in Cha p ter 8 of the \'final report\nwith a full discussion of the methodology.\nThe study of the memory requirements showed that the canonical problem variables and number of grid \t\npoints produce a data base memory of 14 40 million words INASA Ames requirement), the workspace\nsize was found to be approximately 40 temporaries per database variable, This of course is progr\xe2\x80\x9emmer and\narchitecture dependent and hence is only an indication of the relationship between work space and data\nbase. It was found that the problem arrays are generally 4 dimensional with 3 geometric arid variable\ncoordinator. They are accessed in a fairly regular manner in the sense that the indexing is a function of the\nloop variables plus or minus a small integer. There is almost no indexing that occurs as a function of loop\nvariable and eocither integer variable set outside of the loop. The structure of the loops indicate that entire\narrays are processed in a given piece of the computation rather than small subanays. \'Program size is rela\ntively small at under 4000 card images.\nRequirements on communication between processor and mernory structure were determined by a number\nof f.ow model ... procram parameters. The data dependency studies of variables in loops showed that there\nexisted complex first order linear recurrences which were functions of each of the three geometric variables.\nThese recurrences occurred in over 60% of the executing Implicit program. The study of the control or\nbranching structures within the programs showed t hem to be relatively simple and generally linlr- d to loop\nvariables. Some were data dependent but when they oc :urred the variables were functions of inner loop\nparameters.\nFurther studies of the relationship between the data base mernory requirements, the work space require\nments and the number of floating point operations showed that a fetch or store to data base memory\noccurred infrequently in comparison to the number of floating point operations. Typically the Implicit\n(Steger) program has an average incidence of 15 floating point operations per fetch.\nAdditionally, by investigation of the indexing patterns within loop structures one found that there is\nrelatively low interaction among problem variables on different grid points. For example, variables are\nfetched from several adjacent points, computations are performed and then a result is stored relative to ti-.e\ngrid point. There is no continual switching back and forth of index patterns. The access patterns appear to\nhe simple rows, columns and planes with a skip distance of 1.\nProcesser requirement studies showed that multiply, add, and multiply-acid instructions are extremely\nimportant floating point operations. For example, in the Implicit Code it was found that 53% of all opera\ntions were multiplies, 44% were adds and 2.5% were divides. About 60% of all operations occurred as\nmultiply add pairs. Division and intrinsics as SQRT and EXP occur rarely and double precision is never\nrequired. Since most of the array references are to & and 4- dir,.ensional arrays integer arithmetic calcula\n\n14\n\n_\t\n\ni\n\n..\n\nI\n\n-7\n\nmqlqllppw-- I -\n\n-1\n\ny\t\n\n\xc2\xad_ I\n\ntions are a strong requirement. The combination of work space requirements and the average numt)er of\ninput operands to output operands (3.5) places certain requirements on the proc,.,sor NASA Arnes has\nadditionally specified 10 digit accuracy requirement.\nThe data collected from the studies was used to define and delimit the characteristics of the requisite\narchitecture. The output from the matching study together with the technology study and facilities study\ndata were then used toolevelop definitions of an architecture discussed after the results of the facility study.\nFACILITY STUDY\nThe primary objectives of this sub study were threefold: \t\n\nOP\xe2\x80\xa2\n\n\xe2\x80\xa2 Identifv housing and support requirements of the facility\n\xe2\x80\xa2 To provide cost and schedule engineering estimates for effective planning\n\xe2\x80\xa2 Assessment of NSS implementation issues as they would impact architecture and design choices.\nThese objectives were pursued by determining the facility requirements of those units or subsystems\nalready identified and placing reasonable bounds on facility requirements for those elements which have yet\n\nto be specified. After a preliminary definition of the NSS, an implementation schedu l e and an engineering\ncost estimate were assembled, and analyzed. As the NSS definition proceeded, additional iterations on the\nschedule and cost were performed.\nFinally, the critical issues relevant to implementing the NSS were defined and guidelines developed to insure that the design would indeed be realizable. This effort raised some interesting considerations which im\npacted the architecture choice and some design details as well.\nCritical issues affecting the implerentation or realization of the NSS in particular are:\nCRITICAL PATH ANALYSIS was examined to eliminate short waterfalls in the schedule by locating their\nsource and minimizing their occurrence.\nPROCUREMENT problems can be avoided if there is an early identification of long lead items, if custom\ncomponentry is minimized, if multiple sources are employed wherever possible, and if adequate protective\ndocumentation is obtained from each vendor. This issue can be the largest single risk factor in any program\'s schedule, cost, and possibly performance.\nPRODUCTION considerations include maximizing the number of replicated units to minimize production\nlearning curves and take advantage of economies of scale. Standardization of componentry, connectors,\ncables, etc., minimizes inventory problems and smoothes the production process.\n\nMODULE OR SUBSYSTEM INTERFACE MANAGEMENT demands the reduction of complexity of\ninterconnections between all functional elements.\nDEBUGGING AND MAINTENANCE: As in the production considerations, if the number of complex\nelements, which field engineers must work with, are kept to a minimum, then debugging and maintenance\nare simplified -- furthermore, this minimizes the inventory of spares.\nPACKAGING of any design must have the highest density consistent with heat removal. It must be such\nthat the LRU (lowest replaceable unit) is easy to isolate, test and replace. Additionally, usage of common\nboard types should be mjximized.\nLOGIC DESIGN RULES AND NOISE BUDGETS. A technology choice for the design must be mature\nenough to develop credible noise budgets, and provide adequate operational margins.\nPOWE R. Finally, power consideration. suggest that we avoid complex power distribution schemes, and con\ncurrently maximize the distribution -)f heat dissipation. These considerations will lead to some interesting\nfeatures explai p .^d in the next section.\n15\n\n_\t\n\nr\t\n\n^\t\n\n1\t\n\n1\n\nARCHITECTURE EVOLUTION\n\nThe selection of the Synchronizable Array Machine for the NSS is presented as an evolution of concepts\nthat grew out of the findings of the t hree sub studies.\nThe first step in this evolution was the selection of a parallel architecture after examination of three generic\ntypes: hybrid, pipeline, and parallel. The hybrid was rejected for three reasons.\nDIFFICULTY OF PROGRAMMING. Many difficulties make it impossible to translate the current\nNavier Stokes algorithms to d hybrid machine. Years have already burn spent in algorithm research\nin digital form. Even more investigation would be needed to recast the equations into suitable form\nfor analog cornputbtion.\nINACCURACIES, AND UNPREDICTABILITY OF THE INACCURACY. Such limited accuracy as\nexists in analog computation is often data dependent, and changes with age. In digital computation,\nany desired degree of accuracy can be specified.\nCOMPONENT FAILURES. Unlike a digital computation, wh-re tests can continuously ensure that\ncorrect results are being produced, an analog computer has no error control. A faulty component or\noff scale input produces an output voltage which is riot distinguishable in kind from the output\nvoltage of a properly functioning component.\nAlthougrr analog processors have a very high computation rate, these limitations are totally unacceptable\nfor the objectives of an NASF project.\nPipeline architectures as we know them today appear to suffer from inefficiencies, namely:\n\xe2\x80\xa2 Long start up times between vector operations,\n\xe2\x80\xa2 Difficulty in dealing with transpositions, and\n\xe2\x80\xa2 The need for massive amounts of work space memory to accommodate propagation of temporary\nvariables.\nCertainly these Problems can be dealt with and solutions developed to make a pipeline a suitable archi\ntecture (as we have done for the parallel architecture) but a reexamination of the Facilities Study high\nlighted other issues which made the selection of a parallel array more sensible for Burroughs.\nAssuming both architectures could be evolved to produce a design of equal performance, Burroughs is\nmore confident that the parallel machine can be manufactured with less risk. The claim is based on obser\nvations:\n\xe2\x80\xa2 The large number of replicated units in a parallel array minimizes production and debugging and\nfield engineering learning curves. Certain economics of scale could be realized in development\nas well.\n\n16\n\nII\t\n\nf - --\t\n\n\xe2\x80\xa2 Burroughs experience, in three generations of parallel high performance systems (namely ILLIAC,\nPEPE, and the Burroughs Scientific Processor (BSP)), provides an invaluab l e data base of knowledge\nin the detailed design and manu facture of such a system.\nThe beginning of the architectural development, therefore, was based on the generic parallel configuration\nshown In Figure 4,\nDATA BASE MEMORY\n\nTO HOST SYS7kM\n\nMEMORY .^ y\n\nCONTROL\n\nV_\n\nUNIT\n\nPROCESSING\n\nELEMENT (PE)\t\n\n\tFigure\n\nL J\t\n\n4\t\n\nt\t\n\n^\n\nParallel Configuration\n\nFrom this point, the definition of SAM can be well understood as a series of refinements based on results\nof the sub-studies.\nThe ADI method of solution of the aerodynamic equations, with split operators, demands that many data\narrays be transposed during access. The access patterns of this method require that 2 dimensional planes of\nthe 3 dimensional grid be accessed in parallel. Planes are required from any 2 of 3 dimensions in the same\ngrid. This implies the need for an efficient transposition mechanism.\nSeveral different designs were considered. The selected Transposition Network (TN) is a unique innovation\noffering:\n\xe2\x80\xa2 low parts count\n\xe2\x80\xa2 minimal data access delay\n\xe2\x80\xa2 simple control requ.rements\n\xe2\x80\xa2 simple but flexible data allocation.\nThis design demands that memory be partitioned into a prime number of banks larger than the number of\nprocessors.\n\nThe Transposition Network (TN) is shown in Figure 5 as the first refinement of the generic parallel configuration.\n\n17\n\n-!\t\n\nL\t\n\n1\t\n\n1\n\nDATA BASE MEMORY\n\nTO HOST SYSTEM\n\nMI MORY\n\nMEMORY\nMODULES\t\n\nq\n\nq q q G\nCONTROL\n\nUNIT\nT\n\nRANSPOSITION\t\n\nPROCESSING\t\nELEMENT (FE)\t\n\nvE\n\nFigure 5\t\n\nNETWORK\n\nq\t\n\n.r r\n\nL_\n\nParallel Configuration Hefrnement 1\n\nThe c:;currence of a significant number of floating point operations to fetches (especially in the implicit\ncode) implies a large workspace requirement. In fact up to 40 temporary variables per data baseveriable may\nbe generated. Propagation of such a large number of temporaries throughout the machine would cause\nsevere timinq penalties. To nutigate this problem, local memories for each processor are requirerf, In adds\ntion, the bandwidth of the TN can then be reduced without performance degradation. This makes ;he\nTransposition Network simpler and less costly. The absence of data dependencies among points in the same\nplane allows this refinement (Figure 6) to occur. The increased cost of many data memories in the proces\nsor is offset by the decreased requirement for storage capacity in Extended Memory for temporary vari\xe2\x80\xa2\nables. The nomenclature for the main memory can now be appreciated as Extended Memory (EM)\nDATA BASF Mr MnRY\n\nTO HOST SVSTKM\n\nEXTENDED MEMORY\nMEMORY\n\nq q q\n\nMODULES\t\n\nq\n\nC\'\n\n\xe2\x80\xa2 \xe2\x80\xa2 . r\n\nL\nCONTROL\nUNIT\n\nTRANSP,)S TI0N 4,,^ NETWORK\n\nPRO\n\nG\n\nELE\t CES {PE)\nMENT\nPE MEMORY\n\nLJ\n\nve\nvM\n\nn\n\t\nuT\n\n\xe2\x80\xa2\t\n\n-\n\n^\n\n( P EM )\n\nFigure 6\t\n\nParallel Configuration Refinement 2\n\nThe result of this refinement allows one to think about parallelism as a series of vertical slices. That is\n\n18\n\n0\nGiven a series of statements of the following form\nDOPARALLEL lone or more indices, say 1, J, K, between limits)\nSTATEMENT 1 - involving variables indexed on the parallel indices\nSTATEMENT 2 involving variables indexed on the parallel indices\n\nSTATEMENT n \xe2\x80\xa2- involving variables indexed on the parallel indices\n\nENDDO\nthere are two ways of thinking of the parallelism.\ndw^I\n\nIn the first method, statement 1 is executed on the vectors implied by the parallel indices. Then statement\n2 is executed as a vector statement, and so on up to the nth statement. Having each statement executed\nseparately as a vector statement is called "horizontal slicing" of the parallelism.\nThe second method is to assign a processor to a particular instance of the set of indices. Processor 17, for\nexample, may handle all computation associated with J-- 1 and K = 19, while processor no. 222 handles J=3\nand K=22. Each processor now executes, essentially independently, a piece of code involving the I index.\nThis kind of parallelism has been called "vertical slicing." Vertical slicing is appropriate when, as in the\nNavier Stokes equations, there is little interaction between the variables at one grid point and the variables\nat anwher.\nThree or more generations of parallel processors have shown that instruction interpretatiun of parallel constructs by the CU creates a bottleneck. The CU must be extremely fast to keep up with the array. Its\ncomplexity is severe enough without this responsibiuty. The program size has been observed to be small\nenough to consider placing program memories in each processor as shown in Figure 7. This now results\nin a stand alone processor with maneageable interface lver,i few lines) to the control unit, elimination of\nmassive cabling and a simpler CU. These savings and their attendant design and schedule Issues will offset\nthe cost of multiple copies of the program memory, as well as improve performance.\nDATA BASF MEMORY\n\nr\n\nTO HOST SYSTEM\n\nEXTLNULU MEMORY\n\nMEMORY\n\nC\n\nU\t\n\nMODULES\t\n\nCONTROL\nUNIT\nIRANSPOSiI iON\t\n\nPE PROGRAM\nMEMORY(PEPM)\t\nPROCESSING\t\nELEMENT (PE)\nPE MEMORY\t\nIPEM)\n\nNETWOHn\n\noEPW\nof\naM\n\nFigure 7\t\n\nParallel Configuration - Refinement 3\n\n19\n\nIn a parallel array with a single program memory, the distribution of Instructions by the CU serves to\nsynchronize the operation of the PE\'s. Distribution of the program to local program memories results in\na requirement for a synchronization mechanism between CU and PE\'s. To provide maximum flexibility,\nwe elected to Invoke the synch mechanism explicitly In the code stream (Fiqure 8). This allows synchronl\nzation to occur only when necessary, (i.e., dust prior to parallel fetches and stores). Processors can run con\ncurrently without waiting for each other, which permits data dependent Instruction options (e.g. round after\nnormalize if overflow) to be executed only when needed. The independence allows idle processors to\nexecute confidence checks on themselves. Different code sequences for different areas of the airspace may\nbe executed in different processors.\nDATA BASF MEMORY\nTO HOST SYSTEM\n\nEXTENDED MEMORY\n\nWIMORY\nMODULES\t\n\nr\t\n\nLJ\t\n\nRANSPOSITION\t\n\nPE PROGRAM\t\nMEMORYiPEPM)\t\n\nPROCESSING\t\nELEMENT (PE)\nPE MEMORY\t\n\n-\n\n-\n\n`--1\n\nCONTROL\n\nN! \'WORK\n\n\xe2\x80\x94\n\noEVM\n\nof\no4\t\n\nSYNC\n\n(PEM)\n\nFigure 8\t\n\nParallel Configuration - Refinement 4\n\nThe choice of 512 as the number of processors is based primarily on the highest expected speed of efficient\nmemory chips. 16k bit static RAM chips are expected to be available at about 100 ns cycle time, by 1980,\nand are appropriate to processor and control unit memories. 64k bit dynamic RAM chips are expected to\nbe available at about the same time, at speeds nearly matching the present 200 ns or so speed of current\n16k dynamic RAMS. These are the memory chips in the baseline system.\nConsider, for example, the effect on the design of a choice of 256 processors. The twice-as fast processor\nmemories would require 50 ns chips, which would be available only In a 4k-bit size. Thus, the total number\nof memory chips would double, from the 37,888 memory chips of the baseline system to a total of 75,776\nchips. The twice as fast EM would require 16k bit chips to maintain the same speed, and its size would\nquadruple from 29,176 meniory chips to 116,704 chips. Parts count in the twice as fast processor is esti\nmated to double, making no net savings, but increasing the required design effort.\nThe size of data base for codes expected to execute for 10 minutes indicates as much as 10 1 > bits of data\nare operated upon. To expect no failures in that time is ambitious indeed, therefore it was necessary to\nimpose a strict philosophy of fault detection and correction in the design of the hardware and software,\nincluding:\n\n20\n\n\t\n\n\xe2\x80\xa2 Hardware Error Detection\n\xe2\x80\xa2 Hardware Error Correction\n\xe2\x80\xa2 Arithmetic Checking\nFigure 9 is a block diagram of SAM, the Baseline Design for the NSS. Its evolution, as well as subsequent\ndesign decisions and guidelines results in a design which features the items described below.\nDATA BASF Mf MORv\nTO HOST SY511M\nr\xe2\x80\xa2\n\nEXTENDED Mt Moa_\'^\n4\t\n1\t\n2\t\n3\t\nq q q q\n\nMODES\t\nOR\n\n52\n\n5\t\n\nq\xe2\x80\xa2.\xe2\x80\xa2l\n\nCON T R OL\nUNIT\n\nTRANSPOSITION , NE TW_ORK\n521/512 PA14ALLEL DATA CHANNELS\n\nPE PROGRAM\n\nR\n\nMEMO Y iPEPM)\t\n\ni\t\n\n^EPM\n\nPROCESSING\t\nELEMENT (PE)\n\n\xe2\x99\xa6[\n\nPF MEMORY\t\n\n2\n\n\'y\t\n\n512\n\n^\nI 1\t\n\nSYNC\n\nIPEM)\n\nFigure 9\t\n\nParallel Configuration Refinement 5\n\nHIGH THROUGHPUT\nThe throughput potential of the NSS is 13 billion Floating Point Operations per second. This is derived\nfrom the selective ratios of the instruction mix combined with the expected execution time of the opera\ntions. This yields 294 nsec per 512 floating point operations which is equivalent to 1.7 billion FLOPS.\nAdditional study of the baseline f,..r the specific codes indicates that the required effec \xe2\x80\xa2 ive rate of 1 billion\nF LOPS is achievable.\nEASE OF USE\nHigh level language requirements, the guidelines of matching machine code to the user language and indeed\nthe use of a High Level Language to write the compiler were inportant decisions made early in the study.\nThe Vertical Slice Concept allows all classical serial optimi7-ion techniques to be utilized on the SAM.\nRecognizing that this architecture has unprecedented flexibility, it is incumbent upon the compiler to\nhave debug aids to protect the user.\nThe protected environment in which SAM operates the high speed computational envelope isolated from\nthe rest of the system \xe2\x80\x94 requires that it have only a very small operating system of its own. 110 to and from\nthat envelope will not encumber the user or SAM as well. A typical work flow is illustrated in Figure 10.\nThis architecture is a tradeoff optimized for the aerodynamic problem, yielding lesser performance for\n\xe2\x80\xa2 Problems with intimate arithmetic data dependency from one grid point variable to another,\n\xe2\x80\xa2 Interactive environments, and\n\xe2\x80\xa2 Multi-programming environments.\n\n21\n\nWe feel this represents a unique solution to the problern of numerical aerodynanuc simulativ-, and Burroughs\npresents this design with full confidence in its feasibility. We believe that this system is the test opproac:h\nto meeting the NASF goals In a timely and cost effective manner, maintaining NASA\'s position it the\nforefront of scientific endeavor\n\nUSER\t\n\nFILE MEMORY\n\nCU ,I\n\n\xe2\x80\xa2 SMADED AREA INDICA T t S\nINFORMATION IN USE\na ARROWS q /OICATE\nINFORMA TI ON FLOW\n\nm T EREO\t\n\nv\n\n874100\nftZ FLQw LANGUAGE_ANALIZEQ\n\n- \xe2\x80\x93\t\n^l\n\nARCNIvE\n\nNSS\nDATA BASE\n\nJ -\t\n\nMEMORY\n\nr\t\n\n0 SUB ASSLM LU\nIN NSS MEMO RY\n\n-T......\n\nNSS\nPROCESSOR\n\nO EXECUTION ON NSS\nf\xe2\x80\x94\n\nO QUUT PUT TO FILE\n\nO DATA REDUCTIQN\n\n07\n\nOUTPUT TO USER\n\nFigure 10 Typical Work Flow Schematic\n\n22\n\na\n\n'