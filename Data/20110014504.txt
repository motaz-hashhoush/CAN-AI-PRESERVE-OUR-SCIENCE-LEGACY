b'NASA Contractor Report CR-2011-216299\n\nUpgrade Summer Severe Weather Tool\n\nLeela Watson\nApplied Meteorology Unit\nKennedy Space Center, Florida\n\nApril 2011\n\nNASA STI Program ... in Profile\nSince its founding, NASA has been dedicated\nto the advancement of aeronautics and space\nscience. The NASA scientific and technical\ninformation (STI) program plays a key part in\nhelping NASA maintain this important role.\nThe NASA STI program operates under the\nauspices of the Agency Chief Information\nOfficer. It collects, organizes, provides for\narchiving, and disseminates NASA\'s STI. The\nNASA STI program provides access to the NASA\nAeronautics and Space Database and its public\ninterface, the NASA Technical Report Server,\nthus providing one ofthe largest collections of\naeronautical and space science STI in the world.\nResults are published in both non-NASA channels\nand by NASA in the NASA STI Report Series,\nwhich includes the following report types:\n\xe2\x80\xa2\n\nTECHNICAL PUBLICATION. Reports\nof completed research or a major\nsignificant phase of research that present\nthe results of NASA Programs and\ninclude extensive data or theoretical\nanalysis. Includes compilations of\nsignificant scientific and technical data\nand information deemed to be of\ncontinuing reference value. NASA\ncounterpart of peer-reviewed formal\nprofessional papers but has less stringent\nlimitations on manuscript length and\nextent of graphic presentations.\n\n\xe2\x80\xa2\n\nCONFERENCE PUBLICATION.\nCollected papers from scientific and\ntechnical conferences, symposia,\nseminars, or other meetings sponsored\nor co-sponsored\nby NASA.\n\n\xe2\x80\xa2\n\nSPECIAL PUBLICATION. Scientific,\ntechnical, or historical information from\nNASA programs, projects, and\nmissions, often concerned with subjects\nhaving substantial public interest.\n\n\xe2\x80\xa2\n\nTECHNICAL TRANSLATION.\nEnglish-language translations of foreign\nscientific and technical material\npertinent to\nNASA\'s mission.\n\nSpecialized services also include creating\ncustom thesauri, building customized databases,\nand organizing and publishing research results.\nFor more information about the NASA STI\nprogram, see the following:\n\n\xe2\x80\xa2\n\nTECHNICAL MEMORANDUM.\nScientific and technical findings that are\npreliminary or of specialized interest,\ne.g., quick release reports, working\npapers, and bibliographies that contain\nminimal annotation. Does not contain\nextensive analysis.\nCONTRACTOR REPORT. Scientific and\ntechnical findings by NASA-sponsored\ncontractors and grantees.\n\nAccess the NASA STI program home\npage at http://www.sti.nasa.gov\n\n\xe2\x80\xa2\n\nE-mail your question via the Internet to\nhelp@sti.nasa.gov\n\n\xe2\x80\xa2\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nFax your question to the NASA STI\nHelp Desk at (301) 621-0134\n\n\xe2\x80\xa2\n\nPhone the NASA STI Help Desk at\n(301) 621-0390\n\n\xe2\x80\xa2 Write to:\nNASA STI Help Desk\nNASA Center for AeroSpace Information\n7121 Standard Drive\nHanover, MD 21076-1320\n\n-\n\n---------------------\n\nNASA Contractor Report CR-2011-216299\n\nUpgrade Summer Severe Weather Tool Phase III\n\nLeela Watson\nApplied Meteorology Unit\nKennedy Space Center, Florida\n\nNational Aeronautics and\nSpace Administration\nKennedy Space Center\nKennedy Space Center, FL 332899-0001\n\nApril 2011\n\nAcknowledgements\nThe author would like to thank Ms. Winnie Crawford of the Applied Meteorology Unit for lending her\nstatistical expertise to this project and for providing sounding stability and flow regime parameters, and Mr. Mark\nWheeler and Dr. William Bauman for their guidance and feedback on the overall direction of this task.\n\nAvailable from:\n\nNASA Center for AeroSpace Information\n7121 Standard Drive\nHanover, MD 21076-1320\n(301) 621-0390\n\nThis report is also available in electronic form at\nhttp://science. ksc.nasa.govlam ul\n\nExecutive Summary\nThe 45th Weather Squadron (45 WS) Commander\'s morning weather briefing includes an assessment of the\nlikelihood of local convective severe weather for the day. This forecast is provided in order to enhance protection of\npersonnel and material assets of the 45th Space Wing, Cape Canaveral Air Force Station (CCAFS), and Kennedy\nSpace Center (KSC). The severe weather elements produced by thunderstorms include tornadoes, strong surface\nwinds and/or large hail. Forecasting the occurrence and timing of these phenomena during the warm season (MaySeptember) is challenging for 45 WS operational personnel.\nIn the first phase of the task, the Applied Meteorology Unit (AMU) analyzed stability parameters and synoptic\npatterns from east-central Florida severe weather days during the warm season in the years 1989-2003 to determine\nwhich were important to severe weather development. A HyperText Markup Language (HTML)-based tool was\ncreated that helped determine the probability of issuing severe weather watches and warnings for the day by\nassigning weights to the important parameters and patterns based on their threat value. A Meteorological Interactive\nData Display System (MIDDS)-based Graphical User Interface (GUI) replaced the HTML tool in a follow-on task.\nThe new tool retrieved stability parameters and other information from MIDDS automatically, minimizing the\nforecaster\'s interaction with the tool. Later, the AMU updated the severe weather database with data from the years\n2004-2009, re-analyzed the data to determine the important parameters, made appropriate adjustments to the index\nweights depending on the results of the analysis, and updated the MIDDS GUI.\nFor this task, the 45 WS requested the AMU upgrade the severe weather database by adding weather\nobservations from the 20 I0 warm season, update the verification dataset with results from the summer of 20 I0, use\nstatistical logistic regression analysis on the database and develop a new forecast tool, and update the MIDDS GUI\nwith the new tool if it outperforms the current tool. The added data increased the period of record (PaR) from 21 to\n22 years. With this update, the datasets included reported severe weather events, sounding stability parameters, and\nsurface weather patterns and the upper jet patterns identified from surface and upper air maps.\nThe AMU analyzed seven stability parameters that showed the possibility of providing guidance in forecasting\nthe occurrence of severe weather for the 2010 season, calculated verification statistics for the Total Threat Score\n(TTS) in the 20 I0 season, and calculated warm season verification statistics. Analysis of the seven stability\nparameters indicate that adding the 2010 data had little effect on the tool\'s overall severe weather predicting\ncapability. On days that severe weather was reported, the TTS ranged from -II to +20 compared to the 2006\nsummer season verification in which the TTS was never below 0 on days when severe weather was reported.\nFinally, the Severe Weather Worksheet TTS did not verify well in the 2010 warm season, with a high False Alarm\nRate (FAR) and low values for Probability of Detection (POD), Critical Success Index (CSI), and Heidke Skill\nScore (HSS).\nThe AMU also performed statistical logistic regression analysis on the 22-year severe weather database. The\ncandidate predictors included the flow regimes from the Florida rawinsondes, the placement of the upper-level jet,\nand seven stability parameters calculated from the XMR rawinsonde. The data were stratified into equation\ndevelopment and verification datasets and one equation for the warm season was developed. A process called\nscreening regression was used to determine which candidate predictors to include in the equation in which an\niterative technique was used to test each predictor\'s ability to explain the variance in the predictand iridividually and\nin combination with other predictors. Four predictors were chosen for the warm season logistic regression equation.\nFour equation performance tests were conducted. The results indicated that the logistic regression equation did\nnot show an increase in skill over the previously developed TTS. The equation showed less accuracy than the TTS at\npredicting severe weather, little ability to distinguish between severe and non-severe weather days, and worse\nstandard categorical accuracy measures and skill scores over TIS. The results showed that the equation had some\nskill in predicting non-severe events, but no skill in predicting severe events.\nBased on the findings of this study and after reviewing the results with the 45 WS, a new tool was not\ndeveloped based on the performance of the logistic regression equation. The previously developed TTS and MIDDS\nGUI were not updated due to the inability of the 2010 severe weather season data to help improve the tool.\n\n3\n\nTable of Contents\n\n1.\n\nIntroduction\n\n7\n\n2.\n\nPrevious Work\n\n7\n\n3.\n\nDatabase\n\n8\n\n3.1 Severe Weather Events\n3.2 Sounding Parameters\n3.3 Synoptic Weather Pattems\n\n8\n8\n8\n\nData Analysis Results\n\n9\n\n4.\n\n4.1\n4.2\n4.3\n4.4\n4.5\n4.6\n4.7\n\nTotal Totals (TT)\nK-Index (KI)\nLifted Index (LI)\nThompson Index (TI)\nCross Totals (CT)\nShowalter Stability Index (SSI)\nPrecipitable Water (PW)\n\n10\nII\n12\n13\n14\n15\n16\n\n5.\n\n2010 Verification Results\n\n17\n\n6.\n\nLogistic Regression Analysis\n\n20\n\n6.1 Elements of the Logistic Regression Equation\n6.2 Development of the Logistic Regression Equation\n6.3 Logistic Regression Equation Performance\n\n20\n20\n23\n\nSummary\n\n26\n\n7.\n\n4\n\nList of Figures\nFigure 1.\n\nStacked column graph of TT thresholds. The number of severe/non-severe occurrences for the\nLow, Medium and High threat thresholds for all 22 years in the severe weather database\n10\n\nFigure 2.\n\nScatter plot of probability of occurrence vs. TT for both the non-severe and severe days for all\n22 years in the severe weather database\n\n10\n\nFigure 3.\n\nSame as Figure I except for KI...\n\n11\n\nFigure 4.\n\nSame as Figure 2, except for KI...\n\nII\n\nFigure 5.\n\nSame as Figure 1 except for Ll\n\n12\n\nFigure 6.\n\nSame as Figure 2, except for Ll\n\n12\n\nFigure 7.\n\nSame as Figure I except for TI and the fourth threat category Very High\n\n13\n\nFigure 8.\n\nSame as for Figure 2, except for TI...\n\n13\n\nFigure 9.\n\nSame as Figure 4 except for CT\n\n14\n\nFigure 10.\n\nSame as Figure 2, except for CT\n\n14\n\nFigure 11.\n\nSame as Figure I except for SSI.\n\n15\n\nFigure 12.\n\nSame as Figure 2, except for SSI.\n\n15\n\nFigure 13.\n\nSame as Figure 1 except for PW\n\n16\n\nFigure 14.\n\nSame as Figure 2, except for PW\n\n16\n\nFigure 15.\n\nTotal Threat Score versus date from 1 May - 30 September 2010. Red lines represent days\nwith reported severe weather, blue lines represent days with no reported severe weather.\n\n17\n\nFigure 16.\n\nMap of Florida showing the six counties (shaded in yellow) included in the severe weather\nevents database. The location of KSC and CCAFS are shown on the map\n18\n\nFigure 17.\n\nScatter plot of probability of occurrence vs. TTS for both the non-severe and severe days for\nthe 2009 and 2010 seasons in the severe weather database\n19\n\nFigure 18.\n\nThe total percent reduction in residual deviance from the NULL model as each predictor was\nadded to the equation using the development dataset.\n22\n\nFigure 19.\n\nForecast probability distributions for severe (red) and non-severe (blue) days in the\nverification data. The y-axis values are the frequency of occurrence of each probability value,\nand the x-axis values are the forecast probability values output by the equation\n24\n\nFigure 20.\n\nGraph showing the CSI (blue) and bias (red) values for the equation probabilities over a range\nof equation output probability values from 0.05 to 0.7 in increments of 0.05. The vertical\nblack line shows the resulting probability cutoff that had the maximum value of CSI and a\nbias value closest to 1\n25\n\n5\n\n,----------------------------------------------\n\nList of Tables\nTable 1.\n\nThe six stability (in bold font) and eight other sounding parameters in the severe weather\ndatabase and the equations used in their calculation\n\n9\n\nTable 2.\n\nThe standard contingency table used for forecast verification\n\n18\n\nTable 3.\n\nWarm season 2010 TTS Verification Statistics\n\n18\n\nTable 4.\n\nTIS Verification Dataset Statistics\n\n25\n\nTable 5.\n\nEquation Probabilities Verification Dataset Statistics\n\n25\n\n6\n\n1.\n\nIntroduction\n\nThe 45th Weather Squadron (45 WS) Commander\'s morning weather briefing includes an assessment of the\nlikelihood of local convective severe weather for the day. This forecast is provided in order to enhance protection of\npersonnel and material assets of the 45th Space Wing, Cape Canaveral Air Force Station (CCAFS), and Kennedy\nSpace Center (KSC). The severe weather elements produced by thunderstorms include tornadoes, convective surface\nwinds ~ 50 knots, and/or hail with a diameter ~ I inch. Forecasting the occurrence and timing of these phenomena\nduring the warm season (May - September) is challenging for 45 WS operational personnel.\nIn the fITst phase of the task, the Applied Meteorology Unit (AMU) analyzed stability parameters and synoptic\npatterns from east-central Florida severe weather days during the warm season in the years 1989-2003 to determine\nwhich were important to severe weather development. The AMU then created a HyperText Markup Language\n(HTML)-based tool using the important parameters and patterns to help determine the probability of issuing severe\nweather watches and warnings for the day. The HTML tool was replaced with a Meteorological Interactive Data\nDisplay System (MIDDS)-based Graphical User Interface (GUI) in a follow-on task that retrieved stability\nparameters and other information from MIDDS automatically, minimizing the forecaster\'s interaction with the tool.\nLater, the AMU updated the severe weather database with data from the years 2004-2009, re-analyzed the data to\ndetermine the important parameters, made appropriate adjustments to the index weights based on the results of the\nanalysis, and updated the MIDDS GUI.\nFor this task, the 45 WS requested the AMU to:\n\xe2\x80\xa2 Add severe weather reports and indices for the warm season May-September 2010 to increase the period of\nrecord to 22 years,\n\xe2\x80\xa2 Use the daily severe weather forecast threat scores from 2009 and 2010 as the verification data of the tool,\n\xe2\x80\xa2 Use logistic regression to determine the best predictors and provide a probability forecast, and then compare\nthe performance ofthe logistic regression equations with the previous tool, and\n\xe2\x80\xa2 Update the MIDDS GUI implementation of the tool with the new results if the logistic regression equations\nare successful.\n2.\n\nPrevious Work\n\nIn the initial Severe Weather Forecast Decision Aid task (Bauman et al. 2005), the AMU completed a 15-year\nclimatological study of severe weather events and related severe weather atmospheric parameters. The period of\nrecord (POR) for the analysis was May-September, 1989-2003. Data sources included stability parameters derived\nfrom archived sounding data, local forecast rules used to set threat assessment thresholds, Cloud-to-Ground\nLightning Surveillance System (CGLSS) used to differentiate between lightning and non-lightning days, surface and\nupper air maps, and two severe weather event databases covering east-central Florida used to identify reported\nsevere weather. These datasets provided the foundation for analyzing stability parameters and synoptic patterns with\nthe goal of developing an objective tool to aid in forecasting severe weather events. Based on the results from the\nanalyses, an interactive web-based Severe Weather Decision Aid was developed to assist the duty forecaster by\nproviding a level of objective guidance based on the stability parameters from the CCAFS morning sounding,\nCGLSS data, and synoptic-scale dynamics. The tool outputs the Total Threat Score (TTS), which is a measure of the\nlevel of severe weather threat. The higher (lower) the TTS, the greater (lesser) the chance of severe weather\noccurring.\nIn a follow-on study (Wheeler 2009), the functionality of the web-based tool was migrated to MIDDS. A\nMIDDS GUI worksheet was created using Tool Command Language and its associated Tool Kit (Tcl/Tk). The GUI\nretrieves and calculates most of the daily sounding stability indices needed by the worksheet when opened. The\nforecaster is required to answer a few more subjective questions before the TTS is calculated and displayed.\nIn the final follow-on study (Wheeler 20 I0), the AMU updated the existing severe weather tool by adding data\nfrom May-September, 2004-2009, creating a 21-year severe weather database. Data sources included local forecast\nrules, archived sounding data, surface and upper air maps, and two severe weather event databases covering eastcentral Florida. The new POR for the analysis was May-September, 1989-2009. Results from this study showed a\n\n7\n\ngreater ability to predict severe weather in the added years as compared to the original study. The MIDDS GUI was\nalso updated and mouse-over help was added to allow the forecaster to quickly compute and analyze the daily TTS.\n\n3.\n\nDatabase\n\nFor this work, the AMU updated the severe weather database with data from the 2010 warm season, increasing\nfrom a 21- to a 22-year climatological study of atmospheric stability indices and severe events from 1989-2010. To\nbe consistent with previous work, the AMU collected the same data types and parameters used to update the severe\nweather database. Severe weather reports during 2010 were collected from the Storm Prediction Center (2009, SPC)\nand data from severe weather days in that period from the National Climatic Data Center (2010, NCDC) database.\nThe sounding stability parameters were calculated from the 1000 UTC CCAFS soundings available from the\nNational Oceanic and Atmospheric Administration\'s (NOAA)/Earth System Research Laboratory (ESRL) and from\nthe objective portion of the daily Severe Weather Worksheet in MIDDS. Also, the 200 mb charts were analyzed to\nidentify the placement and characteristics of the upper-level jet. With this update, the datasets included reported\nsevere weather events, sounding stability parameters, and surface weather patterns and the upper jet patterns\nidentified from surface and upper air maps. Each data type proved to have some relevance to forecasting the threat\nof convection in east-central Florida and at KSC/CCAFS.\n\n3.1\n\nSevere Weather Events\n\nSevere weather events for this study included tornadoes, convective surface winds ~ 50 knots (~ 26 m S-I),\nand/or hail with a diameter ~ I inch (~ 2.54 cm) that were observed in east-central Florida. The previous studies\nused a ~ % inch diameter criterion for hail, however, the National Weather Service changed the minimum size for\nsevere hail from 314" to I" in January 2010. Therefore, the POR prior to the 2010 summer season reflected the %"\ncriterion and the new 1" hail criterion was used for the 2010 summer season. The 2010 database contained 16 days\nwith reported severe weather, which included three tornadoes, six hail events, and 15 high wind events.\nIt is important to note that the database contains only those severe weather events reported by human observers.\nSevere weather events can only be recorded when observed by people in the vicinity, and then only if the proper\nauthorities are notified. Therefore, severe weather days are more accurately described as "reported" severe weather\ndays. To determine relationships between the data and severe weather occurrence for this and previous studies, the\nAMU had to assume that severe weather only occurred on reported severe weather days.\n\n3.2 Sounding Parameters\nA thorough analysis of atmospheric stability based on a local upper air sounding is needed for any convective\nforecast. A listing of the sounding stability indices (bold) and additional calculated parameters from MIDDS used in\nthe TTS calculation is shown in Table 1. These sounding parameters are calculated in MIDDS from the CCAFS\nrawinsonde and are readily available.\n\n3.3 Synoptic Weather Patterns\nThe synoptic weather patterns investigated by the AMU included the position of the upper-level jet streak if one\nexisted and the position of the surface high pressure ridge axis over east-central Florida. It is commonly known that\nupper-level divergence and/or the left-exit and, to a lesser degree, right-entrance quadrant of a jet streak in the\nvicinity of convective systems can help produce severe weather. The 45 WS forecasters often analyze the position of\nthe surface high pressure ridge axis protruding westward from the Bermuda high pressure center as an indicator for\nconvection occurrence. It is generally known that if the surface ridge is south of the KSC/CCAFS area the\nprobability for convection is increased due to the low-level convergence generated from the southwesterly flow\naround the ridge interacting with the east coast sea breeze off the Atlantic Ocean and the west coast sea breeze off\nthe Gulf of Mexico.\n\n8\n\nTable 1. The eight stability parameters (in bold font) that showed the possibility of providing guidance in\nforecasting severe weather and the six other sounding parameters in the severe weather database and the\nequations used in their calculation.\nIndex Acronym\n\nDefinition\n\nLI\n\nLifted Index\n\n= (T500 - T*)\n\nT* = Temperature ofa parcel characterized by the mean T d in the lowest 3000 ft and\nthe forecast maximum surface temperature if it were lifted dry adiabatically to\nsaturation and then moist adiabatically to 500 mb.\n\n= (T 8S0 - T soo) + T d8S0 - (T 700 - T d700)\n\nKI\nTT\n\nTotal Totals\n\nSSI\n\nShowalter Stability = Index (T soo - T*)\nT* = Temperature a parcel characterized by the T 850 and T d850 would have if it were\nlifted dry-adiabatically to the LCL and then moist-adiabatically to 500 mb.\n\nCT\n\nCross Totals = (T d850 - T 500)\n\nTI\n\nThompson Index\n\nPW\n\nPrecipitable water in mm in the layer from the surface to 500 mb\n\nCAPE FMaxT\n\nCAPE calculated using the forecast maximum temperature (FMaxT) for the day\ninstead of the surface temperature in the morning\n\n10070RH\n\nAverage Relative Humidity in percent (%) from 1000-700 mb\n\nLLJ\n\nLow Level Jet below 5000 ft (Wind direction and speed)\n\nINY\n\nHeight of Inversion below 8000 ft\n\nT850\n\nThe sounding temperature at 850 mb\n\nTDif\n\nThe difference between forecast maximum and convective temperatures\n\nMDPI\n\n4.\n\nK Index\n\nMicroburst Day Potential Index\n\n= (T8S0 - T 500) + (T d850 - T 500)\n\n= KI - LI\n\nData Analysis Results\n\nThe AMU gathered severe weather reports for 2010 from SPC and data for those severe weather days from\nNCDC. The 200 mb charts were analyzed to identify placement and characteristics of any jet streaks overhead. The\nFlorida flow regime patterns that identified the position of the surface high pressure ridge axis over east-central\nFlorida were also added to the severe weather database. The datasets were integrated and compared to the severe\nweather reports of hail, high wind, and tornadoes to determine what the parameter values were on each of the severe\nweather event days.\nThe AMU analyzed seven of the eight stability parameters that showed the possibility of providing guidance in\nforecasting the occurrence of severe weather in the first phase of this task (Bauman et al. 2005). The parameter\nCAPE FMaxT was not calculated for the years 2004-2009 and was therefore not analyzed in this phase of the task.\nThe parameters TT, KI, LI, TI, CT, SSI and PW were analyzed to determine if they increased the severe weather\nforecast capability of the tool in the 20 I 0 data and in all 22 years (1989-2010) combined. Results indicate that\nadding the 2010 data had no effect on the forecast capability of the tool for TT, KI, PW, SSI, and CT. The forecast\ncapability decreased when adding the 2010 LI and TI data. Overall, there was minimal change in the tool\'s overall\nsevere weather predicting capability. The relationship between each stability parameter and threshold criteria for the\nsevere weather threat was calculated for severe and non-severe days. The results for each of these seven parameters\nare detailed below.\n\n9\n\n4.1\n\nTotal Totals (TT)\n\nThe TT thresholds specify a low threat for severe weather when TT :s 45, a medium threat when 46 :s TT :s 48,\nand a high threat when TT > 48. When TT was> 48, a severe weather event was reported in 13% of the 2010 warm\nseason days. This slightly decreased the 21-year value of 34%. The 22-year value decreased to 33%. Figure I\ndisplays the threat levels of Low, Medium and High with the occurrence/non-occurrence of severe weather for the\n22-year POR, while Figure 2 displays the same data, but shows the individual TT values for each day. It is evident\nthat TT poorly discerns severe from non-severe weather for our POR.\n\nTotal Totals\n- Severe _ Non-Severe\n\n100%\n\n~\n\n90%\n\n~\n\n70%\n\nf\n\n80%\n\n,\n0\n\n~\n\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nLow(= 45)\n\nHigh (> 48)\n\nMed (46 to 48)\nThreat\n\nFigure I. Stacked column graph of TT thresholds. The number of severe/non-severe occurrences for\nthe Low, Medium and High threat thresholds for all 22 years in the severe weather database.\n\nTotal Totals\n~Severe\n\n-+-Non Severe\n\n16%\n\nJI\n\n14%\n\n~\nf\n\n11\nJr\\\n\n12%\n\n~ 10%\no\n,\n\n6%\n\n~\n\n~\n\n8%\n\n4%\n\nI\n\n\'I\n\n\\~\n\n40\n\n50\n\n;.\n\n2%\n\n~\n\n0%\n\no\n\n10\n\n20\n\n30\n\n\\.\n\n\\.~\n60\n\n70\n\nTotal Totals\n\nFigure 2. Scatter plot of probability of occurrence vs. TT for both the non-severe and severe days for\nall 22 years in the severe weather database.\n\n10\n\n4.2\n\nK-Index (KI)\n\nThe KI thresholds values indicate a low threat for severe weather when KI < 26, a medium threat when 26 ~ KI\n28, and a high threat when KI > 28. When KI was> 28, a severe weather event was reported in 16% of the 2010\ndays. This did not alter the 21-year value of 18%. The 22-year value remained at 18%. Figure 3 displays the threat\nlevels of Low, Medium and High with the occurrence/non-occurrence of severe weather for the 22year POR, while\nFigure 4 displays the same data, but shows the individual Kl values for each day. It is evident that Kl poorly\ndiscerns severe from non-severe weather for our POR.\n\n~\n\nK-Index\n.Severe .Non-Severe\n\n792\n\n100%\n\n80%\n\nf\n\n70%\n\n,\n0\n\n~\n\n1638\n\n90%\n\ne\n\n~\n\n279\n\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nLow\xc2\xab\n\n26)\n\nHigh (> 28)\n\nMed (26 to 28)\n\nThreat\n\nFigure 3. Same as Figure 1 except for KI.\n\nK-Index\n..... Severe\n\n~NonSevere\n\n12%\n\n~\n~\n\n.\n\nIf\n\n.\n\n\\\n\\..\n\noAt.J\n\xe2\x80\xa2\xe2\x80\xa2\n\n0%\n\n-50\n\n-40\n\n-30\n\n-20\n\n-10\n\no\n\n10\n\n20\n\n30\n\n40\n\n50\n\nK-Index\n\nFigure 4. Same as Figure 2, except for KI.\n\nII\n\n4.3 Lifted Index (LI)\nThe Ll thresholds values indicate a low threat for severe weather when Ll ~ -2, a medium threat when-3 ~ Ll ~\n-5, and a high threat when Ll < -5. The Ll was never < -5 in the 2010 dataset and, therefore, slightly decreased the\npercentage of severe weather in the 22-year POR from 31 % to 30%. Figure 5shows the LI Low, Medium and High\nthreat distribution for all years in the severe weather database, while Figure 6 displays the same data, but shows the\nindividual LI values for each day. LI also poorly discerns severe from non-severe weather for our POR.\n\nLifted Index\n\xe2\x80\xa2 Severe \xe2\x80\xa2 Non-Severe\n\n1565\n\n1071\n\nLow (= -2)\n\nMed (-3 to -5)\n\n100%\n\n69\n\n90%\n\n~\n\n80%\n\nf\n\n70%\n\n~\n\n,\nP\n0\n~\n\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nHigh \xc2\xab -5)\n\nThreat\n\nFigure 5. Same as Figure 1 except for LI.\n\nLifted Index\n___ Severe\n20.00%\n\n...,&..It\n\n18.00%\n\n~\n\nF14.00%\n\n~ 12.00%\n\n11\n\n0 10.00 %\n\n~\n~\n\n,\n\nII \\..\\\nII\n\n16.00%\n\nr\n\n-+-Non Severe\n\nI\n\n8.00%\n6.00%\n\n7\n\n4.00%\n\nA\n7\n\n2.00%\n0.00%\n\n-10\n\n\\\n\\\n\\\n\n,\nl\\\n,,",,,~~\n\n-5\n\no\n\n5\n\n10\n\nLifted Index\n\nFigure 6. Same as Figure 2, except for LI.\n\n12\n\n15\n\n20\n\n4.4 Thompson Index (Tn\nThe TI specifies a low threat when TI < 25, a medium threat when 25 :s TI :s 34, a high threat when 35 :s TI :s\n39, and a very high threat when TI 2: 40. The TI value was> 40 on 4 days in the 2010 season and severe weather\nwas not reported on any of those days. The percent occurrence decreased to 25% for the 22-year POR over the\nprevious 21-year value of 26%. Figure 7 shows the severe weather threat distribution for all years in the severe\nweather database, while Figure 8 displays the same data, but shows the individual TI values for each day. As above,\nTI poorly discerns severe from non-severe weather in our POR.\n\nThompson Index\n.Severe .Non-Severe\n\n100%\n\n1069\n\n761\n\n165\n\n90%\n\n8\n\n80%\n\nF\n\n70%\n\n~\n\n,\n\n60%\n\nP\n\n50%\n\n0\n\n~\n\n635\n\n40%\n30%\n20%\n10%\n0%\n\nLow\xc2\xab\n\n25)\n\nHig h (35 to 39)\n\nMed (25 to 34)\n\nVery Hig h (> 40)\n\nThreat\n\nFigure 7. Same as Figure 1 except for TI and the fourth threat category Very High.\n\nThompson Index\n~Severe\n\n~Non Severe\n\nor------------------------------14% +-------------~ ..---------------8\nF12%\n16%\n\n~ 10%\no\n\n8%\n\nr\n\n+-------------+-+-----------------\n\n6%\n\n1\n\n4%\n\n+----------+--+-----=--------\n\n2% +--------------f:j~_lI~------I\n\n-50\n\n-30\n\n-10\n\n10\n\n30\n\n50\n\n70\n\nThompson Index\n\nFigure 8. Same as for Figure 2, except for TI.\n\n13\n\n4.5 Cross Totals (CT)\nThe CT thresholds indicate a low threat when CT ~ 19, a medium threat when 20 ~ CT ~ 21, a high threat when\n22 ~ CT ~ 23, and a very high threat when CT 2: 24. When CT was 2: 24, a severe weather event was reported in\n20% of the 2010 days. This did not alter the 21-year value of 31 %. The overall 22-year value remained at 31 %.\nFigure 9 displays the threat levels of Low, Medium, High, and Very High with the occurrence/non-occurrence of\nsevere weather for the 22-year POR, while Figure 10 displays the same data, but shows the individual CT values for\neach day. It is evident that CT poorly discerns severe from non-severe weather for our POR.\n\nCross T ota Is\n\xe2\x80\xa2 Severe .Non-Severe\n\n1084\n\n100%\n90%\n\n~\n\n80%\n\nF\n\n70%\n\n~\n\n,\nP\n0\n~\n\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nLow (= 19)\n\nMed (20 to 21)\n\nHigh (22 to 23)\n\nVery High (= 24)\n\nThreat\n\nFigure 9. Same as Figure 7 except for CT.\n\nCross T ota Is\n~Severe\n\n~Non\n\nSevere\n\n20%\n\n~\n\n-r------------------------------\n\n18%\n16%\n\n+-\n\n+------------------------\xe2\x80\xa2\xe2\x80\xa2- - - - -\n\n--lJ~I----\n\nF +----------------,...,-. ....---......\n14%\n\n~ 12% +-----------------------....--=l\\,~----\n\nf\n\n10%\n\nr\nK\n~\n\n+------------------------lIJ--.....- - - j\n\n8%\n\n+-----------------------::p--.......- - +---------------.llfl------lHl\\,...--\\,\n2% +-------------------..~.~-~+-, f ------+...- . n\n....\n\n6%\n4%\n\n0%\n\n-20\n\n-15\n\n-10\n\n-5\n\no\n\n5\n\n10\n\n15\n\nCross Totals\n\nFigure 10. Same as Figure 2, except for CT.\n\n14\n\n.\n\n.l-----4lp--...........-......~....._~,.~~-_r___~ ~.L~............\n20\n\n25\n\n30\n\n4.6 Showalter Stability Index (SSI)\nThe SSI thresholds indicate a low threat when SSI 2: 3, a medium threat when 2 2: SSI 2: -2, and a high threat\nwhen SSI < -2. The 2010 severe weather database confIrmed that SSI is a good severe weather predictor. When SSI\n< -2, severe weather was reported in central Florida 33% of the time. The 22-year POR value remained the same as\nthe previous work at 37%. Figure II shows the SSI Low, Medium and High threat distribution for all years in the\nsevere weather database, while Figure 12 displays the same data, but shows the individual SSI values for each. SSI\npoorly discerns severe from non-severe weather for our POR.\n\nShowalter Stability Index\n\xe2\x80\xa2 Severe \xe2\x80\xa2 Non-Severe\n\n969\n\n100%\n\n1689\n\n49\n\n90%\n\n~\n\n80%\n\nF\n\n~\n\n70%\n\n,\n0\n\n~\n\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nLow(= 3)\n\nMed (2 to -2)\n\nHigh \xc2\xab -2)\n\nThreat\n\nFigure 11. Same as Figure I except for SSI.\n\nShowalter Stability Index\n~Severe\n\n.....NonSevere\n\n20%\n\n~\n\n18%\n\n~\n\nT/\'J\n\n16%\n\nfj\n\nF\n~\n\n14%\n12%\n\n0 10 %\n\nr\n~\n~\n\n~\n\n~\n\n8%\n\nI\n\n6%\n\nI\n\n4%\n\n.J1\n\n2%\n\nIL\\\n\n~\n\nI\n\nI\n\n\\\\\n\nJ\n\n......\n\nl.. ......\n\n.b\n\n0%\n\n-10\n\n-5\n\no\n\n~\n\n5\n\n&\n\n10\n\n15\n\n20\n\nShowalter Stability Index\n\nFigure 12. Same as Figure 2, except for SSI.\n\n15\n\n4.7 Precipitable Water (PW)\nThe PW thresholds indicate a low threat when PW < 1.0 in, a medium threat when 1.0 in :S PW :S 1.75 in, and a\nhigh threat when CT > 1.75 in. When PW was> 1.75, a severe weather event was reported in 13% ofthe 2010 days.\nThis did not alter the 21-year value of 15%. The overall 22-year value remained at 15%. Figure 13 displays the\nthreat levels of Low, Medium, and High with the occurrence/non-occurrence of severe weather for the 22-year POR,\nwhile Figure 14 displays the same data, but shows the individual PW values for each day. As above, PW does not\ndiscern severe from non-severe weather in our POR.\n\nPrecipitable Water\n\xe2\x80\xa2 Severe .Non-Severe\n\n72\n\n1301\n\n1334\n\nLow\xc2\xab 1.0)\n\nMed (1.0 to 1.75)\n\nHig h (> 1.75)\n\n100%\n90%\n\n~\n\n80%\n\nf\n\n~\n\n70%\n\n,\n0\n\n~\n\n60%\n50%\n40%\n30%\n20%\n10%\n\n0%\n\nThreat\n\nFigure 13. Same as Figure 1 except for PW.\n\nPrecipitable Water\n~Severe\n\n~NonSevere\n\n8%\n7%\n\n~\n\nf\n\n6%\n\n~5%\n0 4%\n\n, 3%\n\n~2%\n1%\n0%\n\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nPrecipitable Water (in)\n\nFigure 14. Same as Figure 2, except for PW.\n\n16\n\n60\n\n70\n\n5.\n\n2010 Verification Results\n\nThe TTS used for verification was developed from the first severe weather study (Bauman et al. 2005). The\nAMU calculated verification statistics for the TTS from an independent dataset created by the 45 WS forecasters and\nAMU personnel during the 2010 warm season. When the 45 WS forecasters/AMU personnel completed the Severe\nWeather Worksheet GUI and computed the daily TTS, a text file was saved that contained their answers to the\nsubjective questions and the sounding stability parameters for the day. This allowed a comparison of the daily TTS\nwith reported severe weather events in 2010.\nFrom 3 May to 30 September 2010, the AMU and 45 WS forecasters completed 132 worksheets. Total Threat\nScores ranged from -23 to 20. Severe weather was reported in east-central Florida on 16 of the 153 days. Figure 15\nshows the TTS values color-coded for reported severe weather. On days that severe weather occurred, the TTS\nranged from -II to 20. During the 2006 warm season verification (Bauman 2006), the TTS was never below 0 on\ndays when severe weather was reported.\nThe 2010 warm season was one of the hottest and driest summers on record across east-central Florida. This\nwas due to the placement and strength of the surface Atlantic ridge and high pressure ridge aloft. This resulted in\nfew severe weather reports during the 20 I0 summer season and may account for the wide range of TTS values when\nsevere weather was reported over the 20 I0 season.\nTotal Threat Score versus Reported Severe Weather\nMay - September 2010\n- No Severe Reported\n\n_ Severe Reported\n\n25\n20\n\n~ :~\nf ~\n-\n\n,\n\nI\n\nI\nI\n\nI\n\n-5\n\nI,\n\nI\n\nr\n\nII\n\n"II\'\nI\n\nt\' -10\n\nI\n\nI\nI\n\nIII\n\nII\n\nI\n\nI\nII\n\nI II\n\ntwm R~\n\n,II\n\n1\n\'1I1111~I\'1 I 11111[11 III I \'1\'11111 "I\'HI I \'I\'\n\nI\n\n\'II\n\nI II\n\nII\n\nI\n\nIII\n\nI II\n\nI\n\nI\'\n\ny-15\n\n-20\n\n-25\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~ ~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~\n\n~ ~\n\n~\n\n~\n\n~~~##~#$#~~$~~~~~~~~##\nDate\n\nFigure 15. Total Threat Score versus date from I May - 30 September 2010. Red lines represent days with reported\nsevere weather, blue lines represent days with no reported severe weather.\nThe AMU computed verification statistics for the 2010 warm season. The standard 2x2 contingency table\nshown in Table 2 was used to calculate the statistics and scores described in the last row of Table 2:\n\xe2\x80\xa2 The False Alarm Rate (FAR) is the fraction of \'yes\' forecasts that are incorrect,\n\xe2\x80\xa2 Probability of Detection (POD) is the fraction of \'yes\' forecasts that are correct,\n\xe2\x80\xa2 Critical Success Index (CSl) measures the fraction of observed or forecast events that were correctly\npredicted,\n\xe2\x80\xa2 Heidke Skill Score (HSS) is the probability of a correct \'yes\' forecast by random chance, and\n\xe2\x80\xa2 True Skill Statistic (TSS) measures how well the forecast separated the \'yes\' events from the \'no\' events\ncompared to random chance, but with an assumption of an unbiased forecast.\n\n17\n\nObserved Event\n\nTable 2. The standard contingency table\nused for forecast verification.\n\nYes\n\nNo\n\nYes\n\na\n\nb\n\nNo\n\nc\n\nd\n\nForecast Event\nN=a+b+c+d\n\nCritical Success Index (CSI) = a/(a+b+c)\n\nFalse Alarm Rate (FAR) = b/(a+b)\n\nHeidke Skill Score (HSS) = [ (a+d) - E ]/( N-E )\n\nProbability of Detection (POD) = a/(a+c)\n\nE = [(a+c)(a+b)+(b+d)(c+d)]/N, N=a+b+c+d\nTrue Skill Statistic (TSS) =a/(a+c) - b/(b+d)\n\nTable 3. Warm season 2010\nTTS Verification Statistics\n\nObserved Severe\n\nFAR\n\n0.46\n\nNo\n\nPOD\n\n0.44\n\nYes\n\n7\n\n6\n\nCSI\n\n0.32\n\nNo\n\n9\n\n110\n\nHSS\n\n0.42\n\nTSS\n\nForecast\nSevere\n\nYes\n\n0.39\n\nGulf\n\nof\nMl"xi<"O\n\nFigure 16. Map of Florida showing the six counties (shaded in yellow) included in the\nsevere weather events database. The location of KSC and CCAFS are shown on the map.\n\n18\n\nTable 3 shows the contingency table statistics for the 20 10 warm season. The TTS forecast threshold value for\nthe contingency table was chosen based on the results of the 2006 summer season verification. If the TTS was < 5 it\nwas considered a No forecast and if ~ 5 it was a Yes forecast. The east-central Florida severe weather verification\narea (Figure 16) included three coastal counties (Brevard, Volusia, Indian River) and three inland counties\n(Seminole, Orange, Osceola), all of which are typically in the same large-scale air mass as KSC/CCAFS on most\nwarm season days. If severe weather was reported in these Florida counties, that was classified as observed Yes. The\nSevere Weather Worksheet TTS did not verify well in the 2010 warm season, with a high FAR and low values for\nPOD, CSI and HSS. However, it should be noted again that the 2010 warm season was atypical being much warmer\nand drier with much less severe weather than normal.\nFigure 17 displays a scatter plot of probability of occurrence/non occurrence of severe weather vs. the TTS for\nboth the 2009 and 2010 summer seasons. There were 36 severe weather and 186 non-severe weather days for which\nthe TTS was calculated. The results show that ITS was a fairly good indicator of severe weather, particularly when\nthe value was ~5. When TTS was ~5, the occurrence of non-severe weather was 1% or less. Based on these results\nand those from Section 4, it is evident that the fmal daily value of the TTS is driven by the subjective questions that\nthe forecaster is required to answer as the daily stability indices poorly differentiated severe from non-severe\nweather.\n\nTotal Threat Score\n\xe2\x80\xa2 Severe\n\n\xe2\x80\xa2 Non Severe\n\n35%\n\n\xe2\x80\xa2\n\n~ 30%\n\n~ 25%\n\n~20%\n\no\nr\n\n\xe2\x80\xa2\n\n15%\n\nB10%\n\n~\n\n..\n\n5%\n\n.. ....\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\n\n0%\n\n-30\n\n-25\n\n-20\n\n-15\n\n-10\n\n\xe2\x80\xa2\n\n... ......... _..\n\n... \xe2\x80\xa2\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n-5\n\no\n\n5\n\n10\n\n\xe2\x80\xa2\xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2 \xe2\x80\xa2\n15\n\n20\n\n25\n\nTotal Threat Score\n\nFigure 17. Scatter plot of probability of occurrence vs. TTS for both the non-severe and severe days\nfor the 2009 and 2010 seasons in the severe weather database.\n\n19\n\n6.\n\nLogistic Regression Analysis\n\nThe AMU was tasked to perform statistical logistic regression analysis on the 22-year severe weather database\nand possibly develop a new forecast tool. There were three major steps in this portion of the task:\n\xe2\x80\xa2 Determine the elements of the equation,\n\xe2\x80\xa2 Develop the logistic regression equation, and\n\xe2\x80\xa2 Determine the equation performance.\nTo accomplish this, the AMU followed procedures outlined by Lambert and Wheeler (2005).\n6.1\n\nElements of the Logistic Regression Equation\n\nThe necessary elements to create the logistic regression equation include a predictand and candidate predictors.\nThe predictand is the element to be predicted. The SPC and NCDC severe weather reports provided the occurrence\nof severe weather in the area and were used to create the predictand. The predictand value was set to "1" if severe\nweather occurred within the six east-central Florida counties on a specific day and set to "0" if no severe weather\noccurred. As mentioned previously, an assumption had to be made that severe weather only occurred on reported\nsevere weather days. The candidate predictors included the flow regimes from the Florida rawinsondes, the\nplacement of the upper-level jet, and seven stability parameters calculated from the XMR rawinsonde.\n6.1.1\n\nFlow Regime Probabilities\n\nProbabilities of severe weather occurrence based on flow regime pattern for each day were calculated using the\nsevere weather binary predictand. The number of days each regime occurred was compared to the severe weather\npredictand to see how many of those days reported severe weather. The probability was calculated by dividing the\nnumber of severe weather days within a particular regime by the total number of days the regime occurred.\n\n6.1.2\n\nUpper-level Jet Probabilities\n\nProbabilities of severe weather occurrence based on the placement of the upper-level jet were calculated in the\nsame manner as the flow regime probabilities. The number of days each jet pattern occurred was compared to the\nsevere weather predictand to see how many of those days reported severe weather. The probability was calculated\nby dividing the number of severe weather days with a particular jet pattern by the total number of days the particular\npattern occurred.\n\n6.1.3 Stability Index Parameters\nThe stability indices chosen as candidate predictors were based on the results from the previous phases of this\nwork. All seven indices showed some skill in predicting severe weather. The stability indices were calculated for\neach day in the database from the 1000 UTC XMR sounding and are available to the forecasters through MIDDS.\nThe stability index candidate predictors included the\n\xe2\x80\xa2 Total Totals (TT),\n\xe2\x80\xa2 Cross Totals (CT),\n\xe2\x80\xa2 K-Index (KI),\n\xe2\x80\xa2 Lifted Index (LI),\n\xe2\x80\xa2 Thompson Index (TI),\n\xe2\x80\xa2 Showalter Stability Index (SSI), and\n\xe2\x80\xa2 Precipitable water (PW).\n\n6.2\n\nDevelopment of the Logistic Regression Equation\n\nThe amount of data available for equation development was critical to the reliability of the new equation. Data\nhad to be stratified into equation development and verification datasets, which limited the amount of data available\nfor equation development. Therefore, the amount of available data was determined before development began. After\ndetermining that an appropriate amount of data was available, one equation for the warm season was developed.\n\n20\n\n6.2.1\n\nData Availability\n\nThe World Meteorological Organization (1992, WMO) states that there should be at least 250 events in the\ndataset in order to derive stable statistical relationships. There are 153 days in the warm season, which equates to\n3366 days over the 22-year POR. However, sounding data were not available for every day in the POR. Data were\navailable for 3192 days or 95% of the time. Of these days, there were 422 reported severe weather days. This was\nsufficient to satisfy the WMO standard after stratifying the full dataset into development and verification datasets.\n6.2.2\n\nDevelopment and Verification Datasets\n\nThe candidate predictors and predictand were stratified into development and verification datasets. The\ndevelopment dataset was required to contain enough samples so that the resulting logistic regression equation was\nstable. The verification dataset was needed for equation testing to ensure that the equation would perform\nsufficiently in an operational setting. If the performance was much worse with the verification data, this would\nindicate that the development dataset was too small or there were too many predictors and the equations were fit too\nstrongly to the development data.\nThe daily TTS values were archived for the years 2009 and 2010. Therefore, these two years were chosen as the\nverification dataset in order to compare the accuracy of the equation vs. the TTS. This left 20 years of data (19892008) for the development dataset. The development dataset contained 380 severe weather events, while the\nverification dataset contained 42.\n6.2.3 Equation Development\nThe development of the logistic regression equation follows the procedure outlined in Lambert and Wheeler\n(2005). One logistic regression equation was developed using candidate predictors determined from the previous\nphases of this task.\n6.2.3.1\n\nLogistic Regression\n\nChoosing the correct statistical regression method is essential when creating a reliable probability forecast tool.\nLogistic regression is deemed most appropriate when using data with a predictand that is binary (Wilks 2006).\nLogistic regression is represented by the equation\n8(b O+ b1%1 ....\xc2\xb7+blc"lc)\n\nY = 1+e(bo +b1%1. +..\xc2\xb7+blc%rcJ\'\n\n(I)\n\nwhere y is the predicted value, XI ... Xk are the set of predictors, and b l ... bk are the coefficients for the corresponding\npredictors. For this task, y represents the probability of a severe weather event occurring and is bound between the\nvalues 0 and I. The candidate predictors for XI ... Xk are those listed in Sections 6.1.1, 6.1.2, and 6.1.3 and the method\nfor determining the corresponding coefficients is outlined in Section 6.2.3.2. A detailed description of logistic\nregression can be found in Section 4.2.1 of Lambert and Wheeler (2005).\n6.2.3.2\n\nPredictor Selection\n\nFollowing Lambert and Wheeler (2005), predictor selection was conducted using the S-PLUS\xc2\xae statistical\nsoftware (Insightful Corporation 2005), which has a built-in logistic regression function. The software also\ndetermines each predictor\'s contribution to the reduction in variance of the predictand, called the reduction in the\nresidual deviance. For logistic regression, the residual deviance is used to assess the fit of the overall model. The\nsmaller (larger) the deviance is the better (worse) the fit of the model. A detailed description of residual deviance\ncan be found in Section 4.2.2 of Lambert and Wheeler (2005).\nA process called screening regression was used to determine which candidate predictors to include in the\nlogistic regression equation. In this approach, predictors were added to the equation one at a time. At each step, the\ncandidate predictor that created the biggest reduction in the residual deviance was chosen as the next predictor in the\n("0)\n\nequation. Selection began with the prediction equation y\n\n= ~) (NULL model), where the only term in Equation\n1+e\\~11\n\n(1) is the intercept. In the next step, each of the seven candidate predictors was added as a lone predictor in Equation\n1 resulting in seven single predictor equations. The predictor that caused the largest reduction in the residual\ndeviance from the NULL model was chosen as the first predictor in the equation. At this stage, the prediction\n\n21\n\n6\'(/10 +/11%:1)\n\nequation is y = 1+<1 (to0 +/1 1 1 Next, the other six candidate predictors were added individually to the equation\ncreating a set of two-predictor equations. The second predictor that caused the largest reduction in residual deviance\nwas chosen as the second predictor. This continued for all candidate predictors. It is important to note that it is\ngenerally not useful to include all potential predictors in a final equation since most predictor variables are mutually\ncorrelated so that the full set of predictors includes redundant information (Wilks 2006). This could create\nunrealistic results.\n.% ).\n\nFigure 18 shows the percent reduction in residual deviance from the NULL model as each predictor was added.\nThe TT reduced the residual deviance by the most (-8%) and was chosen as the first predictor in the equation. The\nsecond predictor was the flow regime probabilities, which brought the total reduction of residual deviance to -13%.\nThe LI and jet probabilities were the third and fourth predictors in the equation, respectively, producing the final\nreduction in residual deviance of 15%.\nThere was no sufficient fifth predictor for the equation. In other words, no other candidate predictor reduced the\nresidual deviance by a significant amount, thereby not providing added value for predicting severe weather. The\nregression coefficients for each predictor, b l \xe2\x80\xa2.\xe2\x80\xa2 bk, should maintain the correct sign during each step described above.\nA positive regression coefficient means that the predictor increases the probability of the outcome, while a negative\ncoefficient means that the predictor decreases the probability of that outcome. For this study, Kl, TI, CT, TI, PW,\nflow regime probabilities, and jet probabilities should have positive coefficients indicating that larger (smaller)\nvalues of each variable increase (decrease) the chance of severe weather. The variables LI and SSI should have\nnegative coefficients indicating that larger (smaller) values decrease (increase) the chance of severe weather. None\nof the fifth candidate predictor coefficients had the correct sign, indicating that none of the predictors added value\nfor predicting severe weather.\n\nReduction in Residual Deviance by Predictor\nJul - Sep 1989 - 2008\n\no\n2\n\n4\n\n\'\\\n\'\\\n\'\\\n\n\'"\'"\n\'"\n\n~\n\n-........-.\n\n16\n\n18\nNull\n\nn\n\nFlow Regime\n\nLI\n\nJet\n\nFigure 18. The total percent reduction in residual deviance from the NULL model as each predictor was added to the\nequation using the development dataset.\n\n22\n\n6.3\n\nLogistic Regression Equation Performance\n\nForecast probabilities were produced using the four predictors from the verification dataset. These probabilities\nwere compared with the binary severe weather observations in the verification dataset using four tests that measure\nforecast performance. The tests included\n\xe2\x80\xa2 Mean Squared Error, which evaluates equation performance,\n\xe2\x80\xa2 Brier Skill Score, which measures equation performance against other forecast methods,\n\xe2\x80\xa2 Distributions ofthe probability forecasts for days with and without severe weather, and\n\xe2\x80\xa2 Contingency table statistics.\n\n6.3.1\n\nMean Squared Error\n\nThe Mean Squared Error (MSE) is the mean of the squared differences between the forecast probabilities and\nthe observations. The MSE is given by\n\n(2)\nwhere n is the number of forecast/observation pairs, Pi is the probability calculated from the equation, and 0i is the\ncorresponding binary severe weather observation (Wilks 2006). The MSE for a perfect forecast is 0, with larger\nMSE indicating decreasing accuracy of the forecast.\nThe MSE was computed for the four-predictor equation using the development and verification datasets. The\nMSE for the full development dataset was 0.10, which indicates skill in predicting severe weather. However, when\nthe data was split into severe and non-severe events, the MSE was 0.61 and 0.03, respectively. Similarly, the MSE\nfor the full verification dataset was 0.0 I, but 0.59 and 0.02 for severe and non-severe events, respectively. These\nresults indicate that the equation was biased towards predicting non-events and failed to adequately predict severe\nweather events. The MSE was also computed for the TTS using the verification dataset. Based on previous work by\nBauman (2006) and Wheeler (2010), a TTS 2: 5 was used as the threshold for severe weather where a TTS < 5 was\nassigned a 0 (a No forecast) and a TTS 2: 5 was assigned a I (a Yes forecast). The observation was subtracted from\nthe TTS forecast value, the result was squared, and then the final mean was taken of all the squared differences. The\nMSE for the full verification dataset was 0.07 and was 0.26 and 0.03 for severe and non-severe events, respectively.\nBased solely on MSE, the TTS was a better predictor of severe weather events than the logistic regression equation.\n\n6.3.2 Brier Skill Score\nThe Brier Skill Score (BSS) measures the improvement in skill of the logistic regression equation against a\nreference forecast. It is calculated using the MSE as\n\nBSS\n\nMSE rpo.-MSZ /\n= ( MSEpOT/RCr-MSEroj) * 100, (Wdks2006\n\xe2\x80\xa2\nTO\n\n(3)\n\nwhere MSE eqn is the MSE of the equation being tested, MSE ref is the MSE of the reference forecast method, and\nMSEperfect is the MSE of a perfect forecast, which is always O. The BSS denotes a percent improvement\n(degradation) in skill of the equation over the reference forecast when it is positive (negative). The calculated TTS\nfor the verification dataset was used for the reference forecast.\nThe BSS values for the verification dataset were -57% for the full dataset, -131 % for the severe weather events,\nand 34% for non-severe weather. As with the MSE, these results indicate that the logistic regression equation is\nbiased towards predicting non-events as the percent improvement for the non-severe weather is large. However, the\npercent degradation for predicting severe events is quite large, again indicating that TTS is a better tool for\npredicting severe weather.\n\n23\n\n6.3.3 Probability Distributions\nThe equation probability forecasts from the verification dataset were stratified by severe and non-severe\nweather days. The distribution of the probability values was calculated for each stratification. Figure 19 shows the\nprobability distribution for severe days (red curve) and non-severe days (blue curve). If the equation performance\nwas considered "good", the red (blue) curve should have a minimum (maximum) in the lower probability values that\nincrease to a maximum (minimum) at the higher values.\nThe non-severe weather days have a peak frequency near 65% at probability values of 0.1 and then decrease to\nnear 0 at 0.6. It shows a high percentage of low probabilities for non-severe events and a low percentage of high\nprobabilities as expected for good performance. The severe weather days have a small peak near 30% at probability\nvalues near 0.2 followed by a dip and then another small peak near 15% at probability values at 0.4. This indicates\nthat the equation performed poorly for severe weather days. The maximum at 0.2 and minimum at 0.6 suggests the\nequation is under-forecasting severe weather events. It should be noted that forecast probabilities for both severe and\nnon-severe days were never greater than 0.7.\nForecast Probability Distributions for Severe and Non-Severe Weather Days\nMay-September 20OS-2010\n70% , - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n60% r----r-~r---------------r======,-------\n\n-Severe\n-Non-Severe\n50%\n\n+----I-----4r-----------------=======---------\n\n~ 40% + - - - + - - - - - - \\ - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\nF\n\n~30% +----jr------::::;;;;IIIIIII....; ; : : - - - - - - - - - - - - - - - - - - - - - - - - -\n\n%\n\n20%\n\n+--t-----1L-------;----"!r------------------------\n\n10%\n\n-Hhf-----------~lI::\'""~=_~".:;..--------"::::OO\'\'\'\'I::\'\'\'"--------\n\n0%\n\nL------,r--------r------r-----r----=:::;::==~__.-~~:::::::\no\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\nForecast Probabilities\n\nFigure 19. Forecast probability distributions for severe (red) and non-severe (blue) days in the verification data. The\ny-axis values are the frequency of occurrence of each probability value, and the x-axis values are the forecast\nprobability values output by the equation.\n\n6.3.4 Contingency Table Statistics\nContingency table statistics were computed for the verification dataset TTS and equation probabilities. As in\nSection 5, the standard 2x2 contingency table shown in Table 2 was used to calculate the statistics and scores. The\ncontingency table statistics were computed using the same threshold values for TTS as in Section 5: if < 5 it was a\nNo forecast and if2 5 it was a Yes forecast. The procedure outlined by Wilks (2006) was used to choose the proper\nthreshold values for the equation probabilities. Figure 20 shows the CSI and Bias values for the equation\nprobabilities over a range of equation output probability values from 0.05 to 0.7 in increments of 0.05. The cutoff\n\n24\n\nvalue that had the maximum value of CSI and a bias value closest to I (no bias) was chosen. The resulting\nprobability cutoff was 0.35 indicated by the vertical black line in Figure 20.\nTable 4 and Table 5 show the contingency table statistics for the TTS and equation probabilities for the\nverification dataset, respectively. The POD and CSI are I for a perfect forecast and 0 for no skil1, and vice versa for\nFAR. The HSS and TSS are 1 for a perfect forecast, 0 for performance equal to a random forecast, and < 0 for\nperformance worse than that of a random forecast. It is evident that the TTS (Table 4) outperforms the equation\n(Table 5) in every computed statistic.\n\nC51 and Bias for Varying Probability Cutoff Values\n\n1-(51\n\n-Bias\n\nI\n\n4.5\n4\n\n\\.\n\\.\n\n3.5\n3\n2.5\n\n2\n1.5\n\n"""-\n\n1\n\n~\n\n0.5\n\n-\n\na\n0.05\n\n0.1\n\n0.15\n\n0.2\n\n0.25\n\n0.3\n\n"\n\n0.35\n\n~\n\n0.4\n\n0.45\n\n0.5\n\n0.55\n\n0.6\n\n0.65\n\n0.7\n\nProbability Cutoff Values\nFigure 20. Graph showing the CSI (blue) and bias (red) values for the equation probabilities over a range of equation\noutput probability values from 0.05 to 0.7 in increments of 0.05. The vertical black line shows the resulting\nprobability cutoff that had the maximum value ofCSl and a bias value closest to I.\n\nTable 4. TTS Verification\nDataset Statistics\n\n()bserved Severe\n\nFAR\n\n0.23\n\nNo\n\nPOD\n\n0.73\n\nYes\n\n30\n\n9\n\nCSI\n\n0.60\n\nNo\n\n11\n\n176\n\nHSS\n\n0.70\n\nTSS\n\nForecast\nSevere\n\nYes\n\n0.68\n\nFAR\n\n0.42\n\nTable 5. Equation\nProbabilities Verification\nDataset Statistics\n\nForecast\nSevere\n\n()bserved Severe\nYes\n\nNo\n\nPOD\n\n0.35\n\nYes\n\n15\n\n11\n\nCSI\n\n0.28\n\nNo\n\n28\n\n238\n\nHSS\n\n0.36\n\nTSS\n\n0.30\n\n25\n\n6.3.5 Equation Performance Summary\nAll four equation performance measures indicated that the logistic regression equation did not show an increase\nin skill over the previously developed TTS. The equation showed less accuracy than the TTS at predicting severe\nweather, little ability to distinguish between severe and non-severe weather days, and worse standard categorical\naccuracy measures and skill scores over TTS. The MSE, BSS, and probability distributions show that the equation\nhad some skill in predicting non-severe events, but no skill in predicting severe events.\nThe overriding difference between the logistic regression equation and the TTS is the inclusion of subjective\nquestions and answers in computing the fmal value for the ITS. The logistic regression equation only takes into\naccount the objective stability parameter values. Bauman et al. (2005) found that persistence, squall line activity,\nmoisture boundaries, and sea breeze and boundary collisions were important for severe weather development and\nincluded questions to account for these phenomena when calculating the TTS. The results of this analysis emphasize\nthe importance of these subjective factors.\n\n7.\n\nSummary\n\nThis report presented a severe weather forecasting tool developed from a 22-year climatological study of severe\nweather events and related severe weather atmospheric parameters. Data sources included archived sounding data\nfrom the 1000 UTC XMR soundings, surface and upper air maps, and two severe weather event databases covering\neast-central Florida. The NCDC and SPC severe weather events databases were used to identify days with reported\nsevere weather. These datasets provided the foundation for analyzing the stability parameters and synoptic patterns\nthat were used to develop the original objective tool to aid in forecasting severe weather events. The severe weather\ndatabase was upgraded by adding weather observations from May-September 2010. The new period of record for\nthe analysis was May-September, 1989-2010.\nStability parameter analysis results indicate that adding the 2010 data had a minimal effect on the severe\nweather forecast potential of the tool. The AMU calculated verification statistics for the TTS values calculated by\nthe 45 WS forecasters and AMU personnel in the 2010 warm season. On days that severe weather occurred, the TTS\nranged from -11 to 20 compared to the 2006 summer season verification in which the TTS was never below 0 on\ndays when severe weather was reported. Standard contingency table statistics showed a high FAR and low POD,\nCSI and HSS. The 2010 warm season was one of the hottest and driest summers on record across east-central\nFlorida due to the placement and strength of the surface Atlantic ridge and high pressure ridge aloft. This resulted in\nfew severe weather reports during the 2010 summer season and accounted for the wide range of TTS values when\nsevere weather was reported over the 2010 season.\nThe AMU created a logistic regression equation that predicted the probability of severe weather occurrence for\nthe day in east-central Florida. The equation was tested using four methods described in Section 6.3.1 - 6.3.4. The\nresults from the tests show a degradation in skill in predicting severe weather over the TTS. The equation also\nshowed less accuracy than the ITS at predicting severe weather, little ability to distinguish between severe and nonsevere weather days, and worse standard categorical accuracy measures and skill scores over TTS.\nBased on the fmdings of this study and after reviewing the results with the 45 WS, a new tool was not\ndeveloped based on the performance of the logistic regression equation. The previously developed ITS and MIDDS\nGUI were not updated due to the inability of the 2010 severe weather season data to help improve the tool.\n\n26\n\nReferences\nBauman, W., M. Wheeler and D. Short, 2005: Severe Weather Forecast Decision Aid: Final Report. NASA\nContractor Report CR-2005-212563, Kennedy Space Center, FL, 50 pp. [Available from ENSCO, Inc., 1980\nN. Atlantic Ave., Suite 830, Cocoa Beach, FL, 32931 and online at http://science.ksc.nasa.gov/amu/finalreports/severe-tool-final.pdf.]\nBauman, W., 2006: Severe Weather Forecast Decision Aid Verification Testing. AMU Memo, Ilpp. [Available\nfrom ENSCO, Inc., 1980 N. Atlantic Ave., Suite 830, Cocoa Beach, FL, 32931.]\nInsightful Corporation, 2005: S-PL US 7for Windows User\'s Guide, Insightful Corp., Seattle, WA, 664 pp.\nLambert, W. and M. Wheeler, 2005: Objective lightning probability forecasting for Kennedy Space Center and Cape\nCanaveral Air Force Station. NASA Contractor Report CR-2005-212564, Kennedy Space Center, FL, 54 pp.\n[Available from ENSCO, Inc., 1980 N. Atlantic Ave., Suite 230, Cocoa Beach, FL, 32931, and at\nhttp://science.ksc.nasa. gov/am ulfinal.htmI.]\nNCDC, 20 I0: U.S. Storm Events Database. [Available online at http://www4.ncdc.noaa.gov/cgiwin/wwcgi.dll?wwEvent-Storms.]\nSPC, 2009: Severe Weather Geographic Information System Database. [Available online at\nhttp://www.spc.noaa.gov/gis/svrgis/.]\nWheeler, M., 2009: Severe Weather and Weak Waterspout Checklist in MlDDS. NASA Contractor Report CR2009-214760, Kennedy Space Center, FL, 16 pp. [Available from ENSCO, Inc., 1980 N. Atlantic Ave., Suite\n830, Cocoa Beach, FL, 32931 and online at http://science.ksc.nasa.gov/amu/final-reports/svr-wx-wkshtm i d<:Is. pdf. ]\nWheeler, M., 2010: Upgrade Summer Severe Weather Tool in MlDDS. NASA Contractor Report CR-2010-216282,\nKennedy Space Center, FL, 13 pp. [Available from ENSCO, Inc., 1980 N. Atlantic Ave., Suite 830, Cocoa\nBeach, FL, 32931 and online at http://science.ksc.nasa.gov/amu/final-reports/severe-tool-upgrade.pdf.]\nWilks, D. S., 2006: Statistical Methods in the Atmospheric Sciences. 2d ed. Academic Press, Inc., San Diego, CA,\n467 pp.\nWorld Meteorological Association (WMO), 1992: Methods ofInterpreting Numerical Weather Prediction Output\nfor Aeronautical Meteorology. Technical Note No. 195, ISBN 92-63-1 ono-x, 89 pp.\n\n27\n\nList of Acronyms\n\nlO070RH\n\nlOOO to 700 mb average Relative\nHumidity\n\nMDPl\n\nMicroburst Day Potential Index\n\n45 WS\n\n45th Weather Squadron\n\nMIDDS\n\nMeteorological Interactive Data\nDisplay System\n\nAMU\n\nApplied Meteorology Unit\n\nMSE\n\nMean Squared Error\n\nBSS\n\nBrier Skill Score\n\nNOAA\n\nCAPEFMaxT Cape using Maximum forecast\nTemperature\n\nNational Oceanic and Atmospheric\nAdm inistration\n\nNCDC\n\nNational Climatic Data Center\n\nCCAFS\n\nCape Canaveral Air Force Station\n\nPOD\n\nProbabi Iity of Detection\n\nCGLSS\n\nCloud-to-Ground Lightning\nSurveillance System\n\nPOR\n\nPeriod of Record\n\nPW\n\nPrecipitable Water\n\nCSI\n\nCritical Success Index\n\nSPC\n\nStorm Prediction Center\n\nCT\n\nCross Totals\n\nSSI\n\nShowalter Stability Index\n\nESRL\n\nEarth System Research Laboratory\n\nT S50\n\nTemperature at 850 mb\n\nFAR\n\nFalse Alarm Rate\n\nTcI/Tk\n\nTool Command Language/Tool Kit\n\nHTML\n\nHyperText Markup Language\n\nTDif\n\nHSS\n\nHeidke Skill Score\n\nForecast maximum temperatureconvective temperature\n\nGUI\n\nGraphical User Interface\n\nTI\n\nThompson Index\n\nKSC\n\nKennedy Space Center\n\nTSS\n\nTrue Skill Statistic\n\nlNY\n\nHeight of Inversion\n\nTT\n\nTotal Totals Index\n\nKI\n\nK-Index\n\nTTS\n\nTotal Threat Score\n\nLl\n\nLifted Index\n\nWMO\n\nWorld Meteorological Organization\n\nLLJ\n\nLow Level Jet\n\n28\n\nNOTICE\n\nMention of a copyrighted, trademarked or proprietary product, service, or document does not constitute endorsement\nthereof by the author, ENSCO Inc., the AMU, the National Aeronautics and Space Administration, or the United\nStates Government. Any such mention is solely for the purpose of fully informing the reader of the resources used to\nconduct the work reported herein.\n\n29\n\nForm Approved\nOMS No. 0704-0188\n\nREPORT DOCUMENTATION PAGE\n\nThe public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing\ndata sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or\nany other aspect of this collection of information, including suggestions for reducing this burden, to Department of Defense, Washington Headquarters Services, Directorate\nfor Information Operations and Reports (0704-0188),1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202-4302. Respondents should be aware that\nnotwithstanding any other provision of law, no person shall be subject to any penalty for failing to comply with a collection of information if it does not display a currentiy\nvalid ?s~B)~n:~.1T nuriITr Y\nPLEA E D N\nRE RN fOUlR FORM T\n\n1. REPORT DATE (DD-MM-YYYY)\n\nTHE ABOVE ADDRESS.\n\n3. DATES COVERED (From - To)\n\n2. REPORT TYPE\n\nOctober 2010 - March 2011\n\nFinal\n4. TITLE AND SUBTITLE\n\nSa. CONTRACT NUMBER\n\nNNK06MA70C\n\nUpgrade Summer Severe Weather Tool\n\n5b. GRANT NUMBER\n\n5c. PROGRAM ELEMENT NUMBER\n\n5d. PROJECT NUMBER\n\n6. AUTHOR(S)\n\nLeela Watson\n5e. TASK NUMBER\n\nSf. WORK UNIT NUMBER\n\n8. PERFORMING ORGANIZATION\nREPORT NUMBER\n\n7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)\n\nENSCO, Inc.\n1980 N. Atlantic Avenue, Suite 830\nCocoa Beach, FL 32931\n\n9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)\n\n10. SPONSORING/MONITOR\'S ACRONYM(S)\n\nNASA\nJohn F. Kennedy Space Center\nCode PH-3\nKennedy Space Center, FL 32899\n\n11. SPONSORING/MONITORING\nREPORT NUMBER\n\nCR-2011-216299\n\n12. DISTRIBUTION/AVAILABILITY STATEMENT\n\nUnclassified, Unlimited\n\n13. SUPPLEMENTARY NOTES\n\nAn electronic version can be found at http://science.ksc.nasa.gov/amu/final.html\n14. ABSTRACT\n\nThe goal of this task was to upgrade to the existing severe weather database by adding observations from the 20 I0 warm season,\nupdate the verification dataset with results from the 20 I0 warm season, use statistical logistic regression analysis on the database\nand develop a new forecast tool. The AMU analyzed 7 stability parameters that showed the possibility of providing guidance in\nforecasting severe weather, calculated verification statistics for the Total Threat Score (TTS), and calculated warm season\nverification statistics for the 2010 season. The AMU also performed statistical logistic regression analysis on the 22-year severe\nweather database. The results indicated that the logistic regression equation did not show an increase in skill over the previously\ndeveloped TIS. The equation showed less accuracy than TTS at predicting severe weather, little ability to distinguish between\nsevere and non-severe weather days, and worse standard categorical accuracy measures and skill scores over TTS.\n\n15. SUBJECT TERMS\n\nSevere, Wind Gust, Hail, Tornado, Decision Aid, Climatology, Wind Tower, Logistic Regression\n\n16. SECURITY CLASSIFICATION OF:\na. REPORT\n\nb. ABSTRACT\n\nc. THIS PAGE\n\nU\n\nUU\n\nUU\n\n17. LIMITATION OF\nABSTRACT\n\nUU\n\n18. NUMBER 19b. NAME OF RESPONSIBLE PERSON\nOF\nDr. Lisa L. Huddleston\nPAGES\n19b. TELEPHONE NUMBER (lnc/ude area code)\n\n29\n\n(321) 861-4952\nStandard Form 298 (Rev. 8-98)\n\nPrescribed by ANSI Std. Z39\xc2\xb718\n\n'