b"Chapter 6\nInteractions with Virtual People:\nDo Avatars Dream of Digital Sheep?\n***\nMel Slater\nMaria V. Sanchez-Vives\nInstituto de Neurociencias\nUniversidad Miguel Hernandez de Alicante\nAlicante, Spain\nhttp://in.umh.es/?page=personalsg&key=50\n\nDepartment of Computer Science\nUniversity College London, Gower Street,\nLondon WC1E 6BT, UK\nwww.cs.ucl.ac.uk/staff/m.slater\n\n1. Introduction\nIn his celebrated book \xe2\x80\x98Do Androids Dream of Electric Sheep\xe2\x80\x99 the author Philip K. Dick\nexplores the relationship between humans and humanoid androids that seem to be human, even\nsuperhuman, in every way. The theme is taken up in the film Bladerunner, based on this original\nstory, where the policeman Dekker is required to terminate renegade \xe2\x80\x98replicants\xe2\x80\x99, but falls in love\nwith one himself. In the more recent movie \xe2\x80\x98A.I.\xe2\x80\x99 the question is raised whether you can love a\nrobot (in this case a child) who exhibits every sign of loving you \xe2\x80\x93 one slogan of the movie was\n\xe2\x80\x98His love is real but he is not\xe2\x80\x99. The book and each of these movies, and many others, explore the\nmoral implications of relationships between humans and machines, machines albeit that are\nconstructed to behave as if human, often also with super-human powers. Their behaviour is so\nvaried, realistic and compelling that the observer is forced to assume that these machines have\nachieved consciousness, that they know themselves, have emotions and feelings, and know that\nthey have these feelings. Indeed in the case of Dekker there is a tantalizing hint that perhaps he\nhimself is unwittingly a replicant.\nThese movies and many others paint a popular conception of a world in the not too distant future\npopulated by physically embodied replications of people \xe2\x80\x93 robots (entirely non-organic\nmaterials) or androids (mixtures of non-organic and organic materials, such as feature in the\nTerminator movies). The story lines then revolve around relationships between these beings and\nreal humans, whether relationships of exploitation (the replicants in Bladerunner are essentially\nslaves), proxy love (in A.I. the main artificial character is to be a new son in the family) or war\n(as in The Terminator). In any case the assumption is that the natural development of artificial\nintelligence and robotics research will eventually lead to such entities becoming essentially mass\nproduced consumer products available to fulfil a variety of human needs and roles.\nThis paper explores another form of artificial entity, ones without physical embodiment. We\nrefer to \xe2\x80\x98virtual characters\xe2\x80\x99 as the name for a type of interactive object that have become familiar\nin computer games and within virtual reality applications. We refer to these as avatars: threedimensional graphical objects that are in more-or-less human form which can interact with\nhumans. Sometimes such avatars will be representations of real-humans who are interacting\ntogether within a shared networked virtual environment, other times the representations will be\n\n75\n\nof entirely computer generated characters. Unlike other authors, who reserve the term \xe2\x80\x98agent\xe2\x80\x99 for\nentirely computer generated characters and avatars for virtual embodiments of real people; the\nsame term here is used for both. This is because \xe2\x80\x98avatars\xe2\x80\x99 and \xe2\x80\x98agents\xe2\x80\x99 are on a continuum. The\nquestion is where does their \xe2\x80\x98behaviour\xe2\x80\x99 originate? At the extremes the behaviour is either\ncompletely computer generated or comes only from tracking of a real person. However, not\nevery aspect of a real person can be tracked \xe2\x80\x93 every eyebrow move, every blink, every breath \xe2\x80\x93\nrather real tracking data would be supplemented by inferred behaviours which are programmed\nbased on the available information as to what the real human is doing and her/his underlying\nemotional and psychological state. Hence there is always some programmed behaviour \xe2\x80\x93 it is\nonly a matter of how much. In any case the same underlying problem remains \xe2\x80\x93 how can the\nhuman character be portrayed in such a manner that its actions are believable and have an impact\non the real people with whom it interacts?\nThis paper has three main parts. In the first part we will review some evidence that suggests that\nhumans react with appropriate affect in their interactions with virtual human characters, or with\nother humans who are represented as avatars. This is so in spite of the fact that the\nrepresentational fidelity is relatively low. Our evidence will be from the realm of psychotherapy,\nwhere virtual social situations are created that do test whether people react appropriately within\nthese situations. We will also consider some experiments on face-to-face virtual communications\nbetween people in the same shared virtual environments. The second part will try to give some\nclues about why this might happen, taking into account modern theories of perception from\nneuroscience. The third part will include some speculations about the future developments of the\nrelationship between people and virtual people. We will suggest that a more likely scenario than\nthe world becoming populated by physically embodied virtual people (robots, androids) is that in\nthe relatively near future we will interact more and more in our everyday lives with virtual\npeople \xe2\x80\x93 bank managers, shop assistants, instructors, and so on. What is happening in the movies\nwith computer graphic generated individuals and entire crowds may move into the space of\neveryday life.\n2. Virtual Environment, Immersion and Presence\nIn most of what follows we will be describing experiments and results that take place within\nvirtual environments (VE) (or \xe2\x80\x98virtual reality\xe2\x80\x99 VR). By a virtual environment we mean a\ncomputer generated \xe2\x80\x98place\xe2\x80\x99 in which it is possible for people to interact. There may be events\noccurring in this place, and there are various forms of interaction. At one extreme the place is\nstatic (nothing changes in it) but the human participant can move around within it taking\narbitrary positions and orientations. At the other extreme, there may be many events taking\nplace, and the participant is able not only to look at (hear and feel) what is happening but also to\nintervene and change the course of events.\nVirtual environments may be more or less immersive. Immersion breaks down into a number of\nfactors (Slater and Wilbur, 1997):\n\n\xe2\x80\xa2\n\n76\n\nInclusiveness \xe2\x80\x93 is the extent to which all sensory data is generated only from within the\nvirtual environment.\n\n\xe2\x80\xa2\n\nExtensive \xe2\x80\x93 is the number of sensory modalities that are accommodated. A system which\nhas vision and sound is more immersive than one that has vision alone.\n\n\xe2\x80\xa2\n\nSurrounding \xe2\x80\x93 is the extent to which the virtual sensory data can be generated from any\nposition and orientation.\n\n\xe2\x80\xa2\n\nVividness \xe2\x80\x93 the degree of fidelity to every day reality \xe2\x80\x93 for example, a system that is able\nto display shadows in real time is more immersive than one that cannot display shadows.\n\n\xe2\x80\xa2\n\nEgocentric \xe2\x80\x93 information is displayed to the participant to the sense organs in the normal\nsense of everyday reality. In other words, they see through their own eyes from a first\nperson point of view as if they were there, rather than looking at scenario from the\noutside (an exocentric point of view).\n\n\xe2\x80\xa2\n\nProprioceptive matching \xe2\x80\x93 there is a correlation between what they feel as they are\nmoving and what they see, feel and hear as a response. For example, when they feel they\nare moving their body the sensory response should be appropriate to this \xe2\x80\x93 when they\nturn their head the visual and auditory sense data should match the head turn in exact\ncorrelation.\n\nAll of the above are ideals, and note that they describe the objective features of a system. Two\nsystems can be at least partially ordered with respect to their degree of immersiveness. Presence,\nhowever, is a phenomenon that may arise on the basis of immersion. This is the extent to which\nindividuals respond as if they are in a real world. This response is at multiple levels \xe2\x80\x93 low level\nphysiological responses, unconscious behavioural responses, volitional behavioural responses,\nfeelings and emotions, patterns of attention, and so on through to high level cognitive responses\n\xe2\x80\x93 all associated with the feeling of acting in a real place.\nIn the context of relationships between people and virtual people we can also consider the\nquestion of \xe2\x80\x98presence\xe2\x80\x99. In real life there are typical responses that occur when people interact.\nFor example, eye contact is a particularly important form of interaction which can evoke strong\nresponses \xe2\x80\x93 especially if it is held too long. If person A gets too close to person B in a situation\nwhich is culturally deemed to be inappropriate (e.g., during a business conversation) it is likely\nthat B will attempt to back away, and feel strong emotions. For people with particular syndromes\nsome types of social interaction can provoke powerful responses. Someone with a fear of public\nspeaking will show strong anxiety responses when forced to be in front of an audience and\nspeak. People with generalized social phobia or shyness will react with strong anxiety to many\ndifferent types of social situation \xe2\x80\x93 such as eating in public, simply attending a party, interactions\nwith members of the opposite sex and so on. People with paranoid delusions will invent entire\nstories about what is happening around them based on the smallest evidence \xe2\x80\x93 a random glance,\na coincidental turning away of someone else, two other people who happen to be looking at them\nwhile talking amongst themselves, and so on. Confronted with such social situations within a\nVE, where the other characters are virtual characters, the extent to which these responses are also\ngenerated is a sign of presence. In the next section we examine some evidence for this in the\ncontext of applications inspired by psychotherapy.\n\n77\n\n3. Anxiety in Social Situations as a Surrogate for Presence\nIn this section we consider some examples taken from the realm of psychotherapy. We consider\ntwo conditions \xe2\x80\x93 social phobia and paranoid ideation. We consider whether people with these\nconditions will experience similar responses as they would in every day reality. The particular\ntype of social phobia we consider is \xe2\x80\x98fear of public speaking\xe2\x80\x99. Will people with this condition\nhave the same anxiety speaking to an entirely virtual audience as they would speaking to a real\naudience? If yes, this is a sign of presence. With paranoia \xe2\x80\x93 will people who tend to towards\nparanoid thoughts (that other people are against them) in everyday life also exhibit such\nsymptoms when the \xe2\x80\x98other people\xe2\x80\x99 are virtual? Again this would be a sign of presence. Of course\nremember throughout that everyone knows that in fact there are no real people there \xe2\x80\x93 so what\nwe are considering are people\xe2\x80\x99s automatic responses, not their perhaps higher level thought that\n\xe2\x80\x98I know this is not really happening but \xe2\x80\xa6\xe2\x80\x99 The \xe2\x80\x98but\xe2\x80\x99 is of crucial importance \xe2\x80\x93 \xe2\x80\x98I know this is\nnot really happening but I still feel anxious when those people look at me\xe2\x80\x99.\nIn this paper we do not at all address the formal scientific results \xe2\x80\x93 these are available in other\npublications which are referenced in the appropriate sections. Here we concentrate only on\nqualitative aspects of the results.\n\n3.1 Fear of Public Speaking\nAt UCL in 2000-2001 we carried out an experiment in which more than 40 people were exposed\nto virtual audiences which had three different types of behaviour \xe2\x80\x93 they were static (did not move\nat all), dynamic and showing very positive responses towards the audience, or dynamic and\nshowing very negative responses towards the audience (Pertaub et al., 2001, 2002). Each person\nexperienced only one of these conditions. Some examples of the positive and negative audiences\nare shown in Figure 1, each consisting of the same eight male virtual characters who changed\nposture and facial expression, and also made verbal comments during the progress of the 5\nminute talk.\nEach person experienced the audience using a head-tracked stereo head-mounted display, as\nshown in Figure 2. A remote operator unseen by the subjects signalled the sequence of responses\nof the virtual audience, only choosing the timing of each next response, to ensure that each\nperson saw the same thing.\nThe statistical results indicated that for those who saw the positive or static audience their\nreported anxiety provoked as a result of the talk correlated with their usual anxiety in everyday\nlife with respect to fear of public speaking. However, irrespective of everyday life anxiety in\nrelation to public speaking the general trend for those who experienced the negative audience\nwas a very strong anxiety reaction. The experimenters noted anecdotally that such subjects had\nchanges in body posture and skin colour, and overall demeanour after experiencing the negative\naudience indicating a strong negative reaction. (For ethical reasons each person who was\nassigned to the negative audience group experienced also the positive group before they went\naway).\n\n78\n\nPositive Audience\n\nNegative Audience\nFigure 1. Virtual Audience for the Fear of Public Speaking Experiment\n\nFigure 2. Head-Tracked Stereo Head-mounted display used in Fear of Public\nSpeaking Experiment\n\nHere are some of the comments made by the subjects who experienced the positive audience:\n\xe2\x80\x98It was clear that the audience was really positive and interested in what I was saying and\nit made you feel like telling them what you know.\xe2\x80\x99\n\xe2\x80\x98I felt great. Finally nobody was interrupting me. Being a woman, people keep\ninterrupting you in talks much more\xe2\x80\xa6 But here I felt people were there to listen to me.\xe2\x80\x99\n\n79\n\n\xe2\x80\x98They were staring at me. They loved you unconditionally, you could say anything, you\ndidn\xe2\x80\x99t have to work\xe2\x80\x99.\nHere are some responses to the negative audience:\n\xe2\x80\x98It felt really bad. I couldn\xe2\x80\x99t just ignore them. I had to talk to them and tell them to sit up\nand pay attention. Especially the man on the left who put his head in his hands; I had to\nask him to sit up and listen\xe2\x80\xa6. I entered a negative feedback loop where I would receive\nbad responses from the audience and my performance would get even worse\xe2\x80\xa6. I was\nperforming really badly and that doesn\xe2\x80\x99t normally happen.\xe2\x80\x99\n\xe2\x80\x98I was upset, really thrown. I totally lost my train of thought. They weren\xe2\x80\x99t looking at\nme and I didn\xe2\x80\x99t know what to do. Should I start again? I was very frustrated. I felt I had\nno connection to them. They weren\xe2\x80\x99t looking at me. I just forgot what I was talking\nabout.\xe2\x80\x99\nThese comments might seem to be unsurprising \xe2\x80\x93 especially the reactions to the negative\naudience \xe2\x80\x93 for after all, their behaviour was extremely hostile. However, it is important to\nremember that there was no audience there! The situation was entirely virtual. What happened\nexpressed the power of the virtual reality to evoke a response that was similar to that of reality \xe2\x80\x93\na \xe2\x80\x98presence\xe2\x80\x99 response.\nIn a later study we compared people\xe2\x80\x99s responses to a virtual reality public speaking scenario\nwhere the audience was dynamically behaving but neither negative nor positive but neutral in its\nresponse. Half of the subjects of this study had anxiety in relation to public speaking and the\nother half were confident public speakers. Moreover, there were two scenarios \xe2\x80\x93 an empty virtual\nseminar room or the seminar room with the neutrally behaving audience. Half of each group\nwere assigned to the empty room and half to the populated room. Our prediction was that those\nwith public speaking anxiety would respond with greater anxiety to the populated room than to\nthe empty room, but for the confident speakers it would not make much difference whether the\nroom was populated or not. These results were observed across a range of subjective measures of\nanxiety response and also by heart rate patterns (Slater et al., 2004).\n3.2 Paranoid Ideation\nParanoid ideation is the typical pattern of thinking displayed in cases of paranoia. It is\ncharacterised by suspiciousness and beliefs that one is being followed, plotted against,\npersecuted, and so on. There are degrees of paranoid tendencies in a population \xe2\x80\x93 ranging from\nnone at all, all the way through to psychotic illness. In 2003 together with colleagues at the\nInstitute of Psychiatry, Kings College London, an experiment was carried out that tested whether\nthe range of paranoid thoughts typically present in a normal population (but excluding people\nwith psychosis) could be reproduced within a virtual reality (Freeman et al., 2003). This\nexperiment was carried out in an immersive projection system (sometimes called a \xe2\x80\x98Cave\xe2\x80\x99)\nillustrated in Figure 3.\n\n80\n\nFigure 3(a) shows someone standing in a white box. In fact the floor and three walls are\nprojection screens onto which a stereo image is back-projected. The glasses worn by the person\nhave left and right lenses switching on and off in synch with the images displayed on the screens,\nthus creating a stereo illusion.\nImages are displayed in Figure 3(b) resulting in the illusion of a kitchen. The person perceives a\n3D stereo scene, and since his head position and orientation is tracked the images on the four\nscreen-walls knit together to form one overall 3D scenario with high immersion. More\ninformation about such systems can be found in (Cruz-Neira et al., 1993).\n\n(a) The projectors are turned off\nin the ReaCTor\n\n(b) The scene shows a kitchen\n\nFigure 3. Trimension ReaCTor \xe2\x80\x93 A Cave-like system\nThe subjects in the paranoia experiment had a simple task to move through a virtual library. The\ncharacters in the library would look at them and make some facial expressions, and objectively\nthey maintained a neutral attitude towards the subjects. Illustrations are given in Figure 4.\nThe statistical results supported the hypothesis that paranoid thoughts were triggered in the\nvirtual reality in correlation with subjects\xe2\x80\x99 propensities to experience these in everyday reality.\nHere we quote some of the remarks made by the subjects in post-experimental interviews.\n\xe2\x80\x9cThe two people to the left, I didn\xe2\x80\x99t like them very much \xe2\x80\x93 well, I don\xe2\x80\x99t know, maybe\nbecause when I entered the room I felt I was being watched and then they started talking\nabout me. The other people were more neutral and more inviting except the guy with the\nbeard.\xe2\x80\x9d\n\n81\n\nFigure 4. The Scenario for the Paranoia Experiment\n\xe2\x80\x9cIt was probably more real to me than I expected it to be. At some point, I was trying to\nnavigate around a table and almost found myself saying sorry to the person sitting there. I\nfelt that they were getting annoyed with me for doing that\xe2\x80\xa6\xe2\x80\x9d\n\xe2\x80\x9cIt was really weird, because they were all definitely in on something and they were all\ntrying to make me nervous. It was clear that they were trying to mock me, they kept on\nlooking at me and when I looked back, they were uuhh\xe2\x80\xa6 The guy with the suit was\nreally weird because he kept smiling at me and it was quite sinister.\xe2\x80\x9d\nIt should be noted that there were no sounds in these environments \xe2\x80\x93 so what the subjects heard\nwere entirely made up from within their own minds. The results were quite remarkable \xe2\x80\x93 people\nreacted strongly to the virtual characters, even though objectively everyone knew that there were\nno people there at all. These studies have been followed up and repeated again, with publications\npending.\n4. Face-to-Face Meetings Between Real People in a Virtual Reality\nAbove we considered the results of encounters between real people and virtual people. In this\nsection we briefly consider what happens when real people, who may be physically separated by\nthousands of kilometres, meet face-to-face in a networked virtual environment. By face-to-face\nwe mean that each person sees a virtual character representing the other one. This virtual\ncharacter speaks in real-time using the real voice of the remote partner, and at least some of the\nmovements (in particular head movements) of the remote person are reflected in the movements\nof the virtual character.\nAn example is shown in Figure 5 \xe2\x80\x93 where a person is in the immersive projection system\ninteracting with another who is physically remote. They can talk to one another and have the\nimpression of being in the same extended 3D space which is experienced in stereo. For example,\nthey can make \xe2\x80\x98eye contact\xe2\x80\x99 and (virtually) stand very close to one another if they so wished. Of\ncourse the remote person may not be in a projection system \xe2\x80\x93 they may be using a head-mounted\ndisplay or even sitting in front of a conventional monitor, keyboard and mouse system, seeing\nthe virtual scenario on the screen in front of them.\n\n82\n\nFigure 5. A meeting in virtual reality\nMany experiments have been carried out examining two and three-party interactions in such\nenvironments (Slater et al., 2000; Schroeder et al., 2001). There are several findings. First greater\nimmersion confers greater social power \xe2\x80\x93 typically in a mixed encounter where one person is in a\nmore immersive system than the others (e.g., one is in a head-mounted display and the others on\ndesktop display systems) the one in the more immersive display will have a tendency to become\nthe leader (other things being equal).\nThe avatar representation must have the capability for the people to express themselves \xe2\x80\x93 at the\nvery least make eye contact, make gestures. If these basic features of everyday communication\nare not possible, then social order tends to break down, with some people even believing that\nothers are deliberately trying to be disruptive and thwart the desires of the others. Similarly\nproblems of network delay so that people for example are unable to immediately hear answers to\ntheir questions may become major impediments to smooth social interaction.\nThe avatar representations must match its corresponding behavioural capabilities. For example,\nin one experiment one avatar looked very sophisticated (photorealistic) but could do nothing \xe2\x80\x93\nnot move its head nor limbs. The other people represented by simple block-like extremely\ncartoonish avatars became suspicious of the intentions of this more sophisticated looking person.\nIn another experiment (Garau et al., 2003) people experienced either more sophisticated looking\nor less sophisticated looking partner avatars, and behavioural capability with respect to eye\nmovement was either more or less in conformance with every day expectations during the flow\nof a conversation. It was found that consistency between appearance and behaviour was very\nimportant to maintain presence between the participants.\nIn spite of technical problems the possibilities are nevertheless very interesting. Here we have\npeople who are physically in remote places who nevertheless can coexist and interact within a\nshared 3D space, talk and accomplish physical tasks together. One such experiment concluded\nthat when two remote people carried out a task similar to solving a Rubik cube type puzzle\ntogether their performance within two \xe2\x80\x98Cave\xe2\x80\x99 systems was almost as good as the performance of\npeople who did the same thing in reality (Steed et al., 2003).\n\n83\n\n5. Presence and Perception\nAbove we have informally reviewed some of the evidence demonstrating that people do respond\nto virtual characters as if they were real. How can this happen? Why do we react to characters\nthat are crude human representations in a way that is similar to how we react to humans? Do\nemotions overrule our cognitive functions? Understanding these phenomena would take us deep\ninto the workings of the brain and in this section we offer some speculations that may point to\nwhere to look for an explanation. First of all, we should consider how we perceive the external\nworld. Perception is constructed from information from different sensory modalities (visual,\nauditory, tactile, etc.) that arrives to the brain in the form of electrical impulses. For instance, all\nthe information of the visual scene travels codified in a binary code (impulse/no impulse) in a 3\nmm wire which is the optic nerve comprised of some one million axons (for each eye). This\ninformation is relayed to the thalamic nucleus and from there it will reach the primary visual\ncortex, to project then to higher or association areas. Different aspects of the visual scene\n(contours, colours, movement, etc.) will then have to be reconstructed such that they create our\ninternal visual representation of the environment. This processing, from the exterior world all the\nway up to associative cortices is called bottom-up processing and is driven by so-called feedforward projections. However, there is evidence to support the view that our perceptual\nprocessing does not solely work as a video camera that films and re-plays the environment. One\npiece of evidence is that the neurons located in the primary visual cortex, and even in the\nthalamus receive more connections from other neurons in the cerebral cortex (or feed-back\nconnections) than from the sensory organs (Bullier et al., 2001). What this means in functional\nterms is that the visual reconstruction that these neurons are achieving is deeply influenced by\ninformation that already exists in the cerebral cortex, which is called the top-down processing\n(e.g. Li et al., 2004). What top-down connections convey are the internal factors that affect our\nsensory perception, including our previous experiences, expectations, motivation, attention, etc.\nThe evidence for the functional correlate of this top-down influence is easily experienced when\nwe look at images like the Kanizsa triangle and similar illusions e.g. (Kojo et al., 1993),\nconfirming the fact that sensory perception is not a passive but an active process where\nperceiving and interpreting are carried out simultaneously. This implies that our perception is\nfinally determined by the confluence between two streams of information, the bottom-up and the\ntop-down, the external world and the \xe2\x80\x9cinternal\xe2\x80\x9d one.\nHow does this relate to our perception of avatars? In studies of presence in virtual environments\nit has been observed that in order to achieve a high level of presence it is not crucial to have a\nhighly realistic visual representation of the environment (Sanchez-Vives and Slater, 2005). A\ncoarse representation may induce a high level of presence; participants in a VE just need to be\ngiven some minimal cues. The reason why minimal cues can be enough to induce presence is\nbecause our perception is an active process and the cortex fills in some of the missing\ninformation (Ramachandran and Gregory, 1991; De Weerd et al., 1998). Since our perception is\ntightly linked to interpretation, the non-sense information is often eliminated and the missing\ninformation is filled-in based on previously experienced schemes. One classical example of fillin processes is the one that takes place in the blind spot of our retina. The retina has a\ndiscontinuity in the back of the eye at the location were the optic nerve emerges, the optic disc.\nThis area of 1.5 mm diameter lacks photoreceptor cells and should therefore appear as a hole in\nour perceived visual scene. This does not happen however because that empty space is\nappropriately filled-in by the brain from surrounding information. In a similar way, probably a\n\n84\n\nfew cues from the avatars such as face elements, eye following, body movements and so on are\nenticing enough for the brain to perceive this and to react to it as if it were a human.\nThere is an additional element that makes interaction with avatars special compared to with other\nelements in the VE: the emotional content. Faces are considered as emotional stimuli. Emotional\nvisual stimuli, are detected faster, they evoke enhanced responses in the visual cortex, and they\ncapture attention more readily than other significant objects in the scene (Lang et al., 1998;\nBradley et al., 2003). Face processing occurs even in non-conscious, pre-attentive states, and\nimmediately recalls attention and induces a response. An area in the brain, the fusiform gyrus\n(inferotemporal cortex)(for a review see Haxby et al., 2000), is specialized in responding to face\nstimuli. This explains why localized lesions in the cerebral cortex can affect specifically the\nability to recognized faces, as it was nicely illustrated in (Sacks, 1998) \xe2\x80\x9cThe man who mistook\nhis wife for a hat\xe2\x80\x9d. This area seems to work as well comparing visual inputs with internal\nrepresentations or recalled images (Frith and Dolan, 1997), or, as we explained above, one of the\nareas where bottom up and top down information meet each other.\nWhat is so special about faces? Facial expression is one of the elements forming emotion, along\nwith autonomic response (changes in heart rate, respiration, blood pressure, etc.) and with the\nsubjective feelings characteristic with emotion (sadness, fear\xe2\x80\xa6). It is also a fast form of nonverbal communication that may have had an important survival role in evolution. For this reason,\nface recognition is deeply engrained in the brain wiring and even newborn humans express the\ncapability of recognizing schematic representations of faces (Turati et al., 2002). Due to this hard\nwiring, we willingly identify faces and respond to them, even if they belong to highly schematic\nvirtual characters.\nTo summarise: top down processing implies that if sufficient minimal cues are provided within a\nvirtual environment, the brain processing fills in missing information. The second element,\ncritical to avatar interaction is that the processing of the human form, especially faces, carries\nemotional aspects, which may still further minimise the degree of fidelity that needs to be\ndepicted within a VE in order to evoke \xe2\x80\x98as if it were real\xe2\x80\x99 responses.\n6. Speculations on the Role of Avatars in the Future\nThe discussion above was based on a review of scientific work \xe2\x80\x93 experiments that were designed\nthe probe the relationships between people and virtual people, and between remotely located real\npeople communicating via avatars, and a brief review of the relevant neuroscience literature\nabout how this process may work. This section is entirely speculative, looking at implications,\npainting a portrait of future possible proliferation of virtual characters in everyday social life.\nWe are already familiar with entirely virtual characters in film. For example, in the film\nGladiator entire crowd scenes were constructed with computer graphics. In the film Final\nFantasy every individual was a computer generated character with almost believable bodies,\nmovements and facial expressions. In films such as Shrek, the characters have excellent postures,\ngestures, motions and facial expressions, but are mostly humanoid rather than human. In spite of\ntheir non-humanness we still laugh at their antics and even maybe identify and sympathise with\ntheir plight. The fundamental difference in technology between such movie based virtual\ncharacters and those who populate virtual environments is that the movie characters cannot be\n\n85\n\ngenerated in real-time (or anything approaching real-time). The rendering and animation\nrequirements are so complex that typically several computers have to work together to produce a\nframe of animation over several minutes or hours. For a movie every aspect of the rendering and\nanimation has to be as perfect as is possible. Speed is sacrificed to quality. In a virtual reality\nexactly the opposite must occur \xe2\x80\x93 quality is sacrificed for speed, because it is completely\nimpossible to interact with a character which has its display updated once every few seconds or\nminutes instead of 20 or 30 times a second at the minimum.\nHowever, it is only a question of time. As processing power in general, and in particular the\nspeed and capabilities of graphics processors essentially double once a year, it will soon be\npossible to populate virtual realities with highly realistic looking and behaving virtual characters\n\xe2\x80\x93 years rather than decades.\nMoreover projection and display technology is advancing \xe2\x80\x93 albeit at a much slower pace. The\nidea of Mixed Reality is to bring virtual elements into the realm of everyday life. A \xe2\x80\x98Cave\xe2\x80\x99 is a\nhighly specific example of this \xe2\x80\x93 we project onto the walls of a particular built-for-the-purpose\nroom. But the goal is to be able to project anywhere and everywhere, and to blend the virtual into\nthe real in a seamless fashion. \xe2\x80\x98Presence\xe2\x80\x99 still has the same meaning as before \xe2\x80\x93 we respond to\nthe virtual as if it were real. However, now the virtual and real form a new totality \xe2\x80\x93 neither real\nnor virtual but something more than the sum of its separate real and virtual parts.\nImagine you walk by a restaurant deciding whether or not to go in. What is important to you is\nthe atmosphere inside \xe2\x80\x93 does it seem friendly are there people in there, are they enjoying\nthemselves? You look into one place \xe2\x80\x93 and it seems empty \xe2\x80\x93 you walk on. You look into another\nplace, and it is full of people. You step inside \xe2\x80\x93 and soon come to notice that most of the \xe2\x80\x98people\xe2\x80\x99\nin there are in fact virtual characters, programmed to behave as if they were having a great time.\nAmongst the virtual people are a few real people. Now you can distinguish the difference. You\nknow that in a few years time even this difference will not be noticeable.\nActually the situation is more complex. You notice that at one table there are real people and\nother virtual people. They all seem to be sitting around the same table and they are conversing.\nIn fact what is happening is that there are real people in this restaurant and real people in another\nrestaurant which might be in another continent, and they are all maintaining the Mixed Reality\nillusion of sitting down to have dinner together.\nLater you need to take a train to get home. You go up to the ticket office inquiry desk because\nyou want to know the most efficient way to get to your home station. The person behind the\nother side of the glass offering you advice is in fact virtual. The program is sophisticated enough\nto understand your question and respond with appropriate information. You wonder why anyone\nhas gone to all the trouble to present the information to you in this very sophisticated way, rather\nthan just, for example, on a text display. However, interaction between humans can provide a\ncertain level of reassurance, comfort. After giving you the information the virtual inquiry clerk\nsmiles warmly at you, and wishes you well on your journey. Somehow you cannot help\nresponding in kind, smiling back and wishing the clerk a pleasant evening \xe2\x80\x93 even though you\nknow that your reaction is absurd at some level. Absurd but human \xe2\x80\x93 it seems that we are\nprogrammed to behave in such a way when all the outward signs give the impression that\n\n86\n\nsomeone else is there and will respond to you. (The experiments described in the previous\nsection lend support to this supposition).\nAs you look at the crowds filling up the station concourse, you realize that in fact there are very\nfew real people actually there. There are many reassuring looking people together all having a\ngood time, giving an overall pleasant ambience to this station scene. You\xe2\x80\x99re not sure who is real\nand who is virtual \xe2\x80\x93 except that you see a group of children (presumably real) hand in hand with\nfull-sized solid looking characters out of a Disney cartoon.\n7. Conclusions\nThe combination of computer graphics, virtual reality, mixed reality, projection and display\ntechnology, artificial intelligence make it more likely that our future will be one where humans\ninteract in their daily lives with virtual characters, rather than the long-predicted time of the\ncoming of the robots. The robots will come but they will be displayed, not physical entities that\nhurt when they bump into you. As we have seen, being virtual does not reduce the probability\nthat people will react to them with appropriate affective responses.\nFor people of a certain age today this is already true in a specific sense \xe2\x80\x93 people who spend hours\nplaying with computer games already are interacting daily and significantly with virtual\ncharacters. People who engage in on-line societies and on-line multi-participant games already\npartly live in a parallel universe with different normative values, different culture, different\nobjectives.\nIn time to come such virtual characters individuals and crowds will permeate our society, taking\non individual roles as information providers, entertainers, advertisers, advisors, counsellors \xe2\x80\x93 and\nmaybe friends, partners, and perhaps \xe2\x80\x93 the idea of A.I. \xe2\x80\x93 proxy pets and children. At some time\nin the future we will be in a real scene and no longer know without substantial investigation who\nis real and who is virtual.\nDo avatars dream of digital sheep? Today they don\xe2\x80\x99t but we act towards them as if they do.\nTomorrow \xe2\x80\x93 maybe the answer will be that in fact they do.\nAcknowledgments\nThis work is a contribution to the FET PRESENCIA project.\n\n87\n\nReferences\nBradley MM, Sabatinelli D, Lang PJ, Fitzsimmons JR, King W, Desai P (2003) Activation of the\nvisual cortex in motivated attention. Behav Neurosci 117:369-380.\nBullier J, Hupe JM, James AC, Girard P (2001) The role of feedback connections in shaping the\nresponses of visual cortical neurons. Prog Brain Res 134:193-204.\nCruz-Neira C, Sandin DJ, DeFanti TA (1993) Surround-screen projection-based virtual reality:\nthe design and implementation of the CAVE. In: Proceedings of the 20th annual\nconference on Computer graphics and interactive techniques, pp 135-142: ACM Press.\nDe Weerd P, Desimone R, Ungerleider LG (1998) Perceptual filling-in: a parametric study.\nVision Res 38:2721-2734.\nFreeman D, Slater M, Bebbington PE, Garety PA, Kuipers E, Fowler D, Met A, Read CM,\nJordan J, Vinayagamoorthy V (2003) Can virtual reality be used to investigate\npersecutory ideation? J Nerv Ment Dis 191:509-514.\nFrith C, Dolan RJ (1997) Brain mechanisms associated with top-down processes in perception.\nPhilos Trans R Soc Lond B Biol Sci 352:1221-1230.\nGarau M, Slater M, Vinayagamoorthy V, Brogni A, Steed A, Sasse MA (2003) The impact of\navatar realism and eye gaze control on perceived quality of communication in a shared\nimmersive virtual environment. In: CHI '03: Proceedings of the conference on Human\nfactors in computing systems, pp 529--536: ACM Press.\nHaxby JV, Hoffman EA, Gobbini MI (2000) The distributed human neural system for face\nperception. Trends Cogn Sci 4:223-233.\nKojo I, Liinasuo M, Rovamo J (1993) Spatial and Temporal Properties of Illusory Figures.\nVision Research 33:897-901.\nLang PJ, Bradley MM, Fitzsimmons JR, Cuthbert BN, Scott JD, Moulder B, Nangia V (1998)\nEmotional arousal and activation of the visual cortex: an fMRI analysis.\nPsychophysiology 35:199-210.\nLi W, Piech V, Gilbert CD (2004) Perceptual learning and top-down influences in primary visual\ncortex. Nat Neurosci 7:651-657.\nPertaub DP, Slater M, Barker C (2001) An experiment on fear of public speaking in virtual\nreality. Stud Health Technol Inform 81:372-378.\nPertaub DP, Slater M, Barker C (2002) An experiment on public speaking anxiety in response to\nthree different types of virtual audience. Presence-Teleoperators and Virtual\nEnvironments 11:68-78.\nRamachandran VS, Gregory RL (1991) Perceptual filling in of artificially induced scotomas in\nhuman vision. Nature 350:699-702.\nSacks O (1998) The Man Who Mistook His Wife for a Hat: And Other Clinical Tales:\nTouchstone.\nSanchez-Vives MV, Slater M (2005) From Presence to Consciousness Through Virtual Reality.\nNature Reviews Neuroscience 6:8-16.\nSchroeder R, Steed A, Axelsson AS, Heldal I, Abelin A, Widestrom J, Nilsson A, Slater M\n(2001) Collaborating in networked immersive spaces: as good as being there together?\nComputers & Graphics-Uk 25:781-788.\nSlater M, Wilbur S (1997) A framework for immersive virtual environments (FIVE):\nSpeculations on the role of presence in virtual environments. Presence-Teleoperators and\nVirtual Environments 6:603-616.\n\n88\n\nSlater M, Sadagic A, Usoh M, Schroeder R (2000) Small-group behavior in a virtual and real\nenvironment: A comparative study. Presence-Teleoperators and Virtual Environments\n9:37-51.\nSlater M, Pertaub D-P, Barker C, Clark D (2004) An Experimental Study on Fear of Public\nSpeaking in a Virtual Environment. In: IWVR 2004. Lausanne, Switzerland.\nSteed A, Spante M, Heldal I, Axelsson A-S, Schroeder R (2003) Strangers and friends in caves:\nan exploratory study of collaboration in networked IPT systems for extended periods of\ntime. In: Proceedings of the 2003 symposium on Interactive 3D graphics, pp 51-54.\nMonterey, California: ACM Press.\nTurati C, Simion F, Milani I, Umilta C (2002) Newborns' preference for faces: what is crucial?\nDev Psychol 38:875-882.\n\n89\n\n"