b"UNIQUE CONSIDERATIONS FOR HUMAN-ROBOTIC\nINTERACTION IN HUMAN SPACEFLIGHT\nJessica J. Marquez, NASA Ames Research Center\n\n1.1 Robots for Space\nThe success of current and future human space exploration missions depends on effective integration of\nhumans, automation, and robotic technology. Advancements in automation and robotics go hand-in-hand:\nbetter automation leads to more sophisticated and capable robots. NASA\xe2\x80\x99s Human Research Program\n(HRP) identifies inadequate design of human, automation, and robotic integration as one of the risks to\nhuman health and performance. It recognizes that failure to design and deploy effective systems and user\ninterfaces, or to properly allocate automation and robotic resources, will compromise mission objectives\nand safety. The focus of this chapter section is to provide an overview of robots for space operations and\nthe unique challenges posed by including robots in space operations, in order to characterize the\nrelationship between safety and human performance when robots are involved.\nIn spaceflight, a generally accepted definition of a space telerobots is \xe2\x80\x9ca remotely operated robot that\nperforms work in a rich space environment\xe2\x80\x9d (pg. 7, Fong et al 2013). Operators may be in space,\nexperiencing either microgravity or partial-gravity, or on Earth. In general, there are two types of\ninteractions people have with robots: remote interactions, where the robotic system is not co-located, and\nproximate interaction, where the robotic agent is co-located (Goodrich & Schultz, 2007). These two types\nof interactions bring about various issues regarding how robotic systems are used by or with people,\ntermed human-robotic interaction (HRI). Robotic systems in the safety-critical domain of spaceflight are a\ndriving function to carefully design and evaluate HRI.\nFundamentally, robotic systems are necessary in spaceflight because they significantly increase our\ncapabilities to live, work, and explore space. Arguably, these ought to be the only reasons to introduce\n\nrobotic systems into safety-critical domains. The benefits must outweigh the introduction of risk and\nsafety concerns. These risks are robots inadvertently hurting astronauts and robotic operations\nunintentionally preventing mission success. Robotic systems need to do tasks that humans alone cannot\ncomplete, such as moving large space assets or scanning large areas of planetary surfaces. Robotic\nsystems should also be leveraged to improve upon one of the most precious resources in space: people\xe2\x80\x99s\ntime. Space telerobots could be deployed to complete mundane tasks for astronauts, freeing up time for\nthem to do other critical work. While intermingling robots and people has the potential of increasing\nsafety risks, on the other hand, space telerobots can improve overall crew and mission safety. Spacewalks\n(or extravehicular activities, EVAs) outside the ISS are considered one of the riskiest activities for\nastronauts due to the limited time humans can spend in a fragile, pressurized spacesuit, exposed to\nadditional radiation. Robotic systems that complete exterior tasks without EVA astronauts improve\nInternational Space Station (ISS) crew safety as it reduces the overall number of EVA hours. Similarly,\nplanetary missions should leverage space telerobots to minimize Lunar or Mars radiation exposure or\nperhaps, exploring terrain treacherous terrain, protecting astronaut crew health in the long term.\nNASA currently leverages space telerobots to conduct critical space operations and is limited to two\nareas: large, robotic arms and planetary surface rovers. Building upon Shuttle\xe2\x80\x99s heritage, the ISS regularly\nuses the Space Station Remote Manipulator System (SSRMS) to complete EVAs, capturing free-flying\nvehicles and complete maintenance tasks. It was used extensively during ISS construction; as recently as\n2015, the SSRMS was utilized to relocate a module (the large Permanent Multipurpose Module),\nallowing the installation of another docking port. The second robotic arm on ISS is the Special Purpose\nDexterous Manipulator (SPDM), or Dextre, which plays a role in many of the exterior maintenance tasks\nrequired, such as inspection and relocation of Orbital Replacement Units (ORUs).\nThese dexterous robotic arms enable astronauts to safely live and work aboard ISS. Ground teams use\nDextre to complete many tasks while crew completes other interior activities. They enable critical tasks\nthat could not have been accomplished otherwise. For instance, in late 2007, Astronaut Scott Parazynski\n\nrepaired an ISS solar array, which could only be reached while propped by the Shuttle\xe2\x80\x99s RMS (Cupples &\nSmith, 2011). SSRMS is essential for capturing visiting vehicles, including Space-X\xe2\x80\x99s Dragon and\nOrbital\xe2\x80\x99s Cygnus, and berthing them into one of the ISS docking ports. These spacecraft regularly\nresupply ISS with spare parts, science payloads, as well as food and medicine for astronauts.\n\nFigure 1: Astronaut Scott Parazynski (STS-120) attached at the end of Remote Manipulator System.\nCredit: NASA, ISS016E009207.\nBeyond low Earth orbit, NASA has deployed several rovers and landers on the Mars surface since 1976.\nCurrently, there are two operational Mars rovers: Mars Exploration Rover, Opportunity, and Mars\nScience Laboratory, Curiosity. Each are equipped with a variety of scientific instruments and their own\nmanipulator arm. The rovers traverse Mars, collecting data and analyzing samples for teams of scientists\nback on Earth. These rovers, far exceeding their planned lifetime, have increased our exploration\n\ncapabilities, gathering scientific evidence to answer the question if Mars is or was habitable. Robotic\nmissions, at first glance, may not appear to have an impact on space safety and human performance, but\nthere are safety considerations for the human operators back on Earth. For example, the Curiosity mission\npurposefully determined to only operate on Mars time for the first 90 days. Unfortunately, Mars and Earth\ndo not share the 24-hour day cycle. This meant that all the operators and scientists had to shift their work\nand sleep schedule 40 minutes every day. Such changes in circadian rhythm and sleep cycle have shown\nto have detrimental fatigue effects on people back on Earth, as experienced during Opportunity mission\n(Barger et al., 2012).\nWhile there is no imminent safety risk on the operators, there are mission safety considerations.\nMaintaining mission safety is still important and must be balanced against exploration objectives. For the\nrover missions, engineers and operators want to mitigate any risk that might damage the valuable\nspacecraft asset. For that reason, the mission control team carefully plans out every command sent to the\nspace telerobot, operating the rover well within its capabilities. Even under such risk-adverse operating\nconstraints, unexpected circumstances still challenge mission operators to act safely. Notably, the\nOpportunity rover got stuck in a sand dune 446 sols into its surface mission (Helmick, Angelova, and\nMatthies, 2009). After a month, the engineers were able to maneuver it out. Such illustrative cases inform\nNASA of the indispensable value of good human-robotic interaction for crew and mission safety.\n\n2.1 Space Human-Robotic Interaction Design Challenges\nNASA\xe2\x80\x99s Human Research Program (HRP) succinctly summarizes the interaction challenges (NASA,\n2017): Given that automation and robotics must seamlessly integrate with crew, and given the greater\ndependence on automation and robotics in the context of long-duration spaceflight operations, there is a\nrisk that systems will be inadequately designed, resulting in flight and ground crew errors and\ninefficiencies, failed mission and program objectives, and an increase in crew injuries. Furthermore, it\n\nidentifies four gaps or research areas for the Risk of Inadequate Design of Human and\nAutomation/Robotic Integration (HARI):\n\n\xe2\x80\xa2\n\nWe need to identify and scope the critical human-automation/robotic mission activities and tasks\nthat are required for future long duration, long distance space missions.\n\n\xe2\x80\xa2\n\nWe need to evaluate, develop, and validate methods and guidelines for identifying humanautomation/robot task information needs, function allocation, and team composition for future\nlong duration, long distance space missions.\n\n\xe2\x80\xa2\n\nWe need to develop design guidelines for effective human-automation-robotic systems in\noperational environments that may include distributed, non-colocated adaptive mixed-agent teams\nwith variable transmission latencies.\n\n\xe2\x80\xa2\n\nWe do not know how to quantify overall human-automation-robotic system performance to\ninform and evaluate system designs to ensure safe and efficient space mission operations.\n\nIn many ways, the fact that NASA can relate automation and robotic integration concerns together speaks\nto the tight relationship between these technologies. We should be able to infer, or at the very least,\nanticipate potential pitfalls in HRI from what we know about HAI. For instance, it is likely that higher\ndegree of automation in robotic systems should result in decrements in situation awareness, though it was\nonly concluded from a meta-analysis by Onnasch, Wickens, Li, and Manzey (2014) for automated\nsystems. Challenges with operators maintaining mode awareness or overreliance in automation have been\nrecognized in the past (Parasuraman & Riley, 1997). Arguably, we may have already evidenced this in\nspace operations when Opportunity accidently drove into non-navigable terrain. Operators may have\nassumed incorrectly the capabilities of the robotic systems or may have over-relied on the existing\ncapabilities of the rover.\n\nFundamentally, HRI challenges deal with the interaction between humans and robots. Goodrich &\nSchultz (2007) outline five attributes that affect HRI (pg. 216):\n\n\xe2\x80\xa2\n\nLevel and behavior of autonomy,\n\n\xe2\x80\xa2\n\nNature of information exchange,\n\n\xe2\x80\xa2\n\nStructure of the team,\n\n\xe2\x80\xa2\n\nAdaptation, learning, and training of people and robot,\n\n\xe2\x80\xa2\n\nShape of the task.\n\nHRI design solutions for spaceflight are further constrained by the inherent nature of spaceflight. First,\nthe space environment notably affects both robots and humans. Space-bound hardware systems need to be\nrobust to survive environmental factors such as radiation, temperature extremes, illumination variations,\nand micrometeoroids (Fong et al., 2013). As a result, they usually are not as capable as their modern,\nEarth counterparts. Analogously, astronauts must live and work in microgravity (and partial gravity for\nexploration-class mission), exposed to high cumulative dosages of space radiation. Extended exposure to\nthis extreme environment affects people\xe2\x80\x99s physiology, and in turn, their performance duration space\noperations (for overview, see Jones, 2010; for more details, see Churchill, 1997). Furthermore, astronauts\nmust perform in less-than-ideal habitats and workspaces, exposed to long-duration isolation, spaceefficient work-areas, and minimalist sleeping quarters. In turn, crews are at risk of experiencing chronic\nergonomics-related disorders, prolonged sleep loss and corresponding fatigue, and other behavioral health\nissues (Jones, 2010).\nSecond, the distance, spatially and temporally, between space telerobots and their operators further limits\nHRI designs. Long-distance space exploration has equivalent transmission latencies, and current deep\nspace communication infrastructure prevents continuous, large bandwidth transmissions. Even if the\nbandwidth is mitigated with future improvements to NASA\xe2\x80\x99s Deep Space Network, intermittent\nasynchronous communications result in unique space HRI designs. For Earth-Mars communication, one-\n\nway transmission latencies range from four to twenty-four minutes, and about every two years, Mars solar\nconjunction prevents transmissions between the two planets.\nConsidering future exploration-class missions, NASA\xe2\x80\x99s Design Reference Missions, like NASA (2009)\ndescribe a particular team structure. Crew teams will be small, likely four astronauts, with various diverse\nbackgrounds and expertise. On their way to Mars, there will not be opportunities to \xe2\x80\x9cbring in\xe2\x80\x9d a robotics\nexpert or rotate in any specialty operator during the three-year long mission. This small team will bear the\nresponsibility of learning and using all robotic systems required of the mission. The robotic systems\navailable to them will also be assorted. Future capabilities for space telerobots range from partnering with\nastronauts to explore to maintaining habitats while in quiescence (Weisbin, Lavery, & Rodriguez, 1997;\nMarquez et al. 2016). Some robots will be co-located, others may be operated from long distances at first,\nand then while in line-of-sight. Along with the previously mentioned constraints, the diversity in robotic\nsystems accompanied by a small crew team necessitates space HRI to include interfaces for the support\nheterogeneity, multiple control modes, and varying degrees of autonomy (Fong et al., 2013).\n\n2.1.1\tIllustrative\tSpace\tHRI\tExample:\tShape\tof\tTask\t\nIn the last few years, robotics operations have become a critical component to berthing visiting vehicles.\nCrew and ground teams work together through the SSRMS to grapple and berth visiting vehicles (Figure\n2). Additionally, the visiting vehicle is undocked and moved with the SSRMS to a safe distance and\ntrajectory from ISS for its return back to Earth. Berthing visiting vehicles is an adapted procedure from\npreviously existing robotics tasks. For visiting vehicle operations, a robotics workstation is arranged by\nthe crew within the Cupola to conduct the task and the task is coordinated between ground teams and\nonboard crewmembers. This new operation, which changed the shape of the previously vetted robotic\ntasks, require careful HRI evaluation, applying lessons learned regarding systems, procedures and\noperations collected over the life of ISS.\n\nFigure 2: Astronaut Karen Nyberg (Expedition 36) at the robotics workstation in the ISS Cupola\npreparing for grappling and berthing of the Japanese H2 Transfer Vehicle-4 (HTV-4). Credit:\nNASA.\nThe SSRMS manipulation for EVA-related robotics and visiting vehicle operations share many\nsimilarities with respect to tasks, but diverge in two key manners. First, visiting vehicle operations\nrequires the SSRMS to capture another spacecraft moving in space. Second, despite using functionally the\nsame robotic workstation, visiting vehicle operations requires the astronaut to integrate more (or different)\ninformation. There are two robotic workstations aboard the ISS, one in the Cupola, surrounded by\nwindows, and the other is in the U.S. Lab module. The Cupola affords crew a direct view of the\nspacecraft and the SSRMS; this visual input thus must be integrated as part of the task. Crew commented\nthat, initially, limited guidance was provided on how best to set up the robotic workstation in the Cupola.\nAdditionally, there are many crew comments regarding the out-the-window lighting conditions (i.e., too\n\nbright or too dark) and their potential effect on performance (e.g., ability to assess out-of-window views\nlike relative size or changing rates of motion). It is important to note that ground teams immediately\naddressed these crew comments to better support visiting vehicle robotic operations aboard ISS (Marquez\net al., TBD). The adaptation of space robotics operations, using a single robotic system with a rich\noperational history, for a comparable yet slightly different task illustrates how challenging space HRI is\nand will be for future exploration-class missions.\n\n3.1\n\nDeveloping Operationally-Valid Space HRI\n\nThrough various space analogous test environments, NASA has begun to investigate the complexity of\nthe design space encompassed by space-bound HRI: different types of robotic systems, control modes\n(manual through supervisory control), and operational concepts (co-located/proximal teaming, 1:many vs.\nmany:1, robot before/after human, etc.). For example, there are several studies that have been performed\naboard ISS. Robonaut 2 (R2), a highly dexterous humanoid robot, is currently aboard the ISS (Diftler et\nal., 2011) and is being evaluated as a means to reduce crew time by completing routine and redundant\ntasks. Bualat and her team tested remote surface telerobotics from the ISS (Bualat et al., 2013), while the\nEuropean Space Agency has several ISS experiments evaluating methods of human-robotic interaction,\nincluding haptic feedback (Schiele et al., 2016). On Earth, space robotic evaluations are difficult because\nit is hard 1) to have high fidelity simulations of all aspects of the space environment, 2) to acquire\nmatching astronaut or ground controller populations, and 3) to mimic one-of-a-kind space telerobots\n(Fong et al., 2013). Nonetheless, in an effort to understand how to design human-robotic interaction for\nsafe and efficient use, studies have examined rovers as scouts and as systems to follow-up after human\nexploration (e.g., Bualat et al., 2011; Deans et al., 2012).\nWhile exercising future space telerobots in extreme environments is essential for operationally validating\nsafe and efficient human-robotic systems, there is still fundamental research that can be studied in\nlaboratory settings. The HARI gaps (previously mentioned) recommend areas of investigation. For\n\ninstance, developing user interface designs that quickly help operators recover situation awareness when a\nsystem enters an off-nominal state will be important for both highly autonomous and robotic systems.\nSeamless integration of various control modes will be indispensible in future space telerobotics, yet we\nhave not developed design standards to accommodate these types of interactions, or to assess their\nimpacts on situation awareness, workload, and task performance. There is much to learn and understand\nwith regards to the effects of trust in safety of these robotic systems, particularly with robots that will be\nin close proximity with astronauts. Inadequate training may also play a role in trust, leading to automation\nbiases, over or under-reliance on automation, increased operator workload, safety hazards, and failure of\nmission objectives. For example, Olsen al. (2011) acknowledges the importance of training to reduce\nbiases and educate the operator on how the robot functions. Lastly, while we an infer a relationship\nbetween robotic tasks and fatigue, there is limited evidence that directly maps the relationship between\nsleep deprivation and the performance of human-automation/robotic systems.\n\n3.1.1\tConcluding\tRemarks\t\nFuture exploration-class missions will require heterogeneous robots to enable mission objectives without\nsacrificing safety. Good design is foundational to reducing integration risks, both of safety and of failure\nto complete missions due to inefficiency or ineffectiveness. Continued work and research in humanautomation and human-robotic interaction will improve and inform NASA Standards 3001 in order to set\nstandards for human-automation-robotic safety.\n\n4.1 References\nBarger, L.K., Sullivan, J.P., Vincent, A.S., Fiedler, E.R., McKenna, L.M., Flynn-Evans, E.E., Gilliland,\nK., Sipes, W.E., Smith, P.H., Brainard, G.C. and Lockley, S.W., 2012. Learning to live on a Mars day:\nfatigue countermeasures during the Phoenix Mars Lander mission. Sleep, 35(10), pp.1423-1435.\n\nBualat, M., Abercromby, A., Allan, M., Bouyssounouse, X., Deans, M., Fong, T., . . . Utz, H. 2011.\nRobotic recon for human exploration: Method, assessment, and lessons learned. In W. Garry, & J.\nBleacher (Eds.), Analogs for planetary exploration (Special Paper 483, pp. 117\xe2\x80\x93135). Boulder, CO:\nGeologic Society of America.\nBualat, M., Fong, T., Allan, M., Bouyssounouse, X., Cohen, T., Fluckiger, L., . . . Wheeler, D. 2013.\nSurface telerobotics: Development and testing of a crew controlled planetary rover system. In AIAA Space\n2013 Conference and Exposition (AIAA 2013-5475) Reston, VA: American Institute of Aeronautics and\nAstronautics.\nChurchill, S.E. ed., 1997. Fundamentals of space life sciences (Vol. 1 & 2). Krieger Publishing Company.\nCupples, S. & Smith, S. 2011. EVA - Don't Leave Earth Without It. AIAA SPACE 2011 Conference &\nExposition, AIAA SPACE Forum, http://dx.doi.org/10.2514/6.2011-7276\nDeans, M., Fong, T., Bualat, M., Heggy, E., Helper, M., Hodges, K., . . . Zacny, K. 2012. Using robots\nbefore and after humans to improve space exploration. In IAF/AIAA Global Space Exploration\nConference (GLEX-2012.04.1.512344). Reston, VA: American Institute of Aeronautics and Astronautics.\nDiftler, M., Mehling, J., Abdallah, M., Radford, N., Bridgwater, L., Sanders, A., . . . Ambrose, R. 2011.\nRobonaut 2: The first humanoid in space. In Proceedings of the IEEE International Conference on\nRobotics and Automation, pp. 2178\xe2\x80\x932183. New York, NY: IEEE.\nFong, T., Rochlis Zumbado, J., Currie, N., Mishkin, A., & Akin, D. L. 2013. Space Telerobotics: Unique\nChallenges to Human\xe2\x80\x93Robot Collaboration in Space. Reviews of Human Factors and Ergonomics, 9(1),\npp. 6\xe2\x80\x9356. http://doi.org/10.1177/1557234X13510679\nGoodrich, M.A. & Schultz, A.C., 2007. Human\xe2\x80\x93Robot Interaction: A Survey. Foundations and Trends in\nHuman\xe2\x80\x93Computer Interaction (Vol. 1, No. 3), pp. 203-275.\n\nHelmick, D., Angelova, A. and Matthies, L., 2009. Terrain adaptive navigation for planetary rovers.\nJournal of Field Robotics, 26(4), pp.391-410.\nJones, P.M. (2010) \xe2\x80\x9cHuman Performance in Space.\xe2\x80\x9d Reviews of Human Factors and Ergonomics (Vol. 6,\nIssue 1), pp. 172 \xe2\x80\x93 197.\nMarquez, J.J., Adelstein, B.D., Ellis, S., Chang, M.L. and Howard, R., 2016, March. Evaluation of human\nand automation/robotics integration needs for future human exploration missions. In Aerospace\nConference, 2016 IEEE (pp. 1-9). IEEE.\nMarquez, J.J., Adelstein, B.D., Billman, D., Chang, ML., Cross, E.V., Ellis, S.R. and Sandor, A. TBD.\nEvidence Report: Risk of Inadequate Design of Human and Automation/Robotics Integration. NASA JSC,\nHouston, TX.\nNASA 2009. Human Exploration of Mars Design Reference Architecture 5.0. NASA/SP-2009-566,\nNASA Headquarters, Washington, DC.\nNASA 2017. Risk of Inadequate Design of Human and Automation/Robotics Integration, Human\nResearch Roadmap, accessed 1 February 2017. <https://humanresearchroadmap.nasa.gov>\nOleson, K. E., Billings, D. R., Kocsis, V., Chen, J. Y. C., & Hancock, P. A. 2011. Antecedents of trust in\nhuman-robot collaborations. Presented at the Proceedings of the IEEE International Multi-Disciplinary\nConference on Cognitive Methods in Situation Awareness and Decision Support.\nOnnasch, L., Wickens, C.D., Li, H. and Manzey, D., 2014. Human performance consequences of stages\nand levels of automation: An integrated meta-analysis. Human Factors, 56(3), pp.476-488.\nParasuraman, R. and Riley, V., 1997. Humans and automation: Use, misuse, disuse, abuse. Human\nFactors: The Journal of the Human Factors and Ergonomics Society, 39(2), pp.230-253.\n\nSchiele A, Aiple M, Krueger T, Van Den Hulst F, Kimmer S, Smisek J, den Exter E. 2016. Haptics-1:\nPreliminary results from the first stiffness JND identification experiment in space. Haptics: Perception,\nDevices, Control, and Applications, pp. 13 \xe2\x80\x93 22.\nWeisbin, C., Lavery, D. & Rodriguez, G. 1997. Robots in space: US mission requirement in technology\ninto the next century. Auton. Robots, (Vol. 4) pp. 159\xe2\x80\x93173.\n\n"