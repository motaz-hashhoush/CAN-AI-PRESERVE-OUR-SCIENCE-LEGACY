b'Ecology Based Decentralized Agent\nManagement System\nMaxim D. Peysakhov, Vincent A. Cicirello and William C. Regli\nDepartment of Computer Science, Drexel University,\nPhiladelphia PA 19104\n\nA b s t r a c t . The problem of maintaining a desired number of mobile\nagents on a network is not trivial, especially if we want a completely\ndecentralized solution. Decentralized control makes a system more r e\nbust and less susceptible to partial failures. The problem is exacerbated\non wireless ad hoc networks where host mobility can result in significant\nchanges in the network size and topology. In this paper we propose an\necology-inspired approach to the management of the number of agents.\nThe approach associates agents with living organisms and tasks with\nfood. Agents procreate or die based on the abundance of uncompleted\ntasks (food). We performed a series of experiments investigating p r o p\nerties of such systems and analyzed their stability under various conditions. We concluded that the ecology based metaphor can be successfully\napplied to the management of agent populations on wireless ad hoc networks.\n\n1 Introduction\nIn a typical agent based system, a number of mobile agents cooperate to achieve\na desired goal. The efficiency of the agent system in reaching the goal, and the\ncompleteness of the result depends on the number of agents in the system. Too\nfew agents will not achieve the full potential of parallelism and will lead to\ndecreased system efficiency. Too many agents can overburden the system with\nunnecessary overhead, and may also result in significant delays. The task of\nfinding the optimal number of agents required to achieve the desired effect is\ndifficult and problem-specific. In this paper, we propose an ecosystem-inspired\napproach to this problem. Similar to a real ecosystem, our solution exhibits\nproperties of emergent stability, decentralized control, and resilience to possible\ndisturbances. In our work, we propose to solve the technical problem of agent\nmanagement using an ecological metaphor.\nIn Section 2 we describe the current state of research in the fields of simulated ecosystems and multi-agent control and stability. Section 3 introduces\nthe problem of managing the number of agents populating a physical network\nand also explains a proposed solution. Lastly, Section 4 demonstrates the initial\nexperimental results and conclusions.\n\n2\n2.1\n\nRelated Work\nSimulated Ecology\n\nThe majority of ecologyinspired systems are used to answer some question about\nreal world ecosystems and its properties. For example, the RAM system has been\nused to study mosquito control [23]. There are two major approaches to simulating an ecosystem [SI. One is a speciebased view of the system, where large\nclasses of individuals interact in the simulation (Le., modeling the dynamics of\ninteraction of species rather than the interaction of individuals). Evolutionary\ngame theory (e.g., [l][18] [17]) and dynamical systems (e.g., [9] [l5] [14]) are two\napproaches that often take the speciebased view. The second approach is to\nsimulate individuals and their interactions, a bottom up approach to construction of the ecological simulator.\nWe are most interested in individual-based simulations, since they are\nusually built with software agents. An example of an individual-based approach to ecosystems is a simulated habitat populated with synthetic organisms (agents) [19]. Often such systems are used to study the evolution (and\ncc-evolution) of different species and testing their interactions and emergent behavior. Genetic Algorithms [ I and Genetic Programming [lo] engines can be\nS\nused in conjunction with synthetic ecosystems to allow species to evolve over\ntime. Some of the most well known examples of synthetic ecosystems of this\ntype are Evolve 1, 2 and 3 [4] [5][all, \xe2\x80\x9dArtorg world\xe2\x80\x9d [3] and LAGER [19].\nWith this approach, global trends in the behavior of the system may emerge\na a result of the low-level interactions of individual agents. The emergent behavs\nior observed in an ecosystem may not be obvious given the individual behaviors\nof agents.\n2.2\n\nAgent S y s t e m Stability\n\nService replication An increasing number of researchers are investigating the\nproblems of reliability, robustness, and stability of multi-agent systems (MAS).\nMost approaches toward improving system robustness revolve around the replication of agents and/or services on the MAS network. This direction has been\ntaken by [7], 1121, [16] and several others. Existing approaches focus on the\nmethodology of agent/senrice replication.\nf\nProbabilistic models Another approach is the application o probabilistic\nmodels to the prediction of agent system stability and robustness. This research\nassumes some uncertainty in agent behavior or the agent\xe2\x80\x99s environment, and proposes mechanisms for estimating, evaluating and hopefully improving stability of\nzgect s y s t e m Cbe of the fird rwenrrhem to anal-me probabilistic survivability\nIn\nin an MAS is Kraus in [ll]- that paper Kraus proposed a probabilistic model\nof MAS survivability based on two assumptions: (1) global state of the network\nis known at all times; and (2) the probabilities of host or connection failure are\nknown. An alternative approach was proposed in [20,2], where agents reason\nabout the state of the network and security (insecurity) of their actions.\n\n3\n3.1\n\nProblem Formulation\nMotivation\n\nIn a typical dynamic ad hoc network there is limited, variable bandwidth between\nhosts, and the memory and CPU on each host is constrained. Given this dynamic\nand resource constrained environment, it is impractical to prescribe any precomputed solution.\nThe solution we propose for such networks is to create a system that can\ncontrol the number of agents dynamically, adapting to the ever-changing environment. In order to work in the context of an agent based system, a control\nsystem should be distributed and decentralized. By distributed, we mean that the\nsystem should be able to use the underlying network to parallelize problem solving on multiple hosts. By decentralized, we mean that the system should avoid\nreliance on a single node, and should allow each agent to act independently.\nThe emergent behavior resulting from the individual localized control decisions\nideally will yield an optimal, or near-optimal, solution at the global level.\n3.2\n\nApproach\n\nLarge ecosystems usually have several attractive qualities (such as dynamic decentralized control, self regulation, no single point of failure, robustness, and\nstability) that we require for our system. We propose a solution to the problem of determining the number of agents appropriate for a task at hand that is\ninspired by large ecosystems:\n1.\n2.\n3.\n4.\n5.\n\nEach task in our system is associated with food.\nAgents which successfully complete a task collect the associated food points.\nAgents consume food points over time to sustain their existence.\nAgents that exhaust their supply of food die.\nAn abundance of food can cause a new agent to spawn.\n\nBy this analogy, tasks can be thought of as plant life growing at some rate.\nAgents are associated with herbivore animals that perform tasks, therefore eating\nall the food provided by successfully completing a task. Upon completion of a\ntask, an agent is forced to migrate to look for more food (tasks to complete).\nAs time passes, agents consume food according to a predefined consumption\nfunction, analogous to a metabolic rate of an animal. Agents unable to find\nenough food (tasks) to sustain their existence over time will exhaust their food\nresources and will be terminated. Large amounts of food collected by a single\nagent or accumulated in a single location can force a new agent to spawn at\nthis location. Agents procreate by division similar to a cell mitosis. However,\nthis approach makes it impossible for the system to recover from a state with\nno agents. Therefore, we also allow tasks the ability to spawn a servicing agent\nwhenever a certain threshold of accumulated food supply is reached. This control\nmetaphor allows the system to dynamically adjust to the environment, while\navoiding centralized control.\n\n4\n\n3.3\n\nFormal Model\n\nThe set H denotes the set of producers h where h E H , with the production rate\nd&ed by a function F h ( t ) each individual producer h. The set A defines the\nfor\nset of consumers a (a E A), and each consumer has a predeked consumption\nfunction f a ( t ) . The dynamic system of H producers and A consumers is considered to be in an equilibrium state over some period of time from tl to t 2 , if and\nonly if the amount of food produced during that period of time is equal to the\namount of food consumed during that same period of time. This relationship\ncan be expressed as:\n\nFh(t) d t =\nhEH\n\nIt2\n\nf a ( t dt\n)\n\naEA\n\n*l\n\nAt the simplest level, these principles can be modeled by a dynamic system of\nhomogeneous producers and homogeneous consumers with constant production\nand consumption rates, c and d respectively. The equations below define the\nequilibrium state for this simple example:\n\nIHI x c x (tz - ti) = IAl x d x ( t z - t i )\n\n1 = PI,\n4\n\nC\n\nThis is essentially a speciesbased analysis of our individual-based ecological\ncontrol system.\n\n4\n4.1\n\nExperimental Results\nSystem Setup\n\nIn order t o confirm our conclusions we implemented a series of experiments\nusing a discrete event simulation. The control flow of an ecology based agent\nis shown in Figure l(a). According to this control flow diagram, an agent first\ndecreases it\xe2\x80\x99s internal food bank by f a ( t ) for each second that elapsed since the\nlast decrement. Then, the agent completes the task and collects all food points\nzss~\\datPCJ\nari_th that task. Based on its current food rsouTcces, the agent may\ndecide to die or to reproduce. Lastly, the agent migrates to another random host\nlooking for food. We experimented with different ways for an agent to decide\nwhen t o reproduce. We chose a fuzzy threshold method. Given the threshold\nvalue T , the probability of an agent reproducing is 0 if the amount of food is\nless then T - i. The probability of an agent reproducing is 1 if the food ievel\n\n(For all the time\nsince last\n\n*\n\n(Complete the tas\n\n4\n\nCollect the food\n\n1\n\nI\n\n1\n\n0.8\n\n- 0.6\nE\nn 0.4\n\nn\n.\n0.2\nMigrate to\n\n0\n0\n\nFood\n\n(4\n\nI\n\n200 400 600 800 1000120014001600\n\nI\n\n(b)\n\nFig. 1. Agents life cycle (a) and probability of reproduction based on the food level\n\n0)).\n\n+ a.\n\nexceeds r\nAnd the probability of reproducing grows linearly between these\ntwo points. A plot of the probability of reproducing is shown in Figure l(b). The\nthreshold needs to be fuzzy to avoid undesirable oscillations in the system.\nIf a small number of agents is desired on the network, it is possible for the\nsystem to go into an extinction mode - state with no agents on the network. In\norder to recover from this situation, we enable hosts to spawn new agents. The\nsame fuzzy threshold rules apply to hosts a to agents. All of the experiments\ns\nwere performed on the completely connected network of statically placed hosts.\nAll hosts grow food at the rate 1 unit per iteration. All experiments start with\na single agent with initial food bank of 500 units. The reproduction threshold\nr was set to 800 resulting in 800 f 400 range for hosts and agents. Additional\nexperiments were performed using the real agent system EMAA [13] over a wired\nlocal area network.\n4.2\n\nSystem Behavior Over Time\n\nIn this section, we investigate the changes in the number of agents over time.\nThe consumption rate is set to 5 food units per iteration for all agents. Each\nexperiment consists of 15 trials. A single trial consists of initializing the system\nand running it for 90,000 iterations. The number of agents is recorded every 10\niterations. Data is averaged across all trials to obtain the plots.\n\nAgents\n\nHosts\n\n35\n\n7\n\n-23\n\n4.6\n\n15\n\n3\n\na\n\n1.6\n\nFig. 2. System behavior over time.\n\nI\n\nI\n\nFig. 3 Distribution of the number of agents for the network sizes of 8 (a), 15 (b), 23\n.\n( c ) and 35 (d) hosts.\n\nConstant Number of Hosts. Experiments were repeated for graphs of 35,23,\n15 and 8 hosts on the Figure 2 (top to bottom). Horizontal bold lines represent\nthe targeted number of agents 7.0, 4.6, 3.0 and 1.6 respectively and the actual\nnumber of agents on the system is plotted by the thinner lines. I t is easy to see\nthat in all of the experiments, the actual number of agents oscillates close to the\ntarget value, however oscillations are somewhat higher for the network of 8 hosts.\nFigure 3 demonstrates the actual distribution of the numbem of agents during the\nexperiments for 8 (a), 15 (b), 23 (c) and 35 (d) hosts with a normal distribution\ncurve fitted to the data. Distribution is close to normal for a l experiments but\nl\nthe one with 8 hosts. Such system behavior can be explained by the fact that the\nsystem with the small number of agents is prone to extinction of the population.\nWhenever the system recovers, it usually overshoots the targeted number of\nagents and osclllates \xe2\x82\xacor a whiie. These osciiiations are repeated every time the\n\n7\n\nI l7\nFig. 4. System behavior over time (a) and Standard deviation (b)\n\nsystem goes into extinction mode. More detailed analysis of this phenomenon is\ngiven in Section 4.3.\nChanging N u m b e r of Hosts. During this test we observed the system\xe2\x80\x99s abil;\nity to react to rapid unplanned changes in the number of hosts. Experiment was\nsetup identically to the one described in Section 4.2 except that the number of\nhosts was changed every 30,000 iterations without reinitializing the system. The\nnumber of hosts was changed from 23 to 15 to 8 and back to 35 hosts. We feel\nthat such drastic changes in the number of hosts approximate the process of\nislanding and merging in wireless mobile networks of lightweight devices carried\non foot by police or military units. Whenever the hosts were shut down all of the\nagents on these hosts and agents traveling to these hosts were also shut down.\nWhenever brought back on line, hosts initiaIly had no food or agents on them.\nThat type of change introduces a high level of disturbance into the system. The\nnumber of agents over time is plotted in Figure 4(a). The bold red line represents the target number of agents at any given moment. The black thinner line\nshows the actual number of agents. One can see that the actual number of agents\nfollows closely the target number in all segments of the plot except for the one\nthat corresponds to 8 hosts.\nThe standard deviation of the number of agents is plotted in Figure 4(b).\nStandard deviation peaks when we change the number of hosts on the network\ndue to the highly disruptive nature for the agent community of shutting down\n(or starting up) several hosts. Also standard deviation is higher at the segment\ncorresponding to 8 hosts. We believe that such high standard deviation is caused\nby temporary extinction of agents and the oscillations that occur during recovery\nfrom it.\n4.3\n\nDependency Between t h e N u m b e r of Agents and t h e N u m b e r\nof Hosts\n\nIn this Section, a single trial consisted of 100,000 iterations of the simulator.\nThe number of agents is recorded every iteration and averaged across the trial\n\nFig. 5. Dependency between number of agents and number of hosts ( ) between numa,\nber of hosts and standard deviation (b), number of agents and standard deviation\n\n(4to obtain a singie data point. l t i a l s were repeated for networks of sizes 3 to 35\nhosts (odd numbers of hosts only). Experiments are plotted in Figure 5(a) with\nconsumption rates set to be 3 times, 5 times and 7 times the production rate from\ntop to bottom. Although all 3 graphs appear to be linear, they are composed\nof 16 independently obtained data points. The experiment confirms that the\nsystem does what it is designed to do, namely maintain the given average ratio\nof hosts to agents, despite dynamic changes in the number of hosts. Figures 5(b)\nand 5(c) show the standard deviation of the number of agents in terms of the\nnumber of hosts and the number of agents respectively for all 3 experiments.\nStyles and colors of the plots correspond to the ones in figure 5(a). Although\neach is unique, the overall shape of the plots is similar. After the initial hump\nassociated with the extinction mode and recovery horn it, the plots level off in\nthe area of 3 - 4 agents and then increase slightly. The linear increase can be\nexplained by the linear increase in the number of agents. The only disturbance\nto that scheme is the point with target d u e of exactly 1 agent. For such systems\nit is possible to sustain a single agent for the duration of the whole experiment\nwithout ever going into the extinction mode resulting in no variance in the data.\n4.4\n\nDependency Between the Number of Agents and the Link\nQuality\n\nThis set of experiments was set up exactly as the one described in Section 4.3\nexcept that the changing parameter w s link quality. A l n o 100% quality\na\nik f\n&pi;ihai ui, &iScid &&y is &.trc&c& md z i g z t t i n ~\nnnly takes one iteration. Link of 0% quality means that maximum possible delay is introduced\nand migration takes 16 iterations (in simulator time). Figure 6(a) shows the\ntarget number of agents, actual number of agents and standard deviation of the\nmmber ~f zgents changing based on the link quality. Although the actual number of agents slightly increases with decrease in l n quality, it remains within\nik\n\nR\n\nFig. 6. Dependency between number of agents and standard deviation from liq speed\n(a), and distributions for 10% (b) and 90 % (c) link speed.\n\n10% of the target value. Standard deviation however increases significantly as\nthe speed,of communication decreases. Some improvement of standard deviation\nat extremely low speeds can be explained by consistently poor performance of\nthe system. Figure 6 (b) and (c) show the actual distribution of the number of\nagents for 10% and 90% respectively. The distribution for the higher link speeds\nis more compact and closer to normal. Such behavior of the system can be explained by the fact that at the lower values, agents cannot move from one host\nto another fast enough to collect enough food to sustain their existence. This\ncauses extinction of agents and forces the system to re-stabilize after it recovers\nfrom the state with no agents.\n\n5\n5.1\n\nFuture Work and Conclusions\nFuture Work\n\nIn the future we are planning several extensions to this work.\n1. We are planning more extensive set of live experiments utilizing the Secure\nWireless Agent Testbed (SWAT) [22].\n2. We would also like to create a more detailed mathematical model of such\nsystems to be able to predict and control the emergent behavior of an agent\nsystem. This model should be used for parameter fine tuning, something that\nwas done manually during current experiments.\n3. We are also planning to introduce an on-line system for tuning such parameters as consumption and production rates, thresholds and fuzzy intervals,\netc. Some of the techniques we are planning to try include machine learning,\nswarm based techniques and genetic algorithms.\n4. It would be interesting to expand the model from plant - herbivore system\nto plant - herbivore - carnivore. That extension wilI allow us to create\nmore complicated food chains resulting in more elaborate control over the\npopulations of different types of agents.\n\nI"\n\nAll of these techniques promise to improve on the current research and provide\na more stable decentralized ways to control the number of agents on a wireless\nad hoc network.\n52\n.\n\nConclusions\n\nThis paper developed an ecology-basedmodel for managing the number of agents\non ad hoc wireless networks. We have discovered that an ecosystem based model\ncan provide decentralized distributed robust control of agents in dynamic and\nu\nuncertain network environments. O r approach involves a novel exploitation of\nproperties of ad hoc networks, enabling mobile agents to automatically adapt\nto changes that affect their communication and migration. The capability to\ndynamically adjust to the state of their network provides new possibilities for\nstable MAS.\n\nReferences\n1. J. M. Alexander.\n\nEvolutionary game theory.\nIn E. N. U t a , editor,\nThe Stanford Encyclopedia of Phdosophy. Stanford University, Summer 2003.\n\nhttp://plato.stanford.edu/archives/s~2OO3/entries/gam~evolution~/.\n2. Donovan Artz, Max Peysakhov, and William C. Regli. Network meta-reasoning for\ninformation assurance in mobile agent systems. In Eighteenth International Joint\nConference on Artificial Intelligence, pages 1455-57, Aug 2003.\n3. A. Assad and N. Padrard. Emergent colonization in an artificial ecology. In\n\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n11.\n\n12.\n\nF. Varela and P. Bourgine, editors, Toward A Practice of Autonomous Systems:\nP o e d n s of the First Europenn Conference on Arti$cid Life-; pages 143-152.\nrceig\nMIT Pr&, 1992.\nM. Conrad and H.H. Pattee. Evolution experiments with an artificial ecosystem.\nJ. Theoret. Biol., 28:393-409, 1970.\nM. Conrad and M. Strizich. EVOLVE 1 : A computer model of an evolving ecosys1\ntem. BioSystem, 17245-258, 1985.\nGary William Flake. The Computational Beauty of Nature: Computer Ezpl0ration-s\nof Fractals, Chaos, Complez Systems, and Adaptation. MIT Press, July 1998.\nFelix C . Gartner. Fundamentals of fault-tolerant distributed computing in asynchronous environments. ACM Computing Surveys, 31(1):1-26, 1999.\nD. Goldberg. Genetic Algorithm a Search, Optimization and Machine Learning.\nn\nAddison-Wesley P u b Co,December 1989.\nS. Goldenstein, E. Large, and D. Metaxas. Non-linear dynamical system approach\nto behavior modeling. The Visual Computer, 15349-364, 1999.\n3. R. Koza, F. H. Bennett 1 1 F. H. Bennett, D. Andre, and M. A. Keane. Ge1,\nnetic Programming 111: Automatic Programming and Automatic Circuit Synthesis.\nMorgan Kaufmann Publishers, 1999.\nS. Kraus, V.S. Subrahmanian, and N. Cihan Tacs. Probabilisticaliy survivable\nmass. In Proceedings of the International Joint Conference on Artzficid lnteiiigence\n(IJCAI-2003), pages 789-795,2003Sanjeev Kumar, Philip R. Cohen, and Hector J. Levesque. The adaptive agent architecture: Achieving fault-tolerance using persistent broker teams. In Proceedings\nof the Foiiith T;itmxtionc! CeEference on Multi-Agent Systems (ICMAS 2000),\npages 159-166, July 2000.\n\n13. R.P. \'Lentini, G. P. Rao, J. N. Thies, and J. Kay. Emaa: An extendable mobile\nagent architecture. In A A A I Workshop on Software Tools for Developing Agents,\nJuly 1998.\n14. K. Lerman and A. Galstyan. A general methodology for mathematical analysis\nof multi-agent systems. Technical Report ISI-TR-529, USC Information Sciences,\n2002.\n15. K. Lerman and A. Galstyan. Macroscopic analysis of adaptive task allocation in\nrobots. Submitted to IROS-03, 2003.\n16. 0. Marin, P. Sens, J. Briot, and Z. Guessoum. Towards adaptive fault tolerance\nfor distributed multi-agent systems. In Proceedings of the first international joint\nconference on Autonomous agents and multiagent systems: part 2, pages 737 - 744,\n2002.\n17. J. Maynard-Smith. Evolution and the Theory of Games. Cambridge University\nPress, Cambridge, 1982.\n18. 3. Maynard-Smith and G. Price. The logic o animal conflict. Nature, 146:15-18,\nf\n1973. .\n19. R. L. Olson and A. A. Sequeira. An emergent computational approach to the study\nof ecosystem dynamics. Ecological Modeling, 79:95-120, 1995.\n20. M. Peysakhov, D. Artz, E. Sultanik,,and W. C. Regli. Network awareness for\nmobile agents on a d hoc networks. In Proceedings of the Third International Joint\nConference on Autonomous Agents and Multi Agent Systems ( AAMAS-2004), July\n2004.\n21. M. Rizki and M. Conrad. EVOLVE 111: A discrete events model of an evolutionary\necosystem. BioSystems, 18:121-133, 1985..\n22. Evan Sultanik, Donovan Artz, Gustave Anderson, Moshe Kam, William Regli,\nMax Peysakhov, Jonathan Sevy, Nadya Belov, Nicholas Morizio, and Andrew\nMroczkowski. Secure mobile agents on ad hoc wireless networks. In The Fifteenth Innovative Applications of Artificial Intelligence Conference, pages 129-36.\nAmerican Association for Artificial Intelligence, Aug 2003.\n23. Taylor, E. Charles, Turner, Scott, and Seth R. Goldman. Ram: Artificial life for\nthe exploration of complex biological systems. In C.G. Langton, editor, Artificial\nLife: SFI Studies in the Sciences of Complexity., pages 275-295. Addison-Wesley,\nRedwood City, CA, 1989.\n\n'