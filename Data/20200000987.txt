b'National Aeronautics and Space Administration\n\n5...4...3...2...1...\n\nSPACE LAUNCH SYSTEM\nDecember 11, 2019\n\nSLS GNC Model-based Design Approach\nNaeem Ahmad, Evan Anzalone, Young Kim, Paul Von der Porten (NASA/MSFC)\nJimmy Compton, Steven Hough, Thomas Park, John Wall (NASA/MSFC/ESSCA/Jacobs/DCI)\nChristian Garcia (NASA/MSFC/ESSCA/Jacobs)\nwww.nasa.gov/sls\n\nwww.nasa.gov/sls\n\n1\n\nOverview\n\xe2\x80\xa2SLS Top-level GNC Requirements\n\xe2\x80\xa2SLS GNC Architecture\n\xe2\x80\xa2Model-based Approach to Analysis and\nDesign\n\xe2\x80\xa2Simulation Architecture\n\xe2\x80\xa2SLS GNC FSW Model Description\n\xe2\x80\xa2Model Delivery Process\n\xe2\x80\xa2Verification and Validation\n\nwww.nasa.gov/sls\n\n.2\n\nGNC Requirements\n\xe2\x80\xa2High level requirement: insertion of payload into a predefined\norbit with high accuracy (Apogee, Semi-Major Axis, Wedge\nAngle) and ensure vehicle dynamic stability\n\n\xe2\x80\x93 Also must do this safely, respond to in-flight conditions, and provide\noutputs capturing vehicle health and status\n\n\xe2\x80\xa2Provide traceability from system requirements to subsystem\nrequirements to demonstrate verification of vehicle design to\nmeet high level requirements\n\nwww.nasa.gov/sls\n\n.3\n\nGNC Architecture\n\xe2\x80\xa2 Inputs:\n\n\xe2\x80\x93 Sensor observations across vehicle (navigated position, velocity, and attitude, observed\nangular rates and acceleration), flight parameters, mission manager inputs\n\n\xe2\x80\xa2 Navigation Functions:\n\n\xe2\x80\x93 Down-selection of redundant sensors, convert data into vehicle frame, verify sensor\noperational status\n\n\xe2\x80\xa2 Guidance Functions:\n\n\xe2\x80\x93 Open and closed loop algorithms to command attitude and engine state to reach\norbital target\n\n\xe2\x80\xa2 Controls Functions:\n\n\xe2\x80\x93 Convert attitude and engine commands to actuator level interface, maintain vehicle\nstability\n\n\xe2\x80\xa2 Outputs:\n\n\xe2\x80\x93 Current vehicle state, sensor health, actuator commands, throttle commands, engine\ncutoff commanding\n\n\xe2\x80\xa2 Analysis through Monte Carlo simulation to demonstrate integrated vehicle\nperformance across nominal and off-nominal scenarios\n\nRINU\nRGA1\nRGA2\n\nTVC\n\nSLS GNC\n\nNavigation\n\nMM\nwww.nasa.gov/sls\n\nGuidance\n\nControls\n\nEngine\nThrottle\nEngine\nCutoff\n.4\n\nSLS SE&I Model Based Design\n\xe2\x80\xa2 Reduced Program structure\n\xe2\x80\xa2 Emphasis on heritage hardware\n\xe2\x80\xa2 Relatively sparse requirements set\nover previous design projects\n\xe2\x80\xa2 Design Math Models (DMM) convey\nthe design\n\n\xe2\x80\x93 Controlled at program level\n\xe2\x80\x93 Maturity/limitations/use tightly\ntracked\n\xe2\x80\x93 Component models are verified\nagainst vendor design and validated\nagainst flight hardware (or equiv.)\n\xe2\x80\x93 Physics models (e.g. 6DOF sim)\nverified against other simulations and\nvalidated with test data\n\xe2\x80\x93 Model parameters of high sensitivity\ncan be elevated to requirements\n\xe2\x80\xa2 Example\n\xe2\x80\x93 Level II DMMs: GN&C Model, MAVERIC\n(6DOF Sim)\n\xe2\x80\x93 Level III DMMs: Sensor Performance,\nActuator Response, Aerodynamics\nProperties, Flexible Body Dynamics, etc.\nwww.nasa.gov/sls\n\nSLS Program Structure\n\nCertification\n\nLevel I\nRequirements Interface\n\nIntegrated\nModels\n\nLevel II\nIntegrated Vehicle\n\nRequirements Interface\n\nElement &\nComponent\nModels\n\nLevel III\nVehicle Elements\n\n\xe2\x80\x9cBuild a vehicle.\xe2\x80\x9d\n\xe2\x96\xba Payload performance\n\xe2\x96\xba Target accuracy\n\xe2\x96\xba Payload impact\n\nGN&C\nInt. Loads & Dyn.\nInt. Avionics (FSW, SIL)\n\n\xe2\x96\xba INS I/F, accuracy\n\xe2\x96\xba GPS I/F, accuracy\n\xe2\x96\xba TVC performance\n\nCore Stage\nUpper Stage\nEngine\n\n.5\n\nGN&C Implementation of MBD Processes\n\xe2\x80\xa2 Heritage programs used documentation\nto describe GNC algorithms to FSW team\n\xe2\x80\x93 Test cases included to verify functionality\n\n\xe2\x80\xa2 MBD began as pilot program in 2010\n\n\xe2\x80\x93 Working towards efficient GNC and FSW\nProcess\n\n\xe2\x80\xa2 DMM Contents\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\nExecutable Algorithms\nParameter Definition\nTechnical Memorandum\nInterface assumptions\nUnit test cases\n\n\xe2\x80\xa2 GNC Model\n\n\xe2\x80\x93 Pulled directly from simulation\narchitecture\n\xe2\x80\x93 Direct tie to performance results\n\xe2\x80\x93 Captures implementation of design\n\xe2\x80\x93 Includes unit test functionality and\nhardware testing\n\n\xe2\x80\xa2 Detailed CR Process for integration with\nFSW and internal development\n\nwww.nasa.gov/sls\n\n.6\n\nGNC/FSW High-Level Process Flow\n\xe2\x80\xa2 Component delivery through\nmanaged repository\n\xe2\x80\xa2 Early introduction of FSW\narchitecture, common\nprimitive library, and\ncommon coding/(modeling)\nstandard\n\xe2\x80\xa2 Iterative, closed-loop\nmaturation to flyable\nimplementation\n\xe2\x80\x93 Modifications fed back\nthrough Change Request\n\n\xe2\x80\xa2 Simulations performed to\nverify system performance\nwith updates\n\nwww.nasa.gov/sls\n\n.7\n\nGNC/FSW Implementation Process Flow\nGN&C\nDesign and\nAnalysis\nProcess\n\nExecutable Model\nDevelop Core\nAlgorithm Solution\n(Maveric or\nSimulink)\n\nCommon Coding\nStandard\nCommon\nPrimatives Lib\nFSW Arch\n\nAlg Test Cases\n\nChange Request\n\nMAVTOOL\n\nCommon\nOwnership\n\nCommon component approach includes\n\xe2\x80\xa2 Common primitive library in place and tested\n\xe2\x80\xa2 Standard GN&C/FSW architecture\nimplemented and verified through confidence\ntesting\n\xe2\x80\xa2 Coding standard adherence verified by static\nanalysis tool, PRQA\nFunctional unit test cases (FUTCs) are provided\nfor every GN&C Design Level Requirement\n(DLR)\n\xe2\x80\xa2 38 FUTCs ensure implementation of 107\nGN&C DLRs\n\nManaged\nRepository\n\nReleased through MavTool and Windchill\n\nGN&C/EV40\nOwnership\nFSW/ES50\nOwnership\nFlight Code\nImplementation\n\nConfidence Test\n\nFull Unit Test\n\nRun official static analysis, code inspections,\nconfirm architecture, remove dead code, build\nwrappers, execution time measurements, fix bugs,\n\xe2\x80\xa6\nRe-run algorithm test cases\n\nFSW Integration\n\nFSW Integration\nTest\n\nStandard FSW approach\n\nFSW Req-based\nTesting\n\nwww.nasa.gov/sls\n\n8\n\nVerification and Validation Activities\n\xe2\x80\xa2 At GNC Level\n\n\xe2\x80\x93 Changes to simulation and GNC model managed as implemented into\nMAVERIC 6DOF simulation CR Tool\n\xe2\x80\xa2 GNC model changes late in the design require formal CR from FSW Team\n\n\xe2\x80\x93 Unit testing between MAVERIC releases to validate integrated\nperformance\n\xe2\x80\x93 Used for verifying system performance metrics\n\n\xe2\x80\xa2 At GNC Model Delivery\n\n\xe2\x80\x93 Unit test wrapped around GNC model delivery (includes inputs and\noutputs from MAVERIC) to validate performance on GNC model alone\n\xe2\x80\x93 Unit test repeated on flight-like processor platform and outputs\ngenerated\n\n\xe2\x80\xa2 At FSW Integration Level\n\n\xe2\x80\x93 Repeat of unit test with MAVERIC generated data to verify integration\nwithin FSW architecture\n\xe2\x80\x93 Design-Level Requirement testing and verification\n\n\xe2\x80\xa2 At FSW System Level\n\n\xe2\x80\x93 Test cases and comparisons within Software- and Hardware-in-the-Loop\nsimulations to verify performance\n\xe2\x80\x93 Comparison between SIL/HIL results and MAVERIC to identify any mismodeling and verify GNC performance on flight hardware\n\nwww.nasa.gov/sls\n\n.9\n\nSummary of Approach\n\xe2\x80\xa2 GNC Functionality\n\n\xe2\x80\x93 Common component approach\n\n\xe2\x80\xa2 Common algorithm implementation is iteratively matured to a flyable state.\n\n\xe2\x80\x93 At the G, N, and C component level, the same implementation is\nexercised in the GN&C development environment and the FSW target\nenvironment.\n\xe2\x80\x93 GN&C team delivers algorithm components in the form of executable\npseudo-code.\n\xe2\x80\xa2 Iterative, closed-loop maturation process\n\xe2\x80\xa2 Each component meets the quality and testing standards of the FSW\n\norganization\n\n\xe2\x80\xa2 Advantages from Cross-discipline Viewpoint\n\n\xe2\x80\x93 Efficiency through elimination of non-value added and error prone\ndocumentation steps\n\xe2\x80\x93 Leveraging test and analysis done in previous steps\n\xe2\x80\x93 Early introduction of flight software architecture and implementation\nconstraints\n\xe2\x80\x93 Controlled mechanism for version/release management and change\nrequests\n\xe2\x80\x93 Establish a mechanism which enables rapid prototyping in the target\nenvironment\n\xe2\x80\x93 Establish a traceability between all algorithm and software artifacts\nwww.nasa.gov/sls\n\n.10\n\nConclusions\n\xe2\x80\xa2 Implementation of MBD on SLS has significantly increased efficiency\n\n\xe2\x80\x93 Reduces requirements burden\n\xe2\x80\x93 Provides explicit communication of component and integrated system design\n\n\xe2\x80\xa2 Provides a mechanism for\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\xe2\x80\x93\n\nDetailed modeling and design insight\nIdentification of key vehicle sensitivities\nGaining additional insight through testing and validation process\nEnforcing rigor in modeling through validation\n\n\xe2\x80\xa2 DMM V&V process forces high fidelity emulation of hardware\n\xe2\x80\xa2 Lessons Learned:\n\xe2\x80\x93 Model form and function should consider user and developer\n\xe2\x80\x93 GN&C Model\n\xe2\x80\xa2 Software requirements drive the software test program\n\xe2\x80\xa2 Approach conflicted with established FSW processes and culture\n\n\xe2\x80\x93 Component models\n\n\xe2\x80\xa2 Good data requirements and supplier integration are key to enabling process\n\xe2\x80\xa2 V&V plans should be defined early to support data requirements definition and to identify\n\ngaps which require additional testing.\n\xe2\x80\xa2 Sensitivity analyses should be used to identify key performance drivers\n\xe2\x80\xa2 Commonality between HWIL models and Performance/Analysis models reduces crossvalidation effort in verification\n\n\xe2\x80\x93 Interfaces should be included in FSW requirements to ensure compatibility with\nhardware ICDs\n\nwww.nasa.gov/sls\n\n.11\n\nThank you!\n\nAny questions?\nwww.nasa.gov/sls\n\n.12\n\n'