b'LESSONS LEARNED AND COST ANALYSIS OF HOSTING A FULL STACK\nOPEN DATA CUBE (ODC) APPLICATION ON THE AMAZON WEB\nSERVICES (AWS)\n1\n\nSyed R Rizvi, 2Brian Killough, 1Andrew Cherry, 1Sanjay Gowda\n1\n\nAnalytical Mechanics Associates, Hampton, VA\nNASA Langley Research Center, Hampton, VA\n\n2\n\nABSTRACT\nThe Open Data Cube (ODC) initiative, with support from\nthe Committee on Earth Observation Satellites (CEOS)\nSystem Engineering Office (SEO) has developed a state-ofthe-art suite of software tools and products to facilitate the\nanalysis of Earth Observation data. This paper presents a\nshort summary and cost analysis of our experience using\nAmazon Web Services (AWS) to host one such software\nproduct, the CEOS Data Cube (CDC) web-based User\nInterface (UI). In order to provide adaptability, flexibility,\nscalability, and robustness, we leverage widely-adopted and\nwell-supported technologies such as the Django web\nframework and the AWS Cloud platform. The UI has\nempowered users by providing features that assist with\nstreamlining data preparation, data processing, data\nvisualization, and the sub-setting of Analysis Ready Data\n(ARD) products in order to achieve a wide variety of Earth\nimaging objectives.\nIndex Terms\xe2\x80\x94 Open Data Cube, ODC, CEOS, Remote\nSensing, Earth Observation, Satellite, Amazon Web Services\n1. INTRODUCTION\nThe Committee on Earth Observation Satellites (CEOS)\nSystem Engineering Office (SEO) has supported the Open\nData Cube (ODC) initiative to provide a data architecture\nsolution that has value to its global users and increases the\nimpact of EO satellite data [1-2]. The Open Data Cube\n(ODC) is an open-source platform for managing satellite\ndata. We have developed software products and tools around\nthe core ODC. The CEOS Data Cube (CDC) web-based\nUser Interface (UI) is one such well-known tool [3-4]. The\nUI has empowered users by providing features that assist\nwith streamlining data preparation, data processing, data\nvisualization, and exporting ingested data in order to achieve\na wide variety of Earth imaging objectives. In a nutshell, the\nUI allows analyses to be run from a web interface (Figure 1).\nDue to the efforts put into developing the UI, CEOS SEO is\n\nuniquely able to provide substantial contributions to the\nODC initiative and to support global implementations. The\nweb interface, available to the public at http://ec2-52-201154-0.compute-1.amazonaws.com/, has been used by\nmembers of the remote sensing community around the\nworld, and has also been presented at multiple conferences,\ntutorials, training sessions, and international presentations\n[5-7].\nThe UI (along with the ODC core) utilizes a number of\ndifferent software frameworks, including Python, JavaScript,\nPostgreSQL, and the Django web framework. It is hosted on\nan Ubuntu operating system and the source code is publicly\navailable under the Apache License, Version 2.0. The\nPython programming language is greatly suited for research\nin scientific computing, remote sensing, Earth science, and\nmachine learning due to its extensive standard library and\nselection of add-on packages, its readability, and its ease of\nprogramming compared to other languages, and the great\nnumber of help resources easily found online. The ODC\nutilizes PostgreSQL to meet security and performance\nrequirements by organizing the data into stacks of consistent,\ntime-stamped geographic \xe2\x80\x9ctiles\xe2\x80\x9d which can be rapidly\nmanipulated in an HPC environment. The database not only\norganizes the data and metadata for the ODC core and\nDjango framework, but can also be used to track every\nobservation back to the point of collection, thus providing\ndata provenance. AWS has been used as a one-stop solution\nfor web hosting, parallel and distributed processing, and data\nstorage, distribution, and analysis.\nThe bulk of our usage has been Amazon Elastic Compute\nCloud (Amazon EC2) instances, which we are using for both\nanalysis of remote sensing data and the hosting of the UI.\nEC2, in general, makes web-scale cloud computing easier\nfor developers. Amazon EC2\'s simple web service interface\nallows us to obtain and configure capacity with minimal\nfriction. With EC2, we created an Amazon Machine Image\n(AMI) containing an operating system, application\nprograms, and configuration settings.\n\nFigure 1. Web User Interface (UI) of CEOS Data Cube (CDC).\nWe are currently running two instances that are used\ntogether as a clustered computing system for both our\nanalysis cases and the UI operations. The two instances\nsubscribe to a single job queue and the main process divides\nlarge tasks into smaller tasks in order to take advantage of\nall CPU cores and memory available to us. This gives us the\noption of adding additional instances in the future, scaling\nhorizontally to handle periods of heavy demand.\nS3 has been used mostly for distribution of sample\ndatasets to interested parties and the long-term storage of\nsuch datasets. We have developed an interface that includes\ndescriptions of our datasets, the datasets themselves, and\ninstructions for the use of the data, as well as an\nadministrative interface to manage the UI itself. The fullycustomizable source code of the UI is available at our public\nrepository [3]. Interested parties can download the source,\nand build their own UIs. In the future, we may keep a larger\namount of data on S3 and put links to the relevant data on\nour UI for users to download.\n2. COST BURDEN\nWe began using AWS for our hosting and storage needs\nin April of 2016. A sample report of our costs grouped by\nservice from April 2017 to January 2018 can be seen in\nFigure 2. This paper will describe the cost during this\nduration in order to illustrate some insights obtained from\nour recent experience. Additionally, Table 1 and 2 show the\nmonthly AWS calculator for the Amazon EC2 Instances and\nthe Amazon EBS Volumes respectively [8].\nThe bulk of our cost has been the EC2 instances. We are\ncurrently running two c4.8xlarge instances for use in our\nparallel processing cluster for a combined 72 virtual CPU\ncores and 120 GB of RAM. The EC2 instances have a\npredictable and constant cost as they have 100% uptime and\nare used to host our Data Cube UI. Note that the actual\n\nutilization of this 100% uptime is low. Since many of the\nanalyses involve loading and processing multiple gigabytes\nof data per region, we have been able to optimize our\nsystems to use all available resources for each task.\nSecondary costs to the EC2 instances are in the EC2Other category and include snapshots, storage, and elastic IP\naddresses.\nThis cost is driven mostly by the amount of storage we\nare using at any given time. The raw data (mostly GeoTIFF\nscene data) is ingested, i.e. pre-processed into aligned,\ncompressed blocks which are 7-8 times smaller. For\nexample, in one of our case studies related to determining\nhistorical trends in the water quality of Lake Chad in\nCameroon, we created a small data cube (0.25 degrees\nsquare) for the southern portion of the lake. The raw data in\nthis case study was around 920GB (unzipped) but the preprocessed NetCDF files amounted to around 117GB. After\npre-processing, the raw data is not needed for any later\nprocessing so we are only hosting the pre-processed data,\ntotaling roughly 500GB per server. We are currently\nreplicating data between the servers, but plan to move to\nshared Elastic File Systems for dataset storage in the future.\nS3 was our lowest cost, showing only small spikes during\ntimes of large data transfer. Note that large data transfer\noccurs when moving the raw data to the cloud for ingestion.\nCEOS SEO aims to reach operational Data Cubes in 20\ncountries by 2020. As of early 2018, there are three\noperational Data Cubes (Australia, Colombia, and\nSwitzerland) [6], seven in development (Georgia, Moldova,\nTaiwan, Uganda, United States, United Kingdom, and\nVietnam) [7] and 29 other countries with expressed interest.\nAs the interest and involvement from these counties grow in\nthe future, the S3 cost will go up in when we move to make\nmore of our datasets available to additional UI users.\n\nFigure 2. Costs grouped by service.\nTable 1. Monthly Calculator for Amazon EC2 Instances (Compute) [8].\nDescription\n\nInstances\n\nUsage\n\nType\n\nBilling Option\n\nMonthly Cost\n\nWorker\n\n3\n\n100% utilized per month\n\nLinux on c4.2xlarge\n\nOn-demand\n\n$874.02\n\nNotebook Server\n\n1\n\n100% utilized per month\n\nLinux on m4.xlarge\n\nOn-demand\n\n$146.40\n\nCEOS Main (Burstable)\n\n1\n\n1% utilized per month\n\nLinux on t2.2xlarge\n\nOn-demand\n\n$2.97\n\nWorker Image\n\n1\n\n0% utilized per month\n\nLinux on m4.2xlarge\n\nOn-demand\n\n$0.00\n\nTable 2. Monthly Calculator for Amazon EBS Volumes (Storage) [8].\nDescription\n\nVolumes\n\nVolume Type\n\nStorage\n\nCEOS Main\n\n1\n\nGeneral Purpose SSD (gp2)\n\nCEOS Main Data\n\n1\n\nThroughput Optimized HDD (st1)\n\nMisc. (attached)\n\n6\n\nMisc. (unattached)\n\n3\n\nIOPS\n\nBaseline Throughput (MBs/sec)\n\n300GB\n\n900\n\n160\n\n8192GB\n\n0\n\n320\n\nGeneral Purpose SSD (gp2)\n\n75GB\n\n225\n\n128\n\nGeneral Purpose SSD (gp2)\n\n75GB\n\n225\n\n128\n\n3. JUPYTER NOTEBOOKS\nRecall that the bulk of our usage has been EC2 instances,\nwhich are used for both analysis of remote sensing data and\nhosting the UI. We also host an ODC Jupyter Notebook\nserver on EC2. These notebooks act as interactive Python\ndevelopment environments which allow developers to divide\ntheir code into blocks which can be run independently of\neach other, with variables stored in the background and the\nenvironment persisted between blocks. The notebooks were\ninstrumental in providing hands-on training to many\ninternational users in the remote sensing community and\nhave been presented at multiple conferences, tutorials,\ntraining sessions, and international presentations [5-7].\n4. TESTING APPROACH\nTesting a web application such as the UI component of\nODC is a complex task because it is made of several layers\nof logic \xe2\x80\x93 from HTTP(S) request handling, to form\nvalidation and processing, to template rendering. We heavily\nutilize Django\xe2\x80\x99s automated test-execution framework and\n\nassorted utilities. It simulates requests, inserts test data,\ninspects the application\xe2\x80\x99s output and generally verifies the\nsource code for correctness. We have utilized the\ncombination Unittest/Nose2 testing framework for\nautomated unit tests, code coverage, etc. The Selenium and\nLocust web testing frameworks have also been explored for\nadditional UI testing.\n5. WORK-IN-PROGRESS\nApart from the plans for AWS usage that have been\ndescribed in the previous sections, the main features we are\ncurrently targeting for near-term development are Elastic\nFile System, SPOT Processing, and increasing the utilization\nof our current resources.\nThe current plan is to set up an EFS system to cut back\non our data duplication and to allow for greater scalability as\nwe add more EC2 instances. Some added benefits of this\napproach include using the same system for passing data and\nintermediate products back and forth between EC2 instances\nduring parallel processing, and removing the need to transfer\nlarge amounts of data when we create a new instance.\n\nAlthough this will slightly increase our storage costs per\nmonth with our current number of instances, it allows for\ngreater scalability and will reduce costs when we have many\nmore instances. Figure 5 illustrates the cost of storage with\nand without EFS as additional nodes are added. Currently,\nwe are using EBS ST1 volumes which are $.045 per GB per\nmonth. Our parallel processing requires keeping redundant\ndata on each server. Therefore, we pay 2 \xc3\x97 $.045 = $0.09\nper GB per month. On the other hand, EFS storage costs\n$0.30 per GB month, so if we were running 6+ instances\nthen using EFS would become cost-effective.\n\nthe use of our currently employed features and branched out\nto several new services offered by Amazon. The services\nAWS provides have allowed us to create an internationally\naccessible interface where users in the remote sensing\ncommunity can see our progress, access our data, and\nunderstand the impact of open satellite data and its\napplication. The AWS-hosted CDC UI and Jupyter\nnotebooks play a critical role in demonstrating how the\nOpen Data Cube can take advantage of the AWS\ninfrastructure and exploit open datasets in order to achieve\nthe CEOS SEO goal of having operational Data Cubes in 20\ncountries by 2020.\n8. ACKNOWLEDGMENT\nThe authors would like to acknowledge the efforts of Jesse\nHarrison and Alfredo Delos Santos on the early\ndevelopment of the CEOS ODC web-based UI.\n9. DISCLAIMER\nAny use of trade, product, or firm names is for descriptive\npurposes only and does not imply endorsement by the U.S.\nGovernment.\n\nFigure 5. The theoretical growth of cost with EFS and\nwithout EFS, as nodes are added.\n6. FUTURE PLANS\nFor the coming year, we intend to investigate the\nfollowing ODC concepts with AWS:\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n\nDevelop a "Data Cube on Demand" function using\nhosted AWS datasets.\nTest the use of "spot" on-demand processing to\nsupport global data cube deployments.\nTest the use of Lambda functions for finding new\ndatasets to ingest into data cubes.\nTest how EC2 instance performance scales with\nmultiple data cube users.\nTest elastic load balancing for horizontal scaling of\nEC2 instances for data cubes.\nTest AWS "Workspaces" to host QGIS and Jupyter\nNotebooks for cloud analysis.\nTest the use of Docker Containers for on-demand\ncomputing instances\nExplore the use of QGIS to read data cube content\ndirectly from S3\n7. CONCLUSION\n\nAmazon AWS has served as a unified solution for all of our\nCDC storage and analysis needs. We have both expanded\n\n10. REFERENCES\n[1] Open Data Cube Website:\nhttps://www.opendatacube.org.\n[2] Open Data Cube GitHub Repository:\nhttps://github.com/opendatacube.\n[3] CEOS Data Cube User Interface GitHub Repository:\nhttps://github.com/ceos-seo/data_cube_ui.\n[4] CEOS Data Cube web-based User Interface:\nhttp://ec2-52-201-154-0.compute-1.amazonaws.com/.\n[5] The 1st CEOS Open Data Cube Workshop:\nhttp://ceos.org/home-2/1st-ceos-open-data-cube-workshop/.\n[6] G. Giuliani et al., \xe2\x80\x9cBuilding an Earth Observations Data\nCube: lessons learned from the Swiss Data Cube (SDC) on\ngenerating Analysis Ready Data (ARD),\xe2\x80\x9d Big Earth Data,\nvol. 1, no. 1, pp. 1\xe2\x80\x9318, Nov. 2017.\n[7] A. Singh, \xe2\x80\x9cNew satellite data sharing system, Vietnam\nData Cube, introduced,\xe2\x80\x9d GeoSpatialWorld, Mar-2018.\n[Online]. Available:\nhttps://www.geospatialworld.net/news/new-satellite-datasharing-system-viet-nam-data-cube-introduced. [Accessed:\n15-Mar-2018].\n[8] AWS Calculator for CEOS Data Cube systems. [Online].\nAvailable:\nhttps://calculator.s3.amazonaws.com/index.html#r=IAD&s=\nEC2&key=calc-FAF98858-1C94-4FDF-AC1ECEE1F33EDDE6. [Accessed: 03-Jan-2018].\n\n'