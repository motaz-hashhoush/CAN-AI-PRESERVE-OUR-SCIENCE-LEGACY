b'Document: Abstract\nMeeting:\nAnnual Technical Symposium (ATS)\nDate:\nMay 17, 3013\nOrganization:American Institute of Aeronautics and Astronautics (AIAA)\nLocation:\nHouston, Texas\n\nTitle:\nAuthor:\n\nHRA Aerospace Challenges\nDiana DeMott\n\nCompared to equipment designed to perform the same function over and over, humans\nare just not as reliable. Computers and machines perform the same action in the same\nway repeatedly getting the same result, unless equipment fails or a human interferes.\nHumans who are supposed to perform the same actions repeatedly often perform them\nincorrectly due to a variety of issues including: stress, fatigue, illness, lack of training,\ndistraction, acting at the wrong time, not acting when they should, not following\nprocedures, misinterpreting information or inattention to detail.\nWhy not use robots and automatic controls exclusively if human error is so common? In\nan emergency or off normal situation that the computer, robotic element, or automatic\ncontrol system is not designed to respond to, the result is failure unless a human can\nintervene. The human in the loop may be more likely to cause an error, but is also more\nlikely to catch the error and correct it. When it comes to unexpected situations, or\nperforming multiple tasks outside the defined mission parameters, humans are the only\nviable alternative. Human Reliability Assessments (HRA) identifies ways to improve\nhuman performance and reliability and can lead to improvements in systems designed to\ninteract with humans. Understanding the context of the situation that can lead to human\nerrors, which include taking the wrong action, no action or making bad decisions\nprovides additional information to mitigate risks. With improved human reliability comes\nreduced risk for the overall operation or project.\n\n'