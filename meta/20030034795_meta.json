{"copyright": {"licenseType": "NO", "determinationType": "GOV_PUBLIC_USE_PERMITTED", "thirdPartyContentCondition": "NOT_SET"}, "subjectCategories": ["Statistics and Probability"], "exportControl": {"isExportControl": "NO", "ear": "NO", "itar": "NO"}, "distributionDate": "2019-07-09T00:00:00.0000000+00:00", "fundingNumbers": [{"number": "NSF IIS-99-07331", "type": "CONTRACT_GRANT"}, {"number": "NAG2-1394", "type": "CONTRACT_GRANT"}, {"number": "NAG2-1463", "type": "CONTRACT_GRANT"}], "title": "Transition-Independent Decentralized Markov Decision Processes", "stiType": "OTHER", "distribution": "PUBLIC", "submittedDate": "2013-09-07T12:02:00.0000000+00:00", "authorAffiliations": [{"sequence": 0, "submissionId": 20030034795, "meta": {"author": {"name": "Becker, Raphen"}, "organization": {"name": "Massachusetts Univ.", "location": "Amherst, MA, United States"}}, "id": "8d92503dde3342d0b0082f3a8d3cf12b"}, {"sequence": 1, "submissionId": 20030034795, "meta": {"author": {"name": "Silberstein, Shlomo"}, "organization": {"name": "Massachusetts Univ.", "location": "Amherst, MA, United States"}}, "id": "bb99f1e2278944a7bc1c3c127c23b75d"}, {"sequence": 2, "submissionId": 20030034795, "meta": {"author": {"name": "Lesser, Victor"}, "organization": {"name": "Massachusetts Univ.", "location": "Amherst, MA, United States"}}, "id": "af6200512b724eb5bd8f6ed010d9ca1c"}, {"sequence": 3, "submissionId": 20030034795, "meta": {"author": {"name": "Goldman, Claudia V."}, "organization": {"name": "Massachusetts Univ.", "location": "Amherst, MA, United States"}}, "id": "49130dca6ef44f8583c71f63a4f67ad5"}, {"sequence": 4, "submissionId": 20030034795, "meta": {"author": {"name": "Morris, Robert"}, "organization": {"name": "NASA Ames Research Center", "location": "Moffett Field, CA, United States"}}, "id": "d6f1af00eb244187b8c8605261a6904e"}], "stiTypeDetails": "Other", "technicalReviewType": "TECHNICAL_REVIEW_TYPE_NONE", "modified": "2013-08-29T00:00:00.0000000+00:00", "id": 20030034795, "created": "2013-09-07T12:02:00.0000000+00:00", "center": {"code": "HQ", "name": "Headquarters", "id": "f0865a34ba1f474d865ab51f212fc69f"}, "onlyAbstract": false, "sensitiveInformation": 2, "abstract": "There has been substantial progress with formal models for sequential decision making by individual agents using the Markov decision process (MDP). However, similar treatment of multi-agent systems is lacking. A recent complexity result, showing that solving decentralized MDPs is NEXP-hard, provides a partial explanation. To overcome this complexity barrier, we identify a general class of transition-independent decentralized MDPs that is widely applicable. The class consists of independent collaborating agents that are tied up by a global reward function that depends on both of their histories. We present a novel algorithm for solving this class of problems and examine its properties. The result is the first effective technique to solve optimally a class of decentralized MDPs. This lays the foundation for further work in this area on both exact and approximate solutions.", "isLessonsLearned": false, "disseminated": "DOCUMENT_AND_METADATA", "meetings": [{"submissionId": 20030034795, "name": "Second International Joint Conference on Autonomous Agents and Multi-Agent Systems", "id": "1b7afad6ae114e3fa483ae8656415433"}], "publications": [{"submissionId": 20030034795, "id": "6fbfd1a10d6c4e0f937360bd7783681e", "publicationDate": "2003-01-01T00:00:00.0000000+00:00"}], "status": "CURATED", "related": [], "downloads": [{"draft": false, "mimetype": "application/pdf", "name": "20030034795.pdf", "type": "STI", "links": {"original": "/api/citations/20030034795/downloads/20030034795.pdf", "pdf": "/api/citations/20030034795/downloads/20030034795.pdf", "fulltext": "/api/citations/20030034795/downloads/20030034795.txt"}}], "downloadsAvailable": true, "index": "submissions-2022-09-30-06-07"}