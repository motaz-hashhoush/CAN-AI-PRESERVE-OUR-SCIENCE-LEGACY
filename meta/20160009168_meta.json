{"copyright": {"licenseType": "NO", "determinationType": "PUBLIC_USE_PERMITTED", "thirdPartyContentCondition": "NOT_SET"}, "subjectCategories": ["Computer Operations and Hardware", "Air Transportation and Safety", "Aircraft Communications and Navigation"], "exportControl": {"isExportControl": "NO", "ear": "NO", "itar": "NO"}, "distributionDate": "2019-07-11T00:00:00.0000000+00:00", "otherReportNumbers": ["NF1676L-23918"], "fundingNumbers": [{"number": "WBS 432938.09.01.", "type": "WBS"}], "title": "Using Natural Language to Enhance Mission Effectiveness", "stiType": "PRESENTATION", "distribution": "PUBLIC", "submittedDate": "2016-07-20T09:32:09.3500000+00:00", "authorAffiliations": [{"sequence": 0, "submissionId": 20160009168, "meta": {"author": {"name": "Trujillo, Anna C."}, "organization": {"name": "NASA Langley Research Center", "location": "Hampton, VA, United States"}}, "id": "24614d3f87824da193970093a7f42968"}, {"sequence": 1, "submissionId": 20160009168, "meta": {"author": {"name": "Meszaros, Erica"}, "organization": {"name": "University of Eastern Michigan", "location": "Ypsilanti, MI, United States"}}, "id": "2bd37112083541c0aec0f0aae3215500"}], "stiTypeDetails": "Presentation", "technicalReviewType": "TECHNICAL_REVIEW_TYPE_NONE", "id": 20160009168, "created": "2016-07-20T09:32:09.3500000+00:00", "center": {"code": "LaRC", "name": "Langley Research Center", "id": "1e229fe5b7284965a153b0f761643383"}, "onlyAbstract": false, "sensitiveInformation": 2, "abstract": "The availability of highly capable, yet relatively cheap, unmanned aerial vehicles (UAVs) is opening up new areas of use for hobbyists and for professional-related activities. The driving function of this research is allowing a non-UAV pilot, an operator, to define and manage a mission. This paper describes the preliminary usability measures of an interface that allows an operator to define the mission using speech to make inputs. An experiment was conducted to begin to enumerate the efficacy and user acceptance of using voice commands to define a multi-UAV mission and to provide high-level vehicle control commands such as \"takeoff.\" The primary independent variable was input type - voice or mouse. The primary dependent variables consisted of the correctness of the mission parameter inputs and the time needed to make all inputs. Other dependent variables included NASA-TLX workload ratings and subjective ratings on a final questionnaire. The experiment required each subject to fill in an online form that contained comparable required information that would be needed for a package dispatcher to deliver packages. For each run, subjects typed in a simple numeric code for the package code. They then defined the initial starting position, the delivery location, and the return location using either pull-down menus or voice input. Voice input was accomplished using CMU Sphinx4-5prealpha for speech recognition. They then inputted the length of the package. These were the option fields. The subject had the system \"Calculate Trajectory\" and then \"Takeoff\" once the trajectory was calculated. Later, the subject used \"Land\" to finish the run. After the voice and mouse input blocked runs, subjects completed a NASA-TLX. At the conclusion of all runs, subjects completed a questionnaire asking them about their experience in inputting the mission parameters, and starting and stopping the mission using mouse and voice input. In general, the usability of voice commands is acceptable. With a relatively well-defined and simple vocabulary, the operator can input the vast majority of the mission parameters using simple, intuitive voice commands. However, voice input may be more applicable to initial mission specification rather than for critical commands such as the need to land immediately due to time and feedback constraints. It would also be convenient to retrieve relevant mission information using voice input. Therefore, further on-going research is looking at using intent from operator utterances to provide the relevant mission information to the operator. The information displayed will be inferred from the operator's utterances just before key phrases are spoken. Linguistic analysis of the context of verbal communication provides insight into the intended meaning of commonly heard phrases such as \"What's it doing now?\" Analyzing the semantic sphere surrounding these common phrases enables us to predict the operator's intent and supply the operator's desired information to the interface. This paper also describes preliminary investigations into the generation of the semantic space of UAV operation and the success at providing information to the interface based on the operator's utterances.\n\n", "isLessonsLearned": false, "disseminated": "DOCUMENT_AND_METADATA", "meetings": [{"country": "United States", "submissionId": 20160009168, "endDate": "2016-05-13T00:00:00.0000000+00:00", "sponsors": [{"meta": {"organization": {"name": "Department of Defense", "location": "Arlington, VA, United States"}}, "meetingId": "3344eebb9b5441c8be4b3b2ec7c1813b", "id": "6e08b2e00bc24f89bcb99552414467de"}], "name": "Department of Defense: Human Factors Engineering Technical Advisory Group Meeting", "location": "Hampton, VA", "id": "3344eebb9b5441c8be4b3b2ec7c1813b", "startDate": "2016-05-09T00:00:00.0000000+00:00"}], "publications": [{"submissionId": 20160009168, "id": "71eada5970d34b5b91f94f35c8cbe715", "publicationDate": "2016-05-09T00:00:00.0000000+00:00"}], "status": "CURATED", "related": [], "downloads": [{"draft": false, "mimetype": "application/pdf", "name": "20160009168.pdf", "type": "STI", "links": {"original": "/api/citations/20160009168/downloads/20160009168.pdf", "pdf": "/api/citations/20160009168/downloads/20160009168.pdf", "fulltext": "/api/citations/20160009168/downloads/20160009168.txt"}}], "downloadsAvailable": true, "index": "submissions-2022-09-30-06-07"}