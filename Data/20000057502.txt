b'AUTONOMOUS\n\nPERFORMANCE\nMonitoring\n\nand\n\nMONITORING\nSelf-Tuning\n\nSYSTEM:\n\n(MAST)\n\nChariya\nPeterson\nComputer Sciences Corp. 7700 Hubble Drive,\nLanham-Seabrook, MD 20706. c_eters5ra=csc.com\n\nNigei A. Ziyad\nNASA/GSFC Code 588,\nGreenbelt, MD, 20771, Nigel.Ziyad@gsfc.nasa.gov\n\nAbstract\nMaintaining the long-term performance\nof software onboard a spacecraft can be a major factor in\nthe cost of operations. In particular, the task of controlling and maintaining\na future mission of\ndistributed spacecraft will undoubtedly\npose a great challenge, since the complexity" of multiple\nspacecraft\nflying in formation\ngrows rapidly as the number of spacecraft\nin the tbrmation\nincreases.\nEventually, new approaches will be required in developing viable control systems that\ncan handle the complexity of the data and that are flexible, reliable and efficient.\nIn this paper we\npropose a methodology\nthat aims to maintain the accuracy of flight software, while reducing the\ncomputational\ncomplexity of software tuning tasks. The proposed Monitoring\nand Self-Tuning\n(MAST) method consists of two parts: a flight software monitoring\nalgorithm\nand a tuning\nalgorithm.\nThe dependency\non the software\nbeing monitored\nis mostly contained\nin the\nmonitoring process, while the tuning process is a generic algorithm independent\nof the detailed\nknowledge\non the software.\nThis architecture\nwill enable MAST to be applicable\nto different\nonboard software controlling various dynamics of the spacecraft, such as attitude self-calibration,\nand formation control.\nAn advantage of MAST over conventional\ntechniques\nsuch as filter or\nbatch least square is that the tuning algorithm\nuses machine\nlearning\napproach\nto handle\nuncertainty\nin the problem domain, resulting in reducing over all computational\ncomplexity.\nThe\nunderlying\nconcept of this technique is a reinforcement\nlearning scheme based on cumulative\nprobability\ngenerated by the historical performance\nof the system.\nThe success of MAST will\ndepend heavily on the reinforcement\nscheme used in the tuning algorithm, which guarantees\nthe\ntuning solutions\n\n1.\n\nexist.\n\nIntroduction\n\nSome of the problems encountered during the development\nof a control system are the uncertainty,\nin the application domain and the balancing between efficiency and complexity" of the system. In\na large and complex problem such as distributed spacecraft, the accuracy of the control software\nsystem depends on how much in_brmation about the problem can be modeled into the system.\nThe more information\ntaken into account, the more complex the system becomes,\nleading to\nhigher computational\ncost.\nMoreover, the task of maintaining\nlong-term\nperformance\nof the\ncontrol software onboard spacecraft can be a major lector in the operation cost of future multiple\nspacecraft\n\nmissions.\n\nIn the control of distributed\nspacecraft flying\nin tbrmation, conventional\ncontrol algorithms are\nvery complex due to large number of variables and the interaction\namong individual control\nsystems in the formation. This makes tbrmation maintenance\nand control of future constellations\n\nor distributed\nspacecraft greatchallenge,\na\nsincethecomplexity a spacecraft\nof\nformation\ngrows\nnon-linearly the numberof spacecraft the formation. New approaches\nas\nin\narerequiredthat\nresultin vi_ablcontrolsystemshatcanhandlethecomplexity, the dataandthatareflexible,\nc\nt\nof\nreliable\nandefficient.\nIn this paper propose\nwc\ntheMonitoring\nandSelt-Tuning\n(MAST)algorithmthataimsto reduce\nthecomplexity\' onboard\nof\nsottware dealingappropriately ith uncertainty.MAST usesan\nby\nw\napproachased\nb\nonthereinforcement\nlearning\nscheme\nthatcanbeappliedtovariousdynamics\nof\nspacecraft\nsuchasonboard\nattitudeself-calibration, formation\nor\nkeeping.Thistypeof machine\nlearning\napproach asa muchwideroperational\nh\nrange\nthantheconventional\nbatchleastsquare\nor\nfilter techniques. his is simplybecause;\nT\nthelearningsystem\ncanbedesigned automatically\'\nto\naccumulate\nandreuseits pastactivities,which will enablethe systemto reactand adaptto\nchanges the environment.This approach thereforeappropriate problemswith large\nin\nis\nfor\ndegreeof uncertainties.\nMoreover,this technique not critically dependent the detailed\nis\non\n"knowledge the software\nof\nbeingtuned.As a result,someof thetechnical estrictions\nr\ngenerally\nrequired conventional\nin\ntechniquesuchaslinearity,or conditions\ns\nonprocess\nandmeasurement\nnoises\narenotrequired a learning\nif\nalgorithm beingused.\nis\nMASTis anextension a projectatNASA/Goddard pace\nof\nS\nFlightCenter(GSFC): utonomous\nA\nModel-basedrendAnalysisSystem\nT\n(AMTAS)[1]. Theobjectiveof AMTAS is to monitorthe\nhealthand safetyof spacecraft\nhardware\nand subsystems. AST extendsthis objectiveto\nM\ndynamic\napplicationsy proposing applytechniques eveloped AMTAS to onboard\nb\nto\nd\nin\nflight\nsoftware, hich controlthe dynamicsof spacecraft. In general,the performance flight\nw\nof\nsoftware\ncanbemeaningfully\ndefined measuref thecloseness\nasa\no\nbetween\ntheobserved\nandthe\npredicted of thesystems.\nstate\nThese\nquantities reusuallyreferred\na\ntoasresiduals.\nUnderstanding\nthe uncertainty\nunderlyingthe residuals,dentifyingits controllingfactors,andquantifyingthe\ni\npropagationf thesefactors\no\nthrough\nthemodelfor the system\ncanleadto animprovement the\nin\nperformance thesoftware.\nof\nMASTalgorithm\nconsists f twomainparts:apredictor and a tuner. The predictor is a real-time\no\ndynamic system that performs the monitoring task, coupling with the software it is monitoring,\ntaking as input the states of the software at regular time intervals.\nThe step size of the sampling\ntime varies depending on the parameters\nbeing monitored.\nThe state of the predictor represents\nthe performance\nof the software.\nWhen the software performance\nis found to approach a given\nlimit, the tuner will be activated.\nThe tuner is a closed-loop\nlearning algorithm\nguided by a\nreinforcement\nscheme, which is generated by an uncertainty\nhandler.\nThe goal of the tuning\nprocess is to minimize a cost fimction.\nDuring each cycle the values of the model parameters\nbeing tuned are increased or decreased, depending on the outcome of the previous few cycles.\nWith the adjusted parameters, the software performance\nis recalculated\nand the next cycle begins.\nThe rate of convergence\nof the tuning process depends on the reinforcement\nscheme used to score\nhow successful the adjusted parameters\nare towards the tuning goal. If the reinforcement\nscheme\nis completely\nimpartial, then the learning algorithm\nis simply a random search.\nOn the other\nextreme, a reinforcement\nscheme that always scores perfectly is equivalent\nto the conventional\ngradient (steepest descent) method.\nrunning in parallel and isolated from\ntuning goal has been reached, that the\nparameters.\nHence, the tuner may be\n\nIt should be noted that the tuner is an off-line algorithm\nthe routine operation of the flight software.\nNot untilthe\nsoftware will be updated with the new values for the model\nperformed on the ground or on an onboard computer.\n\nIn this paper we will discuss two possible applications\nof MAST: the attitude monitoring and sellcalibration\n(ASCAL),\npreviously\nproposed in [2] and an application\nof MAST to tbrmation\ncontrol.\nIn the first application,\nthe accuracy of attitude software shall depend on, among other\nthings, how accurate its sensor models are.\nSensor models are generally\na function with\nparameters\nrepresenting\nrelevant uncertainties\nsuch as bias, scale factor or misalignment.\nIn the\n\nbeginning,heseparameters\nt\naresetat certainpre-calibratedaluesandaremanuallytunedand\nv\nupdated\nperiodicallythroughouthe life of the spacecraft.Sometuningprocessesreroutine\nt\na\nactivities,while othersareelaborated ndperformed groundby attitudespecialists.Inthis\na\non\nproposed pplication,\na\nMASTwill automatically onitorandtunea setof sensor arameters.\nm\np\nFor\nfurtherreadings nstandard ttitude\no\na\ncalibration\nprocedures,\nseefor instance\n[3-6].\nIn the second\nexample, e propose applicationof MAST to the maintenancef a future\nw\nan\no\nmission largeformation.Thetaskof controllinga number spacecraft fly in formation\nof\nof\nto\nis\nmorecomplicated\nthancontrolling singlespacecraft.Oneproblem\na\nthatmaybeencountered\nin\nthedevelopment formation\nof\ncontrolalgorithms largeformation thecomplexity.\'\nfor\nis\nthatarises\nfrom the high degreeof freedomof the system. In practice,the conventionalstate-space\nrepresentation\napproach manageable for formationof a smallnumber\nis\nonly\n(2-3)of spacecraft.\nThe complexitybecomes\nvery high in a large formation,which makesthe controlalgorithm\ncomputationally\nintensive. oreover, ncertainties the system\nM\nu\nin\nmodels fromenvironmental\nor\ndisturbances\ncanbepropagatedndmagnified.To correct hese\na\nt\nerrorsthecontrolsystem\nhasto\nbetunedoftenandregularly.Hence,hetaskof keeping\nt\ntheformation\nintactrequires\ncontinuous\nmonitoring\nandadjusting\nthepositionof eachindividualspacecraft.\nHence is moredesirableo\nit\nt\nperformthis taskonboard, ndhence, fficientandfastalgorithmsfor the real-timesolutionof\na\ne\nsucha large-scaleptimization\no\nproblem\nareneeded.\nThe organization this paperis as follows. Section2 describeshe architecture MAST\nof\nt\nof\nincludingthe interfacebetweenonboardsoftware,the predictor,and the tuner. Section3\ndescribes formulationof the monitoring\nthe\nmodeincludingthe predictor\nandits interface\nwith\ninputsoftware\nbeingmonitored. ection describeshe tuningmode. Section describeshe\nS\n4\nt\n5\nt\nformulationof the learningsystem\nandits reinforcement\nscheme.Section6 discusseshetwo\nt\nexamples:\nASCALanda formation\nmaintenance\nmethodologysingMAST.\nu\n2. MAST\nThere\n\nArchitecture\n\nare two\n\ndifferent\n\nmodes\n\nin MAST:\n\nThe\n\nmonitoring\n\nmode\n\nand\n\nthe tuning\n\nmode.\n\nThe\n\nmonitoring mode consists of the control software being monitored and the predictor, both running\nin real time. Figure 1 demonstrates\nthe connection between the predictor and the software.\nThe\npredictor is the part of MAST that is dependent on the software being monitored.\nIt is necessary\nthat, in order to monitor and diagnose the problem accurately,\nthe predictor must understand\nthe\nnature of the software it is interacting\nwith. A model for the predictor is described\nin the next\nsection.\nThe tuning mode consists of three components connected in a closed-loop:\nan oft-line copy of the\nsoftware being monitored, the evaluator, and the tuner. Their interface is demonstrated\nin Figure\n2. The evaluator measures the convergence\nof the tuning solutions and the tuner makes appropriate\nadjustment\nto certain model parameters\nof the software guided by a reinforcement\nlearning\nscheme.\nIn general, the reinforcement\nlearning scheme can be generated by various uncertainty\'\nhandling technique.\nIn blAST, the scheme is based on the Local Dempster-Shafer\ntheory (LDS)\nwhich is a modification\nof the Dempster-Shafer\ntheory of belief and evidence [7,8].\nLDS was\noriginally\ndeveloped\nfor AMTAS\ndiagnosis\nprocess\n[1,9].\nIt is specifically\ndeveloped\nfor\nproblems with a large number of variables.\nAs opposed to the predictor, the evaluator and the\ntuner are generic processes that do not require in-depth knowledge\nof the software being tuned.\nTheir basic requirements\nare a set of software parameters\nto be tuned and an appropriate\ncost\nfunction that measures the inaccuracies\nof the software.\nThe evaluator evaluates and scores the\nresult of each cycle by monitoring\nthe effect of the parameter\nBased on this score, the tuner continues to adjust the parameters\n\nadjustment\non the cost function.\nuntil the process converges.\n\nS_,.\'r__" input Ii_m sVacecl"ai t\n\nSensor\n\ninput\n\nfrom\n\nspacecralt\n\ni\nI\nv\n\n,\xc2\xa2\n\nPeal-titreCa3trollcr\nI_\'ming\n\n,,_,ilh strull\n\nCon\xc2\xa2ol\n\nc_q\'_ut\n\nOff-line estimator\n\nD\n\ntl\'nLsters\n\ntin-,: stcpdt\n\nwith\n\nsmall\n\ntime\n\nstepdt\n\n..... , Adjusted\nmodel\n_ters\n\n]Residuals\n\n1 P,_duals\n\nEvaluator\n\nPr_ct_\n\nervai_o,outwt\n\nRunning at a lad.n" tirc\xc2\xa2 _t_ Dt\n\nwith\n\nlarger\n\ntime\n\nSCort.._\n\nTuner\n\nstepDt\n\nto tun_\n,b\nT\ntrio&Is\n\nReinforcement\n\n4\ngenerator\n\n[\n\nrr,Mels\n\nFigure 2. Tuning Mode\nFigu-e 1. N_nitcxingNk_:te\n\n3. Monitoring\n\nmode\n\nThis mode is performed\nsoftware\nand s denotes\nthat an expected\nsoftware\n\nand\n\ndynamic\n\nduring normal operation.\nLet x denotes\nthe state vector estimated\nthe vector of sensor parameters\nbeing monitored\nand calibrated.\n\nstate\non\n\nvector\n\nsensors\n\nx a is given,\n\nand\n\nx.\n\nparameters\n\nmay\n\nin various\n\n: f(x(t))\n\nZr. _ is the measurement\n\nfor sensor\n\nThe\n\nvectors\n\nperformance\n\nresiduals\n\nbe\n\ndesired\n\nor\n\nresidual\n\nthe linear\n\nsoftware\n\nby\n\ndriven\n\nthe\n\n(1)\n\nr at time\n\nt k , and\n\nnoise\nDuring\n\ns r is the parameter\n\nvector\n\nassociated\n\nu and measurement\nnoise w is assumed\nto be\nthe monitoring\nmode (normal\noperation)\nthe\n\ns, are constant.\nof (1)\n\nx-%,\n\nthe\n\non the\n\nx(Q )) + w(Q )\n\nwith the model of measurement\nr. The process\nuncorrelated\nwhite Gaussian\nwith zero mean.\nparameter\n\nLet\n\ndepending\n\n+ u(t)\n\nz k = G(s,,\nwhere\n\nmonitored.\n\nways\n\nsystem\n\n._t)\n\nbeing\n\nbe obtained\n\nby the\nAssume\n\nis observable\n\nsensor\n\nobservations.\n\ndynamic\n\nof _ and\n\nresiduals,\nThe\n\nfrom\n\nthe\n\ndeviation\n\nz,. k -G(s,x\nmonitoring\n\nits slope\n\nof\n\n(t_)).\n\nprocess\n\ncertain\n\nLet\n\nis then\n\n_\n\nquantities,\n\nrepresents\n\ndefined\n\nsuch\n\nthe\n\nvia a tracking\n\nas\n\nvector\n\nstate\nof the\n\nprocess,\n\ni.e.\n\n_,&.\n\n((t:,..,) : .::(Z,. + &t-.,._t ,_) + ? >.-"v(t,.. )\n)\n_tx.\nwhere\nresidual\n\nv\n\nis a zero\nsamplings\n\nthe state-space\n\nmean\nmay\n\nwhite\n\nbe larger\n\nrepresentation\n\n, ) = _._t x ) + At.\n\nGaussian\nthan\n\nacceleration\n\nthe time step\n\nof the predictor\n\nv(t x )\nnoise.\n\nof the input\n\ncan be written\n\nas\n\nThe\nsystem\n\ntime\n\nstep\n\n( 1 ). Let\n\nAt =tx.\n\n_ -t x for\n\n._:= [,-" _df,.\n\nThen\n\n._(t_.., ) = ,-1..{\'(t_ ) + V \xe2\x80\xa2v(t,.,\n:\n\nwhere\n\n,-1=10\n\nAt ]\n\n(2)\n\n:H..qt_)+y_\n\n-K\n\ni- l\n\n)\n\n,.h\n\n1_\'" F=[At:/._\n\nNote that, the measurement\nthe level of performance\n\nAt],\n\nH=[I\n\n5 x. represents\n\n0].\nthe residual\n\nsampling\n\nof (1) during the time t x . A propagation\n\nwhile the state ._(t_. ) measures\nof .f(t_. ) predicts\n\nif and when\n\nthe performance\nof (1) approaches\nan acceptable\nthreshold.\nSystem (1) and the predictor (2)\nconnect as shown in Figure 1. Higher order derivatives\nof the state residual can be included in\n._(t_.) in a similar way. In which case, we would have a higher order predictor.\nHigher order\nderivative may be crucial for software systems that are sensitive to uncertainties\nin measurement\nmodels, which is generally the case for a highly non-linear, chaotic or unstable systems.\n\n4. Tuning\n\nMode\n\nThe tuning process is a closed-loop\nalgorithm composed\nof the software to be tuned, e.g.\ndynamic estimator (1), an evaluator that evaluates the outcome of the tuner during each cycle,\na tuner, which is a learning system that adjusts model parameters based on the evaluation.\nevaluator takes as input the estimated states of (1) and a nominal state given by a model.\nevaluation is based on the effect of the tuner on a cost function, typically written as\n\nthe\nand\nThe\nThe\n\n= .C \xe2\x80\xa2M..i\nwhere M is a symmetric positive\namong the residuals. This weight\n\ndefinite quadratic form that provides\nreflects the importance\nand sensitivity\n\nthe weight and relations\nof each state variable in\n\nthe tuning process.\nRemark:\n\nFor the tuning process\n\nto be fully independent\n\nof the application\n\nsoftware\n\nbe a preprocessor\nthat properly\ninitializes\nthe tuner when it is activated.\nidentifies\nand initializes\nthe parameters,\nstep size, and parameter\nranges.\n\nthere should\n\nThe preprocessor\nFor instance, the\n\nparameter ranges are chosen in such a way that the region is void of any singularity and at least\none solution exists. This knowledge can be given a priori by human experts in terms of rules or a\nbelief measure on the set of parameters,\ntheir ranges, and step sizes. Moreover,\nwith proper\nlearning capability, these values can be based on the past experiences\nof the tuner. For instance,\nthese measure functions can be updated each time the system completes a tuning task, whether it\nis successful or not. This preprocessor\nis highly dependent of application domain and will not be\ndiscussed\n\nin this paper.\n\n5. Reinforcement\n\nLearning\n\nSystem\n\nReinforcement\nlearning is the type of learning that is popular among most current researches in\nmachine learning and statistical pattern recognition.\nOther popular type of learning systems such\nas artificial neural network, requires _tpriori training from examples provided by an experienced\nsupervisor.\nSuch systems are not\ninteraction. In interactive problems it\nahead of time, which are both correct\nhas to react. In an unknown situation,\nto learn proactively\n\nquite appropriate\nfor problems\ninvolving\nlearning\nfrom\nis often impractical\nto obtain examples of desired behavior\nand representative\nof all the situations to which the system\nwhere learning is most beneficial, the system must be able\n\nfrom its own experience.\n\nDuringthe tuningprocess,he parameter\nt\nadjustments based the rate of convergence\ni\non\n(or\ndivergence) theresiduals uringtheprevious\nof\nd\ntwo(or more)cycles. ssume\nA\ntherearensensor\nparameters beadjusted,\nto\nandeachparameter\ncanbeincreasedr decreased a fixedquantity.\no\nby\n_FI]iS\n\ncorresponds\n\nto\n\nH=.\n\ni-\n\n\\1)_0\n2ilia)\n\npossible\n\nways\n\nof adjustment.\n\nEach\n\nchoice\n\nisaset\n\nof\n\nparameters\nwith a + or - sign to denote if the parameter\nis being increased or decreased.\nFor\ninstance, an increase in parameter a and a decrease in parameter b is represented\nby the "signed"\nset {a.,b_\n\n}.\n\nprobability\n\neach loop K, the set H of all possible\n\ndistribution\n\nThe learning\nindex\n\nDuring\n\nprocess\n\np_. which\n\nis computed\n\nin the tuner is precisely\n\nchoices\n\nusing the Local\nthe mechanism\n\nis indexed\n\nby a cumulative\n\nDempster-Shat\'er\nthat adapts\n\nPx\n\n(LDS)\nto obtain\n\ntheory.\nthe new\n\npx+_ for the next cycle.\n\nDue to space limitation, we will describe a simpler algorithm based on the Dempster-Shafer\n(DS)\ntheory, which we modified to suit our tuning problem.\nFor a more in-depth discussion of the\nLDS theory see [2]. DS theory is defined on a set of n elements. Recall that, H is a set of all\npossible ways of modifying model parameters being tuned. A mass function onH is a probability\nfunction that assigns a degree of belief to each of its element.\nThe mass function satisfies the\nfollowing\n\nconditions\nZm(A)\n\n= 1, forA;eQ\n\nand\n\nre(Q)\n\n= 0\n\nA__tf\n\nTwo mass functions\nthe Dempster\n\nm I and tn_ on H can be combined\n\ncomposition\n\nm_ \xc2\xaem2(A\n\n)\n\ninto a single mass function\n\nml \xc2\xae m_, by\n\nrule:\n=\n\nZml(B)m2(C)/(1-\n\nZm_(B)m,.(C))\n\nB_C=A\n\n,\n\nfor A_@\n\nBwC=Q\n\nm_ \xc2\xae m__\n(\xc2\xae) = O.\nThese mass functions\nbelief function\n\nare used to generate\n\ngenerated\n\nthe degree\n\nby a mass function\np:H\n\nof belief associated\n\nm is defined\n\nto each element\n\nofH.\n\nA\n\nas:\n\n--* [0,11; b(A) = __, re(B)\nB__A\n\nwhere\n\nthe union\n\nbetween\n\ntwo signed sets is obtained\n\nby "adding"\n\nall elements\n\nin the two sets\n\naccording to their sign. This way, every subset of the form {a, a_ } will all be cancelled\nstatistical terms, the belief function is a cumulative probability on H.\n\nout. In\n\nDuring each tuning cycle, the belief function is evaluated and used to index the set H. If the\nresulting residuals are tbund to decrease with a faster rate or increase with a lower rate, the tuner\nwill re-compute\n\nthe next belief vector Px-: by applying\n\na positive\n\nlearning\n\n[l,9]. The new index will strengthen the performance\nin the previous\nresiduals peribrmed in the opposite manner, then the negative learning\nresulting in lessen the degree of belief on the failed action.\n\nalgorithm\n\ndescribed\n\nin\n\ncycle. Conversely,\nif the\nalgorithm will be applied.\n\nThe learning process discussed above is the simplest application of the (modified)\nDS theory to\nthe tuner. In practice this algorithm can be enhanced in various ways to increase the performance\nand robustness of the tuner. First. the localization\nof the DS theory onH defined in [l,9] will\nreduce the size of search space. Second, the size of parameter increment may be decreased as the\nresiduals\n\nbegin\n\nto converge.\n\nThird,\n\nthe\n\nuse\n\nof hierarchical\n\nor multilevel\n\nlearning\n\nsystems\n\naccelerates learningprocess\nthe\n(more\nstructure\n\nso for the initial\n\nrate of learning)\n\nand simplifies\n\nthe\n\nof tile tuner in each layer.\n\nRemark:\n\nIn some situation,\n\nthe dynamics\n\ndriven\n\nthe sotiware\n\nmay have a hierarchy\n\nstructure.\n\nA\n\ntypical example: in a formation with complex topology, it may be more convenient\nto partition\nthe system into layers of homogeneous\nsub-fornmtion.\nIn which case, the control algorithm will\nhave to be partitioned accordingly.\nHence, the set H will also be required to have a hierarchical\nstructure to support the hierarchy of the control software.\nA hierarchical\nversion of DS theory\ncan be defined in a natural way, and the parameter tuning is performed\nin a sequence of steps.\nFirst, the highest level in the set H is selected, following by a lower level. This procedure\ncontinues\nuntil the last level is reached. This hierarchical\nstructure will reduce the size of the\nsearch space in each layer, and hence enhance the performance\nof the tuning system. The third\ncomponent in the tuning mode is the evaluator.\nIts important task is to diagnose the problems that\npredictor predicted.\nThis corresponds\nto determining,\nbased on the residual data alone, which\nparameters\nin the software need adjustment, and what are the "safe" ranges that these parameters\nmay vary. Such information\nmust be determined\nprior to the tuning process.\nUsually, expert\nknowledge can be encoded in some form, such as rules.\n\n6.\n\nExample\n\n1: ASCAL\n\nDuring an attitude sensor calibration, where both states and modelparameters\nare simultaneously\nsolved for, it is natural to consider extended state vectors consisting of both attitude and sensor\nparameters.\nHowever, including sensor\nnon-linearity\ninto the system, making\nalternative approach is to apply MAST\ncycle, sensor parameters\nare adjusted\ndifferent combination\nof sensors and\n\nparameters\nas part of the state will introduce additional\nit more complex and too costly to run onboard.\nAn\nto adjust these parameters\nincrementally.\nDuring each\nand attitude and sensor residuals\nare computed.\nUsing\ngyroscope,\ntwo or more attitudes are estimated.\nThe\n\npredictor\nmonitors and predicts\nthe values of the residuals\nusing conventional\nprediction\nalgorithms such as the dynamic\npredictor\ngiven in Section 3, or standard\nregression\nand\nextrapolation.\nWhen it is discovered that the residuals will exceed a given threshold sometime in\nthe future, implied by an inconsistency\nin the estimated\nattitudes, the tuning mode will be\nactivated.\nIn the tuning mode, the evaluator will diagnose the inconsistencies\nand create one or\nmore calibration goals, usually expressed as "which measurement parameters\nare needed to adjust\nthe ranges for the appropriate calibration\nalgorithm".\nThe tuning process is then planned and\nscheduled. In a spacecraft where one or more sensors need regular calibration, or where computing\nresource is stringent, the predictor may be replaced by a fixed schedule or by a cron table.\nThe calibration process is an iterative process, where sensor parameters believed to be in error are\nadapted on the basis of the system experience with a goal that the mean of all residuals converge\nto zero. The calibration procedure depends on the types of sensors available onboard. If there are\nsufficient\nnumber\nof redundant\nsensors, a standard\ntechnique\nis to compare\nthe attitude\ndetermined by the measurements\nfrom a set of sensors including the sensor to be calibrated with\nthose determined\nfrom a different set of sensors with at least equal or higher accuracy. On the\nother hand, if there are no redundant sensors of high enough accuracy, then the procedure usually\ninvolves more in-depth analysis. In this paper, we assume there is at least one accurate sensor\nsuch as a CCD. Typically, CCD is chosen as the standard frame of reference and generally does\nnot need calibration.\nIn this case, we may calibrate other sensors by comparing\nthe resulting\nestimated attitude and sensor residuals with that determined\nfrom the CCD. Any inconsistency\nthat occurs\n\nindicates\n\nthat there are errors in one or more model parameters.\n\nFor current\n\nmissions,\n\nby attitude\n\nspecialists.\n\nthe gyro scale lector calibration\nMAST\n\ncan be applied\n\ntask has to be done manually\n\nto this problem\n\nit" there\n\nand regularly\n\nis sufficient\n\nplanning\n\ncapabilityon board.The gyro scalet:actorparameters calibratedby inspectingchanges\ni\nin\nattitudeduringa planned\nmaneuvering,laving an autonomous\nl\nplannerandschcduler nboard\no\nwill enablethe systemto piggybackgyro scalefactorcalibrationduring routine spacecraft\nmaneuvering.\n7.\n\nExample\n\nFormation\n\n2: Formation\n\ncontrol\n\narchitectures\n\nKeeping\nare being\n\ndeveloped\n\ntbr various\n\nfuture\n\nmissions\n\nand\n\nseveral\n\napproaches\nare being investigated.\nOne of the research efforts in this area at the Goddard Space\nFlight Center is the tbrmation flying tbr the New Millennium Program [10, 11] designed tbr Earth\nOrbitor 1 (EO-1) spacecraft\nflying in formation with the Earth Observing\nSystem-AaM1 (EOSAM1).\nThe tbrmation\nof EO-1 and EOS-AMI\ninvolves position\nmaintenance\nof the two\nspacecraft relative to measured\nseparation errors.\nThis involves the use of an active control\nscheme to maintain the relative positions of EO-1 (chaser) with respect to EOS-AM1\n(target).\nThis formation\nstructure\nis specifically\ndesigned\nfor the EO-1/EOS-AM1\nformation,\nwhich\ninvolves only two spacecraft.\nWith care, conventional\ncontrol algorithms can be used effectively\nin such a small formation.\nFor a large formation,\nthe complexity\nrises very rapidly and\neventually conventional\nalgorithm will break down and new approach will be needed. GSFC and\nStanford have form a partnership\nto develop the Autonomous\nControl System (AutoCon)\narchitecture which employs innovative use of fuzzy logic and natural language to resolve multiple\nconflicting\nconstraints\nand autonomously\nplan, execute and calibrate routine spacecraft\norbit\nmaneuvers.\nThe underlying\ncontrol algorithm is a robust autonomous\nclosed-loop\nthree-axis\nsystem.\nHowever,\nit is still not clear if AutoCon will be feasible for the control of a large\nformation.\nOur main objective\nin this application\nof MAST is to improve on our machine\nlearning approach to work with or integrate into AutoCon environment.\nSee also [12] for another\napproach\n\nto formation\n\ncontrol.\n\nCurrently, there are two major\nslave and master architecture,\n\napproaches in spacecraft formation control and maintenance:\nand the decentralized\nformation\narchitecture.\nIn the slave\n\nthe\nand\n\nmaster approach, one of the spacecraft, designated\nthe center of the tbrmation, perlbrms all the\nnecessary computation\nto determine control requirements\nfor itself and for the rest of its crew.\nThe master spacecraft\nhas two-way communication\nwith each of the slave spacecraft.\nIn the\ndecentralized\napproach,\nall spacecraft\nin the formation\nare peers. They transmit necessary\nattitude, position,\nvelocity\nand control information\namong each other.\nA decentralization\nalgorithm with minimal exchanged\ninformation\nhas been developed by R. Carpenter\n[13]. His\ntechnique is based on the Linear-Quadratic\nGaussian Control algorithm [14]. Another approach\nto the control of a large formation is to use synchronization\nalgorithm introduced by Pecora and\nCarroll\n\n[ 15,16].\n\nAt the time this paper was written, none of the approaches\nauthors have been tully developed and tested.\nNevertheless,\napplying MAST algorithm\nattitude sensor calibration\n\nto tbrmation flying "known to the\nwe will discuss the possibility, of\n\nto formation control and maintenance\nproblems.\nAs opposed to the\nwhere sensor parameters\nare adjusted to achieve\ndesired attitude\n\naccuracy goal, in tbrmation maintenance\napplication,\nthe control vectors are adjusted to achieve\ndesired position (and attitude) of each spacecraft in the formation.\nIn the decentralized\ntbrmation\ncontrol, each spacecraft\nin the formation pertbrms local closed-loop\ncontrol using input from its\nlocal sensors in addition to intbrmation\ntransmitted\nfrom other spacecraft in the formation.\nIn the\nmonitoring\nmode, relative position and attitude of each spacecraft\nis monitored\nagainst a\ntbmmtion model. When sizable drifts are predicted, MAST tuning mode will be activated.\nAn\nexample of this mode is demonstrated\nin Figure 3. In this mode, an extended Kalman filter is\nused in the position estimation, while MAST tuning process is used to adjust control parameters.\n\nThetunerwill takeasinputpast easurements positionresiduals ndattempto adjustcontrol\nm\nof\na\nt\nparameters\nbased theresults previous\non\nof\ncycles. Of course, ASTtuningprocess houldbe\nM\ns\ndone\noffline(to savefuel). Not until thesystem\nhasaccumulated\nsufficientinforrnation terms\nin\nof cumulative\nprobabilitydistribution), r thesolutions\no\narenearlyconverging,henMAST may\nt\nbeswitched real-time\ntoa\ntuningprocess.\n\nInputfromnetworkof spacecraft\nandsensors I\nt\nI\nposition\nestimator\n(Off line) estimate position\ngiven a control\n\n_djusted\n\nvector\n\ncontrol\n\nvector\n\ni Residuals\n\nEvaluator\nEvaluates position relative\nto the neighboring\nspacecraft\n\nFormation\n\nFigure\n\nFor future invesngation,\nor coupling\n\nwith MAST\'s\n\nscores\n\nTuner\nSearch on Control\n\nReinforcement\n\nmodels\n\n3. An example of using MAST\nMaintenance\nApplication\n\nextended\n\nKalman\n\ntuning algorithm\n\nfilter in the position\n\nspace\n\nscheme\n\nin Formation\n\nestimator\n\nwill also be replaced\n\nin order to reduce the computational\n\nby\n\ncost even further.\n\n8. Conclusion\nThe proposed\nprogram\nMAST is designed\nwith the following\nphilosophy\nin mind: the\ndependency\non the application domain lies entirety in the predictor component,\nwhile the tuning\ncomponent\nis generic\nand independent\nof application\ndomain.\nWith this concept,\nnew\napplications\ncan be developed quickly by focusing on developing a predictor with full knowledge\nof the nature of the application domain enough to monitor and diagnose problems that may occur.\nThe tuning mode, on the other hand, will only need information on the cost function that needs to\nbe optimized,\n\nand parameters\n\nto be modified.\n\nThis study is part of our program to increase the level of autonomy\nproof of concept\nof ASCAL, the first phase of the program\nNIATLAB TM.\n\nofonboard\nflight software.\nis now being developed\n\nA\nin\n\nReferences:\n\n[lt\n\nC. Sary, C. Peterson, J. Rowe, K. Mueller, W. Truszkowski,\nT. Ames, N. Ziyad. Autontated\n3,fidtimodal Trend Anah\'sis System, Proceedings of the AAAI Spring Symposium\n1998.\n\n[2]\n\nC. Peterson,\nJ. Rowe, K. Mueller,\nN. Ziyad, ASCAL.\nAutonontous\nAttitude\nSensor\nCalibration,\nproceedings\nof the Flight Mechanics Symposium,\nNAS,%\'GSFC May 1999.M.\nD. Shuster, D. M. Chitre, andD.\nP. Niebur. b_Jlight Estimation\nof Spacecraft\nAttitude\nSensor Accuracies and Alignments, J. of Guidance and Control, 5, 4, 1982.\n\n[3]\n\nM.D.\nSchuster, hi-Flight Estimation\nAstronautical\nSciences, 72, 1990.\n\n[4]\n\nM.D. Shuster, D. M. Chiter, and D. P. Niebur, Inflight estimation of Spacecraft\nSensor Accuracies and Alignments, J. of Guidance and Control, 5, 4, 1982.\n\n[5]\n\nG.J. Bierman and M. D. Schuster, Spacecraft Alignment\non Decision and Control, Austin, TX, Dec. 7-9 1988.\n\n[6]\n\nJ. E. Keat, Gyro Calibration\n(HEAO-A), Computer Sciences\n\n[7]\n\nG.A.\n\n[8]\n\nA.P. Dempster,\nUpper and Lower Probabilities\nof Math. Stat. 38, pp. 325-329, 1967.\n\n[9]\n\nC. Peterson,\n\n[10]\n\nD. Folta, Enhanced Formation Flying for the New Millennium\nand Mission to Planet Earth\nProgram, Mission Design and hnplementation\nof Satellite Constellation,\nvan der Ha (ed.)\npp. 243-254, International\nAstronautical\nFederation,\n1998.\n\n[11]\n\nF. Bauer, J. Bristow, D. Folta, K. Hartman, D. Quinn, J. P. How, Satellite Formation\nUsing an hmovative\nAutonomous\nControl\nSystem\n(AUTOCON)\nEnvironment,\nProceedings\n1998.\n\n[12]\n\nJ.P. Diris, J. Fourcade,\nC. Jayes, T. Toumier,\nL. Lefebvre,\nJ. Dulac, N. Dubemet,\nAutonomous\nOrbit Determination\nand Control in Constellations\nof Satellites,\nMission\nDesign and Implementationn\nof Satellite Constellations,\n255-261, J. C. van der Ha (ed.),\nInternational\nAstronautical\nFederation,\n1998\n\n[13]\n\nJ. R. Carpenter,\nA Prelimina_\nhlvestigation\nof Decentralized\nControl for &_tellite\nFormation, Proceedings\nof the IEEE Aerospace Conference, Big Sky, NIT, March 2000.\n\n[14]\n\nJ. L. Speyer, Computation\nand Transmission\nRequirements\nfor a Decentralized\nLinearQuadratic Gaussian Control Problem, IEEE Trans. Automatic Control, AC-24, 2, pp. 266269, 1979.\n\n[15]\n\nT. L. Carroll, L. M. Pecora. Synchronizing\nSystems, 38, 4, pp. 453-456, 1991.\n\nChaotic\n\n[16]\n\nL. M. Pecora, T. L. Carroll, Svnchropzization\n64, 8. pp. 821-824, 1990.\n\nin Chaotic\n\nShafer, Mathematical\n\nLocal Dempster\n\nof Spacecraft\n\nSensor\n\nAlignment,\n\nEstimation,\n\nAnalysis for the High Energy\nCorporation,\nCSC/TM-77/6082,\n\nTheory of Evidence,\n\nShafer\n\nTheory,\n\nPrinceton\nInduced\n\nAdvances\n\nin the\n\nAttitude\n\n27 th IEEE Conference\n\nAstronomy\nJune 1977.\n\nObservatory-A\n\nU. Press, 1976.\nby Multivalued\n\nCSC-AMTAS-98001,\n\nCircuits.\n\nSystems.\n\nMappings,\n\nC.S.C Internal\n\nIEEE\n\nTrans\n\nPhysical\n\nAnnals\n\nReport\n\nFlying\nAIAA\n\nCircuits\n\nReview\n\nand\n\nLetters,\n\n10\n\n'