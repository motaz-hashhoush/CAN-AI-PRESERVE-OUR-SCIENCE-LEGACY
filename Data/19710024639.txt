b'17618-HI 74-RO-00\n\nPROJECT TECHNICAL REPORT\n\nTask 707\n\nNEW CRITERIA DEVELOPMENT\n\nNAS 9-8166\n\n29 June 1971\n\n\nPrepared for\n\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n\nMANNED SPACECRAFT CENTER\n\nHOUSTON, TEXAS\n\n\n\'71-\n\n(ACCESSIO\n\n-\n\n/Il\nER)\n\n1N(Par\n\n(NASA CRORTMX OR ADNU~\n\n(THRU)\n(CODE)\n\n(CATEGOPIY\n\nPrepared by\n\nCommunications and Sensor Systems Department\nElectronics Systems Laboratory\n\nTRW\n\n\nSYSTEMS GROUP\nfleproduced by\n\nNATIONAL TECHNICAL\nINFORMATION SERVICE,\nSprlngfipld, Va, 1215t\n\n\'\n\n.\n\n#\n\n_.\n\n17618-H174-RO-O0\n\nPROJECT TECHNICAL REPORT\n\nTask 707\n\nNEW CRIJERIA DEVELOPMENT\n\nNAS 9-8166\n\n29 June 1971\n\n\nPrepared for\n\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n\nMANNED SPACECRAFT CENTER\n\nHOUSTON, TEXAS\n\n\n(ACCESSIO\n\nEL~~R)\n\n(THRU)\n\ni~\n\n(CODE)\n\nNASA CR OR TMX OR AD NUA 4 ER\n\n(CATEGO\n\n2\n\nPrepared by\n\nCommunications and Sensor Systems Department\n\nElectronics Systems Laboratory\n\n\nTmrN\n\nSYSTEYS GROUP\n\n1\n\nReproducod by\n\nNATIONAL TECHNICAL\nINFORMATION SERVICE\nSprifiold, V.\n\n22151\n\n17618-H174-RO-O0\n\nPROJECT TECHNICAL REPORT\n\nTask 707\n\nNEW CRITERIA DEVELOPMENT\n\nNAS 9-8166\n\n29 June 1971\n\n\nPrepared for\n\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n\nMANNED SPACECRAFT CENTER\n\nHOUSTON, TEXAS\n\n\nPrepared by\n\nJ. C. Miller\n\n\nApproved by:\n\n____________-_\n\nW. B.\\ Warren, Task Manager\n\n\nApproved by:\nACommunications and Sensor Systems\n\no ohn DeVillier, Manager\nDepartment\n\n\nTRW\n\n\nSYSTEMS GROUP\n\nCONTENTS\n\nPage\n\n1. INTRODUCTION ......\n\n...\n\n.. ....\n\n.................\n\n2. METHODS OF SPECIFYING PERFORMANCE CRITERIA .......\n3. CANDIDATE CRITERIA SYSTEMS ......\n\n...\n\n..\n\n1\n\n\n........\n\n2\n\n\n.............\n\n4\n\n\n3.1 \t Voice Criteria - Method A\n\nDetermination of Articulation Index of Output......5\n\n\n3.2 Voice Criteria - Method B\n\nDetermination of Articulation Index Using\n\n...................\nDiscrete Input Frequencies ....\n3.3 \t Voice Criteria - Method C\n\nDevelopment of Speech-to-Noise Ratio Using\n\nAnalog Measurements ...... .. ... ..\n\n15\n\n\n20\n\n\n..........\n\n3.4 \t Voice Criteria - Method D\n\n.....\n\n25\n\n\n3.5 \t Voice Criteria - Method E\n\nDifference of Power Spectra Between Input\n\n...........................\nand Output ......\n\n31\n\n\n3.6 \tVoice Criteria - Method F\n\nDigital Method of Determining Speech SNR ......\n\n.....\n\n35\n\n\n3.7 \t Voice Criteria - Method G\n\nBit-by-Bit Comparison of Input and Output Tapes..\n\n.\n\n. .40\n\n\nCross Correlation of Input and Output .......\n\n3.8\n\nVideo Criteria - Method A\n\nVideo Signal to Noise Ratio Measurement Using\n\n...\n......... ...\na Weighted Noise Concept .......\n\n3.9 \t Video Criteria - Method B\n\nCross Correlation of Input and Output .....\n\n..\n\n44\n\n\n...... 51\n\n\n3.10 Video Criteria - Method C\n\nEqual Importance Frequency Bands ......\n\n...\n\n.....\n\n3.11 Video Criteria - Method D\n\nMean Squared Error of Input and Output Spectra ......\n\n53\n\n56\n\n\n3.12 Video Criteria - Method E\n\nBit-by-Bit Comparison of Input and Output .....\n\n...\n\n58\n\n\nCONTENTS (Continued)\n\nPage\n\n3.13 \t Digital Data Systems Criteria - Method A\n\n.\n........ ...\n 60\n\nBit-by-Bit Comparison ...... ...\n3.14 \tDigital Data Criteria - Method B\n\nPseudo-Error Extrapolation .........\n\n63\n\n\n............\n\n4. COMPARISON OF CANDIDATE SYSTEMS ..........\n\n..........\n\n69\n\n\n4.1\n\nRating of Comparison Parameters ...........\n\n....\n\n69\n\n\n4.2\n\nWeighting of Comparison Parameters ..........\n\n....\n\n70\n\n\n5.1\n\nGeneral Considerations ......\n\n5.2\n\nVoice Systems ...................\n\n5.3\n\nVideo Systems ........\n\n5.4\n\nData Systems ......\n\n5.5\n\nRecommendattions ..................\n\n.......\n\n.....\n\n....\n\n......\n\n.........\n...\n....\n...\n\nii\n\n\n75\n\n\n....\n\n................. \t\n\n6. REFERENCES . ....................... \t\n\n75\n\n\n.... ......\n\n5. SUMMARY AND CONCLUSIONS ...........\n\n76\n\n76\n\n76\n\n77\n\n78\n\n\nILLUSTRATIONS\n\nPage\n\n1. Normal Voice Spectrum ......\n\n...\n\n2. Voice Criteria - Method A\n\nArticulation Index ......\n\n....\n\n.. ..........\n....\n...................\n\n9\n\n\n3. Intelligibility Versus Articulation Index .....\n\n..\n\n...\n\n.I..11\n\n\n.......\n\n4. Word Intelligibility as a Function of Average S/N .....\n5. \t\nVoice Criteria - Method B\n\nArticulation Index ......\n\n....\n\n.....\n\n6. Voice Criteria - Method C\n\nSpeech SNR - Analog Method of Identification ......\n\n16\n\n\n...\n\n..\n\n21\n\n\n.....\n\n7. \t\nExample of Analog and Digital Printer Output\n\n..............\n. ........\n.\n(Reference 3).\n\n9. Voice Criteria - Method E\n\nMean Squared Error ......\n\n13\n\n\n...........\n\n8. Measurement of the Performance Parameter R ..\n\n7\n\n\n..\n...\n\n23\n\n\n...........\n....\n\n28\n\n\n..................\n\n32\n\n\n10. \t Voice Criteria - Method F\n\nDigital Determination of Speech SNR .....\n\n.. ...\n\n.....\n\n36\n\n\n11. \t Voice Criteria - Method G\n\nBit-by-Bit Comparison ......\n\n..\n\n....\n\n..........\n\n12. \t Video Criteria - Method A\n\nPicture SNR Using Weighted Noise ......\n\n....\n\n.........\n\n13.\n\nQuality Scales in Terms of Impairment ...\n\n14.\n\nNoise Weighting Curves ......\n\n...\n\n...\n\n...\n\n17. \t Digital Data Criteria - Method B\n\nPseudo-Error Rate Extrapolation ......\n\n....\n\n54\n\n\n.............\n..\n\n61\n\n\n............\n\n65\n\n\n18. \t Plot of Pseudo Error Rate (PP) versus Threshold Parameter\n\nK compared to plot of Actual Error Rate (Pe) versus SNR\n\niii\n\n\n46\n\n\n............ \n 48\n\n...\n\n15. \t Frequency Composition of 500 kHz Bands of Random\n\nInterference Centered at Various Video Frequencies ....\n16. \t Digital Data Criteria - Method A\n\nBER by Bit-by-Bit Comparison ......\n\n45\n\n\n.............. ...\n\n..\n\n41\n\n\n.\n\n.\n\n.\n\n66\n\n\nTABLES\n\nPage\n\n.........\n\n6\n\n\n1. Equal Importance Bands for Normal Speech ......\n\n..\n\n2. Criteria Evaluation Weighted Parameters .....\n\n............\n\n73\n\n\n.....\n...........\n\n74\n\n\n3. Criteria Evaluation Unweighted Parameters ..\n\niv\n\n\n1. INTRODUCTION\n\nThe purpose of this technical memorandum is to describe and evaluate\n\nseveral methods of specifying performance criteria for voice, video, and\n\ndigital data systems.\n\nThe selection of a specific criteria for use in\n\n\nevaluating a given system is highly dependent on the detailed nature of\n\nthe system under test.\n\nConsequently, it has not been possible in the work\n\n\ndescribed in this memorandum to make a definitive selection of criteria for\n\nuse in each of the three general system categories considered.\n\nHowever,\n\n\nit has been possible to determine, for each category some general charac\xc2\xad\nteristics which are common to most systems considered. These characteris\xc2\xad\ntics were used to arrive at particular choices for test criteria in each\n\nsystem category.\n\nThe method employed is to propose several candidate\n\n\nevaluation systems in each category, and make an evaluation of each system\n\nbased on a number of parameters.\n\nThese parameters include precision of\n\n\ntest data, conciseness of results, required data reduction, pertinence to\n\nactual system performance, and ease of simulation.\nis assigned a relative weighting value.\n\nEach of these parameters\n\n\nIn order to evaluate the candidate\n\n\nsystems, the factors affecting each of the performance parameters of each\n\nof the candidate systems are listed, and a numerical rating value is assigned\n\nto each.\n\nBy this procedure an overall score for each of the candidate\n\n\nsystems is achieved which will provide the basis for recommendations con\xc2\xad\ncerning these methods of specifying performance criteria.\n\nBefore these\n\n\ncriteria are applied in the evaluation of a specific system, the numerical\n\nratings assigned in the trade-off matrix should be re-examined to determine\n\nif the more detailed information available is sufficient to warrant the\n\nselection of a different test criteria.\n\n\nI1\n\n\n2. METHODS OF SPECIFYING PERFORMANCE CRITERIA\n\nJudgement of performance of a communication system depends upon a\n\nsubjective evaluation in most cases (what is the message, how good is the\n\npicture, what is the data).\n\nEven though it is sometimes possible to express\n\n\nthese evaluations in numbers (word intelligibility for voice systems, pic\xc2\xad\nture quality rating for video) it is usually simpler and easier to measure\n\nphysical quantities and to attempt to determine a calibration relationship\n\nbetween these quantities and subjective ratings.\n\nSince the amplitude and\n\n\nfrequency distribution of both the desired signal and noise introduced by\n\nthe system under consideration have obvious bearing of the performance of\n\nthe system, the idea of a signal-to-noise ratio is inherent in most criteria,\n\neither explicitly or implicitly.\n\nBecause of the non-linear response of\n\n\nthe human sensory organs to amplitude-frequency and amplitude-time relation\xc2\xad\nships, and to the redundancy inherent in many systems, methods other than\n\naverage signal-to-noise ratios are often employed.\n\nMethods listed in this\n\n\nmemo include:\n\nMethods based on frequency considerations\n\nWeighted signal concept (articulation indices for voice, equal\n\nimportance bands for video)\n\nWeighted noise concept (video SNR)\n\nMean squared difference of input and output spectra (voice and video)\n\nMethods based on amplitude-time considerations\n\nAnalog and digital methods of computing speech SNR\n\nCross-correlation techniques - (Voice and video)\n\n\n2\n\n\nMethods based on statistical counting of errors (digital data)\n\nBit-by-bit counting to determine BER\n\nExtrapolation of pseudo-error rates\n\n\n3\n\n\n3. CANDIDATE CRITERIA SYSTEMS\n\n\nSection 3 contains a brief description of the systems considered as\n\nmeans of specifying performance criteria for voice, video, and television.\n\nMost of them represent well established principles.\n\nAn attempt has been made\n\n\nto suggest possible means of mechanization with the intention of simplifying test\n\nprocedures and data reduction.\n\nAt least one method, method B for television,\n\n\nrepresents an unproven principle - that video signals can be separated into\n\nfrequency bands having equal subjective importance to the viewer, in a manner\n\nsimilar to the principle involved in determining the articulation index of\n\na voice system.\n\nThe discussion of each candidate system includes a description of the\n\nmethod involved in mechanizing the test and computing the criteria, a simpli\xc2\xad\nfied block diagram of the process, and a listing of the factors considered\n\nin assigning a numerical rating for each system for each of the five parameters\n\nused in Section 4 to compare the candidate systems.\n\nTwo of the candidate systems, Methods C and F for determining speech SNR\n\nfor voice systems have been developed and tested under NASA MSC direction by\n\nthe Philco-Ford corporation. (Reference 3 and 5).\n\n\n4\n\n\n3.1 \t Voice Criteria - Method A Determination of Articulation Index\n\nof Output\n\nThe use of the articulation index (AI) as a means of relating articulation\n\ntesting to more easily measured physical quantities such as signal to noise\n\nratios has been the subject of interest, research, and testing for a long\n\nperiod of time (Reference 1).\n\nSince it is based on the spectral distribution\n\n\nof both speech signal and noise, it tends to be a more accurate method of\n\ndescribing voice quality than an average signal-to-noise value taken over the\n\nentire voice band (Reference 1).\n\nThe concept of Al is based on experimental evidence which has shown that\n\nnormal speech siqnals can be divided into a number of frequency bands such\n\nthat the speech information in each band has an equal effect on the overall\n\nintelligibility (Reference 1).\n\nA list of these "equal importance" frequency\n\n\nbands is given in Table I. It has also Eeen established that numbers repre\xc2\xad\nsenting the articulation values or each band can be considered as probabilities\n\n(Reference 10).\n\nThus, the overall articulation can be represented as the\n\n\nproduct of the individual articulation values of each band.\n\nThis fact allows\n\n\nus to define AI (in Step I of Method A given below) as the sum of the weighted\n\nsignal-to-noise ratios of each band (wi), since they are expressed as decibels.\n\nSince the composition of the "equal importance" frequency bands was\n\ndetermined using real speech, any mechanization of the AI method using a\n\nsubstitute for real speech should employ weighting factors experimentally\n\ndetermined to be representative of real speech.\n\nSuch a curve, shown in Figure\n\n\n1, should be used in Method B, an alternate means of determining AI using\n\ndiscrete input frequencies.\n\n\n5\n\n\nTable 1\n\nEqual Importance Bands for Normal Speech\n\n\nArticulation\nBand Number\n\nFrequency\nRange in Hz\n\nBandwidth\n\nin Hz\n\n\n1\n\n200 - 330\n\n130\n\n\n2\n\n330 - 430\n\n100\n\n\n3\n\n430 - 560\n\n130\n\n\n4\n\n560 - 700\n\n140\n\n\n5\n\n700 - 840\n\n140\n\n\n6\n\n840 - 1000\n\n160\n\n\n7\n\n1000 - 1150\n\n150\n\n\n8\n\n1150 - 1310\n\n160\n\n\n9\n\n1310 - 1480\n\n170\n\n\n10\n\n1480 - 1660\n\n180\n\n\n11\n\n1660 - 1830\n\n170\n\n\n12\n\n1830 - 2020\n\n190\n\n\n13\n\n2020 - 2240\n\n220\n\n\n14\n\n2240 - 2500\n\n260\n\n\n15\n\n2500 - 2820\n\n320\n\n\n16\n\n2820 - 3200\n\n380\n\n\n17\n\n3200 - 3650\n\n450\n\n\n18\n\n3650 - 4250\n\n600\n\n\n19\n\n4250 - 5050\n\n800\n\n\n20\n\n5050 - 6100\n\n1050\n\n\n6\n\n\no\n\n30\n-2\n\nHill\n\n-40\n\n0.1\n\n0.5\n\n1.0\n\n2.0\n\n3.0 4.0 5.06.0\n\nI7 1\nFrequency in kHz\nNorma] Voice Spectrum\n\nFigure 1\n\ntl\n\nl\n\nMethod A described below is a method of mechanizing the testing to\n\ndetermine the Al of a voice communication system.\n\nA block diagram is shown\n\n\nin Figure 2.\n\n\n3.1.1\n\nDescription of Method\n\nA. The input tape is composed of a standard phonetically balanced word\n\nlist scored for word intelligibility.\n\nB. \t\nModulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. The input tape signal is fed into a variable equalizer to\n\nmatch the magnitude, IA(e)I, and phase, 4(m), of the system under test.\n\nD. The output signal S is fed through switch Sl to a difference net\xc2\xad\nwork, to which the output S+N from the system under test is also\n\napplied.\n\nE. In switch position 1, only the output S+Al from the system under test\n\nis fed to the difference network, resulting in an output S+N.\n\nF. \t switch position 2, both the matched output S and the output S+N\n\nIn\nare fed to the difference network resulting in N, the system\n\nnoise, as an output.\n\nG. The output of the difference network is applied to an RMS meter to\n\nread the S+N and N values in order to compute an overall S/N ratio.\n\nH. \t\nThe output is also sent in parallel to 20 bandpass filters\n\ncorresponding to the equal importance bands of the articulation\n\nindex.\n\nThe S/N ratio of each band is then computed, and the\n\n\nweighting functions wi determined for each band as indicated below.\n\n\n8\n\n\nEQUAL IMPORTANCE BANDS\nSPEECH\nTAPE\nINPUT\n\nMODULATOR\nAND\nRF SOURCE\n\nRF LINK SIMULATOR\nATTENUATOR, NOISE,\nPROPAGATION\nEFFECTS\n\nSYSTEM\nUNDER\nTEST\n\n(S+N), N1\n\n4(S+N)2\n2, N\n\nI\n\nVARIABLE EQUALIZER TO\nSCHARACTERISTICS OF\nkoSUBJECT\n\nS+N\n1\n\n(S+N)N\n\n0\nLMTROWRM\n\nUNDER TEST\n\nVOICE CRITERIA - METHOD A\n\nARTICULATION INDEX\n\nFigure 2\n\n,\n\nNN\n\nThe weighting functions wi applied to each equal importance\n\nfrequency band depend on the observation that if the SNR in a par\xc2\xad\nticular band is less than -12 dB, the effect of that band on the\n\noverall articulation index (AI) can be disregarded, and also that\n\nthe effect of increasing the SNR in a particular band beyond +18 dB\n\nhas no addition affect. For each band the values of SNR between\n\n-12 dB and +18 dB have a linear effect on AI, resulting in the\n\nvalues of wi given below.\n\nUse of this method results in a value\n\n\nof AI which never exceeds 1 (corresponding to a word intelligibility\n\nscore of 100%).\n\nwi = 0\n\nif (S/N) i < - 12 dB\n\n\n(S/N) i\nWi\n\n\xc2\xb1\n\n12\n\nif - 12 dB C (S/N)\n\n=\n\n30\n\nwi = 1\n\ni\n\n< 18 dB\n\n(1)\n\nif (S/N) i > 18dB\n\nI. The articulation index (AI) is then computed\n\nN\n\n\nN IL\n\nwi\n\n(2)\n\nwhere N = number of articulation bands in the pass band of the\n\nsystem under test.\n\nN = 20 for the band pass of the normal speech\n\n\nranging from 200 to 6,100 Hz.\n\nJ. The Al is converted to word intelligibility (WI) by means of an\n\nempirical relationship determined by subjective testing. Such a\n\nrelationship is controlled by the word list used in preparing the\n\ninput tape. An example of this type of relationship is shown in\n\nFigure 3.\n\n10\n\n\n500 WORDS\n100\n\n256 WORDSj\n\nI-o\n80\n\n60\n\nSYLLABLES\n\n\n-\n\n\xc2\xad\n\n(,\n\nLU\n\n40\n\n20\n\n40\n\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\nARTICULATION INDEX, A\n\nFigure 3. Intelligibility Versus Articulation Index\n\n\n11\n\n\n0.I0\n\n\nK. The overall S/N ratio computed in Step G could also be converted\n\nto WI by an appropriately developed empirical relationship as\n\nshown in Figure 4.\n\n\n3.1.2 \t Discussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nThe following factors affecting precision of data were considered in\n\ndetermining the rating for Parameter One:\n\nA. \t\nPrecision of equal importance band filters\n\nB. Precision of measurement of individual SNR\'s in\n\nequal importance bands\n\nC. \t\nPrecision of amplitude and phase comparisons in\n\nvariable equalizer\n\nD. \t\nPrecision of difference circuit (Sfrom S+N)\n\nE. \t\nPrecision of RMS meters in individual S+N circuits\n\nF. \t\nPrecision of calculations of AI and WI\n\nG. \t\nPrecision of relationship of WI versus SNR\n\nH. \t\nPrecision of data reduction\n\n\nParameter Two - Conciseness of Results\n\nThis method results in a single criteria value, the articulation\n\nindex (AI), which is a weighted average of SNR\'s calculated for\n\na number of "equal importance" frequency bands within the speech\n\npass band.\n\nThe Al value must be converted to percent word intel\xc2\xad\n\nligibility (WI) by means of empirical relationships previously\n\ndetermined by performing standard WI tests on audio outputs and\n\ncomparing the results to the AI.\n\n\n12\n\n\n100\n\nso\n\n0\n\n0\n\nI-\xc2\xad\n\nz\n\n0\n\n-20\n\n-10\n\n0\n\n10\n\n20\n\nAVERAGE (\'-)IN dB\n\nFigure 4.\n\nWord Intelligibility as a Function of\nAverage S/N\n\n13\n\n30\n\nParameter Three - Data Reduction Required\n\nManual recording and calculation of the S+N/N ratios for up to 20\n\nequal importance bands for each test calculation of AI are required.\n\nConversion to WI is made by reference to calibration curves.\n\n\nParameter Four - Relationship to Actual System Performance\n\nMethods based on AI should show excellent relationship to actual\n\nsystem performance based on a long history of experimentation and\n\nuse.\n\nAreas of concern include the accuracy of the variable equalizer\n\n\nin matching IA(w)I and 4(m) of input and output.\n\n\nParameter Five - Ease of Mechanization\n\nMethod A would require hardware development of the variable equalizer\n\nused to match the amplitude and phase characteristics of the subject\n\nunder test.\n\nNo computer use would be required.\n\n\n14\n\n\n3.2\n\nVoice Criteria - Method B Determination of Articulation Index Using\n\nDiscrete Input Frequencies\n\n\nMethod B is a variation of the method for mechanizing the articulation\n\nindex testinq in which the input voice tape is replaced by a series of discrete\n\nfrequencies centered in each of the "equal importance" frequency bands.\n\nSuch\n\n\na system should be easier to implement since the requirement for an equalizer\n\nto match the input and output would not exist.\n\nThis method is suggested by\n\n\nreferences to "Test Tone SNR" contained in a draft document of a CCIR study\n\ngroup (Reference 2).\n\n3.2.1\n\nA block diagram is shown in Figure 5.\n\n\nDescription of Method\n\nA. \t\nThe input to the equipment under test consists of a series of single\n\nfrequencies centered in each.of the "equal importance" frequency\n\nbands.\n\nThe amplitudes of the signal frequecies would be adjusted\n\n\nrelative to each other in order to conform with a standard speech\n\nfrequency distribution.\n\nB. Modulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. A wave analyzer is used to measure the signal power of each of the\n\ncenter frequencies of the equal importance bands.\n\nSince the filter\n\n\ncharacteristics of the analyzer can be very sharp, only a small\n\namount of broad-band system noise will be measured, resulting in\n\nmeasuring only signal power.\n\nD. Signal plus noise (S+N) for each of the equal importance bands is\n\nmeasured using filters with the proper response for each band.\n\n\n15\n\n\nEQUAL IMPORTANCE BANDS\n\n1,\n\n-_(S+N)\n\nSINE WAVE\nGENERATORS\nCENTERED AT\nEQUAL IMPOR-\n\nTANCE BANDS\n\nMODULATOR\nAND\nRF SOURCE\n\nRF LINK SIMULATOR\nATTENUATORS, PRO-\n\nSYSTEM\nUNDER\nTEST\n\n(S+N)\n\nS1\n\nSN\n\nPAGATION EFFECTS,\n\nNOISE\nRMS\nPOWER\nMETER\n\nVOICE CRITERIA - METHOD B\n\nARTICULATION INDEX\n\nFigure 5\n\n\nS+N, S\n\nE. The S/N ratio of each band is then computed from the signal and\n\nsignal plus noise measured in steps C and D, and weighting functions\n\nderived:\n\nWi = 0 if (S/N)i < -12 dB\n\n_(S/N) i + 12\n=\n30\nif -12 dB < (S/N)i < 18 dB\n\n(3)\n\nW, = 1 if (S/N)I > 18 dB\n\n\t\nF. \t\nThe articulation index (AI) is then computed\n\nAI =\n\nwhere N\n\n=\n\nk\n\nN\ni\n\n(4)\n\nthe number of equal importance articulation bands in\nthe pass band of the system under test.\n\nN\n\n=\n\n20 for the band pass of normal speech ranging from 200 Hz\nto 6100 Hz.\n\nG. \t\nThe AI can then be converted to word intelligibility (WI) by means\n\nof an empirical relationship.\n\nSince the WI versus AI characteristic\n\n\ndepends upon the length of the word list used, determination of WI\n\nwould require subjective testinq of the system using standard word\n\nlists and techniques such as those developed by the U.S. Standards\n\nAssociation.\n\nThe WI would be determined using the same average\n\n\nSNR as was used in determining the AI.\n\nA relationship between the\n\n\ntest signal AI and WI would thus be determined for one value of\n\naverage SNR.\n\nH. \t\nDetermination of test signal AI for several different average SNR\'s\n\ncould also be determined, and conversion into WI could be accom\xc2\xad\nplished using methods indicated in Step G, resulting in a calibra\xc2\xad\ntion curve.\n\n17\n\n\n3.2.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nThe followinq factors affecting precision of test data were\n\nconsidered in determining the rating of Parameter One:\n\n1. Precision of test sine wave generators used as input.\n\n2. Precision of equal importance band filters.\n\n3. Precision of RMS meters used to measure S+N and S.\n\n4. Precision of calculations of AI and WI.\n\n5. Precision of relationship of WI versus SNR.\n\n6. Precision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nSince the difference between Method A and Method B is in the\n\nmethod of obtaining the individual SNR\'s for each equal importance\n\nband, the same considerations for Parameter Two of Method A are\n\napplicable to Method B.\n\n\nParameter Three - Data Reduction Required\n\nManual recording and calculation or S+N/N ratios are required for\n\nup to 20 equal importnace bands for each test calculation of Al.\n\nConversion to WI is also required.\n\n\nParameter Four - Relationship to Actual System Performance\n\nResults of this method should approach those of Method A. Un\xc2\xad\nknown is the effect of using the single line spectra centered in\n\nthe equal importance bands instead of using a typical voice\n\nresponse over each band.\n\n\n18\n\n\nParameter Five - Ease of Mechanization\n\n\nMethod B would require little hardware development and no\n\ncomputer use.\n\n\n19\n\n\n3.3\n\nVoice Criteria - Method C\n\nDevelopment of Speech-to-Noise Ratio Using Analog\n\nMeasurements\n\n\nThe unique feature of Method C is the method of identifying speech in\n\nthe presence of noise, based on the identification of the soeech plus noise\n\nand noise only segments of an analog record.\n\nThese analcq records are used\n\n\nto separate and identify the corresponding binary coded decimal (BCD) print\xc2\xad\nouts of a digital voltmeter used to integrate the instantaneous squared wave\xc2\xad\nform of the voice input.\n\nThe BCD values of speech plus noise and noise only\n\n\nare then averaged to produce a speech to noise ratio.\n\nThis method was\n\n\ndevloped under NASA MSC direction by the Philco Ford Corporation (Reference 3).\n\n\n3.3.1\n\nDescription of Method\n\nA. \t\nThis method is based on the ability of recognizing vowel sounds\n\nwhich represent approximately 90% of speech power spectrum.\n\nB. \t\nStandard test tape records scored for word intelligibility\n\nwill be used as input.\n\nC. \t\nModulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nD. The output is converted to an instantaneous squared waveform by the\n\ntrue RMS meter; and recorded on a paper recorder.\n\nE. Also, a time averaged output over a pre-selected time interval is\n\nprovided by an integrating digital voltmeter.\n\nF. The digital voltmeter converts the average power in each sample time\n\nto BCD and prints out the decimal values.\n\nAt the same time "print\n\n\ncommands" from the DVM are recorded on the paper tape along with the\n\nsquared analog output.\n\nAn example of the combined analog and digital\n\n20\n\n\nSPEECH\nTAPE\nINPUT\n\nMODULATOR\nRF SOURCE\n\nRF LINK SIMULATOR\nATTENUATOR, NOISE,\nPROPAGATION EFFECTS\n\nTRUE RMS\nMETER\n\nSASTEM\nUNDER\nTEST\n\nMEAN SQUARE DATA\n\nAUDIO\nOUTPUT\n\nDIGITAL\nVOLTMETER\n\nPRINT\nCOMMANDS\n\nANALOG\nRECORDER\n\nVOICE CRITERIA - METHOD C\n\n\nSPEECH SNR - ANALOG METHOD OF IDENTIFICATION\n\n\nFigure 6\n\n\nBCD\nDATA\n\nDIGITAL\nRECORDER\n\nprinter output is shown in Figure 6.\n\nG. The &nalog record is used to time correlate the digital printout of S+N\n\nand N. (To distinguish noise samples from speech + noise samples)\n\nH. \t\nSpeech SNR is then calculated by speech SNR = 10 log\n\n\nP1 = average value of speech + noise\n\n\nP1\n\n2\n\n\nP2 \t average value of noise\n\n=\nI. To determine word intelligibility (WI) versus SNR relationship, several\n\ntapes of different quality will be used as input to the system under test.\n\nThe output take will be scored by a trained listening team for WI, and\n\ncompared to the SNR\'s.\n\n\n3.3.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nFactors Affecting Precision of Data\n\n1. \trecision of true RMS meter\n\nP\n2. \t\nPrecision of BCD output of digital voltmeter\n\n3. \t\nPrecision of relating the time of the BCD "Print Commands"\n\nto analog record of vowel sounds\n\n4. \t\nPrecisionof calculation of SNR\n\n5. \t\nPrecision of WI versus SNR relationship\n\n6. \t\nPrecision of data reduction\n\n\nParameter Two - Conciseness of Results\n\nThis method results in an average of speech SNR\'s taken over a\n\nnumber of time increments.\n\nThis average SNR must be converted\n\n\nto percent WI by means of empirical relationships determined by\n\nstandard word intelligibility tests.\n\n\n22\n\n\n-4\n\n2 002764i.\n2 002794\n2 002684\n2 037634\n\nM\n\n2 104844\n\na\n\n2 190774\n\n,uJ x\n\n-h\n\n(D \'0\n\n((\n\n\xe2\x80\xa2,\nI\n\n2 039704\n\nn o\n\n!\n\n2 002604\n2 002584\xc2\xad\n2 002454\n\nO,\n\nC2\n\n(D\n\nC\nC+\n\n2 066054\xc2\xad\n2 1297942 200654\n022234\n2 002634\n2 002674\n2 002624\n2 050014\n2 151204\n2 164884\n\nrC\n\nK\n\n\'.\n\n""\n-\xc2\xad\n\nParameter Three - Data Reduction Required\n\nThis method requires manual determination of S+N and N intervals\n\nby comparison of DVM "print commands" with analog data, averaging\n\nof the BCD values for each of the intervals, determination of overall\n\naverage of S+N and for N, and calculation of speech SNR.\n\nCorrelation\n\n\nof SPNR with WI would require calibration curves produced by sub\xc2\xad\njective testinq.\n\n\nParameter Four - Relationship to Actual System Performance\n\nUse of input speech tapes which have been scored for WI and for\n\nwhich test data on WI-SPNR (speech power to noise ratio) relation\xc2\xad\nships have .already been developed should produce results which\n\nsimulate actual system performance very closely for noise dis\xc2\xad\ntributed over the voice band.\n\nNoise concentrated in the high end\n\n\nof the speech band would tend to produce lower WI scores than\n\nshould be expected in actual practice.\n\n\nParameter Five - Ease of Mechanization Voice Systems\n\nMethod C would require no hardware development but considerable\n\nmanual data reduction.\n\n\n24\n\n\n3.4\n\nVoice Criteria - Method D\n\nCross Correlation of Input and Output\n\n\nOne method of assessing overall system performance is to measure\n\nhow well the system input and output functions are correlated\n4).\n\n(Reference\n\n\nMore specifically, the cross correlation function, Rxy(T),\n\n\ndefined by\n\nT\n\nRxy()\n\nX (t\n\n=\n\n+ r) y(t) dt\n\n(5)\n\n0\n\n\nwhere x(t) is the system input and y(t) is the system output, can be\n\nused as a measure of system performance.\nwith the delay,\n\nT,\n\nThe value of RXY(T)-varies\n\n\nreaching its maximum value when the value of\n\napproximates the delay through the system under test.\n\nT\n\n\nSince the presence\n\n\nof a fixed delay in a transmission system generally causes no degradation\n\nof the transmitted information, only the maximum value of Rxy(T) Is\n\nneeded to rate system performance.\n\nIf the cross correlation function\n\n\ndefined by Equation (5) is normalized by diiiding by the geometric mean\n\nof the mean square values of the input and output signals, the maximum\n\nvalue of the normalized correlation function is confined to the\n\nrange - <p xy(T) < 1. The quantity, R, needed to specify performance\nis given by\n\n\nR = I\n\nxy\n\nimax\nIR\nxy\n(r)Imx\nmRaxXX (0)Ry(0)\n\n\nand is confined to the range 0 < R < 1.\n\n\n25\n\n\n(6)\n\nThe quantities Rxx(0) and Ryy(0) are the autocorrelation functions\n\nof the input and output signals evaluated at\n\nT\n\n= 0, and are equal to\n\n\nthe meansquare values of input and output signals respectively.\n\nIf\n\n\nthe system under test provides distortionless transmission, the output,\n\ny(t), is simply a delayed version of the input, x(t), i.e.,\n\n\ny(t) = Kx(t + -)\nThen from Equation (2)\n\nIK ]_T x(t+r) x(t+r) dt max\nR:\n\nt)dtjfK2\nJfTXt) x(\n\n2\nK fT [x(t + r)] dt\n\no=\n\nf\xc2\xa7 (t)\n\ndt]\nx(t)\n\n(7)\n\n\n1\n\nKJoT Ex(t)] 2dt\n\n\nIf, on the other hand, the system output, y(t), were pure noise when\n\na deterministic x(t) was used as a system input, then\n\ny(t) = Kn(t),\n\n\nKIJT x(t + r) n(t) drlmax\n\nand\nR =\n\nK\n\nRxx(0)\n\nRnn(0)\n\nbut\n\n\nfoTx(t + r) n(t) dr-.--0\n\n26\n\n\nfor large T\n\n\nConsequently, R---O\n\nThe block diagram of Figure (8)outlines one method of implementing\n\nthe normalized correlation coefficient measurement for a receiving\n\nsystem for voice transmission.\n\n3.4.1\n\nDescription of Method\n\nA. \t\nThe input tape is composed of a phonetically balanced word list\n\nscored for percent word intelligibility.\n\nB. \t\nModulation, RF source and RF link simulation are determined by\n\nthe \t ystem under test.\n\ns\nC. The input tape signal, x(t), and the system output signal, y(t),\n\nare fed to the correlation coefficient computer if the test is\n\nbeing made in real time.\n\nOtherwise, the two signals, x(t) and y(t),\n\n\nare recorded for off-line processing at a later time.\n\nD. \t\nThe value of the performance parameter, R, is obtained from the\n\ncomputation of the normalized cross correlation function.\n\nE. This value of R is used to determine a corresponding value of the\n\nArticulation Index, AI, from a calibration curve which has been\n\npreviously determined by experiment.\n\nF. \the value of AI is converted to percent Word Intelligibility by\n\nT\nmeans of the standard calibration curve already determined\n\n\'by subjective testing for the particular type and length\n\nof word list used on the input voice tape.\n\n\n3.4.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nThe precision of the test data obtained by the cross correla\xc2\xad\ntion \t\nmethod hinges primarily on two factors.\n\n27\n\n\nThey are first,\n\n\nSPEECH\nTAPE\nINPUT\n\nMODULATOR\nAND\nRF SOURCE\n\nRF LINK SIMULATOR,\nATTENUTATION, NOISE,\nPROPAGATION EFFECTS\n\nSYSTEM\nUNDER\nTEST\n\nI--y(t)\n\nI x(t)\nCOMPUTE\n-\n\nRxy (7)\n\nCALCULATE R\n"\n\nCROSS CORRELATION,\n\nICOMPUTE\n\ny(t) 2\n\nx(t) 2\nCOMPUTE\n\nNORMALIZE\n\nFigure 8. Measurement of the Performance Parameter R\n\n\nthe length of the integration time used in evaluating the cross\n\ncorrelation integral and second, the precision with which the\n\nexperimental relationship between Al and R can be determined\n\nand repeated.\n\nThe length of the integration time determines the degree to\n\nwhich the effects of system noise perturb the computed value of\n\nR. As long as this time interval is long with respect to the\n\ncoherence time of the system noise, these perturbations will\n\nbe small.\n\nSince the coherence time is of the order of the\n\n\nreciprocal of the system bandwidth, B, the integration time,\n\nT, should meet the criterion\n\nT >> I\nB\nThe accuracy with which the connection between Al and R can\n\nbe established is difficult to assess without having sufficient\n\nexperimental data on which to base an accuracy estimate.\n\n\nParameter Two - Conciseness of Results\n\nThe provision of a single parameter, R, to describe the system\n\nperformance under a fixed set of conditions is highly concise.\n\n\nParameter Three - Data Reduction Required\n\nIf the output data is considered to be the parameter R, then\n\nthe only data reduction required is the translation of this\n\noutput R data into the corresponding Al or percent word intel\xc2\xad\nligibility data.\n\n\n29\n\n\nParameter Four - Relationship to Actual System Performance\n\nThe lack of experimental data on the use of this technique\n\nmakes it difficult to determine whether or not the parameter\n\nR is one-to-one related to actual system performance as deter\xc2\xad\nmined by subjective listener testing.\n\n\nParameter Five - Ease of Mechanization\n\nThe current availability of commercial equipment with the\n\ncapability to compute correlation functions indicates that\n\nthe measurement of the parameter, R, could be readily mechanized.\n\nThe use of tape recording with subsequent computer processing\n\nof the recorded input and output signals offers an alternate\n\nmethod of obtaining data on R.\n\n\n30\n\n\n3.5\n\nVoice Criteria - Method E\n\nDifference of Power Spectra Between Input\n\nand Output\n\n\nThis method is based on the fact that the essential intelligence of\n\nspeech signals is contained in the-short term running power spectrum.\n\nThe\n\n\ncriterion used therefore is a measure of the mean squared error between the\n\ninput and output power spectra of the system under test.\n\nThe input and output\n\n\ntapes are converted to digital form, accumulated over a specified time period,\n\nsubjected to a Fourier transform routine, and compared in a difference circuit.\n\nThe output error is then squared and accumulated at the end of each test word.\n\nThe average of the accumulated errors is the evaluation criterion.\n\n\n3.5.1\n\nDescription of Method\n\nStandard voice test tapes scored for word intelligibility are used\n\nA. \t\nas the input.\n\nB. \todulation, RF source and RF link simulation are determined by the\n\nM\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\'\n\nC. The tape recording of the output of the system under test is con\xc2\xad\nverted into digital form by an analog-to-digital converter, stored\n\nin a computer and examined in short time blocks; subjected to a\n\nFourier transform routine to compute the power spectra of each\n\nblock, and compared to the power spectra of the input tape processed\n\nby a similar routine.\n\nD. \t\nThe difference between the input and output spectra is squared and\n\naccumulated for each test word.\ncriteria for voice quality.\n\n\n31\n\n\nThe average difference is the\n\n\nA\'D CONVERTER \n\nAND BUFFER \n\n\nA/D CONVERTER\nAND BUFFER\n\nDATA BLOCKS \n\n\nTAPE RECORDER\n\nCOMPUTE FOURIER \n\nTRANSFORM\n\n\nDATA BUFFER\n\nSTORE SPECTRUM \n\nOF T SEC BLOCKS \n\n\nDATAPLOCK\n\nT SEC. LONGI\n\n\nDIFFERENCE\n\nFORT\n\nSQUARE\n\nACCUMULATE\n\n.EVALUATION\nOUTPUT\n\nVOICE CRITERIA - METHOD E\n\nMEAN SQUARED ERROR\n\nSEC LONG\n\nE. To relate to word intelligibility, the output tape would also be\n\nscored by an experimental test team.\n\nSeveral different tapes would\n\n\nbe used as inputs, and the output word intelligibility for each would\n\nbe plotted as a function of the differences of the power spectra,\n\nproviding a calibration curve.\n\n3.5.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nFactors Affecting Precision\n\n1. \t\nPrecision of A-D conversions\n\n2. Precision of Fourier transformer routine in computing\n\npower spectra of input and output\n\n3. \t\nPrecision of difference and squaring routing of input and\n\noutput power spectra\n\n4. \t\nPrecision of WI versus power spectra relationship\n\n\nParameter Two - Conciseness of Results\n\nThis method results in an average of squared differences between\n\ninput and output power spectra.\n\nSince no known relationship between\n\n\nthis criteria value and percent WI exists, this relationship would\n\nhave to be determined by testing using evaluation teams to score\n\nthe output tapes.\n\n\nParameter Three - Data Reduction Required\n\nThe input and output digital data are stored in computer and\n\nexamined in short blocks.\n\nThe blocks are processed by a Fourier\n\n\ntransform routine, the difference of the input and output power\n\nspectra thus produced is squared and accumulated as a measure of\n\nvoice quality.\n\nIntially, analog output tapes must be scored for\n\n33\n\n\nWI by subjective testing to provide calibration of the quality\n\nrating.\n\nFurther signal conditioning will probably be necessary to\n\n\nprovide means for compensating for system time delay and level\n\nshifts through the system.\n\n\nParameter Four - Relationship to Actual System Performance\n\nAssuming that sufficient quanti zing levels are employed in the A/D\n\nprocess to insure that quantizing noise is small with respect\n\nto the system noise, this method should produce acceptable\n\nresults.\n\nSince the spectral content of the speech and noise are\n\n\nconsidered in the process, the problem concerning noise concentrated\n\nin the high end of the speech band should be minimized.\n\n\nParameter Five - Ease of Mechanization\n\nMethod E would possibly require some hardware development, and\n\nconsiderable computer programming and \'use.\n\n\n34\n\n\n3.6\n\nVoice Criteria - Method F\n\nDigital Method of Determining Speech SNR\n\n\nMethod F is based on the fact that vowel sounds are much longer and\n\nstronger than consonants.\n\nIt has been estimated that vowels contribute over\n\n\n90 percent of the total power spectrum of speech.\n\nUse can then be made of\n\n\nthis fact to determine speech to noise ratios if monosyllabic test words-(or\n\nwords spoken so slowly that the syllables can be separated) are used in pre\xc2\xad\nparing input speech tables.\n\nThis method converts the output of the system under test to digital form\n\nand uses a computer routine to separate speech plus voice from the noise that\n\noccurs between words or syllables.\n\nTo effect this separation the following\n\n\nassumptions are made:\n\n\n1. The average power of a vowel plus noise waveform will not deviate\n\nmore than 1 dB throughout the duration of the word or syllable\n\n\n(100 msec minimum to 200 msec maximum)..\n\n2. The average power of the in-between-syllable noise (or in-between\xc2\xad\nword noise) will not deviate more than 1 dB for approximately the\n\nsame time interval as that of a vowel sound.\n\n\nThis method was developed under NASA MSC direction by the Philco Ford\n\nCorporation (Reference 5).\n\n3.6.1\n\nA block diagram is shown in Figure 10.\n\n\nDescription of Method\n\n\nA. Standard voice test tapes scored for WI are used as the input.\n\n\n35\n\n\nSPEECH\nTAPE\nINPUT\n\nMODULATOR\nAND\nRF SOURCE\n\nRF LINK SIMULATOR,\nATTN, PROPAGATION\nEFFECTS, NOISE,\nETC.\n\nSYSTEM\nUNDER\nTEST\n\nAID CONVERTER\n\nCOMPUTER\n\nLINE PRINTER\n\nVOICE CRITERIA - METHOD F\n\nDIGITAL DETERMINATION OF SPEECH SNR\n\nFigure 10\n\n\nANALOG\nOUTPUT\n\nB. Modulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. After analog to digital conversion, the output is applied to a\n\ncomputer with a program designed to mechanize solution of the\n\nproblem and provide the output on a line printer.\n\nD. \t\nThe computer program is based on:\n\n1. \t\nUse of 20 msec as the measurement interval, with the average\n\npower in at least three consecutive intervals being- compared\n\nto be within 1 dB, (each 20 msec interval contains 400 samples\n\nat sample rate of 20K).\n\n2. Three or more consecutive intervals are averaged and placed in\n\nstorage until 50 consecutive intervals have been accumulated.\n\n3. The logic assumes that the smallest value of average power for\n\nthree or more consecutive intervals (which agree within 1 dB)\n\nrepresents noise and this value is taken as a reference level.\n\n4. \t\nAll other values of (three or more consecutive intervals) are\n\ncompared to this reference level.\n\n5. If a value compares within 1 dB of the reference value, it is\n\nconsidered noise for the purpose of computation.\n\n6. If a value is 3 dB or greater than the reference value, it is\n\nconsidered S+N for the purpose of computation.\n\n7. \t\nValues between 1 dB and 3 dB of the reference value are ignored.\n\n8. The mean is calculated for all values of N and for all values of\n\nS+N, thus providing the basis for speech signal-to-noise ratio\n\n(SPNR) computation for each are second interval.\n\nSNR \t (S+N) - N\n\n\nN\n\n37\n\n\nThus, the minimum SPNR is 0 dB and occurs when S+N = 2N.\n\nE. The value of SPNR calculated above are converted to word intelli\xc2\xad\ngibility by producing a system output analog tape for scoring by\n\ntrained observers.\n\nSeveral input tapes of different quality would\n\n\nbe used to produce a SPNR versus WI calibration.\n\n3.6.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nFactors Affecting Precision of Data\n\n1. Validity of assumptions concerning uniformity of average power\n\nfor duration of one word, and for uniformity of power of the\n\n"inbetween syllable" and "in between word" time periods.\n\n2. Precision of analog to digital conversions.\n\n3. Precision of computer program in averaging, sorting, comparing\n\nand calculating speech SNR.\n\n4. Precision of WI versus speech SNR relationship.\n\n5. Precision of data\n\nParameter Two - Conciseness of Results\n\nThis method results in a weighted average of speech SNR\'s determined\n\nfor a number of time increments.\n\nThe weighting is a result of a\n\n\nrather arbitrary differentiation of speech and noise levels.\n\nTo\n\n\nconvert to WI would require test results based on tapes scored for WI.\n\n\nParameter Three - Data Reduction Required\n\nAfter A to D conversion, output tape is processed by a computer\n\nprogram which measures S+N and N by defining as noise the smallest\n\nvalue of consecutive samples whose amplitudes agree within 1 dB,\n\nand as signal + noise the values of consecutive samples whose average\n\n\n38\n\n\nvalue is 3 dB above this base line.\nthe mean SNR.\n\nThe computer routine computes\n\n\nThis SNR must be then converted to WI by comparison\n\n\nto known WI versus SNR-WI relationships.\n\n\nParameter Four - Relationship to Actual System Performance\nGood relation to actual system performance has been demonstrated\nin lab tests.\nare:\n\nSome problem areas that became apparent in testing\n\nsudden shifts in noise levels, and fast continuous speech which can\n\ncause speech SNR (SPNR) errors.\n\nOptimization of test parameters and\n\ncomputer programs should minimize these problems.\n\nParameter Five - Ease of Mechanization\n\nMethod F would require some hardware development, considerable\n\ncomputer use and program development.\n\n\n39\n\n\n3.7 \t Voice Criteria - Method G\n\nBit-by-Bit Comparison of Input and\n\nOutput Tapes\n\n\nThis method is simple in concept in that it merely takes the input and\n\noutput of the system under test, converts them into digital form and\n\ncompares them bit-by-bit to determine the bit-error-rate.\n\nBER versus word\n\n\nintelligibility calibration would have to be made by subjective testing of\n\nthe analog output of the system under test.\n\n\n3.7.1\n\nDescription of Method\n\nA. As a system input, standard voice test tapes of scored for\n\nword intelligibility (WI) will be used.\n\nB. Modulation, RF source and RF link simulation are determined by\n\nthe system under test.\n\nIf test is end-to-end, the modulator\n\n\nand RF source would be replaced with components of the system\n\nunder test.\n\nC. The output of system under test is converted into digital form\n\nby an A/D converter; in addition, an analog tape output is\n\nprovided for comparison.\n\nD. The input is also fed through a delay calibrated to match the\n\nsystem delay to an identical A/D converter.\n\nE. The output of the two A/D converters are compared on a bit-by\xc2\xad\nbit basis and a bit error rate (BER) is calculated.\n\nF. To establish a calibration of \t\nBER versus WI, the output analog\n\ntape would be scored by a trained observer team.\n\nInput tapes\n\n\nof different qualities would be used to produce a BER-WI cali\xc2\xad\nbration curve.\n\n\n40\n\n\nI\nINPUT TAPE\n\nMODULATOR ANALO\n___ SYSTEM \n\nRF\nLINK\n\nSIMULATOR,\nAND\n\nRF SOURCE\n\nATTN, NOISE, ETC.\n\nUNDER\nTEST\n\n\nOUTPUT\n\n\nATDCOVRE\n\n\nTIMING\n\nCOMPARATOR\n\nATTN\n\nVOICE CRITERIA - METHOD G\n\n\nBIT-BY-BIT COMPARISON\n\nFigure 11\n\n\nA TO D CONVERTER\n\n\nBER\n\n\n3.7.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nThe following factors affecting precision of data were considered\n\nin determining the rating for Parameter One:\n\n1. Precision of input tape (amount of "Jitter").\n\n2. Precision of A/D converters.\n\n3. Precision of delay circuit.\n\n4. Precision of comparator circuits.\n\n5. Precision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nThis method results in bit-error-rate (BER) directly.\n\nBER rela\xc2\xad\n\ntion to word intelligibility (WI) would have to be established by\n\nWI testing of analog output and comparison with digital BER.\n\n\nParameter Three - Data Reduction Required\n\nBit-by-bit comparison of input and output tapes would require little\n\ndata reduction since BER is computed directly.\n\nThe bit error rate\n\n\nwould have to be converted to WI by appropriate relationship and\n\ndetermine by WI testing.\n\n\nParameter Four - Relationship to Actual System Performance\n\nBit-by-bit comparison should yield accurate bit error rates (BER),\n\nassuming that problems such as tape jitter are solved.\ndisc recording should help to minimize this problem.\n\nUse of\n\nThe BER-WI\n\n\nrelationship would require subjective testing to provide calibra\xc2\xad\ntion.\n\n\n42\n\n\nParameter Five - Ease of Mechanization\n\nThe principal problem in the bit-by-bit comparison technique is\n\nthat of timing and synchronization, which is complicated by tape\n\nrecorder jitter in the input.\n\nDisc recordings or digital test\n\n\nword generators would help to reduce this problem.\n\n\n43\n\n\n3.8 \t Video Criteria - Method A Video Signal to Noise Ratio Measurement Using\n\na Weighted Noise Concept\n\n\nUse of a noise weighting scheme in determining picture signal-to-noise\n\nratios (SNR) is based on the fact that noise in the lower end of the video\n\nspectrum has a greater effect on picture quality than noise at the upper end\n\nof the spectrum.\n\nMethods using noise weighting have been investigated by\n\n\nseveral groups of researchers such as the International Radio Consultative\n\nCommittee (CCIR), the Electronic Industries Association (EIA), Bell Telephone\n\nLaboratories, the Television Allocation Study Organization (TASO), and the\n\nUnited States Standards Association. This method is described in more detail\n\nin TRW Document No. 17618-HI23-RO-O0, the project technical report covering\n\nphase one of Task 707 (Reference 1).\n\nA graph of weighted SNR versus two\n\n\npicture quality rating scales is shown in Figure 13. Since the noise weighting\n\ncurve is an experimentally determined relationship describing relative video\n\npicture degradation as a function of noise frequency, use of the noise\n\nweighting curve should be applicable to systems which have non-flat video\n\nnoise spectrums as well as to those which have white noise.\n\nFor example,\n\n\nthe noise weighting function should be applicable to frequency modulated\n\ntelevision systems which result in parabolic noise.\n\n\n3.8.1\n\nDescription of \t\nMethod\n\nA. \t video tape or a color slide scanner and selected color slides will\n\nA\nbe used to provide video input to the system under test.\n\nA noise\n\n\ngenerator capable of providing a flat noise spectrum over the video\n\nbandwidth may be used to inject noise into the system either at the\n\ninput or as part of the link simulator.\n\n\n44\n\n\nVIDEO TAPE\nOR COLOR\n\nSCANNER\n\nMODULATOR\nAND\n\nRF LINK SIMULATOR\nATTN, PROPAGATION\n\nRF SOURCE\n\nEFECTS, NOISE, ETC.,\n\nSYSTEM\nUNDER\n\nTV\n\nTEST\n\nFLAT NOISE\nGENERATOR\n\nPEAK\nPEAK SIG\n\nNOISE\nSHAPING\nNETWORK\n\nPM S\nNOISE\n\nVIDEO CRITERIA - METHOD A\n\nPICTURE SNR USING WEIGHTED NOISE\nFigure 12\n\n6\n\n7&Lr \t\n\n6J\n\n7F \n\n\ng5\n\nw\n\n6\n\nI_\n\n1--I\n\n\'\n\n<\n\nBLL LA\n\n2 4 V \'5rI \t\n\nT\n\n./i\n\nit,\n\n__--\t\n\n504\n\n-T\n\n"H,\n\nJ:\n.\n\n-; t:;,lL21,\nI\n\'_ Yf, H2\nIIi\' L\n\n_\n-i,\n:\n\nL.h\n\n\':i--\n\n_\n\no-\t\n\n--\n\n--\n\n--\n\n__\n\n4\n\n5\n\n--\n\n!\n\n",\n\n-\xc2\xad\n\n-- I\n\n025 \t\n\n20\n\n\nSNR IN dB\n\nQuality Scales in Terms of Impairment.\n\nBell Labs \t\n\nTASO (Impairment\n\nComments}\n\n\n1. \t\nNot Perceptible\n\nI. Excellent\n\n\n2. \t\ndust Perceptible\nImpairment\n3. \t\nDefinitely Perceptible\n\nSliciht Impairment\n\n4. \t\nImpairment but not\nObj ecti onable\n5. \t\nSomewhat Objectionable\n\n2. Perceptible\n\nInterference\n\n\n6. \t\nDefinitely 0bjectionable\n7. \t\nExtremely Objectionable\n\nFitiure 13\n\n46\n\n3. Interference not\n\nObjectionabl e\n\n4. Somewhat Objectionable\n\nInterference\n\n5. Definitely Objectionable\n\nInterference\n\n6. Unusable\n\n\nB. \t\nModulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. A noise shaping network at the output will provide noise weighting\n\nin accordance with the noise weighting curve provided by the United\n\nStates Standards Association.\n\nThis curve is shown in Figure 14.\n\n\nThe weighted noise will be measured by a true RMS voltmeter when\n\nno video signal is-provided to the input of the system under test.\n\nD. With the video signal applied, the white to blank video signal will\n\nb6 measured.\n\nE. \t weighted picture SNR will be calculated:\n\nThe\nS\'N\n\n(blank to white video voltage\n2\n\n(weighted RMS voltage of video noise \t\n\n(8)\n\n\nAt\nF. \t the same time, an observer team will make an assessment of the\n\nquality of the output picture on the TV monitor, using a standard\n\n5 or 6 point Bell Laboratories, CCIR or TASO scale.\n\nUse could be\n\n\nmade \t the curves shown in Figure 13, but improvements made in TV\n\nof\nequipment since the time the curves were taken make it important\n\nto repeat this step.\n\nSeveral combinations of video signal level input and noise input\n\nG. \t\n(either at the input or as part of the link simulator) will be\n\nmeasured and scored by the observer team, resulting in a calibration\n\ncurve of picture SNR versus picture quality.\n\n\n47\n\n\n.\n,,--......\n\n-\n\nti 4\n\nt\n\n{\n\n44t\n\n.i,\n\n-\n\nL\n\n41zt\n\n4\n\n-,\n-.\n\nILr\n\n-\'\n\n"ht-I\n\'-\n\n-7-\n\nCOLORV\n\n---\n\n-\xc2\xad\n\nlia\n\n14~~_\n\n5\n\ntij4\n\ni--\xc2\xad\n1\n\n,\n"-___,"\n\n-\n\nL\n\n.2\n\n-\n\n_\n\n....\n-\' -\n\n,,Jr\n\nLUL\n0T\n\n:{x:1\n\n-\xc2\xad\n\ni\n\n-20\n\n...\n\n"+-.----...\n\n+\n\n\'\n\ni~i,".i\n\n-\n\nI\n\nI~I\n\n,\n\n-\n\n0.5\n\n0.1 \t\nVideo Frequency in Mi-lz\n\n\nFigure 14.\n\nNoise Weighting Curves\n\n\n-\'-15\n\n,\n\nt-\n\nII\n\nK\xc2\xad\n\n1\n\n2\n\n3\n\n4\n\n5\n\n\n3.8.2 \tDiscussion of Comparison Parameters\n\nParameter One - Precision of Data\n\nThe following factors affecting precision of data were considered\n\nin determining the rating for parameter one:\n\n1. \t\nPrecision of peak measurement of blank to white signal.\n\n2. \t\nPrecision of measuring RMS noise.\n\n3. \t\nPrecision of filters for weighting noise.\n\n4. \t\nEffectiveness of filters matching subjective effects of\n\nnoise.\n\n5. \t\nPrecision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nThis method results in a measurement of overall SNR which is\n\nconverted in picture quality rating index by use of previously\n\ndetermined empirical curve.\n\n\nParameter Three - Data Reduction Required\n\nThis method would require only one manual recording of signal and\n\nnoise and calculation of SNR.\n\nThe picture quality would be manually\n\n\ndetermined from a previously determined relationship.\n\n\nParameter Four - Relation to Actual System Performance\n\nThe weighted noise concept used in measuring SNR and the quality\n\nrating judgement concept used in this method has received con\xc2\xad\nsiderable attention in the past, and seems to be a reasonable\n\napproach to the problem.\n\nThe noise weighting factors should be\n\n\nchecked with up-to-date hardware.\n\n49\n\n\nParameter Five - Ease of Mechanization\n\nOnce the noise weighting factor and SNR-picture quality relation\xc2\xad\nship have been established, the method is reasonably simple and\n\nstraight forward.\n\nThe picture SNR is determined by measuring the\n\n\npeak blank-to-white signal level and the RMS noise in the video\n\nband.\n\nThe picture quality is then determined byuse of the known\n\n\nrelationship of SNR versus picture quality.\n\n\n50\n\n\n3.9\n3.9.1\n\nVideo Criteria - Method B\n\nCross Correlation of Input and Output\n\n\nDescription of Method\n\nThis method is essentially the same as that described for Method D,\n\nVoice Criteria, with the substitution of a standard video tape or the\n\noutput of a slide scanner used in place of the voice tape as input to\n\nthe system under test.\n\nThe analog-to-digital conversion of the input\n\n\nx(t) and output y(t) to the correlation computer would operate at a\n\nhigher data rate because of the video bandwidth, but the principles\n\nand method would be the same as those described for the voice system.\n\n3.9.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Test Data\n\nAs discussed in Section 3.4.2, one of the principal factors\n\naffecting precision in the correlation method is the length of\n\nthe integration time used in evaluating the cross correlation\n\nintegral.\n\nSince the coherence time of the system noise is of\n\n\nthe order of the reciprocal of the system bandwidth, and it is\n\ndesirable that the integration be long with respect to the co\xc2\xad\nherence time of the system noise, this factor should be more\n\neasily realized in the video system since the bandwidth is\n\nlarger.\n\nHowever, this advantage is offset by the fact that more\n\n\nsamples per second are required, and the difficulty in synchro\xc2\xad\nnizing the analog to digital mechanization of the input and\n\noutput to the correlation computer.\n\n\n51\n\n\nParameter Two - Conciseness of Results\n\nThe sinqle parameter R results from determining an average of\n\nvalues of R computed over fixed time intervals.\n\n\nParameter Three - Data Reduction Required\n\nAssuming that the calculation of the parameter R is completely\n\nmechanized, the data reduction required would consist of determin\xc2\xad\ning the corresponding value of picture quality from calibration\n\ncurves previously established by subjective testing.\n\n\nParameter Four - Relationship to Actual System Performance\n\nThe relationship of this method to actual system performance\n\nwill have to be established from experimental test results.\n\nSince the subjective effects of picture quality are more diffi\xc2\xad\ncult to assess than those of voice systems, this relationship\n\nwill probably be more difficult to establish.\n\n\nParameter Five - Ease of Mechanization.\n\nThe higher data rates required to mechanize the correlation\n\ncoefficient computer would increase the size and cost of the\n\ncomputer as compared to that needed to mechanize the system\n\nfor voice.\n\n\n52\n\n\n3.10\n3.10.1\n\nVideo Criteria - Method C\n\nEqual Importance Frequency Bands\n\n\nDescription of Method\n\nThis method is hypothetical and is based on the fact that in the\n\nweighted noise concept of measurinq video signal-to-noise ratios, bands of\n\nnoise centered at different frequencies in the video band cause equal sub\xc2\xad\njective interference effects when the applied through a noise weighting\n\nnetwork (reference 7).\n\nThe fretquency composition of a typical series of\n\n\nnoise bands is shown in Fiqure 15.\n\nWhen the noise amplitudes in these bands\n\n\nwere weighted in accordance with the standard of the U.S. Standards\n\nAssociation, equal SNR\'s caused equal subjective effects as judged by a\n\npanel of observers.\n\nAdditionally, a more or less linear relationship of a\n\n\npicture quality rating scale and the weighted noise level in dB appears to\n\nexist. Thus it is postulated that it might be possible to divide the video\n\nfrequency bands into a number of "equal importance" frequency bands which\n\ncould be used as a basis for establishing video criteria in a manner\n\nsimilar to that used in calculating the articulation index of voice systems.\n\nThe method used is such a system would be similar to that described\n\nin Method A, Voice Criteria.\n\n3.10.2 \t Discussion of Comparison Parameters\n\nParameter One - Precision of Data\n\nThe following factors affecting precision of data were considered\n\nin determining the rating for parameter one:\n\n1. \t\nPrecision of equal importance band filters\n\n2. Precision of measuremnt of individual SNR\'s in equal\n\nimportance bands.\n\n3. \t\nPrecision of amplitude and phase comparisons in variable\n\nequalizer\n\n4. \t\nPrecision of difference circuit (Sfrom S+N)\n\n\n53\n\n\n-0\n-10\n\nui\n\n30\n\nI MHz\n\n250 kHz\n\n-20\n0\n\n200 400 600 800\n\n.6\n\n.8\n\n1.\n\n1.55 MHz\n1:2 1.4\n\nFREQUENCY, kHz\n\n1.2 1:4 1:6 1.8 2.\n\n2.2\n\nFREQUENCY, MHz\n\n.- J\n\n-10\nLU~\n\n.1~\n\nS-20\n\n-20\n\n2.3 MHz\n2.\n\n2.2 2.4 2.6 2.8\n\nr\n3,2\n\n3.65 MHz\n3.4 3.6 3.8\n\n42\n4.\n\n3.8 4.\n\n~\n\n4.2 4.4 4.6 4.8\n\nFREQUENCY, MHz\n\nFigure 15.\n\nFrequency Composition of 500-kHz Bands of Random Interference\n\nCentered at Various Video Frequencies\n\n\n5. Precision of RMS meters in individual S+N circuits.\n\n6. Precision of calculation of picture quality index.\n\n7. Precision of relationship of picture quality index and SNR.\n\n8. Precision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nThis method results in a single criteria value, the picture index,\n\nwhich is a weiqhted average of SNR\'s calculated for a number of\n\n\'equal importance" frequency bands in the TV pass video band.\n\n\nParameter Three - Data Reduction Required\n\nManual recording and caluclation of signal to noise ratios for a\n\nnumber of frequency bands are required by this method.\n\nCalculation\n\n\nof the picture index from the weighted average of the individual\n\nSNR\'s is also required.\n\nCalibration of picture index would require\n\n\nsubjective testing.\n\n\nParameter Four - Relation to Actual System Performance\n\nThe idea of determining "equal importance" frequency bands for\n\nvideo has not been proven.\n\nHowever, the process used in\n\n\ndetermining the noise weighting factors used in Method A involved\n\na similar idea - the magnitude of noise in different bands was\n\nadjusted to give equal impairment to the picture.\n\n\nParameter Five - Ease of Mechanization\n\nThe test mechanization would be complicated by the number of band\n\npass filters necessary to separate the "equal importance" signal\n\nbands.\n\nManual computation of the "picture index" based on the\n\n\nweighted average of the band pass SNR\'s would be required.\n\n55\n\n\n3.11 \t Video Criteria - Method D Mean Squared Error of Input and Output\n\nSpectra\n\n3.11.1\n\nDescription of Method\n\nThis method would be essentially \the same as that described for\n\nt\nMethod E - Digital Voice Criteria, with the substitution of a standard\n\nvideo tape or the output of a slide scanner in place of the voice tape\n\nas input to the system under test.\n\nThe A to D converters would require\n\n\na larger number of quanitizing levels (128 levels, or 7 bits has been\n\nsuggested as adequate for picture information encoding, Reference 8)\n\nand higher data rates, but the technique would be the same.\n\nThe analog\n\n\nvideo output would be scored for quality by an observer team to provide\n\na calibration relationship to the difference of the mean squared errors.\n\n3.11.2\n\nDiscussion of Comparison \t\nParamters\n\nParameter One - Precision of Data\n\nThe following factors affecting precision of data were considered\n\nin determining the rating for Parameter One\n\n1. \t\nPrecision of A-D conversions.\n\n2. \t\nPrecision of Fourier transform routine in computing power\n\nspectra of input and output.\n\n3. \t\nPrecision of difference and squaring routine of input and\n\noutput power spectra.\n\n4. \t\nPrecision of relationship of picture quality to power\n\nspectra.\n\n5. \t\nPrecision of data reduction\n\n\n56\n\n\nParameter Two - Conciseness of Results\n\nThis method results in an average of squared difference between\n\ninput and output power spectra.\n\nSince no known relationship be\xc2\xad\n\ntween this criteria and picture quality rating index is known. this\n\nrelationship would have to be established by testing using an\n\nevaluation team to score the output tapes.\n\n\nParameter Three - Data Reduction Required\n\nThe data reduction requirements for Method D are similar to those\n\nfor the same type of criteria for voice systems, except that larger,\n\nfaster computers would be necessary because of the higher data rate\n\nrequired for video.\n\n\nParameter Four - Relation to Actual System Performance\n\nThis method should produce acceptable results if the number of\n\nquantizing levels is high enough to keep the quantizing noise\n\nlow with respect to the system noise.\n\n\nParameter Five - Ease of Mechanization\n\nThe analog-to-diqital equipment required would be complicated by\n\nthe high data rate required to reduce quantization error.\n\nCon\xc2\xad\n\nsiderable software development would be required to implement the\n\nFourier transform, squaring and computation of the mean square\n\nerror of the spectra. Assuming that the test configuration had\n\nbeen fully developed, this method would be fairly simple to\n\nmechanize.\n\n\n57\n\n\n3.12\n3.12.1\n\nVideo Criteria - Method E\n\nBit-by-Bit Comparison of Input and Output\n\n\nDescription of Method\n\nThis method would be similar to Voice Criteria - Method G. A\n\nstandard video tape or the output of a slide scanner would provide the\n\ninput.\n\nThe A to D converters and digital comparators would be required\n\n\nto operate at a much higher data rate.\n\nThe analog video output would\n\n\nbe scored for quality by an observer team in order to provide a cali\xc2\xad\nbration relationship of picture quality versus BER.\n\n3.12.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Data\n\nThe following factors affecting precision of data were considered\n\nin determining the ratings for Parameter One:\n\n1. Precision of input tape (amount of jitter).\n\n2. Precision of A-D conversions.\n\n3. Precision of redundancy removal-coding and decoding (if required).\n\n4. Precision of digital comparison circuits.\n\n5. Precision of BER versus picture quality.\n\n6. Precision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nMethod E would result in an error rate determined by bit-by-bit\n\ncomparison of input and output digital tapes.\n\nThe error rate versus\n\n\npicture quality relationship would have to be established by sub\xc2\xad\njective testing of picture quality.\n\n\n58\n\n\nParameter Three - Data Reduction Required\n\nBit-by-bit comparison of input and output tapes would require\n\nfast computers with a large storage.\n\nIn addition, the BER would\n\n\nhave to be converted to picture quality rating by use of appro\xc2\xad\npriate relationship determined by subjective testing.\n\n\nParameter Four - Relation to Actual System Performance\n\nAccurate BER should result from this method assuming that synchro\xc2\xad\nnizing and timing problems can be solved. These problems are more\n\nacute than those experienced by bit-by-bit methods for voice be\xc2\xad\ncause of the higher data rate required for video systems.\n\nThe\n\n\nBER versus picture quality rating would have to be determined by\n\nsubjective testing, assuming that such a relationship, hopefully\n\nmonotones, exists.\n\n\nParameter Five - Ease of Mechanization\n\nThe timing and synchronizing problems expressed in the bit-by-bit\n\ncomparison method for voice systems would be intensified because of\n\nthe higher data rates required.\n\nIf redundancy removal decoding\n\n\nwere required as part of the test process, the complexity of\n\nmechanization would obviously be increased.\n\n\n59\n\n\n3.13\n\nDigital Data Systems Criteria - Method A\n\nBit-by-Bit Comparison\n\n\nBit-by-bit comparison of digital tapes of the input and output of a\n\nsystem under test is conceptually one of the most simple methods of determining\n\nbit error rate.\na problem.\n\n3.13.1\n\nTiming and synchronization of the input and output can be\n\n\nFor very low error rates, the counting time may be appreciable.\n\n\nDescription of Method\n\nA. \t\nThe input to the system under test is digital test tape of known\n\nmessage content.\n\nB. Modulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. \t\nThe output of the system under test is fed to a comparator where it\n\nis compared to the input bit stream, after the input bit stream has\n\nbeen corrected for system delay.\n\nD. The comparator produces a BER directly by counting the errors in a\n\nspecified length of time.\n\nA problem with this method is that if\n\n\nthe BER is very low, an unacceptably long time may be required to\n\ncount enough errors to give a reliable estimate of the actual error\n\nrate.\n\n3.13.2\n\nDiscussion of Comparison Parameters\n\nParameter One - Precision of Data\n\nThe following factors affecting precision of data were considered\n\nin determininq the rating for Parameter One:\n\n1. \t\nPrecision of input tape (amount of jitter).\n\n\n60\n\n\nDIGITAL\nTAPE\n\nMODULATOR\nAND\nRF SOURCE\n\nSYSTEM\n\nUNDER\n\nTEST\n\n\nRF LINK SIMULATOR\nATTN, PROPAGATION\nEFFECTS, NOISE, ETC.\n\nDIGITAL\n\nCOMPARTO\n\nTIMING\n\n_\n\nDELAY AND\n\n_\n\nATTN\n\nDIGITAL DATA CRITERIA - METHOD A\n\n\nBER BY BIT-BY-BIT COMPARISON\n\n\nFigure 16\n\n\nBER\n\n\n2. Precision of delay circuit.\n\n3. Precision of comparator circuits.\n\n4. Precision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nThis method results in bit error rate (BER) directly.\n\n\nParameter Three - Data Reduction Required\n\nBit-by-bit comparison would require little data reduction since\n\nthe BER is computed directly.\n\nIf the error rate is very low, an\n\n\nunacceptably long time may be required to estimate the actual error\n\nrate.\n\n\nParameter Four - Relationship to Actual System Performance\n\nBit-by-bit should yield accurate bit error rates (BER) assuming\n\nthat problems such as tape jitter are solved.\n\n\nParameter Five - Ease of Mechanization\n\nThe principal problem in the bit-by-bit comparison technique is\n\nthat of timing and synchronization, which is complicated by tape\n\nrecorder jitter in the input.\n\nDisc recording or digital test word\n\n\ngenerators would help reduce this problem.\n\n\n62\n\n\n3.14\n\nDigital Data Criteria - Method B Pseudo-Error Extrapolation\n\n\nIn an effort to overcome the problem of long counting time which may\n\noccur in conventional bit-by-bit comparison of input and output data streams\n\nwhen the error rate is very low, the technique of computing pseudo error\n\nrates which are much larger than the actual error rate, has been developed\n\n(Reference 9).\n\nThis method creates large pseudo error rates by biasing\n\n\nmodified mark-space decision circuits in favor of the incorrect decision,\n\nand is characterized by the following features:\n\n1) The pseudo error rates are generated by use of modified decision\n\nthresholds in the "mark" and "space" channels.\n\n2) A method of estimating the pseudo error rates corresponding to\n\ntwo or more modified decision thresholds.\n\n3) Two or more estimated pseudo error rates based on different decision\n\nthresholds are used to generate a function of pseudo error rates\n\nversus a parameter representing the modified decision thresholds.\n\n4) This function is extrapolated to a point where the decision threshold\n\nparameter corresponds to that of the actual decision threshold.\n\nThus,\n\n\nat this point the estimated pseudo error rate equals the estimated\n\nactual error rate.\n\nThe principle of operation of a device designed to produce a pseudo\xc2\xad\nerror rate (P is based on the following observation:\np)\n\n"for a given type\n\n\nof modulation and given form of probability distribution of the noise and\n\nfading,processes, it is possible to define a threshold parameter K such that\n\nthe logarithm of the pseudo-error rate Pp is a linear function of K for a\n\n\n63\n\n\nwide range of values of P . The linear portion of this curve, when extended\nto K=O, coincides with the logarithm of the actual error rate. Thus, by\nmeasuring P for two values of the parameter K and linearly extrapolating\n\n\np\n\n\nthrough these two points to the value K=O, one obtains an estimate of the\n\nlogarithm of the actual error rate."\n\n(Reference 9).\n\n\nFigure 18 shows the graph (A)of the logarithm of the actual receiver\n\nerror rate Pe as function of signal to noise ratio (R) for some propagation\ncriteria, plotted with curve (B) of the logarithm of the pseudo error rate\nPp versus the parameter K for a particular value of received signal to noise\nratio, R\n\n.\n\nThe point where the linear extrapolation of curve (B)intersects\n\nthe R ordinate is also the point when the curve (A) intersects the R ordinate.\nSince this method of computing pseudo-errors depends on modified thresholds\nin the "mark" and "space" channels, access to these points prior to the\nthreshold detector must be made available in the system under test.\n3.14.1\n\nDescription of Method\n\nA. \t\nThe input to the system under test is a digital test tape of known\n\nmessage content.\n\nB. Modulation, RF source and RF link simulation are determined by the\n\nsystem under test.\n\nIf the test is an end-to-end test of a complete\n\n\nlink, the modulator and RF source would be replaced with components\n\nof the system under test.\n\nC. The "mark" and "space" outputs (prior to the threshold detection) of\n\nthe system under test are fed to a series of modified decision circuit\n\nwhere they are compared with the input data stream in such a manner\n\nthat the pseudo error rates generated are larger than the actual error\n\nrate of the output.\n\nD. The pseudo error rates are counted and fed to an extrapolator where\n\na linear extrapolation of the pseudo errors versus their respective\n\n64\n\n\nDATA\nTAPE\nINPUT\n\nSYSTEM\nUNDER\nTEST\n\nRF LINK SIMULATOR\nATTN, PROPAGATION\nEFFECTS, NOISE,\nETC.\n\nMODULATOR\nAND\nRF SOURCE\n\n"MARK" AND "SPACE"\nCHANNELS\n\nMOIID\nTHRESHOLD\nK\n\nTHRESHOLD\nKK\n\nMODIFIED\nTHRESHOLD\nKn\n\nCOUNTER\n2\n\nCOUNTER\nn\n\nMODIFIED\n\n1\n\nCOUNTER\n1\n\nEXTRAPOLATOR\n\n[1\n\n,\n\nDIGITAL DATA CRITERIA - METHOD B\n\nPSEUDO-ERROR RATE EXTRAPOLATION\n\nFigure 17\n\nBER ESTIMATE\n\nA\n\nLOG\nL\n\nLOG P.\n\nLOG\n\nLOG Pp( J 2,\n\nPp\n\nOGG\n\nPo\nLOGI\nLOGP.\n\n0\n\nP\n\nP\n\nI\n-\n\nLOG Pe { RO)\n\nI\nI\nII\n\nSIGNAL-1O-NOISE RATIO\n\nR (dS)\n\nTHRESHOLDARAMErER K\nP\n-\n\nR - R\nK- 0\n\nPlot of Pseudo Error Rate (P versus Threshold\np)\nParameter K compared to plot of Actual Error\nRate (Pe) versus SNR.\n\nFigure 18\n\n\n66\n\n\nthreshold parameters K, K2, Kn is made to extend to the point K=O (the\n\npoint at which the modified threshold is equal to the actual threshold\n\nin the system under test).\n\nAt this point, the estimated pseudo error\n\n\nrate is equal to the actual estimated error rate.\n\nE. Since the pseudo error rates are larger than the actual error rates,\n\nthe time to count the estimated error is much shorter than that\n\nrequired by a bit-by-bit counting process.\n\n3.14.2\n\nDiscusion of Comparison Parameter\n\nParameter One - Precision of Test Data\n\nThe following factors were considered in determining the rating\n\nfor Parameter One:\n\n1. \t\nPrecision of input tape (amount of jitter).\n\n2. \t\nPrecision of the delay circuit.\n\n3. \t\nDiscrepancy between the actual noise statistics and those\n\nassumed in determining the value of the threshold parameters.\n\n4. \t\nLinearity of the pseudo error rate relationship with the\n\nthreshold parameters.\n\n5. \t\nPrecision of data reduction.\n\n\nParameter Two - Conciseness of Results\n\nThe output BER is determined as result of the extrapolation of\n\npseudo error rate.\n\n\nParameter Three - Data Reduction Required\n\nThis method requires the calculation of the extrapolation of the\n\npseudo error rate curve to determine the estimated true error rate.\n\n\n67\n\n\nThis involves solving for the logarithm of the pseudo error rate\n\n(P for n numbers of modified thresholds, in order to construct\n\np)\nthe Pp versus modified threshold parameter (K) curve and then\n\nextending it to the point K=O.\n\n\nParameter Four - Relationship to Actual System Performance\n\nTests have shown this method to be accurate within a factor of\n\n3 at an actual error rate of 10-6\n (Reference 9).\n\n.\n\nParameter Five - Ease of Mechanization\n\nThis method requires a number of modified threshold decision\n\ncircuits, comparators and a computer program to mechanize the\n\npseudo error curve calculation and extrapolation.\n\n\n68\n\n\n4. COMPARISON OF CANDIDATE SYSTEMS\n\n\n4.1\n\nRating of Comparison Parameters\n\nIn order to determine the relative value of each of the candidate criteria\n\n\nsystems, some scheme of numerical rating must be used.\n\nThe method used here\n\n\nis to assign a rating number for each comparison parameter for each of the.\n\ncandidate systems.\nthe best.\n\nThis number ranges from 1 to 5, with number 1 representing\n\n\nHowever, the numbers are not exclusive.\n\nThat is, if for any par\xc2\xad\n\nticular parameter, such as Precision of Test Data, it is felt that two of the\n\ncandidate systems result in about the same precision of data, each is assigned\n\nthe same numerical rating.\n\nThese rating numbers, when multiplied by the\n\n\nweighting values discussed in Section 4.2 yield a value for each parameter for\n\neach of the candidate systems.\n\nThese parameter values, when added for each can\xc2\xad\n\ndidate system, give an indication of the overall rating for each system, with\n\nthe system resulting in the lowest total value being considered the best.\n\nEach parameter rating was assigned after consideration of the factors\n\nlisted in Section 3 for each of the candidate systems.\n\nOne of the basic\n\n\ndifficulties in the rating scheme is the definition of the comparison parameters.\n\nFor the purpose-of this report the parameter "Precision of Test Data" is used\n\nmore or less synonymously with accuracy.\n\nIn assigning values to\n\n\nParameter One, Precision of Test Data, each factor listed was considered for\n\naccuracy, and an "average" accuracy of each system was determined.\n\nThose\n\n\nsystems with the best "average" accuracy were assigned a rating of 1, etc.\n\nThe parameter "Conciseness of Results" presents something of a problem of\n\ninterpretation.\n\nSince all of the candidate systems provide a number value\n\n\noutput for a given input, it could be said that they were equally concise.\n\n\n69\n\n\nThe values arrived at in this report, however, are based on the relative\n\namount and complexity of the computations required to achieve the final value\n\nfor each of the candidate systems.\n\nThe parameters "Data Reduction Required" and "Ease of Simulation" are\n\ninterdependent and are nearly redundant in concept.\n\nAs used herein, "Data\n\n\nReduction" is taken to indicate not only the total amount of data computation\n\ninvolved in a given system, but also the amount of computation required by\n\nthe operator after the process has been completed.\n\nIt can be seen, then, that\n\n\n"Data Reduction Required" and "Ease of Simulation" are somewhat reciprocal \xc2\xad\na system with a low rating score for required data reduction could be expected\n\nto have a relatively high rating score for ease of simulation.\n\n"Relation to Actual System Performance" is the most difficult of com\xc2\xad\nparison parameters to rate for some of the candidate systems.\n\nMost of the\n\n\nsystems require calibration by subjective testing to establish a relationship\n\nbetween the quantity derived as a result of the test and the desired result \xc2\xad\npercent word intelligibility or picture quality.\n\nSince some of the candidate\n\n\nsystems have not been mechanized, the question of whether there is a monotonic\n\nrelationship between the quantity derived from the test and a subjective\n\nevaluation can only be surmised.\n\n\n4.2\n\nWeighting of Comparison Parameters\n\nAfter first determining the parameters to be used in evaluating performance\n\n\ncriteria, a second question to be considered is that of the relative weighting\n\nof each of the parameters.\n\nDo all of them affect the overall value of\n\n\nperformance equally, or are some of them more important than others?\n\nThe\n\n\nanswer to this question depends upon those who are using the criteria to evalu\xc2\xad\nate the performance of a system.\n\n\n70\n\n\nIn determining a weighting system, the precision of the test data appears an\n\nobvious choice as the most, or one of the most, important parameters and was\n\nthus assigned a value of 1. Relationship to actual system performance seems\n\nalmost as important as precision of data and was also assigned a value of 1.\n\nEase of simulation and the amount of data reduction required were determined\n\nto be of about equal importance, but were judged to be of less critical nature,\n\nand were assigned values of 2. The last parameter, "Conciseness of Results"\n\nwas assigned a value of 3, not so much because it was felt to be of less\n\nimportance than the others, but because the very nature of the candidate\n\ncriteria systems is such that the results tend to represent averages of\n\nmeasured and computed values.\n\nIn addition, the results of criteria systems\n\n\nfor voice and video quality must be related to subjective evaluation.\n\nThis arbitrary numerical weighting, which is listed below, has been used\n\nin Table 2, which lists numerical values of the parameters for each of the\n\ncandidate systems, as well as the total rating for each system:\n\nWeighting\n\n\nParameter\nPrecision of Data\n\n1\n\n\nEase of Simulation\n\n2\n\n\nData Reduction Required\n\n2\n\n\nRelation to Actual System Performance\n\n1\n\n\nConciseness of Results\n\n3\n\n\nAnother weighting system, or none at all (assuming all the parameters to\n\nhave equal importance) could be used, depending upon the needs of the users\n\nof the performance criteria.\n\nThe intention here is to indicate how such a\n\n\nweighting scheme, when combined with a rating for each parameter assigned to\n\neach of the candidate systems can assist in determining the overall ranking\n\n\n71\n\n\nof a particular candidate system. Table 3 lists the unweighted values,\n\nassuming that each of the parameters has equal weight.\n\n\n72\n\n\nCriteria Evaluation Weighted Parameters\n\nVoice Systems\nPrecision\nof\nData\n\nConciseness\nof\nResults\n\nData\nReduction\nRequired\n\nRelation\nto Actual\nSystem\n\nEase of\nSimulation\n\nTotal\nValues\n\nOverall\nRankinq\n\nA AI-Equal Importance Bands\n\n1\n\n3\n\n4\n\n1\n\n2\n\n11\n\n1\n\nB AI-Discrete Frequency\n\n1\n\n3\n\n4\n\n5\n\n2\n\n15\n\n3\n\nC Speech SNR-Analog\n\n2\n\n6\n\n6\n\n2\n\n6\n\n22\n\n5\n\nD Cross Correlation\n\n2\n\n5\n\n6\n\n5\n\n8\n\n27\n\n7\n\nE Mean Squared Error\n\n2\n\n9\n\n2\n\n3\n\n8\n\n24\n\n6\n\nF Speech SNR-Digital\n\n2\n\n6\n\n2\n\n3\n\n8\n\n21\n\n4\n\nG Bit-by-Bit Comparison\n\n1\n\n3\n\n2\n\n4\n\n4\n\n14\n\n2\n\nVideo Systems\nA Picture SNR\n\n1\n\n3\n\n2\n\n1\n\n2\n\n9\n\n1\n\nB Equal Importance Bands\n\n3\n\n5\n\n6\n\n5\n\n6\n\n26\n\n5\n\nC Cross Correlation\n\n2\n\n6\n\n6\n\n5\n\n6\n\n25\n\n4\n\nD Mean Squared Error\n\n3\n\n9\n\n6\n\n3\n\n4\n\n25\n\n3\n\nE Bit-by-Bit Comparison\n\n2\n\n6\n\n6\n\n3\n\n6\n\n23\n\n2\n\nDigital Data Systems\nA Bit-by-Bit Comoarison\n\n1\n\n3\n\n2\n\n1\n\n2\n\n9\n\n1\n\nB. Pseudo Error Extrapolation\n\n2\n\n3\n\n2\n\n3\n\n4\n\n14\n\n2\n\nTABLE 2\n\nCriteria Evaluation Unweighted Parameters\n\nVoice Systems\nPrecision\nof\nData\n\nData\nConciseness\nReduction\nof\nRequired\nResults\n\nRelation\nto Actual\nSystem\n\nEase of\nSimulation\n\nTotal\nValues\n\nOverall\nRanking\n\nA AI-Equal Importance Bands\n\n1\n\n1\n\n2\n\n1\n\n1\n\n6\n\n1\n\nB AI-Discrete Frequency\n\n1\n\n1\n\n2\n\n5\n\n1\n\n10\n\n3\n\nC Speech SNR-Analog\n\n2\n\n2\n\n3\n\n2\n\n3\n\n12\n\n4\n\nD Cross Correlation\n\n2\n\n2\n\n3\n\n5\n\n4\n\n16\n\n6\n\nE Mean Squared Error\n\n2\n\n3\n\n1\n\n3\n\n4\n\n13\n\n5\n\nF Speech SNR-Digital\n\n2\n\n2\n\n1\n\n3\n\n4\n\n12\n\n4\n\nG Bit-by-Bit Comparison\n\n1\n\n1\n\n1\n\n4\n\n2\n\n9\n\n2\n\nVideo Systems\nA Picture SNR\n\n1\n\n1\n\n1\n\n1\n\n1\n\n5\n\n1\n\nB Equal Importance Bands\n\n3\n\n2\n\n3\n\n5\n\n3\n\n16\n\n5\n\nC Cross Correlation\n\n2\n\n2\n\n3\n\n5\n\n3\n\n15\n\n4\n\nD Mean Squared Error\n\n3\n\n3\n\n3\n\n3\n\n2\n\n14\n\n3\n\nE Bit-by-Bit Comparison\n\n2\n\n2\n\n3\n\n3\n\n3\n\n13\n\n2\n\nDigital Data Systems\nA Bit-by-Bit Comparison\n\n1\n\n1\n\n1\n\n1\n\n1\n\n5\n\n1\n\nB Pseudo Error Extrapolation\n\n2\n\n1\n\n1\n\n3\n\n2\n\n9\n\n2\n\nTABLE 3\n\n5. SUMMARY AND CONCLUSIONS\n\n\n5.1 \t General Considerations\n\nSome of the difficulties pertaining to the assignment of numerical\n\nranking of the different criteria systems which have been pointed out\n\nin this report are:\n\n1. The difficulty associated with defining the parameters.\n\n2. Use of a weighting system for the comparison parameters; and the\n\nweighting values assigned to each parameter if used.\n\n3. Rating each system for each parameter.\n\n4. The uncertainties associated with untried methods.\n\nOne problem not treated in the report is that of differentiating\n\nbetween criteria and methods used to test a system to meet that criteria.\n\nThe approach taken in this report is to consider criteria systems or\n\nmethods.\n\nThis leads to some duplication as regards criteria - for\n\n\ninstance, the two methods discribed to achieve voice-articulation index.\n\nSince the two methods result in different ratings, it is felt that this\n\napproach is of value.\n\nAn additional factor not considered in the final selection of a\n\nperformance criteria is the ease with which the criteria can be used by\n\nthe systems or equipment designer in developing the design of the system.\n\nFor example, the performance of a portion of a system might be specified\n\nin terms of a criterion which is accurately related to system perform\xc2\xad\nance, but which is very difficult for the designer to compute.\n\nAlthough\n\n\nthis computational difficulty is not an overriding consideration in\n\ncriteria selection, it could be considered in assigning a weight to the\n\ntrade-off parameter "Ease of Simulation."\n\n\n75\n\n\n5.2 \t Voice Systems\n\nBased on both the unweighted and weighted parameters, the articulation\n\nindex method usinq the equal importance frequency bands appears to be\n\nthe best method for specifying voice performance.\n\nThis ranking may\n\n\nresult because the method is one which has been used most in the past\n\nwith proven results.\n\nThe alternate method B is downgraded primarily\n\n\nbecause of its unproven relation to actual system performance.\n\nReferences to Tables 2 and 3 reveals the composition of the ratings of\n\nthe other systems.\n\nIt is of interest to note that the weighted and\n\n\nunweighted overall ranks are quite similar.\n\nThe important feature of\n\n\nthe Tables is that is assists users with different requirements to\n\ndetermine which of the systems would be more suited to his needs.\n\nFor\n\n\ninstance, if the amount of data reduction required were not of prime\n\nimportance to a particular user, he could downgrade or ignore this\n\nparticular parameter and re-compute the-total for each system, thus\n\narriving at a rating suited to his requirements.\n\n5.3 \t Video Systems\n\nThe picture SNR method using a standard noise weighting is the clear\n\nchoice based on both the weighted and unweighted parameter systems.\n\nAgain, the fact that this scheme has had considerable proven experience\n\nundoubtedly affected the results.\n\n5.4 \t Data Systems\n\nThere is really only one choice for the digital systems criteria \xc2\xad\nbit error rate based on comparison of input and output.\n\nMethod B is\n\n\nactually a sub-method, and under the circumstances of very low BER\n\nconditions could be the number one choice.\n\n\n76\n\n\n5.5 \t Recommendations\n\nIt is recommended that continued study and possibly hardware testing\n\nbe made for at least two criteria systems in each category of voice,\n\nvideo, and digital data.\n\nThe criteria system with the highest rank\n\n\nshould obviously be considered for further investiqation and mechaniza\xc2\xad\ntion.\n\nThe choice of the other method in each category should not\n\n\nnecessarily be restricted to the second ranked system, but could depend\n\non the desires and needs of the user.\n\n\n77\n\n\n6. REFERENCES\n\n1. \t\nProject Technical Report, "Survey of Performance Criteria for Voice,\n\nTelevision, and Digital Data Transmission Systems", TRW Document No.\n\n17618-H123-RO-00, 30 March 1971.\n\n2. \t\nDraft Report "Technical Characteristics of Systems Providing Communi\xc2\xad\ncation and/or Radio Determination Using Satellite Techniques for\n\nAircraft and/or Ships," Document No. USSG IV/W-1142, 1 August 1970.\n\n3. Technical Report, "Development of a Speech-to-Noise Ratio Measurement\n\nUtilizing Analog Techniques," Philco-Ford Document PHO-TN248, 6 September\n\n1968.\n\n4. \t\nPeter T. Roth, "Effective Measurements Using Digital Signal Analysis,"\n\nIEEE Spectrum, April 1971, pp 62-70.\n\n5. Technical Report "Development of a Speech-to-Noise Ratio Measurement\n\nUtilizing Digital Techniques," Philco-Ford Document PHO-TN228, 12\n\nJune 1968.\n\n6. \t\nEIA Standard RS-250-A, "Electrical Performance Standards for Television\n\nRelay Facilities," Electronics Industries Association, February 1967.\n\n7. \t . M. Barstow, H. N. Christopher, "The Measurement of Random Video\n\nJ\nInterference to Monochrome and Color Television Pictures," Proc. AIEE,\n\npp. 313-320, November 1962.\n\n8. J. 0. Weston, "Transmission of Television by Pulse Code Modulation,"\n\nElectrical Communication, Vol. 42, No. 2, 1967.\n\n9. D. J. Gooding, "Performance Monitor Techniques for Digital Receivers\n\nBased on Extrapolation of Error Rate," IEEE Transactions on Communica\xc2\xad\ntion Technology, Vol. COM-16, No. 3, June, 1968.\n\n10.\n\nHarvey Fletcher, "Speech and Hearing in Communication," pp. 278-302,\n\nD. Van Nostrand Company, Inc, 1953.\n\n\n78\n\n\n'