b'NASA-CR-1650l2\n19820005895\n\nA Reprociuced <:Opy\nOF\n\nI t\n\nReproduced for NASA\nby the\n\nNIASA\n\nScientific and Technical Information Facility\n\n11\\\\111\\1 \\1\\\\ IIII \\\\1\\1 11\\\\1 11\\\\\\IIIII \\\\11 1\\\\1\n, r\n\nNF01l30\n\nFFNo 1672 Aug\n\n65\n\nComputer Vision\nDon~ld Gann(~ry\nRt\')b~rt Cunningham\n\nEric Stitund\nJohn High\nCarl Fluoff\nlIne 1.,1;:\'\n,J ttl () i\n\n\'.\n\nI\n\n.:j\n\nNovembf1!\' i, 1931\n\nNational Aeronautics a.nd\nSpes Adf\'ninistration\nJet PI\'O~\\uf*~lon Laboro:!<:~ry\nCalifornia Im;tituto of Technology\nPasadena. California\n\n-#-\n\n;Vgr~-/..37~ y\n\nJPL PUBLICATION 131-92\n\nComputer Vision\nDonald Gennery\nRobert Cunningham\nEric Saund\nJohn High\nCarl Ruoff\n\nNuember 1, i931\n\nNational Aeronautics and\nSpace Administration\nJet Propulsion Labori.:ttory\nCalifornia Institute of Technology\nPasadena. Californin\n\nThO researCh doscnbod II) this publication was carrt\xe2\x82\xac1d Ollt by the Jot PIOplJIS;Or1\nLaboratory. C(!!tfornlO Institute of fochnology. under contract wl!l1 ttle National\nAoronautlcs and Spaco Admtr1lstrr,\\lon.\n\nABSTRACT\nThe field of computer\' vlsion if. surveyed and asscf.sed, key\nresearch issues are identified, and possibilities for a futuro JPL\nvision system nre discussed.\n\niii\n\nCONTENTS\n\n..\n\n1. Introduction.\n\n\xe2\x80\xa2\n\n1-1\n\n1.1 Scope of Document\n\n1-1\n\n1.2 Overview\n\n1-2\n\n..\n\n1.3 Typical Vision Systems \xe2\x80\xa2\n2. Representation \xe2\x80\xa2\n\n1-4\n2-1\n\n2.1 Plxe1s \xe2\x80\xa2\n\n2-1\n\n..\n\n2.2 Textux\'s\n\n2-3\n\n2.3 Regions\n\n2-4\n\n2.4 Edge and Line El Cl\'llents \xe2\x80\xa2\n\n,\n\n.\n\n2-0 !\n\n2.5 Curves \xe2\x80\xa2\n\n2~12\n\n2.6 Chain Code.\n\n2~14\n\n2.7 Corners\n\no\n\n2.8 Pyramids\n\nand\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n..\n\n0\n\nQuadtrees \xe2\x80\xa2\n\n3. l)esCI\'iption\n\n2-17\n3-1\n\n3.1 General Infor-rna tion\n3.2 The\n\n2-15\n\n3-1\n\nTt~o-Dimensional\n\nHorld\n\n3-1\n\n3.3 The Blocks \\olOl\'ld \xe2\x80\xa2\n\n3.. 3\n\n3.4 The tlore General ~lor\'ld \xe2\x80\xa2\n\n3~5\n\n\',J\n\nv\n\nt..;.,:.\n\n\xe2\x80\xa2 ">;,\n\n,~\n\n\xe2\x80\xa2. ,\n\n.~)-\n\n\xe2\x80\xa2. ~ " . \'" .\xe2\x80\xa2\n\nI!. Rooogn! ticn\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n4\xc2\xb7,1\n\n4.1 General Recognition Methods \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n4-1\n\n4.2 Partioular Recognition\n\nEf~orts\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n4-3\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n5-1\n\n5.1 Tracking. \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 ...\n\n5-\'/\n\n5.2 Verification. \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n5-1\n\n~\n\n6~f1\n\n5. T1\'saking and Verificntion\n\n6.\n\ns te 1"\'1;eo\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n7. TeElching and\n\ntI\n\nLelll~nlng\n\n.\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n0\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nII\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\'f\n\n\xe2\x80\xa2\n\n$.\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n7-1\n\n8. Camera COl1t!\'ol and Calibrat.ion \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\xe2\x80\xa2\n\n8-1\n\n9. System Architoctut"O\n\n9~\xc2\xb71\n\n\xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n9.1 Computational Structur0S \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n>\n\n9.2 Hal U"lflnre \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\xe2\x80\xa2\n\n9-4\n\nlo\n\nIJ\n\n\xe2\x80\xa2\n\n(l\n\n~\n\n\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\n\n10-1\n\n\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\n\n0\n\n10-1\n\n10.2 Key Research Issues \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n10-3\n\n10.3 F\'utul\'a JPL System \xe2\x80\xa2 \xe2\x80\xa2 \xe2\x80\xa2\n\n10-5\n\n10. Conclusions\n\n~\n\n!Go\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n9-1\n\n\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2\n\n10.1 state of C()mputer Visi.ol1\n\nReferencos\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n.... . . ..... .. . .....\n\'"\n\nvi\n\nR-1\n\n/\n\n1. INTRODUCTION\n\nThe purpose of this document is to review the state of the\nart of computer vision, to identify some key research issues, and\nto describe the capabilities and architecture that a future JPL\nvision system might have.\nThe document can be used as a brief introduction to the\nfield of computer vision. For more detailed information the\nreadel\' can consult the cited references. In particulap, Dvd[l and\nHart [1973] provide a go()d text on some of the basic princ!pl\';I.3\nof computer vision; Pavlidis [1977] discusses in detnil some of\nthe algorithms of computeit\' vision; Winston [1975a] presents a feH\nsignificant pieces of work; and Aggal"vlS1 .!itt ru... (197?]p Hanson\nand Riseman [1978a], and Barrow and Tenenbaum [1981) provide\nsurveys of SOll).(~ of tho mOI\'e important Hork, portions of Hhich are\ncited elsewhere herein.\n\nAlao 9 Rosenfeld provides an annual\n\nbibliography of image processing and computer\n\nyis1o~\n\n(FLr\n\nexample, Rosenfeld [1901] COVGrs the yeaI\' 1980 and contoJ.l1S 897\nreferences. )\nThe t.erm Ucomputer vision" is considered here to be\nsynonymous with "machine vision" and "robot vision". The t.erms\n"scene analysis," "image undeI\'standing,~ and "pictorial pattern\nrecognition" often are also considered to be synonymous to these,\nalthough some authors use the latter three terms in more\nrestricted senses. Tne general field of pattern recognition\nincludes the recognition of abstract patterns in arbitrary nonpictorial data, and 1s not covered here. Also, techniquB$ for\n\nanalyzing highly specialized two-dimensional sceDes (as in\ncharactrir recognition) are not covered here.\n/\n\n/\n\n1-1\n\n,\n}.,\n\nWe have attempted to provide a survey of the more\nsignificant developments in the field of computer vision, but\nvery likely some iraportant lIork has been omitted.\n\nFor\' this we\n\napologizE\'.\n\nThere are ~any ways in which a description of computer\nvision could be organized. For example, the field could be\ndivided according to the\nlnd:lvlo\\\\als or groups,\npl\'ocesaed, by the\n\nsy~tema\n\ndeveloped by difforent\n\nby the nat.ure of the scenes being\n\nnature of the information desired, by the kind\n\nof techniques that are used, or by the pro@\'ession from low-level\n~cl()se to the image) to high-levf;l (close to the desit\'ad fina.1\n\nresults) processing.\n\nThls document uses primarily the latter\n\napPI\'C"ach In Sections 2, 3, and 4, but\n\nalelil~mts\n\nof some of the\n\nother organizations appear in other sections. In addition to\n\ntheBe conSiderations, it ls difficult to produce a coberent\norganiza tion because of the wide vat\'iety of approaches tlw.t are\nused and t.he overlap among them.\nFlr~:t,\n\nth\'! vision task is\n\nVI-H\'Y\n\nl\'his is caused by hro facts ..\n\ndlft\'icul t and requires complicated\n\nmethods. Second, vlsion research is aUll in a very primiUve\nstate.\n\nThere is no consenSUB on the j)est techniques at any IU\'/el\n\nof processing.\n\nThe terms "representa.t:!.on," "descript1.on," Ilnd I\'Imodellingl1\nare used with various moanings and sometimes are used\nlntm\'changeably.\n\nHowever, het\'c definitions al\'e aSSigned\n\narbl t~arily, as follows.\n\n8orne~-1hat\n\nI\'IRepresentation" denotes the choice of\n\nlow\xc2\xb7-level features del\'ived from the picture Hhich capture most of\n\nthe importa.nt infOl\'mation 1~\' t\'le picture but do not explicitly\ndescribe the global na ture of t.he scene. SccUon 2 doscribes the\nrepr\'esentation techniques usually used, Sl\'f\'lmged roughly fr\'om the\n\n1-2\n\nlowes t\n\nlevel\n\nSection 3\n\ntouar\'ds higher level s.\n\nCO\\\'e1\'5\n\n"description," defined hellE! as the wal\'s of describing a scene 01\'\nobject\n\nmore globallyp\n\nperhaps in\n\nterms\n\nof\n\nthe\n\nbasic\n\nrepresentation components and the relations among them.\n"Modelling" is considered to be essentially the aamB as\ndescrlption p except that it is applied to abstract models of\nobjects which are searched for in actual pictures.\n1s recognition,\n\nvision task\n\nOne important\n\nwhich is considered to be the\n\nmatching of a description derived from a picture to one or more\nabstract models, perhaps out of n large number of possible object\nWays of doing this are described in Section 4.\n\nmodels.\n\nl"ituation often is not as simple as\n\nThe\n\nthis straightfof\'W&l"d\n\ndescription-:nodel-matching scenario ieplies, however, for t.his\n13ame type of process can\n\nr~!peat\n\nat several lev::lls in the analysis\n\n(If a scene.\n\nI\'.10ther important vision task is verification, in Hhich i t\n15\n\nkllO~1n\n\nwhat object should be present and approximately where i t\n\nis, and it is desired to verify its presence and correct the\nestimate of its location.\ni.nfol~mation\n\nIn such a case the a priori\n\ncan be used to guide the finding of important\n\nfeatures used in the reprcsenta tion, and comparing the position\nclf these to their predicted positions enables\n\nupdated.\n\nthe model to be\n\nA similar task is the tracking of moving objects.\n\nHere\n\nthe predicted information comes from the results at previous\ntimes.\n\nVerificativn and tracking are discussed in Section 5.\n\nThree-dimensional information can be measured directly by\nsome devices, as\n\nmentioned in Section 2.1.\n\nHowever, usually i t\n\n1s obtained indirectly from two-dimensional pictures.\nsingle\n\ntl~o-diillensivnal\n\npictUre is available,\n\ni f only a\n\nthe\n\ndepth\n\ninformation must be inferred by means of heuristics, some of\n\\>lhleh are inherent in the recognition techniques descl\'ibed in\nSection 4.\n\ni-jOive\\TCJI~,\n\ni f more than one picture is available, often\n\n\'1-3\n\none of several techniques hero cnl1ed l\'Jat.0!\'eo visionll can be used\nto obtain tho dopth information, as des(!ribed in Section 6.\nSection 7 discusses methods for getting the nacess81\'Y\ninformation concerning object, modols into the computer vif.lion\nSect!. .... n 8 discusses method3\n\nsystem.\n\nfor\n\ncontrolling and\n\nSl3ction 9 discusses issues of system\n\ncalibrating the camer,,"1.\n\narchitecture, both in terms of computational structures and\nhard\\~are.\n\nSection 10 summarizes ou!" conclusions concerning the\n\nstate of vision, the key research\n\n1ss~eB\n\nof vision, and the\n\npossible nature of a future .JPL vislon system.\n\nBefore discussing particul.ar aspects of the vision problem\nin the rest of the document,\nsy stems will be briefly\n\nD.\n\nfew l\'opresenta U.ve computer vJ.sion\n\nd~scribed\n\nin th is section.\n\nFirst some opera tional indlistr\'inl vision systemR Hill be\ndElscribed.\n\nHany\n\ncomputel~\n\nvision systems have bC(1n developed to\n\nprovide visual feedback to a robot.\n\nTypically, these systems\n\nidentify objects in the workspace of the robot, estimate the\nposition and oriuntation of objocts, and in some cases estimate\nthe velocity of lDovlng obJects.\n\nIn sorne cases,\n\nidenUncation may include inspection to detect\npl\'oducts.\n\napplication.\nbe\n\ndefective\n\nSome systems are designed around a single object and\n\nuse ad hoc.techniques which may not apply directly\ncbjects.\n\nobject\n\nto any other\n\nOther systems al\'e designed for generiC classes of\n\nTheile systems have a programmable data ba::;e which can\n\nloaded\' with\n\napplication.\n\nmodels\n\nof specific objects for\n\nany given\n\nThe vision system is progl\'ammed to extract a\n\nstandard set of featUres to generate descriptions of objects in a\nscen~\n\nThis is followed by a matching procedure which compares\n\nobject descriptions obtained from\n\nth~\n\nimage to prototypes .1n an\n\nobject model data buss.\n\nFor a given appliaatioo p the system\n\nprovides some means of loading this data base with descriptions\nof specific prototypes.\nAt the NahannI Bureau of Standards (NBS), VandorBrug\n\n.e.t.\n\n.al,.\n\n[19\'(9) have developnd a vi.sion system using structured light and\na oamera mounted on the wrist. of a\n\nro~ot\n\narm.\n\nTho camera is used\n\nto locate an object resting on a flat surface and to estirna.te its\nposition and orientation so that. l.t can be grasped by thtl nrm.\n\nA\n\ndescription of the object is built up through multiple vieus\nobtained by moving the arm and camera.\nsource,\n\nalso on the arm,\n\nThe structured light\n\n1s a stroboscopic flash behind a\n\ncylindrical ler.s which produces a sheet of Hght.\n\nline-of-sight is oblique to the plane of light.\n\nThe camera\n\nImage analySis\n\nconsists of detect! Hg the stripe of light on the .sur-face of an\nobject.\n\nThe oblique viewing geolileti\'Y causes the\n\non different\n\nap~\n\nI?or example a rectangular object viei-led\n\nhead on pi"oduces a straight line, Hhereas a\nob.~ect\n\nto tnke\n\ndrances depending on the geometry of the obje:lt\n\nand its orienta tion.\nwhen the\n\nI3trip~l\n\nis vicl.ed obliquely.\n\nV~shaped\n\nline occurs\n\nCylinders pI\'oduce cuy-ved\n\n3trlpes Mhen viewed parallel to Lhe circular\n\ncroDs-sectio~\n\nPrisUla tic objects \\-litb grooves or ridges p!\'oduce broken s tripOD.\nImage analysis\n\nl~ons1.sts\n\nidentify objects.\nsource\n\nnakes i t\n\nof intel\'prating stl\'ipe featuY\'es to\n\nKnow:i.ng the g(!ometl\'Y of the camera and li::ht\n\nposs:lble\n\nto extract\n\nillumlrw.ted pOints on the ob,1ect,\nposi~ion\n\n3-D\n\nmea~urements\n\nof\n\nand thus ul timately the\n\nand ,-dentation of the object :I.n l\'obat coorMnates.\n\nCONSIGHT 1s a h,wd\xc2\xb7\xc2\xb7eyc system developed at General Motol\'s\n\n(Ward .eJL.Il..:., [1979]) for the purpose of piclclng up parts orf\n\nmov:I.ng conveyor belt.\n\n!l\n\nA J.1near-diode-\xc2\xb7array camera 1s mounted\n\ndirectly above the conve;or belt.\n\nThe image of an object is\n\nbuilt up through a sequence of one-line images taken as the\n\nobject pasaes through the field .of\' vicli of the camer.H.\n\n1-5\n\nWhen the\n\nentire object has pasf;ed by thtl carner-a, a statistical ueser-ipUon\nderived from its 2-D silhouette is used to identify it aad to\ndetermine\n\nthe position and ol\'ientatioD (in n plane) of a\n\npredstarm.i.oed grasp point.\n\nThe visio:1 system can identify\n\nmultiple two-dimensional objects which are\nsimultanecusly.\n,or overlap.\n\n~\n\nn tt,e field of view\n\nThe only requirement is that parts do not touch\n\nThe vision system is pr\'ogramLed to recognize a part\n\nusing a teach-by-showing method.\n\nIn this mode,\n\nthe\n\npart\n\ndescription derived from an image of the part is stored along\nwi ttl its name,\n\nwhich is eutered by tile operat0".\n\nCONSIGHT also\n\nuses structured light consisting of two focused lino light\n:90urces, one on oi ~her side of the camera along thp. direction of\nthe conveyor belt movement.\n\nThe light sources are aimed\n\nobliquely to the conveyor belt so that they both illuminate a\n\'~hin\n\nline on the\n\nsurfa.c(~\n\nof the conveyor bel t perpendicular to\n\nthe di.!\'ectioll of its motion and visible to the linear-diode\xc2\xb7\xc2\xb7m"pay\ncamera.\n\nWhen the belt 113 I9mpty, the camera seef\'. a continuous\n\nIrlh1te stripe.\n\nWhen an object is\n\npresent,\n\nthe ob:Lique\n\n:lllum1nation of the object causes the tiJin :ine of light to muve\nalong the object towards the light source and out of vie"" of the\nI1near\xc2\xb7\xc2\xb7diode-array camera.\n\nThe amount of line of light movement\n\nis proportlonal to the height of the object. Thus objects appear\nas darl< blobs on a bright back,:?,l\'Ound.\n\nThe main advantage of this\n\nstructured light approach is that parts can be detected\nlndependently of their contrust Hith the belt.\nThe SRI Vision Hodule (Nitzan .ill;..al. [1979]) is very similar\nt.o CONSIGHT, and in fact\nsystem.\n\nse"v~d\n\nas an inspiration for the latter\n\nThe SRI system uses a more conventional 2-D array\n\ncamera, and is thus suited to other applications as well as\nlookiag at pe.. ts on conveyor\n\nbelts.\n\nObjects are detected as\n\nblobs In a binary image obtained by thresholding.\n\nContrast is\n\nenhanced by careful Ijght1ng, including backlighting, so that\nobje0,ts are significantly brighter or darker than the background.\n\n1-6\n\nThle system is progrmamed to recognize parts u3ir:;~ the teach-by-\n\nshowing method.\n\nDuring the teaching\n\npha.3e~\n\n>:.he part. is viewed\n\nseveral times in different positions and or\'ienta"\n\nto obtain a statistical\nstandard deviation).\n\ndis~ribut1on\n\n10M;!\n\nin a planE\'\n\not the featUres (mean FInd\n\n\'J\'h(! statistical distribution of foatu;\' e\n\nvalues can optionally be used by the program to automatically\ngenerate an optimul binD!)\' decision tree\nOtherwise, classification\nin feature space.\n\n~s\n\nfOl\'\n\nblob\n\nc:.as~ification.\n\ndone by "nearest neigbbor ll lllatnhing\n\nSRI has used the vision system in sev\xe2\x82\xac.\'l\'al\n\nexperiments incluoJing picking parts from a moving COl\'vt!yOf\' bel t,\npacking and unpacking boxes, inspection, and object tracking.\nAl though the above systems can perform useful vis:l.on tesks\n.in real time, thei r performance is very limited.\n\n.ru...\n\n[1919) point out the\n\nfollo~ling\n\nindustrial vision. systems:\n\nfeller.baum.e.t.\n\nlimitati.ons of current\n\nhigh contrast,\n\nno shadoHs,\n\nno\n\no()clunion, two-dimentiona.l models, rigi(; objects, and standard\nviewpOint.\n\nNext we discUBS the ACRONYM system develop0d at\n\nStanford University uhich oVet\'collJeS all of these limita tion~, t.G a\ncertain extent.\n\n(For a more complete description of ACRC,HM see\n\nBlroo ks.ltl..il.l. (1979), BrDO les and Bi nf ord [19 80], af\'.d Bi nf 0,\' d ..e...t.\n\nAi. [1980].)\n\nACRONH1 is not an operational\n\n~ystp.m.\n\nIt is a\n\nr,esearch vehicle still LInder developme nt, which runs on large\nt:lme-shared computer, and uses pre-stored images.\n\nJ-\'owever, i t\n\narpears that i t (Jill be one of the most advanced visjon programs\nyet produced, and it has D large degree of generality in th&\ndomain of identifying man-made objects.\nACRONnl models scenes and objects as specified by the user\nin terms of generalized COnl1S (del.lcribed in Sertion 3).\n\nAn\n\nobject consists of a hierarchical structure (an object graph) 1n\nwhich the volume primi Uves are generaUzed cones.\nmodel\n\nth e number c"\n\nIn a generi0\n\neach type of\' part. and the dimensi0ns,\n\nrelative pOSition, aud relative orientation (If the parts can \\ary\n\n1-7\n\novc~r\n\napeoH.ted\n\nN~.ngc~~.\n\npr\'edi(~toi"\n\nA\n\nand planner\'\n\nIllodu~e\n\nconverts\n\ntlN IlIod<\':is into prediction (;,.....)112, l<lhich predict the appeet\'ur.oe\nof objects with:l.n the\n\nscetlc~\n\ndescriptive processes\nob.jeots in the image.\n\naD~\n\n8.nd provideD a plan for lower-level\n\na matoher to find instanoes of the\n\nThe edge !.nappei\' module deteotR edgos using\n\nthe method of Nevatil\'!. and Babu (described 1n Seotion 2.4) e,nd\nfOl~~H~\n\nthes\xe2\x82\xac\' into\n\nr1bbons~\n\nwhich arc th e tw(}udimensioli."ll analogue\n\nof generalized cones. \'l\'he l\'caul t i8 a.n obsel"va tion graph. \'rho\nmatc!1er then matches the observation graph (produccd from the\nimag~)\npl~C)duce\n\nand the prediction graph (producod from tho model) to\ntho interpretation gr-aph, from \'l<1hich the\n\nof the soene is derived.\n\nintel"pretatiol~\n\nIn this process the predictor and\n\nplanner can be invoked again to extend the graphs when a ~mbmatch\n\nIt is planned to add stereoscopio vision to\nACRONYM in tno fu.ture. Cel"tain aDpccts of ACRONn1 are discussed\nfurther in Sections 3 p ~: and 7.\nis successful.\n\n,- 8\n\n2.\n\nREFRESEWI\'fiTlON\n\nThe 10uest~1\'wel repI\'{lSentation of a di6iti:ed picture 1s\nthe p$xe1. Each pixel represents the value of one or mo~e\nquantities at some point in the tuo-dimens1c.-nal picture. Usually\n\nthe pixels\n\na uniform rectangular array over the plct;ure, but\n.3()matiroes other arrangements are used, such as a hexagonal array\nliB\n\nfot\'rll\n\nadvocated by Golay (1959).\n\nUsually the pixels represent the brightness and perhaps\n(The\nflmdamentals of image f\'orroatiotl and color are dis;llBI:":~<l by Pratt\n[\'1978), and the tolay 1n whi,)h surface properties determine image\ncolor 1n a projection from a three-dimensional scene.\n\nintensities is discussed by Horn [1977].)\n\nIn a monochromatic\n\npicture each pixel J.s represented by a single numot-ieal value. In\neach pixel is represented by two or marc\n\na color\n\npict~r~,\n\n(three,\n\nj.f human vision Is simula.ted)\n\nvalues representing\n\nl:;and~.\n\n(These values can be\n\nbl\'ightness in different wavelength\ncc)nverted to other\n\nv~.lu;;s\n\nsuch as hue,\n\nsatul\'at;ion,\n\nand\n\nbt\xc2\xb7.ightness.) In geoel\'al, llol-lcver, tLe pixel values de. not have to\n\nrepresent light intensities. 0ther media, such as sound\ntactile pretsure, could be used.\n\nO~\n\n, fact, the pixels do not ha, e to represent intensities at\n\nall.\n\nthe\n\n.,\n\n. can\n\nr\xe2\x82\xacpl~esent\n\nthra~-dimens1onal\n\ndistm;ces to the corresponding paints in\nscene, in which case the pi:el array 113\n\nreferred to as a Hrange image."\n\nSuch data is produced by a\n\nlaser rangef:!.nder ar discussed by Lewis and Johnston\n[1977] or could be produced by an appropriate sonar device.\n(Also see the next paragraph.) Similar data can be obtained\n\nsc=~ning\n\nsomewhat less directly by a triangulation method llsing a laser\nand\n\nan ordinary camera, as descl"ibed by Agin and Binfol"d (1973).\n\nIf distance is not measllPed dj.rectly,\n\nit must be inferred\n\nindirectly from the two-dj taon::>:l.onal plctures if thr\'ee-dirnensional\nsoenes are being (;ons:ldm\'ed.\n\nA lo\\>/\xc2\xb7\xc2\xb7lc\'Jcl method of estimating\n\nt\'E!lative distance and surfaoe orientation from a single picture\ni~1\n\ndescribed by Darrow and Tenenbaum [197 8).\n\nThey use heuristics\n\nbased on the rate of change of brightness across a picture. Born\n[~975J\n\nnnd Woodham [1977] pr\'ovide methods based on the assumption\n\nof a reflectivity fuuotion that 1s consta.nt over an object and\nsome assumptions about the illumina tion.\n\nthan one pict\\u\'t) and high-level methodtl\n\nM\' thods based on more\nIll\'.:!\n\ndiscussed in later\n\nsections.\nNitzan .tl.t.\n\nru..\n\n[\'1977] obtuin register-cd range and intensity\n\ndata by scanning the scene with an aMplitude-modulated lasor\ntr\'ansmitter.\n\nA receiver outputs the amplitude and modulation\n\nphase shift of thf.\' reflected laser light. \\-lh1ch are\nto the intensity and\n\npl~oportional\n\n(\\,\'1thin one phas() per\'iod) the rnnga p\n\nrespoctively, of tho reflecting\n\nsurfac~.\n\nThuB both a range\n\npicture and a conventional brightness picture nre produced\nsl.mul taneously by the same device.\n\nThe runin drawback t.o such an\n\napproach in computer Vision for f\'obotics 113 that such s device is\ncurrently much slower thon a stand.\'lt"d TV camera.\nIf the pixels represent brightness, these\n\nusually suffice for later proceSSing,\n\nbrightn~38\n\nvalues\n\nsince the important\n\nquantity 1s often relative brightness rather than absolute\nbl"ightn~8s.\n\nHowevet\', if it. is desired to identify objects by\n\ntheir absolute color,\nsurf~,ce\n\nthe reflectance (lightness) of their\n\n(in soveral HBvelcngth bands if color is used) must be\n\ndetel~mined.\n\n1\'hus the effacts of 1l1uminaUon must be separated\n\nfroDl the effects of surface lightness,\n\nthe measured brightness.\n\nwhich combine to produce\n\nHuman beings are quite good a t this,\n\neven though the general problem 1s insoluble.\n\ninvestigators \\,\n\n10\n\nSoveral\n\nPl\'oposcd heuristics by which reasonable\n\n2-2\n\n!\n\nrel>ul ts can be obtained for tYPicul scemw.\n\nLand (1971] propored\n\na method based on edges (spatially sudden ehanges in brightncss),\nassuming that\n\nth~se\n\narc\n\nto changes in lightnoss whoreas\n\ndU0\n\nspatially gradual changes are due to illum1rllltion effc(\\ts.\n[197\' 4] extended Land\'s work,\nopc~ratol\'\n\nHorn\n\nusinS the inverse of the Laplacian\n\nas a means of lntt1gra ting the infol"ma tion across two\n\ndim",nsions in or\'der to obtain lightness at each point..\n\nGilchrist\n\n[19709J showed the ir:portance of throe-dimensional posiUon\ninformation in performing the sepal\'ution of illumlnation and\n\nlis;htness, 1n addi tion to tbe two-dimensional infor1ll8 tion used by\nLand and Horn, but did not produce an algorithm for computer\nimplementa tion.\n\nA.li.rue..aJ". (1979] use normalized color val ues to\n\ntry to minimize t;he effects of shadows, as described 1n Section\n\n2.3.\n\nTexture 113 a\'local variation in pixel values (whettHH\'\n\nbrightness, col 01\', or any ot.hel\' ir,form\'l lion wen tioned in Section\n2.1) that repeats in a regular or\n\nan :lmage or object.\n\nr\'H~)dom\n\nTexturo can be\n\nway act\'OSS a pol\'tion of\n\ncha~\'acter:lzed\n\nin various ways\n\nthat result in descriptions including n\',lmerl\'!al or symbolic data,\nor both.\nwit~Jin\n\nSuch H description can val\'Y as a f\\;nction of posi tion\n\nan image.\n\nHowever, t.he texture infc.rmation is usually\n\nobtained at a lower\' resolution than the origi.\'lal image data from\nwhich it is derived, because several pixels are required to\ndetermine each texture\n\nelemen~\n\nOnce the texture has been measured,\nseveral purposes.\n\nit can be used for\n\nThe nnture of the texture may aid in\n\nidcntifying a pal\'ticular object. or material, the scale of the\ntexture in the image may be used to determine distance if the\nseal e of the textux\'(> on an object iG known, and nonisotropy of\n\ntextv,\'e ruay aid 1n determining sllrface ol\'icntu tion.\n\n2-3\n\nAl so, the\n\n\'\\far-iations in\n\nt~llCture\n\nacross an image can be used in the same way\n\nlila variations in untexturod pixel values. Segmentation lIsing the\n\nc:ldgc detection techniquos and regton finding techn:i.ques to be\ndoscribod in later sections can ba done basod cn the texture\ninforwation instead of\npixel informs lion.\n\n011\n\nbrightnoss, color, or othor original\n\nIt 1s even possible to apply the definition\n\nof texture recursivftly in order to obtain a texture of textures.\nTex t.ure infor lilEl tior. :I.s like ly to be u sofcl en nn tu:,nl\noutdoor\' scenes, since those tend to be highly textured. Horrever,\nman-mado objects usually have fairly un1!\'orro sur\'facos.\nt.he nonr-term NASA appli.cntions, which involve\ntexture is unlikely to be illlportllnt.\ndiscussed in further detail here.\n\nThus for\n\naBs~tnbly\n\nTheNlfore,\n\nwork,\n\nit is not\n\nThe many apPJ\'oaches to textur\'o\n\nanalysis that have been used are surveyed by Har\'alick [19781.\n\nA region is a set of connected p1it:els that share a common\nproperty such as average gray\nimage.\n\nlevel~\n\ncolor, or texture 1n an\n\n\'l\'he assumption in forming regiono is that pixels sh}.:ll:\'ing\n\nthe above pr\'operti<\'ls will also share tho proparty of being images\nof pOints en the same objeot (or part of an objoct,\n\nor a\n\ncollection of objects - in other words, an entity of interest to\nthe vision system).\n\nRegions nre typically described by\n\nstatistical features such as perimeter, area, first and second\nmoments, average gray level (or color), etc.\ne:ltpl1cit shape informatlon nuch\n\n813\n\nIn some cuses,\n\nthe location of corners or\n\ntabs is included, or possibly the entire boundary is represented\nfor\n\nmore general shape analysis.\n\ncDntalning.som~\n\nLists of region records\n\nportion of the above set of features for each\n\nl\'egion in the image are often structured as a tree or graph to\n\nindicate nestlne; and adjacency relatiollships between f\'cgtons.\nZUcker\' [19\'{68J and Riseillan flnd Arbib [1977] survay savel\'al region\n\n2-4\n\na!~c\n\ngrowing techntques, some of which\n\ntHscusscd below.\n\nAlso,\n\nKanada [1978] discusses how the region IScgmenta tion problotil\n!\'elate3 to the rest of the v13ion task.\n\nThe simplest approaoh to region growing is to look tor\ncluster\'\'l of O\'s and\n\n\'i\'s in a\n\nbinat\xc2\xb7y\n\nthresholding n gray-level imagL\n\nimage obtained\n\nby\n\nThe approach usod by SRI\n\n(Nitzan I I ,al. [1979 J and CONSIGH\'l\' (\\11:U\'d\n\n.f\'...t. .1.\\1.\n\n[1979]) 13\n\nconnectivity analysis per-foNned in a one\xc2\xb7\xc2\xb7pass raster\' scan of the\nimage.\n\nThe result is a tr<ile-l1ke list of\' re:;ion records uhcre\n\nlinks down the tree indicate nesting; i.e. r if a region record is\nnot a leuf node of the tr\'ee p then the ch:l.1drcn ot\' the r-egion are\ncompletely surroundod by It.\nBoth of the above systems use a global threshold to obtain\nthe binarr image.\n\nEach pixel of the imnge is lhl\xc2\xb7esholde<.1 at the\n\nThis approach \\101"1(\'.$ best in raM-made envir\xc2\xb7onments\nsuch as a Ranufacturlng ar~p where scene parameters such as\nillumina tion anc! background compos! tJ.on can be controlled to\nsame leve1..\n\ninsurt~\n\nhigh contra.st images 3uHublc\n\na survey of\n\nfo,~\n\nglobal thresholding.\n\nthreshold selection techniques,\n\nWcnzlm\n\nidentifies three generic approaches to thresholding.\n\nIn\n\n[1978]\nOne is\n\nglobal thresholding as cler Ined above. Global thresholds are often\nselected by a user on the basis of experimentation to achieve the\nbest t\'csults.\n\nAutomaUc global threshold selection usually\n\ninvolves analysi:3 of the gray level histogram of the image to\nlocate a well defined local minimum between two peaks. and\nsetting the\n\nthres~old\n\nat this gray level.\n\nAttempts to improve\n\nthe results of histogram analysis include weighting th{! histogr!Un\non the basis of the I\'esponse to a local operator such\nor Laplacian operators.\nthresholdJ.ng.\n\nIn this\n\nTho second approach\nCIlSE",\n\nthe threshold 113\n\n~s\n\n8S\n\ngradient\n\ncol led locnl\n\n.\'lllo~Jed\n\nto\n\nVllr}\n\nfrom pixel to pixel depending on some function 0/ gl\'UY levels in\na neighborhood of tho pixel.\n\n2-5\n\nThe third\n\napproa~h\n\nio dynamic\n\nthreshold selection.\n\nThl\'esholds m\'c chose n for a Rubsl;! t of image\n\npOints using local threshold selection techniques.\n\nThresholds at\n\nthe remaining points are obtained by Interpolation.\n\nThus the\n\nthreshold is a function of a pixel\'s locution ill the image.\nimprovt.~d\n\n[19\'78] devised an\n\nOtsu\n\nthreshold selection method that does\n\nnClt require the detection of a minimum in the histogram.\n\nThis\n\nmethod is equivalent to fit ling to the or\';\'ginal picturo by moans\n\nof least-squares the two-valuod (or multivalued for\n\nmultipl~\n\nthresholds) picturEl obtained by thr\xc2\xb7csholding.\nThe above techniques can be extonded to col 01\' images.\nOhlander, .tU. Al. (19\'78J compute histograms for nine color\npal~ameters:\n\nI, Q.\nar~:}\n\nred, green, bllle; intenstty, hue, saturation; and Y.\n\n(ThesE\' parameters are defined in hatt [1978J.)\n\nRegions\n\nextracted by thresholding the parameter that el(h.:t.b1ts the\n\n"best"\n\nh~3togrDm;\n\ni.e., a strong peak\n\nmini rna on either s:l.de.\n\n~ith\n\nwell defined local\n\nThis process :!.s c"Ill.ed region aplit ting.\n\nThE! algorithm is applied recursively to eaeh region ext.racted in\n\na previous itera tion un t 11 no more regions con be spli t.\n\nAli .tl..t. .al.\n\n[1979)\n\nused\n\nc~u\'ol\'(}aticity\n\ncoordinates and\n\nnor\'malized intensity to segment color photographs of airplane\nrunway scenes.\n\nrhe chromaticity coordinates are obtained by\n\ndividing the intensity in eaoh of the red, green and blue bands\nby the sum of all three intensities.\n\nThe sum of the red, liween.\n\nand blue intensities is divided by t.he maximum possible total\nint \'9nsity C3 x 255 for 8-bit digitization in each band) to obt.ain\nnormalized intensity.\n\nThe inter\'esting rC5ul t of this work was\n\nthe ability to segment rUflI.ays as a Single region :tn spite of\nshadowing since the normalized color coordinates are roughly\nindependent of the shadows.\nairplanes in the same scenes\nsucc~ossful.\n\n2-6\n\nAttempts to locate camouflaged\n~/ere\n\nencouraging but not quite as\n\nFor most scenSB a simple threshold is inadequate.\n\nThe\n\nregion-split tins technique of Ohlander llIE:ntioned above performs\nbotter 1n some cases.\nmerging teohnique.\n\nBrioe snd Fennema [1970] use a region-\n\nStarting with small, fairly uniform regions,\n\nt.wo heurisUcs are used that merge l\'eg10ns so that the regions\nformed tend to be of simple shape and\n\nt~eak\n\nboundaries tend to be\n\neliminated.\n\nHorowitz and Pavlidis [197lj J use a split\xc2\xb7-and-mcrge\n\nproceduro.\n\nIt starts from an initial approximation to the\n\ndesired segmentation, and proceeds both to spli t regions and to\nmorge regions until the process s .. abllizes.\nand\n\nfD.st.c~r\n\nIn this way a better\n\nsegmentation can be achieved in some cases than with\n\njust splitting or merging.\nIt is possible to inco\':\'porate semantic informat:!.on about the\n\nnature of the scene into the region segmentation process in order\nto produce a better segmentation than can be produced using\npicture information unly.\n\nYakimovsky and Feldman [19\'[3] use a\n\ndecision-theoretic region-merging approach.\n\nThoy attompt to\n\ntlaximize a probability based on the properties of the regions,\nsuch as color, and the properties of the\n\nboundaries between\n\nregions, such as their crude shape and orientation, and how these\nproperties relate to t.hBir semantic interpretation.\nere used in or\'der to avoid an exhauative\n\ns~arch.\n\nHeuristics\n\nTheir technique\n\nhas been used on na tural outdoor scenes.\nOhte II Al. [7978]\n\nproduced\n\na\n\nsystem\n\nlIsi\'1g\n\nsemantic\n\nknowledge about objects with substructures that is able to\nanalyze outdoor scenes containing buildings.\n\nI~\n\nproduces a\n\npreliminary segmentat:Lon by means of a recursive thresholding\ntechnique similar to Ohlander\'s with local thr\'esholds, and a data\nstrtlcture descl\'ibing the relationship of the\nfOU,ld.\n\nlo\\~-levcl\n\nfeutures\n\nA plan is gener\'atod from this segmentation based on the\n\nlarger\' lowest-level !"\'ogions.\nplan and a set. of production\n\n2-\'7\n\nThe interpretation process uses th ..~\nrules.~/hich\n\nc\')ntain tht, semantic\n\n\'knowledge.\n\nIn this process aome of the\n\nl.o\'iV6k\'~l(we1 l\'OgiOllS Elf\'G\n\nremerged and an 1ntorp!reta tion :!.n terms of objeots :1.8 asaignad to\neaoh I\'oglon.\n\nThe\n\nscgm~mtat1on\n\nsystem developed by TenenbauM a.nd Bar\'row\n\n[1975] uses relax"tion techniques (described in seotion 4. n to\niteratively refine the p8.rtition1ng of an image lnto regions...\n\nAt\n\ne93h step, beginning with a very elementary\n\nof\n\npa~titioninB\n\ns.lngle pixel regions or r\'eg1008 composed of a fCH pixels ,,11th\nj.dentl(Hil attributes, the ey"telll performs\n\nth(~\n\nmoat complote\n\n:l.nterl)I\'etat1on of regions in the current parti.tion. Based on\nthis interpretation, a pair\' of regions is merged. The ohoice of\nthis pair is based on minimizing the risk of merging regions that\n\nare not part of the same object.\nof\n\nThe risk is calculated ill tm\'me\n\nthe currant interpretations of regions and relationel\n\nconstraints ill a model of the scene.\n\nThe new \xc2\xb7partitionin.:; thus\n\nortained is 1"o-interpreted r and so on r until there ere no safe\nI!l&!!"ges available.\n\nIf\' tho p:l.xell\'.l contain range data instead of gray levol or\ncolor infor\'ma t1on~ regions in\n\nconstant are\nsurface:s.\n\nmeaningful~\n\n\\~hich\n\nthe gradient is appror.ii\'"Jately\n\nsince these COl\'l\'f:lspund to planar\n\nMilgram and Bj orklund [1900 ] deterro:l.fI(! :mch regions by\n\nfir\'st fitting local planes to small arcas around each pixel by\nmeans of least squares.\n\nThen regions are grown from these\n\naccording to how well adjacent planes agree and how small the\nres1.duals of the fit are.\n\nAn edge iu a step in pixel values between two regions of\nrelat.ively uniform values. The detection of edges is often an\nimporta.nt step in the segmenti.ng of scenes. (An alternative\napprooclh, the detection of regions, .laS discussed in the pt\'cv1ous\n\n2-8\n\nsElction.\nFor\n\n~he\n\nNovatia and Pr:Lce [1978] compare these tl-l0 methods.)\npresent\n\npurpO~9S9\n\na line is defined as a thin region\n\n(perhaps only one pixel wide) of roughly uniform pixel value\nbElt .. een two regions of r\'oughly equal pixel "duos.\nthus a double edge.\n\nA line is\n\nAn edge ele![ucnt or line element is a short\n\n(several pixels) length of an edge or line that can be assumed to\n\nbe stral.ght, even though the complete edge or line may be curved.\nOne approach to the detE!ction of edges and lines is the use of\n\nC\\\n\nlocal detector to find these shor t elements, which can t.hen be\n1i.nked together by higher-level\n\nmethods.\n\nThe\n\nterm "edge\n\ndetector" is used here to denote the local detectors p which are\nthe suh_1ect of this subsect:lon.\nEven though an edge detector is a very low-level operator\nand the concept of an edge element or line element is fairly\nsimple, many edge detectors have been proposed that differ in\nvarious ways that malce a simplr..) comparison difficult, and no one\nstands aut as thH best.\n\nSurveys of edge detectors have been\n\nprovided by Davis [1975], Fram and Deutsch [1976J, and Shaw\n\nr 1979 J.\n\nA few of the mor\n\ndcscx\'ibcd belo1rl.\n\n~\n\npopular or significant detectors are\n\nUnless oUwr.lise specified, t:lese are designed\n\nto opera\':.c on monochromatic images and to detect edge elements\nonly.\nOne of the most popular edge detectors was desirrned by\nHUE~ckel\n\n[1971].\n\nIt was later generalized to detect an .edge-line\n\ncombination,\n\nand other improvements were made (Hueckel [1973]).\n\nThe Hueckel\n\ndetector operates on a circular field several\n\n(typically nine) pixels in dIameter.\n\nIt attempts to fit t\xc2\xb7.) the\n\ndata an ideal edge function consisting of constant\n\nb;~ghtness\n\non\n\neach side of a perfectly sharp edge which can be at any pvsi tion\n\nand orientation within the field.\n\nThus four parameters are\n\nsolved for (six in the generalized version Hhich fits an edgeline combination).\n\nFor 3pN.:d,\n\nthe operator only approximates a\n\nleast-squares fit by means of a set of orthogonal functions.\n\nSince the edge does not have to pass through the oanter of the\nfield, the operator can be applied on a grid \\-lith sufficiently\nsmall spacing so that there is some\n\nover~ap\n\ninstead of applying i t centered on every pixel.\nfairly good overall speed.\n\nof the fields,\nThis r(l$ul ts in\n\nHowever, the detection of off-center\n\nedges is somewhat degraded.\n\nNavatia [1977J generalized the\n\nHueckel operator to use color .information.\nSaveral edge detectors are based on the use of very small\n(two-by-two or three-by-three) weighting functions which are\nconvolved with the input data to approximate the two components\nof the gradient, from which the magnitude and direction of the\ngradient can be oomputed.\n\nA sufficiently large magnitude is\n\nconsideI\'ed to represent an edge, but these points usually must be\nthinned if a one-pixel thick edge is\n\ndesir(~d.\n\nA popular detector\n\nof this type is tihe Sobel operator (dcseribed by Duda and Bart\n\n[1973J).\n\nIn the elementary forro of these operators as stated\nabove, they ar~ fast but are quite susceptible to noise. To\nimprove their noise rejection (at the cost of lesH speed and\nreso) uUon) their\n\n~/elght1ng\n\nfunctions are sometimes spread out by\n\napplying each Height to tho average of several pixels in a square\narea, as described by Shaw [1979J.\nFrei and Chen [19\'f71 use a varitttion on the method of the\nprevious paregraph.\n\nThey first find\n\nthe magni tude of the\n\ngradient by means of a three-by-three opot\'ator.\n\nNext they\n\ndetermine how well this fits an ideal line by using an orthogonal\nset of three-by-three functions, and then threshold the l\'esult\naccording to the goodnes3 of fit instead of by the magnitude.\nNevatia and Babu [1979] designed an edge detector that\nconvolves the image with a set of ideal edge masks several pixels\nwide,\n\neach of which bas a differoen t\n\n2-10\n\nedge direction.\n\n(In\n\npractice, five-by-five maslts tlith orientation every 30 0 have been\nllsed.)\n\nThe mask orientation that produces the highest output at\n\neach pixel is considered to be the edge orientation for that\npixel.\n\nHowever, an edge ls l\'eported a t a pixel only if its edge\n\nmagnitud,~\n\nis a malcimum along the normal to tho edge d1recti.on,\n\nits edge direction agrees approximately with its neighbor5, and\nits magnitude exceeds a thresilold.\n\n\'1\'hi3 edge detector has been\n\nuStld on distance data by Inolruchi tl.nd Navatia [1j80].\nMarl\' and Hildreth (1979) note that. different edges 8.l\'e found\ndepe!1rling upon the size of the edge mask.\n\nTo capitalize on thiS,\n\nthey use information from severnl spatial frequency channels by\nconvolving the original image wHh Gaussian smoothing filters of\nv\'arious sizes.\nthe\n\nsecond\n\nEdges are located by finding the zero crossing of\nspatial\n\nd(~rj.vatlve\n\nof. the\n\nsmoothed\n\nimage.\n\nComputationally, th:l.s amounts to finding the zero crossings in\nthe convolution of the Cll\'J.ginal image Hith the Laplacian, V 2 g of\nthe Gaussian smoothing fil tet\' for each spatial frequency channel\nThis transformation contains nearly all of the infol\'wat:l.on\n\nused.\n\npresent in the original image.\n\nEdges are said to occur\n\n~Ihe.e\n\nthe\n\nzero crossing$ from several spa tinl frequency channels concur.\nAll of the above edge detectors perform\n\nhigh-quality image.:)"\n\nOf courso,\n\nsatisfactorily on\n\npel\'fect results cannot be\n\nexpected because of the imperfections In real imagcs, so the\nhighel\'-level processing must be able to handle occasional errors.\n\nHowever,\n\non poor-quuli ty images the performance of\'\n\nthese\n\ndeto0tors deg1\'ades 1n diffE:rent ways depending on the amount of\ni1l1age\n\nnoise~\n\nblurrillg of edges, faintness of edges, and smooth\n\nvariations in pixel values Buperimposed on the edges.\nthat none of them is the last word in edge detectors.\n\n2-11\n\nIt appears\n\nLong edges or lines oan be found either by using an edge\ndetector as dlsCllSS.ed in the previous :Jaction and l1l"Jdng these\ninto a long smooth curve, filling in gaps and ignoring stray\nelements, or by a procedure which a.ccomplishes a similar\' reaul t\nby operating directly on the image data, bypas\'3ing the need for\nan edge detector.\n\nIn either case, the algorithm oan operate\n\nsequentially by proceeding along the curve as it links edge\nelements or pixels, in which case it often 1s oalled a line\nfQllower (or tracker),\n\ne~g()\n\nrolloHe!\', or curve follower, or it\n\ncan operate on an effeotively parallel or gestalt basis.\nSeveral investigators have used sequential techniques that\nlink edge or line dements.\n\nFor example, Shirai [1975] used a\n\npair of parameters that vary accordlng to how uontinuously and\nSMoothly the elements arc being found.\ndetel"wir.e thresholds\naCI~ording\n\nrOl\'\n\nThese\n\nparameters\n\ndeciding when to accept a nSH element\n\nto how close i t lies to the lineal\' continuation of the\n\nouprent tracking and \\>lhen to stop the tracking.\n\nRoberts [1965]\n\nusod an elaborate line-finding method that contained elements of\nthis kind of technique.\nMartelli [1976] used a global heuristic search instead of a\nlocal searoh.\n\nHis metbod operates directly on the brightness\n\nVUlUBS instead of uslng a separate edge detector.\n\nIt attempts to\n\noptimizA. a cost function that depends on the curvature and the\ndegree to Hhich the curve separatE!S\nbrightness.\n\nregions of different\n\nYachida rl.iU.. [1979] used a simibr method based on\n\nthe output of a local edge detector.\n\nKelly [1971] devised a method in which edges found in u lowresolution version of the picture and selected according to\nglobal knowledge of the shape being sought are used to form a\n\n2-12\n\nplan, which is then used for\n\n11nki~g\n\nthe edge elements in the\n\nfull-resolution picture.\nEberlein [1976J pl\'oposed a relaxation method (soe Section\nfor linking edges found by a local detector.\neffectively parallel method.\neac~\n\n\'n\n\nThis is nn\n\nOn each iterdion the strength of\n\nlocal edge element is changed accordi"g to how well it\n\nagrees with its neighbors, until the process converges\n\n"\':l\n\na. thin\n\ncontinuous line.\n\nWhen curves <"re derived\npreprocessing step is thinning.\n\nedg~\n\nfrom\n\nThinn~ng\n\ndata,\n\na useful\n\nalgorithms reduce\n\ncontours to a single-pixel width by discarding redundant edges\nwhile ma:l.ntaining the global cor.nectivlty of all contours.\nmethods,\n\nsuch as Eberlein\'::, just mentioned,\n\nan inherent part of the\n\ninclude ",hinning\n\nStefanelli and\n\n~peration.\n\n[1971J describe a thinning algorithm for binary\ndecides the fate of each cdgebasvd\nneare~t\n\n0:"1.\n\nneighors in a 3 by 3 window.\n\nSome\na~\n\nR03~nfeld\n\nimag~s\n\nwhich\n\nthe states of its e.1 ghe\nNevatia ann B&bu [1979)\n\nperform thinning by 3ccept1ng the edge\n\nwhic~\n\nhas a maximal\n\ngradient value compared to adjacent pixels with .?imilar gr\'adient\nol\':l.er.tat1on, as mentioned :;\'n Section 2.11.\nHough [1962] pr\'oposed a global parallel methe,\' for finding\nstraight lines, vl1110h was\n\nimproved aJ:1d extend"Jd to other curve\')\n\n[1972].\n\nIn thj.s method thp. dtsil\'ed CUt\'ve. is\n\nby Duda and Har~\nre~resented\npara.met~r3\n\nby a few parameters.\n\nare needed,\n\n(For a\n\nL~ra1ght\n\nline, two\n\nfor which the angle of its direoUon aad\n\nits normal distance from \\;he origin are recommended.)\n\nEach point\n\nin the image that is a candidate for being on the curve (by\npi\'oducing significant magnitude from an edge detector,\n\nfor\n\n9xample) is transformed into a cUI\'ve in the parameter space.\n\nThe\n\nparameter spncG is quantized, and eDCa cell accumulates the total\nnu~ber\n\n(or total edge magnitude or other weight measure) of\n\n2-13\n\npOints that pass through it.\n\ntransform~d\n\nresul. tins historgram in\n\nth(~\n\ncurve in the original image\n\nr inding\n\nparameter space then represen ts a\n\nThis is a fast method for\n\n~pace.\n\ncurves that requil\'o only a\n\nr\'equirecl accuracy is not teo iligh.\nto quantize the\n\n~arameter9\n\nparameters is more\n\nth~n\n\nA large peak in the\n\nfe~l\n\nparameters,\n\nBOHavel\', it\' it \\5 necessary\n\nvary finely or if the number of\n\nabout three, the number of cells becomes\n\nvery large, r\'a8u:\'.ting in toe noed for muoh computing\n\nst4:>rf\\ge space.\n\nif the\n\nTho computing problem can\n\ndlr~otlonal\n\nbEl\n\nand a large\n\nnllevia ted somewhat\n\ninformation from tho edge detector that\n\nproduced the pOints is used to\ninc toe me n ted for each poi n t.\n\ntle number of cells\n\nre~tr1ct\n\nHOH ever,\n\ndirectional iuforraation .is seldom accurate,\n\nnecessary to increment oells\ndirections.\n\nif the\n\ns~.\n\nnc.e th 1 s 1 00 a1\n\nit is still usullJ.ly\n\nco~responding\n\nto a band of\n\nThese matter\'s ara discussed by Wechsler and Sldansky\n\n[l9111, among others.\n\nEven though the relatively global knowledge about the /;lha;>e\nof the c\\.lrve (t.;hether its procise shape or just:. its s!1lo()thneoss)\n\ntha.t is used in the above method-s tenda to reduco the\non the basis of only local eVic1enoe,\n\ncmpected wi th\n\nr~al\n\nimag(~,;.\n\n131":-0.\'8\n\nrT\\ade\n\npor\'fectiCJn oannot be\n\nEach hip;her lev(!l of processing must\n\nbe .. bIe to tolerate the 4"l\'ror\'S fl\'om the 10U81:\' levels and\nhopefully to filter out some of them, in order to reduce the\nburden on the yet highe\'l" levels.\n\nChain code is a compact representation of region bou tar1es\n\nor, more generally, of an:v\' line stt\'ucture il1 an image.\n\nA chain-\n\ncoded boundary record consists of a header contnilling the image\ncoordinates of. the starting point and the length of the boundary,\nfol\'.owed by a list of chain links,\n\nOl~\n\nvoctN\'s, ..:hich I\'epro8enl:.\n\nthe boundary as a sequence of moves from boundary point to\n\n2-14\n\nboundary potnt.\n\nSevornl chain-codinh Bchamas aro d03crlbodln\nIn its mosL typioal form. thoro orc oight\n\nFl"\'ccU\'lan [1974 J.\n\npo::wit-.LO voCtOl\'S OO~\'t\'03POlldill.s to links but\\woll n point. nnd onch\n\nof\n\n1t~1\n\noight nearest.\n\nnoighbm~s\n\nvee to!\' to OlH1h noighbol\'\n\npo~~ltion\n\nThll~.\n\nZIH\'O t.o Slwon.\n\nIn u lhl\'oo-by- t.hr\'l1o "Iindow.\n\nTho\n\nis u!H1igncd a unique nur.:llor t\'r\'l)ll1\n\n1n its most\n\nooru~\'<1()i,.\n\nf~rm,\n\ntH\\oh chnln\n\nelomcnt l\'oQuiN):;! only lht\'Qa bits ot\' stO!\'ugll.\nu!1(\'lf\\llrw~:>\n\nChllill coda i3 of l1ru!t.oo\n\nin modelling t)hjoct.s fOl\'\n\npattern rocognition 5inc6 it Is difficult to oomputo gone!\'ul\nrotutio~8\n\nor Bculo changos required for mutohlng.\n\nusoful, however,\n\nU8\n\non\n\nintermodi8te-l~vul\n\ndosoription of tho\n\nfcnt\\li\'t.w HI\'t\' tixtract.tHl.\n\nimage [I"om which useful\n\nCunninghnm [19791 d03CI\'ibe\nmom~nt9\n\ncomputing rogion\n\nIt oun be\nWill\' and\n\nbOlindal\'Y tl\'uver~nl algorithm fot\'\n\nII\n\nfrom n chuin-codlld boundary.\n\nTho\n\nmoments (\'nn bo \\l8od to do rive tho arcn, controid, Dnd oriontuti0n\n(oxis of minimum m0mont of inertia) of a region, Hmong othor\n\nFreeman nnd Dovis (1977) describe nn ulgorjthm for\n\nthings.\n\nlo(!uting Q01\'nCrs in linD dr\'!lu!ngl:1 l\'OPNH.\'II\'otcd by chnin code. (Seo\n\nSti(\xc2\xb7t.ion 2.7)\n\n(\'twin codo can\n\nul~~o :301"\\,(\' n~> Il\n\nst.arLing point\n\nhighnl\'-ll\'vel boundnr\'y d"\'IJCf\'ipU.on com1isting,\n\narbHrm\'y lC\'ngto l i no\n\nMgi\'\\Wnt sand\n\nc ircul!w\n\noXlll1lplo, of\n\nfOl\'\n\nFrtH~!ll un\n\n!1t\'C:J.\n\n1\'01\' H\n\n[19" 11)\n\ndescribos othor chain-oode runnipulntiol19 ouch ou smoothing,\nrota tion,\n\nA~\n\nlHlli\n\ncOl\'l\'oln t.ion\n\nan nltllrnntivu to\n\nl\'<iS:()B) tH\' in add i lion to\n\nt. 0\n\nbtl\n\nill a\n\nUSfl d\n\ndimensional\n\nby\n\nimng!)\n\nI\\n!:;lo~\'.\n\nmo~\'c\n\nt}IOS{\\ I\n\nl\'r los:> :stl\'UiS:ll\n(\'{)rn(>r~1\n\n<HH~\n\nilnngn)\n\nbe\n\ndt~l\'.tlH\'d\n\nCr\'om\n\nlil:n~l\n\nt\'ny b0 u sd\'ul\n\nht gtw ~\'-1 (\'II t\' 1 P r\'oe (IS ~I(\' s.\n\n1\'()SOlutl(>llOf lh-n\n\nV1\\1\'101l:;\n\ntclling.\n\nas\n\nA\nn\n\n(including\na:l\n\nCOf\'IHlI\'\n\np()int.\n\nt.hloh two or mOl\'c\n\nI\'t)(~tion\n\nof t.ho\n\n(~UI\'V(:.\n\n0\n\ntur\'os\nt\n\nW 0-\n\n(within\n\nUIW~l\n\nIf t1wr<\' uro only t.wo, lilt\' corno:\' is\n\nubl\'llpt changt; in tll,\', dt\n\nin\n\nfl1!1\n\nt.he\n\nemanate) nl\nmtJl\'~\'ly\n\nun\n\nIn tho lilt tel\' 01\\30, one po::wibil ity fOI\' detooting the cornor\n13 us an integl\'al pal\'l of the curvf.l-fHting p,\'ocess.\n\nHartalli\n\n[1976] includod suoh nn ability in his method montioncd in\nDuda and IItu\'t [1973) di~cu~s an ittll\'llllvt) end-po1.nt\n\nSoc lion 2.5.\nfit mothroJ\n\nfOl\'\n\ndoing tlli:-l I>Ilwn ~\\t:\'night\n\nlillllS\n\nIll\'O bolng f i t by\n\nmeans or leaat nquares.\n\'~hlcl\' a l!UI\'V(l\n\nhus\n\nfolloHOt\\ HUh only Vtl!\'Y locnl (if any)\n\nbt!llll\n\nit is possiblt\\ ttl dt\\toct\n\nCOllstc.,int.s,\n\n(Aft.tll\' tlli::! IH\\S blH\'n dt\'llo,\n:311100t.llOd i f ~1tl:lil\'od.)\n\nCOI\'nel\'S\n\nt.he\n\nl1UI\'VO.\n\nCUI\'VO\n\ncan bo\n\non\n\ntho ::H\'gll1tllits of tho\n\nl19\'j3] dd.uats point.s of maximum\n\nCl,dtll\'bt\'I\'g\n\neUI\'vut.lIl\'O in Ol\'UtH\' t.o locato tho cOl\'nors, by using n !\'ocUrSiVtl\n\nsmoothinM filter techniquo UOS1SDOd t.o be imrlemontod on a\n\nKruso and Rao l1918} detuct C0rners by moans\n\ncollu18r processor.\n\n(\'I\' ,1 mUll~lll\'u filltll\' oplll\'.\\ting on t.he mH\'onu dlll\'lvntive of tilt\'\nIt.mgt.h of\n\n11\n\ndist-fillet) nf1ul\'t.\n\naloll~\n\nFreeMan nnd\nc u\n\nI\'V 1l~1 by\n\n10 l\' 1<1 n ~\n\n(l\n\n[1977] dolue!. cornors in chain-coded\nnr. tilt\' ~11 opo,~ 0 l\' dlOl\'d 9 I\'on Iltll1 t i ng I;l dgl:!\n\ni\n\n+ n 1\'01\' :IOUW ,at\'bit.I\'ar\'ily\n\nt. till\' 910 P I\'\n\ndlan~t\'\n\nl~UI\'Vl\'.\n\nUll1\n\nl)\n\nposit.ion ,)11 t.ht1 CUI\'VI-\',\nntll\'upt\n\ntWl) point.s thut. Ill\'{\\ 11 constant\n\nDRVi~\n\nell 1 eu 1 a t\n\n.1. Hnd i\n\ntlllllUC1:l\\.:l\n\n~l)llIll1~tillg\n\nd10l\'d\n\nin till\'\n\nf\n\nt h () S I\'\n\nC h () I\' d:>\n\nl~OI\'ntH\':l\n\nU 1:\'\n\nell()~ltHl\n\na fun c t. i. 0 il\n\ndettll~t.od\n\n111\'0\n\nCOIl:ltant n.\n0\n\nf i.\n\nBy\nthe\n\non tho basis of an\n\n91\\.)(.\\(\\,\n\nIl ::1imilal\' npPt\'ol\\ch i:l u:lod by Tl\':;\':;"~\xc2\xb7lrt11d and Wr\'szka [19\'75].\nIn !.twil\' algol\'it-hm :ICVtH\'/ll chon1s HI\'I\' ue>fintld t\'lH\'\nt\'\n\n1 u m(\' 11 t i bye 0 nne (\' tin g\n\nvalul\'::I of k.\n~\'bll.\\.1Ill\'d,\n\nanaly~\xc2\xb7.ing th~\'\n\ni\n\niH! ,i\n\nII i\n\nn f 0 t\' (1\n\nt\\~O 01\' thl"H)\n\nk\n\n\xc2\xb7t\n\nII n d\n\ni-\\{ f\n\nliS\n\nn\n\n0 I\' $ 0\n\nSl~t\n\nslopes of tho\n\nthe odgtJ is ,: lass! fied\n\nP (lI\' l.:i n:l\nClWnt\' I" of\n\nBy\n\nl\' d g 1\':J\n\nI~ach\n\nmt\'\n\noi\'lg{\'\n\nI --: r. g <1 l\'\n\nr\n\nof eho!\'ctl:l t.hus\n\nl~OI\'IWI\' ClI\' llon-eO:\'lllH",\n\nl 19., 3 1 d v .t ~Hl d a\n<)\n\nlilltw when it. 1:1\n\nIII tl\n\nklll\'wn\n\ntlw d\n\nr 0 I\' fin din g\n\nIi\n\nIlN>I\'oximat.ely WhtH\'f-\'\n\nthe corner should appoar in the imago. The cxpectod\n\nsNU\'ched for\n\n~ltr\'aight\n\nis\n\nHnen vldch approximately mutch thc\n\nexpt1ctcd linos from tho model.\n\nint.erseotion of these lirHls.\naNI\n\nnr~~\n\nThen a corner is found as the\n\nSeveN\\l refinements in the ntl1thod\n\nincluded to improve ita l\'t,linbilHy.\n\nA pyramid data structure represents an imnge at severnl\nlevels of resolution simul tancot/51}\'.\nthe original full rt,soltlUon imnge,\n\n2"\n\nsquaro array.\n\nThe base of tho pyr\'unlid is\n~lsunlly\n\nand mapping the four\n\npiXt~ls\n\nnonov(~rlllpping\n\n01\'\n\n2 n by\n\n2 by 2 cells\n\nill each cell to a single pixel in tho\nExamples al\'a tho\n\nVarious mappings are possible.\n\nuverage gray level of a ceH, the minimum\ncolI,\n\nIl\n\nThe next level 0f tho pyramid is formed by\n\nplllrt1tioning the originul image into\nnoxt 1 i,)Ve}.\n\n81:\'sumed to be\n\n01\'\n\nmaximum value of\n\ntilo output of an edge detector applied to tho cell.\n\n11\n\nTho\n\nc()mplete pyramid is formed by ropen ting the pI\'ocess r. t (lUoll level\n\nuntil tho image has boon compressed to a single\nhighest H\'vel.\n-,11-1 by\n\nGo\n\n..,0-\'\n\n(_,\n\nTho resul t is a\n.~Qo\n\n,\n\nof images of\n\n2 by 2, 1 by 1, each\n\nat different rosolutions.\n\nS()OIKl\n\nS".1t\n\npi~cl\n\nS!z,iW\n\nat tho\nn by 2n,\n2\n\nropresenting tho somo\n\n\'The pyramid rCpNHHlntation can\n\nbe gcnoraU zod by dofining an urbi trury n by m parti ti oning at,\n\ncBch level.\nTho usofulnoss of pyramids lies in being\nfontures at nn appropriate lovel of\n\nrosolutio~\n\nabl~\n\nto extract\n\nThis simplifies\n\nrocognition by reducing tilt) sour\'oll space (imago lll\'rny size) and\nsuppressing unnecessary details.\n\nfoutures can be extl\'acted\ndotail\n\nClm\n\nfl\'()llI\n\nGenerally speAking, gross\n\nhigh levels of the pyram id.\n\nbe extraotod wller\'(l nocessary\n\nfl\'OUl\n\nlower levelg.\n\nFinOl\'\n\nAs nil\n\nolwmplc, tho (\'csul t,s of odgti detection or\' rtJgioll g\',\'OWillB in a\n\n1.:.. 11 lcvel of tho pyramid can be used to constrain tho soarcll in\n1010101" levels as\n\nobjec\'C\n\nd03(~riptions\n\n2-17\n\nDI\'l1\n\nrofinnd in highet\'\n\nresolution.\n\nUhr\' [1972:l proposed a IfI\'ecogn:l.t.1..on cone" model for\n\nimage analysis in whie;, successive operations produoe abstracted\n\nor simplified versions of the original image at inoreasingly\nlOIHH\'\n\nresolutions.\n\n\'Tanimoto and Pavlidls (1975) used a pyramid\n\nobtained by averaging 2 by 2 blocks.\n\nPyramids orc also contral\n\nto tho scene analysis work of Hanson ond RisemBn [1978b] and\nLevi ne [1978).\nTho quadtrce repl\'csentati on of\n\nH\n\n2 n by 2 n image is obtnlned\n\nin a top-down manner by recursively splitting the image into\nquadrants,\n\ntho quadrants lnt"\n\n~,ubquadrants,\n\nand\n\non.\n\n30\n\nTho\n\npr\'ocess continues until the quadl\'ants aro one pixel in size, or\nall pixels in a quadran t\nfeatul\'o.\n\nare uniform w1 til respoct to\n\nThe result is a tree where each\n\nfour children,\n\nnon~tel\'minal\n\nSOtlC\n\nnode has\n\nand torm:i.nal nodes repr\'osent square uniform\n\nregions of the imnge.\ntorminal node is\n\nB\n\nIn a binary image, this means that each\n\nblock of all white or all black\n\npixel~\n\nWherEas .\\ pyramid ropresents the image at multiple resolutions,\nqundtree 1S a variable resolution image,\n\nB\n\nrepresonting each arca\n\nof th.i image by the largest. t>quare region possible.\n\nSa~et\n\nand\n\nRosenfeld [1980J have adapted several standard binary image\npt\'(lccssing algor\'1 thros to 0 PCl\'1l ta 011 quad tl\'ces,\n\ntrucking,\n\nsuch u.s boundary\n\nconnectivit.y analysis, genua (number of halos)\n\ncomputation, and extraction of features slich as area, momcll"s,\nDnd perimeter.\n\nThey have also developed efflcient tree traversal\n\nalgorithms which do Quadtroe/rBster and Quodtree/chain code\nconvel\'siol1S.\nFor a recent survoy of image analysis techniques using\npyrH.mids and quudtrees see Rosenfeld [1980b).\n\n2-18\n\n3. DESCRIPTION\n\nWnys of describing n scene or object and of deriving tho\n\ndescription from an image will now be discussed.\nconcerned\n\nnCl\'o\n\n\\.;ith fairly high-level\n\ndescription3~\n\nthe , ""er-level concerns of Section 2.\n\nWe are\n\nas oppo:Jcd to\n\nAt these higher level s,\n\n\',\' !leS more difficult to judge what the best approaches al\'e.\n\n:It\n\nJ\\$ a rcsul t a wide variet:,; of techniques has been used.\n\nWe can\n\nprovide h,ero only a oursory view of some of the more important\nwork.\n\nFor more information the reader can consult the surveys by\n\nJ?avl1dis [1978J,\n~(\'enenbaum\n\nShil~ai\n\n[197&], Bajcsy [1980], and Barrow and\n\n(1981).\n\nThis section discussc.3 descriptions that are basicalJ:r tuodimensional.\n\nThese mny be used for planar surfaces f:oni;nined\n\n11\'1ithin a three-dimensional scene, or they may be u::,.ed for-\n\nprojections of flat three-dimensional objects of\n\nk~own\n\norient.ation relative to the camera axis.\nWhen an image has been segmented by the techniques described\nin Section 2.3, a description of each region, or blob,\ngenerated consisting of a list of statistical 1\'e?tures.\n\nc~n\n\nbe\n\nThese\n\nfeatures typically include area, perimeter, first and second\n\nl:>rder moments, color, eto..\n\n\'the individual blob de::.criptors ar\'e\n\nlinked to form a tree data structure which represents nesting\nl~ela\n\ntionshi PI\').\n\nThe parent of any blob in the tree is the\n\nadjacent blob which completely surrounds it.\nr\'1odule (Ni tzan li.il.1 [1979]) and CONSIGHT (Wurd\nuse this npPl\'oacb.\n\nThe SRI Vision\n.ct.~\n\n[1919])\n\nMilgr\'am [1979] presents the details of a \\.\'nc-\n\n3-1\n\npaSf] algorithm whioh (lonstr\'lIo\\;.3 e \')lob tree deosoript1on of a\n\nbiMlt\'y image.\n\nPerkins [1978] describes ob,1ects as a set of "ooncurves."\nconcur".\'c i8 an OrdCN\'ld\n\ns~t of.\'\n\nstraight Hnc\n\nf:h~gD10nt3\n\narCi3 which approltimate tho boundary of an objeot.\n\nAn objeot such\n\nas a connecting rod for an automobile is modelled as\non~\n\nooncurvca,\n\n\'~1th\n\nth~ee\n\nfor tho outer boundary and one eaoh for the\n\ncrankshaft and piston pin\n\nnss()ciated\n\nA\n\nand oircular\n\nhole3~\n\nrespeotively.\n\nConcurvcs\n\nobjects in an image are derived from edges.\n\nIf\n\nthe resulting concurves form closed boundaries? statistical\nfeatures sim:l.lar to those described abovo arc computed for the\nenclosed region.\n\nAlso, aS50cj.atcd wi th each ooncurvc is n number\n\ndescribing its rotational symmetry.\nCOI1I~llrve\n\nThe main advantage of the\n\nrepresentation is that objects may be recognized on the\n\nbasis of partial vj.ews by mat(- ing a subset of the lines and arcs\nin a model conCUI"Ve wi th thf\' image da to..\nde~cription\n\nShapiro [1979] surveys data structures used for\nand pattern recogni tion.\nclf\n\nThe paper concludes wi th a discussion\n\na recursive data structure foX\' representing line ors.wings.\n\nA\n\nfICTURE 1s constructed cHI a result of evaluating a picture\nexpression.\n\nA picture expt\'esl3ion consists of primitives (LINE,\n\nARC, CIRCLE,\n\nSQUARE~\n\netc.) and possi.bly other pictures, with\n\nprovisions for specifying the relati va or absolute position and\norilenta Uon of var:!.()Us components of the image.\nBlum [1967 J PI\'oposed a msthod of representing planar\nreg.ions, known as the medial\xc2\xb7"8xif3 transfol\'ma tion\ntransformation.\n\nOk\'\n\nprairie-fire\n\nIn thj,s method a r\'egion 1.s described by a\n\nskeleton which is the locus of points equidistant from tho\nboundaries of the region on each side of the axiS, and by the\nvalue of th13 distance for each point on the siceleton.\n\n3-2\n\nNevtit.ia and Price (19\'18] describe two-\xc2\xb7dimenstonal scenes by\n\nmeans of a graph struoture in which regions and lines are the\nnodes and the positional t\'elationships between them are the al"cs.\nRosenberg itt..alI [197 8J\n\nprodu~e\n\na I\'clative depth map for\n\nregions in a two-dimensional view by using heuristics that\nindicate the occlusion reIn tion:,tdps amoi1g these regionlJ. A\n\nscene is first segmented into regions by some technique as\ndiscussed in Section 2.3. Heuristics are used to lnulcate Hhlch\nr.~gions\n\nmay be occluding other regiona.\n\nr.~laxation\n\nThen a probabilistic\n\nprocess (see Section 4) is used to resolve the\n\ncontradictions that the heuristics have produced.\n\nIn this section tht\'ee-d1meosional objects are consider\'cd,\n\nbut they are restricted to simple polyhedra with uniform surface\nr,eflectance and usually diffuse illumination.\nRoberts [1965J produced perhaps the first\nanalyzing three-dimensional scenes.\n\nprogram for\n\n\'fhis metbod first extracts a\n\nline drutiing from a p:l.ctul\'e as described in Section 2.5.\nline drawing must be a \\..opologica:j.ly\n\np~H\xc2\xb7rect\n\n\'X\'his\n\nprojection of\n\nobjects made of three simple geometrical models (n cube, a wedge,\nand a hexagonal pr\'ism) that. can be stretched in each dimenf\'lion,\nrotated, and t.ranslated.\n\nThe line drm\'Jing is then matched to the\n\nmodels one at a t.ime by comparing the polygons intersecting a t a\npoint in the picture to the faces of the models, untn the entil\'c\nscene is described in terms of the models.\n\nThe distance and\n\nhence the she of each object is obtained by assuming that each\n\nobject is \'supported by another object seen or by the assumed\nground plane.\nGuzman (1968) produced a progr(\\m that analyzes a perfect\n\n3-3\n\nline clrawing that represents a projection of arbitr\'ary polyhedra.\nBy\n\nmeaos of heuristics it\n\nthe polygons 1n the line drawing\n\ng~oup8\n\nobj~ct\n\nmodels other than the\n\nknowledge that the objects are polyhedra.\n\nThe program usually\n\ninto objects, without the use of any\n\ndoes quite well on complicated scenes j.nclud:1ng occlusion, but\nthe fact that it requires perfect\nlimitation.\n\nli~e\n\ndrawings 1s a serious\n\nBrice anel Fennema (1970J used a technique similar to\n\nGu.zman\'s together with some semantic knot-fledge to identifY the\nfloor and walls in a\n\nroom scene.\n\nto insert misSing lines.\n\nThen some heurist! C5 t"ere used\n\nFalk [1972J extended Guzman\'s\n\nh,eut\'isti cs and used a se t of nine fixed-size three-dimensional\nmodels in terms of whioh the scene is interpreted, so that\npE~rfect\n\nline drawings are not necessary.\n\nGrape [1973J used\n\nhID-\n\ndimensional models of edge structures for convex objects to\nidentify missing lines.\nHuffman [19 r{1] and Clowes (1971] eliminated tLe need for\nhcuristics in intel\'preting perfoct line dra\\..rings.\n\nThey\n\nrE!cognized that each line in the picture represented either a\nconvex edge, a concave edge, or an occluding edge in the threedi.lllensional scene, and they constructed a oatalog of possible\nvertices tfi th allowable line labellings.\n\nA scene can then be\n\nanalyzed by starting at one vertex and proceeding through the\nline drawing performing a tree seal\'ch, lim! ting the number of\npossible line labellings at each step according to the catalog,\nuntil a consistent labelling for the entire scene is obtained.\nWaltz (1975) extended this Hork by inoluding shadows and cracks.\nHe produced a catalog of a few thousand possible vertex typos,\nand used a relaxation-type\nthe\n\ncorrect\n\npK"OCedl~r~\n\nlabelling for\n\npossibilities in the catal.og.\n\neach\n\n(see Section II) to decide on\nline\n\naccording\n\nto\n\nthe\n\nThis pl\'ocedura converges rapidly\n\n(uflually to a unique interprE,tation) regardless of the complexity\n\nof the scene. Hal tz also included a liwitM ability to handle\nImper\'f(\\ct line drawings by :l.ncluding in the catalog some of the\n\nmost co"\'liion cases of missing edges.\n\nPreuder [1980] showeri how\n\nsimple!\' catalogB of vertices ccula be used together with\noccasiollal exam ina tion of the scene to obtain more information.\nShirai [1975] annlY\'Led scenes of polyhedra by first finding\nthe lines separating the objucts from the background by using the\n\nassumption that\ngencl"ull:{ fainter\n\nthese ur-c h1gh-contrast\nedge~\n\nThen\n\nedges.\n\nthe\n\nseparating objects or faces of objeots\n\nare hypothesized by means of heuristics and searched. for in the\nimage.\n\nA het.erarchical structure 1s llsed :l.n the progrrun, rathel\'\n\nthan the usual hierarcbi cal structure.\n\n\'.11111 t\n\nis, it\n\n1.3\n\norganizod\n\nas a comlDunity of experts that communicate with one another\'.\nWinston [197 5b ) produced a program that,\ndra\'~ing\n\ngiven a 11 ne\n\nrepresenting polyhedra, produces a description of the\n\nscene in terms of a network of objects and their rela tions such\n83\n\n"suppox\'ts,1\'I "abC\'ve,1i !lleft of," "in front of," and so forth.\n\nA method siroilor to Guzman\'s is used to segment the :Jeane into\n\nobjects.\n\nThen some rules and heurisUcs are used to derive tho\n\nrelations.\n\nIn this process\n\nprocess of conJecture,\n\ng~oups\n\ncrltlclsm~\n\nof objects are formed by u\n\nand revision.\n\nThe conjectures\n\nfind objects linked by relation chains or bearing the same\nrelation to some common object. Then the criticism and revision\ndelete from a group objects whose membership is weak compared to\nthe average for the group.\nare used by his\n\nl~arning\n\nThe resulting description networks\n\nsystem described in\n\nSectio~\n\n7.\n\nIn this section more complicated objects and scenes, often\nwi th cUf\'ved surfaces, are considel\'ed.\n\nAl though some of these\n\ntechniques have a degree of generality and have been used for\nrecogni tion as described :In\n\nS(1Cti0r.1\n\n4, they still fall\n\nwhat Is needed for u general, powerful\n\n3-5\n\nv~sion\n\n~lh0rt\n\nsystem.\n\nof\n\nFor\n\nth~\n\nexample, two tasks that, al\'e beyond\n\nco.pllbility of any e:risting\n\ncooputer vision system are t~he reoogni t.ion of Pl.U\'ts in a jumbJe\nin a bin and the operaUon of n robot vehicle 1n a complicated\noutdoor environment.\xe2\x80\xa2\nMarl\'\n\n[197 B] desoribed\n\nt!H\'(H~\n\nle\\\'elfl of representation.\n\nlowest to highest, these are the primal sketoh, the\nSkE!tch, and the 3-D modeL\n\nFrom\n\n2-1/~-D\n\nThe primal flketoh if.! in 1conic\n\n(image) form, but it makes information about the location of\nlines and edges explicit.\n\nThe 2-J./2-D sketch is also lconi.cr but\n\nit represents depth information and\n\nBu~face\n\norientation\n\nr~lative\n\nto the viewer, and it makes depth discontinuities explioit.\n\nThe\n\n3-D model is an ob.ject-centered l\'epresenta tion that describes the\nobject in a convenient way, perhaps in tertas of genoraliz<:.\'<i cones\n\n(described belo,,,).\nOhta .e..t.\n\nlJ."k\n\n[1978] use a semantic ncttrork\n\noutdoor scenes oontaining b1.l.:lldings.\nhierBl\'chical st.ructUI\'e describ1ng\n\nfOi\'\n\ndescribing\n\nThe llehwrk consiBts of a\n\npflrt-~lhole\n\nrelationshipc, two-\n\ndimensional positional relationships, and properties such as\ncolor.\n\nThe method of segmenting the scene to produoe this\n\nstructure wa..~ der3cri.bed in Section 2.3.\nBarrow\n\nand\n\nTenenbaum\n\n[1980] propose\n\na method for\n\ninterpl\'eting curved lim drawings as three-dimensional surfaces.\n\nTo interpret a two-dimensional curve they compute a thrcodim(~nsional\n\ncur\'ve\n\npl~oJecting\n\nto it that minind.zes a combinaUon\n\nof variation in curvature and departure from planarity.\n\nFor\n\nexample, an el.l1.pse would be interpreted as a Circle, since a\n\ncircle has constant curvature and i8 planar. To interpolate\nsurfaces between boundaries, they attempt to make the two\nobsel\'vable oompor,ents of the surface normal vary a\xc2\xa31 U.nearoly a3\npossi ble re1n ti ve to the i mnge coordi rm. tes.\n\nBinford introduced the concept of generalized cones (also\nknown as generalized cylinders) as a mean.\'} of representing\ndllllcnsional objects.\n\nthree~\n\n(See Agjn and Binford [1973).)\n\nA\n\ngeneralized cone is defined by a space curve, called the spine or\naxis,\n\nand planar cross sections normal to the spine.\n\nfunction which describes\n\nThe\n\nhow the cross section changes along\n\nthe axis is (Jalled the S1rleep:!.ng rule or cross-secUon function.\nGeneralized cones are useful for descr:\\.bing three-dimensional\nsolids whose cross sections change smoothly along an axiS,\nespecially elongated solids.\n\nComplicated objects often can be\n\nbroke:1 down into parts of this nature.\nAgin and Binford [1973] fit genel\'alized cones to port:J_ons of\nobjects by using throe-dimensional data.\n\nThe spine\n\ngeneralized cone was represented mel\'sly bY.B list of points.\n\nof a\nThe\n\ncross sect.ions were Ci1\'0103; whose radii \\iel\'B a linbar function\nof the position along the axis.\nNevatia and\n\nBinford [19\'77] derive descriptions of\n\ncomplicated articulated cUl\'ved objects in tel\'ms of generalized\ncones.\n\nThey use three-dimensional data, but only the boundaries\n\nof the object as seen from the camera (the depth discontinuities)\nare used.\n\nInitial approximations for the axes are formed by\n\nusing the midpoints of the intersections of the boundaries with\nevenly spaced lines with about eight different orientations.\nThen an iterative process finds cross sections normal to a\nstraight line fit to axis pOints at the centers of these cross\nsections.\n\nThe axes are extended in both directions, and a\n\nne\\~\n\nstraight-line fit is started when a new axis point deviates from\nthe old fit by more than a threshcld.\n\nA large jump in cross\nsection denotes the end of the generalized cone. The possibility\nof multiple representations of the same piece of object is\neliminated by using the cone with the longest axis.\n\nSummary\n\ndescriptions for each plece of the object represented by a\n\n3-7\n\ngeneralized cone ape produced by computing th.1 length of axis,\nthe average cros3-section w:tdt.h, and the cone angle cOl"J:\'esponding\nto a linear fit to the cross-section\ntwo or more pieces of\n\n~\n\nobjeat\n\nfunctio~\n\ncon~ect\n\nThe joints where\n\nare determined.\n\nThe\n\nobject description then consists of the connectivity relations of\nthe pieces and .1oints, which is equivalent to a gpaph stl\'ucture;\nthe summary descriptions of each piece;\n\nand\n\nSOl"~\n\nsummary\n\ninformation about the objoct, including the number of pieces,\nnumbElr of elongated pieces, number of jOints, and information\nabout.\n\npiece~\n\ndistinguished by their large wid th or e10nga tion.\n\nThis description is used formatch1ng to an object model as\ndescribed in Section 4.\nIn ACRONYM (Brooks .eSt Mo [1979], Br-ooks and Binferd [1930],\nand Binford .fll;. ill. [1980])\nin terms of ribbons,\n\nt\\lo~dimensional\n\nscenes are described\n\nwhich are pairs of roughly parallel edges,\n\nand the spa tial. 1\'e1a tionships among the ribbons.\n\nThe ribbons ara\n\nproduced by a rule-based systew which links edge elements by\nmeans of a best-flrct heuristic .seBPch.\nobjeots are\n\nmOdelled\n\nin\n\nThree-diQsnslonal\n\nterms of structures composed\n\ni\n\ngeneralized cones and their spatial relationships.\n\nof\n\nThere exist\n\nI\n\nfuultlple levels of representation of objects, from coarse to\nI\n\nThe object model is a graph, subgraphs represent parts and\n\nfine.\n\nsubparts of the object, and so on to the indiv1dual generalized\ncones.\n\nThe particular generalized cones in ACRONYM use a cross\n\nsection whose boundary can be decomposed into straight-line\nsegments and circular arcs, a sweeping rule which 15 continuous\nand piecewise linear,\n\nand a spine which 1s continuous and\n\ncomposed of straight line segments or, -,nder some restrictions on\nthe l:lross section and sweeping rlil", circular arcs.\n\nThis is a\n\nmore general class of generaHzed cones than is usually used in\n\nother\n\nsyste!Ii~\n\nWOOdham [1979b] sl.\'Hled that the shapes of some surfacos,\n\nincluding a subset of generalized cones, can be determined from\ntho shading\n\n(brightn~s9)\n\nreflectance properties of\n\ninformation in a\ntp~\n\nsurfac~\n\nsingl~\n\nview, if the\n\nare constant.\n\nDaker [19Tf] descr\'ibet\' j.t\'l\'egular three-dimensional objects\nby a;.)proximating thl.\'l:!.l\' 8ul"faccs with circular\'-ar-c Hire-framp.\nmodels.\n\nThe vertices of the model correspond to points where the\n\nsurface curvature changes significantly.\n\nBurr and\n\nC~ien\n\n[1977J\n\nuse t)iecewise-linear \\\'1ire-frame models in which the wire fl\'ame\ncorr~sponds\n\nto edges in brightness,\n\nusually caused b:\n\nillumination effects at intersect.ions of planar 5urf:lces of the\nobject.\n\nThey obtain depth :J.nformation by means of stereo vision\n\nand match the pprcelved edges to a pro-stored model.\nThe geometric modelling I\'lystem developed at IBM by\n\n\\\'Jesl~y\n\ndimensional objects such as mechani(;al parts.\nprimitives stored intermlly are\n\npolyhe,~l\'a,\n\nrl\n\nthree~\n\n.al. [1980] enables the user- tc describe compl.i.catcd\n\nTho volume\n\n\\/tich ca.\') be combined\n\nas needed by the operations of union, intersection 1 dnd\ndifferenoe.\npolyhedra.\n\nCUl\'ved objects are approximated by high-order\nObjects and assetnblies are represented in a graph\n\nstructure that indicates\n\npal~t-whole\n\nconstl\'aint, and assembly.\n\nrelationships, attachmeut,\n\nPhysical properties of objects and\n\npOSitional relationships between objects are also included.\n\nThe\n\nrelevance to computer vision is t.hat the system can determiae the\nappearance of an object for an arbit!\'al\'Y v iew.\n\n\'l\'hi~.\n\ninforma tion\n\ncould be used by a recognition system to guide the se&rch for\nfeatures to match an iillage to the model.\nShapiro\n\n.e.t..ill.\n\nDrimiti78 types of\n\n(1980) describe objects in terms of threE:\n~hape\n\nand the relationship between\n\nprimitive parts in the object.\n\nThe thi\'ee pr-imitives ai\'s\n\nthe~e\n\nSt:!Ck~3,\n\nplates, and blobs, which are mearit to approxiMate roughly the\npar\'ts of the object with s:Lgnifieant extent in one, t\'NO,\n\n3-9\n\n01\'\n\ntt.retJ\n\ndimensions, respective:y.\nconnect~\n\nr~lations\n\nThe\n\nshow how the parts\n\n~patial relationsb\'~s,\n\nindicate their\n\nand limit the\n\nSone global information 1.lbout the object 1s\n\nsize:s of the parts.\n\n8uromnl"bed in a nueeric vector.\n\nThis summa!\':! inform:;. t.ion can be\nfo~\n\nuse.d to nlld likely candidates\n\nlJ),\n\n~ching\n\nloll ttl t:-te full\n\n1\'e181:,1onal model when l\'I.H:\'o6n1 tion is "t tempted.\nGennery [1980] producad a aethod\ndimen~ic~al\n\nnatural DutJoor Dcenus.\n\n~f\n\nThe\n\ndescr1~lns\nB~ound\n\nthree-\n\nsurface 1s\n\nappl\'".ld.n\'\xc2\xb7 ted by ope ox\' lliorCl plan02 or pal\'aholoids, and obJects\nlying on the ground\n\n.... pproxi rna ted\n\n3.::-C\n\nby e I lip\'; 01 ds"\n\nThe me thod\n\nderives this Jescription from three-dimensional dolta in the form\nof points densely spaced\n:>rodu0\'\nI,?;l\'ound\n\n~ by\n\nthe stereo\n\nsurfac~\n\n0":)1\'\n\nt.he scene (such as might be\n\ntn(;l:ini(iU~S\n\nis fO\'.wd\n\nfir~t\n\ndeser.tbed in\n\n~Gct.ion\n\nby a process which\n\nfin~s\n\n6).\n\nThe\n\na set of\n\npoints t.hat. ferm a l.I.:ll-deflned surface su ":h t:lat there are few\n!\n\nPbint~ \\"\'~lJ. 1;)(,\':\'0\\01\n\nrepresent errors.\n\nit, since\n\nth~~~\'e\n\nlower pr ... nts\n\nmos~,\n\nHl<ely would\n\nHO\\ieVer, m3\'1Y fOints al:love the sur\'face can be\n\ntolerated, sincp these may lie on objects.\n\nThen the points\n\nsuffi.ciently abc,ve the computed ground are clustered into\n\ntentative obJect&\n\nEllipsoids are fit to these clusters in such\n\na \'Nay as !;,o use the information that pOints of anr kind should\nnot be hidden from the Damera by an object and to t01erate\n\noccas:lonal. incort\'ect points.\n\nIn this process eluaters of pOints\n\nar\'e apl.:!. t and merged as needed to produce the most reasonable\n\nI\nfits.\n\nThis form of description was devised for describing the\n\nsurface of Mal\'S for a rovlng vehicle; thus the objects would be\nrocks.\n\nF~r\n\nman-made objects, the ellipsoidal representation\n\nseldom liould be suitable.\n\nHowever, the technique fol" finding the\n\ngl\'ound !night be suituble for\' finding the planar surfaces of man-\n\nmade objocts in soma cases.\nl\'ansky [1975] proposed the concept of Ufrnmes" as a way of\n\nrepresenting knowledge.\n\nA frame is a data structure for\n\n3-10\n\nrcpr\'\xc2\xb7e~(\'nt.ing\n\na\n\nstel\'cotY(Ject\n\nsH\\lat.ion.\n\ninformn tion about how to use the framc,\nhappen next, and what to\n\nThe fl\'aruc\n\nwhich\n\ninstantiated l.Jht:n the frnllH\' is l!sed.\noth~r\n\nfl\'HlH\'\n\nincludN1\n\nwhat can be expected to\n\nif t.hese expectations nr\'t) not met.\n\ndl\'\\\n\nconlL-illt! slots,\n\nslota often are\n\nThe\n\nfrnme&\n\nl\'eprC~ollt\n\nvOl\'iahIes\n\ncnt,itlt\':\'~\n\n\'rho\n\nto bo\n\nto fill thoso\n\nAn importart featUre 10 tho\n\nI~ct\n\nthat each slot han a dt:\'fnult assignment? \\Olh1ch 1,8 I\'epluced 0111;\'\nWhen specific informntion overrides it.\nlinked int.o framo sy~\\tC\'m~l.\n\nRelatod frameD nre\n\n1\'111.;) fl\'rune concept\n\nto the wllole tield of nr,t.tficinl 1.ntell1genoc.\nwould\n\n~Jt~ USt~l~ul\n\ni~l\n\nIn\n\nWCllnt to np!,ly\nvl~1.on,\n\nfr\'lu.lcl\'1\n\n1n r\'cco5niU.orl, in othe,,\' at\'cns, thoy would be\n\nuszd ill reasoning Hnd in\n\ni.lndef\'~talldjng\n\ndiscolll\'se.\n\nvisual systcm8 lIsing fr\'!UIle!1 have been implement.ed,\nKRL by Bobr\'ow and W1n0grud\n\nI: 197\'[ J.\n\nSoree nonfor example\n\n4. dECOGNITION\n\nThe process of recognition consists of matching a\ndescription derived from an image to a description of a stored\nmodel, perhaps chosen out of a large number of possible mouel.s\naccording to the best match.\nlevels in the\n\nanal~\n\nThis process can occur at many\n\n,;Ls or a ;scene.\n\nAt tho highee t. levels, the\n\ndescr\'iptions to be matched <.11\'e those of enUre object.s or SC\'flnes,\nDS described in Section\n\n3.\n\n\'l\'he simplest form of matching is cOk":"clationg in which the\ncross-col\'!"elation ooefficlent or a similar mathematical function\nis maICimized.\n\nFor binar\'Y data this reduces to template matching.\n\nSuch a method usually is suits.hIe only\nvision task.\n\nfOl\'\n\nthe lOHe:,.j.; levels of a\n\nFo!" example, some of the edge detectors described\n\nin Section 2.4 and\n\nHOWA of the stereo techniques ~escribed in\n\nSection 6 use thi3 f01.\'m of matching.\nA Slightly more elabm\'ate form of re()ognition 1s stat:!.stiC2.l\n\npattern classification.\n\nIn this method t numerical valt:es for a\n\nset of features are measured.\n\nThe scene 1s classified according\n\nto Hh\'21re the vector of values Has :l.n a roul tidimensiol1al feature\nspace.\n\nTh:i.s method is suitable only for vcry specialized vision\n\ntasks or for minor parts of elaborate vision\n\nsystern~\n\nSuch\n\ntechniquet; are described by Duda and Hart [1973].\nR~laxution\n\n1s a method of selecting appropriate labels for a\n\nset of interrelated units.\n\nIn a recognition task, the units\n\nwould be features extracted from an images and the labels would\nbe the corresponding features 1n an object mOdel.\nforms of relaxation\n\nc~:1tlt!\n\nTwo basic\n\ndlsct\'ete and probabilistic (or\n\ncontinuous).\n\nIn discrete relaxation, a set of pc.,saibIc labelS is\n\ninitially associated t>lith each unit.\nai\'O discarded for\n\nit\n\nOn oach Hera tlon,\n\nlabels\n\nurl:lt \xc2\xb7if t.hey are inconsistent with all of the\n\nremaJ.ning labels on related units.\n\nIn pt\'ObabUistic relaxation,\n\neach label associated with each unit is assigned an initial\nCOl\'t\'ectness probability estimate.\nprobabilities are adjusted\n\nOn each !tera tion,\n\nthe\n\nas a function of the label\n\nprobabilities on related units, according to given compatibilitj\'\nfllnc1;!ons.\n\nIn either case,\n\non each itoration all of the\n\nadjustments are assumed to be done simultaneously, using t.he old\nvalues for t.he related units.\nparallel computation.\n\nThus the method is \\Iell suited for\n\nIn many cases the process converges after\n\na few iterations.\n\nRelaxation has been used in some low-level and\n\nintermediate~level\n\nviSion tasks and may be useful in high-level\n\ntflsks also.\n\nZucker [1976b] deSCribes the basic principles of\n\nrlclalCation,\n\nRosenfeld [1978b] surveys some of the V/ork on\n\nrelaxation, HUmmel and\n\n7ucke~\n\n[1980] discuss its theoretical\n\nfoundations, Yamamoto [1979) discusses the derivation of the\ncompatibility functions,\n\nFaugeras [19[\\0] descrihes some\n\nimpl\'C,vements to the basiC method, and Ullman [\'979] shows hO\\o1 to\nperform constrained optimJ.zation by means of t\'claxation.\nOne approach to recognition is syntactic analysis.\n\nIn this\n\napproach a formal language is devised corresponding to the model\nqf tho scene or object.\n\nThe syntax of this language defines the\n\nhierarchical structure of the model.\n\nFu and Swain (1969],\n\nPavlidls [1977] I and Rosenfeld (1979b] diseuss such me thoda.\nadvantage of this\n\nappro~ch\n\nis that a parser, which does the\n\nmatching, is .1.ndependent cif the knowledge in the models.\nmakes\n\nit\n\neasy\n\nmod.1.f\'icat!ons.\n\nto\n\nchange\n\nThe\n\nt.he\n\nmOdels or\n\nto\n\nmake\n\nThis\nother\n\nHowever, apply:lng s\\lch methods to more than one\n\ndimension and allowing for uncertainty have proven difficul t.\nAt the highest l\'Zvels, most recognition methods that have\n\nbeen used do not fall stl\'ictly into any of tr.e above catagori.es,\na1 though elements of some of. them oft-en appellr.\n\nUsually some\n\nkind of heuristic search is performed, in which features are\nmatohed one at a time to produce a tree structure \\\'1h10h must be\nHeuristic search is a common task in artificial\n\nsearched.\n\nlntolligence.\n[ 19130].\n\nGeneral s.earch methods are discussed by Nilsson\n\nVery often the recognition process involves tile matching\n\nof graph structures.\n\nThe relevant properties of graphs are\n\ndis{lUSSed by Pavlidis [1977].\nFor more information see Barret\'" and Tenenbaum [1981].\n\nThis section discusses some\n\nrecognition programs and\n\nproposals that operate at a fairly hi;:h level.\nA pattern classifier capable of limited two-di[lIcnsional\n\npos:ition,\n\nrotation,\n\nand dlstox\'tion invariant l""\'cognltlon is the\n\nrecognition (Fulmshillla. [1975] and Fukushima and Mil\'al<e [1980]),\nin which feature detectors are self-orsanized in a network\nthrough unsupervised learning.\n\n(See Section \'r.)\n\nThis method is\n\ncomputationally elctremely ,I)tpensive.\nBarrow\n\n~ ~\n\n[1972] discuss ways of recognizing objects by\n\nmatching relational structures, which are graphs showing the\nrelationships between\n\nfe~tures\n\nin the scene or object mOdel.\n\nThey propose the hierarchical synthesiS method, in which\nobject model is broken into\nin t.he scene.\n\nsu~structures\n\nth~\n\nwhich arc searched for\n\nThen ccmbll.atic\',$ of the substructures arc found,\n\nand so on through as\n\nWHtly\n\n1.2vels as necessary.\n\nFischler and Elschlagm\' [1973] describe a way of per\'forming\n\n"rubber-sheet" matching of two-dimensional. structures.\n\n:\':-3\n\nThe\n\nstructure consists of t\'eatul\'EHI connected by Wspringsr" and the\nmatching procoss nt tempts to find a matching elf the foa tm\'os that\n\nminimizes a function of the stretchin\xc2\xab of the springs.\ndeBet.\'tbo 8 dynamic\n\nprogr\'a~Hlling\n\nThey\n\nmethod that finds tho optimum\n\nmatc)h and a !llinear embedding algorithm" that is much fastor but\n\nis not guaranteed to be optimum.\n\nPrioe [1976] produced a method of matching two symbolio\nscene descriptions.\nt1nll:~.\n\nElements of the scene are matched ona at a\n\nFor each element 1n on6 scene the best match ill seleoted\n\naccording to a minimization of the weighted sum of absolute\nvalues of differences of feature values.\nGennery [1980] produced a method of matching scene\ndescriptions conSisting of sets of fe.ltura vectors with estimated\nuncertainties.\n\nIt is assumed that the transfol\'rtlation between the\n\nscenes is known except for a feu par\'ameters (such as tI\'\'-l11s1ation\nand rotation, for example).\n\nThe method performs a search by\n\nsequentially matching the featur\'9s of one scene to those of the\nother, solving for the transforma tion paPBlIl(-;ters, computing the\nprobabilities of these matches by\n\nlI!~an;;\n\nof Bayes\' t.heoreIU, and\n\nusing these probabilitios to prune t.he sear\xc2\xb7ch.\n\nThe method was\n\ndevised to match the scene descriptions 00nsisting of ellipsoidal\nobjects suitable for the Martian surface, as described in Section\n\n3.\n\nIn that casa each featuro vector describes an ellipsoid.\n\nHowever, with c.ifferent featul\'e vectol\'s (perhaps cornot\'s) tho\nmethl:>d may be suitable for matching\nThe world model\n\nIcn01411\n\nman-made objects.\n\nof Ballard .fi.1. .a..l. [1978]\n\nincludes\n\ninformation about the vi.sual characteristiCls of objects.\n\nThis\n\nintermodiate stage between the image anci the world model is\n\n9.\n\n"sketch map," in whlch instantiations of elements of the world\nmodel are explicitly correlated with features of tho current\nimage, with accompanying locatJ.on descriptors. Recoenition is\n\n4-11\n\nsaid to occur when, based on correlation of features in the image\nwith stor\'cd world Imotolledge r a model of the scene is constructed\n\nin the sketch map from elellwnts of t.he total world model.\nHanson and Riseman [19780] use several interm(.;diate stages\nof image processing as they\nrepresentation.\n\n~Irogress\n\nto a high-level\n\nt\n\nsymbolic\n\nThey use the concept of Kschema" (similar to\n\nMinsky\'s Frames described in Section 3) in their highest level,\nby which they cltploit tho fact that certain objects und features\n\nare often found together.\nBolles [1980] uses the local feature focus method to locate\noccluded two-dimensional objects.\n\nIn this mothod a reliable\n\n(focus) feature of the object is located first, and the secoooBI\'Y\nfeatures are located l\'elative to it to identify the focus feature\nand to determine the position and orientation of the object.\nBolles determines tho f.ocus features and the:lr secondary features\nautomatically in a training-time computation in which the program\nanalyzes a. model of the object to determine those features that\ncan most relia;)ly and cheaply determine the location of the\nClbject.\nNeumann [1978] performs recognition of two-dimensional\nobjects wHh\n\nocclusion.\n\nThe out.lines of the objects are usad,\n\nrepresented by straight\xc2\xb7\xc2\xb7line segments.\nis done among tentative matches\n\nbased\n\nfi search for bes t match\n011\n\ncorner\'s.\n\nThe match to\n\na given object model CBn vBry in position, orientation, and\nscale factor.\nPerkins [1978J relies on explicit shape matching to\nrecognize industrial parts.\n\nThis is done by transforming a model\n\nCOneur\\\'c to br\'ing it into registration Hith an image concurve\n\n(descri.bed in Section 3.2).\n\nCandidate con(;urves are selected on\n\nthe ba.sis of gross featureD Stich as area, perimeter and other\n\nstll.tistical values (if\' the image concurvc is olosed, allowing\nsimilar Quantities to be computed fr\'om the image), the number and\ntype of components that make up tl1e con"urves, anel. symmetry.\n\nThe\n\nanalysis is 2-dimensional .\xe2\x80\xa2 - objects are constrained to lie 1n a\nplane\n\na\n\nat\n\nfixed\n\ndistance\n\nfrom\n\nthe camera\n\nso\n\ntransformation of the model is expressed as (x,\nrepresenting a 2-D tl\'anslatiol1 and rotation.\n\nthe\n\ny,\n\n0),\n\nMatching based on\n\npartial views is done in a similar manner by trying various\nsubsets of model concurve components.\n\nAfter the transfortlation\n\nof the model 1s ootel\'mined, a global measure of the goodness of\nthe match is obtained by computlns the distance betwotm the model\nand image concurves at selected\n\npoiD~s\n\nalong the boundary.\n\nThis\n\nsystem is able to correctly identify &everal ovel\'lapplng pal\'ts,\nand i t tolerates fairly high levels of noise.\nThe SRI Vision Bodule (NHzan\nmatchlng techniques to idenUfy lJlobs.\n\n~\n\n.al. [1979]) uses hlo\n\nBoth illethods\n\nreq~ .\xe2\x80\xa2 \'8\n\nthat\n\npos:l tJon uncertainty is 11 mitcd to 2\xc2\xb7\xc2\xb7\xc2\xb7D tN1Dslation rxj rotation\nin a plane parallel to the image plane and that objects Bre\nenti-roly in the field of view without touching any othel\' objects.\nOne is the nearest neighbor method.\n\nA set of n features, each of\n\nwhieh uan be expressed as a single number, is chosen to classify\nobjects.\n\nEach object in the model is repi\'esented as an ordered\n\nn-tuple\n\nof feature values which can be thought of as the\n\ncoordinates of a point in an n-dimensional space.\nimage is comparcll to each object in the\n\n1U0dl~1\n\nA blob in the\n\nby computing the\n\ndistance between the n-tuple extracted from the blob and each\nmodel point.\n\nThe blob is classified as an instance of the object\n\ncorresponding to the nearest model point, if the distance is\nwithin some tolerance set by the expected variation of feature\nvalues.\n\nOtherwise,the object is rejected as unknown.\n\nalso the method u3ed in CONSIGHT (Ward\n\n.e.t\n\n\'l\'his 1s\n\n.il).. [1979J).\n\nThe second method used by SRI (Agin and Duda [1975]) is the\n\nbinary decision tl":H!\n\n~ethod.\n\ntree specifY a featul"\'o to\n\nNon-terminal nodes of the binat\'Y\n\ntested and a threshold to determine\nSingle features are tested sequenUally, Hith e~ch\n\nbranching.\n\nbE~\n\ntest reducing the numbor of possible classifications until a\nterminal\n\nnode is reached which represents the desired\n\nclass:1.fication.\n\nThe method h, optimal given certain assumptions\n\nabout the distributions of the feature values being used.\n\nThe\n\nonly dl\'ai.bac!c to this me thod (if the assump tions are met) is that\n\nit cannot reject unrecognizable objects without resorting to\noomputing the distance between the blob n-tuple\nthe n-tuple\n\nof features and\n\ncorresponding to the objeot represented by the\n\ntc.rminal node.\nVamos.ru...al. [1979] produced a system which can recognize\nsimple industrial parts with arbitrary three-dimensional\n\'fheir system detects edges in a two-dimensional\n\norientation.\n\nview and assembles these into line segments and\n\nal\'CS.\n\nPX\'c:>babilities are assigned to these according to the strength of\n\nav.idence.\n\nThe resul ting desorlpt.ion is matched to wire frame\n\nmodels (including hidden-line elimination) in the data base by\nmeans of a heuristic search.\n\nIt is intended that the system be\n\nable to recognize an object out of ten or tt.!enty poss:/.ble object\nmodels.\nShirai [1978b] uses an iterative approach to recognize\nobjects.\n\nThe\n\nbasic\n\nprocessing sequence\n\nconsists\n\nof edge\n\ndetection, curve fitting (straight lines and ellipses), and\nrecognition.\n\nThe first Hera tion recognizes as many objects as\n\npossible using a conservative edge detection threshold.\nSubsequent iterations obtain more edges by lowering the\nthl\'cshold, and use previous recognition results in combination\nwi ttl rela tional constraints in the model to recogn:!.ze neH objects\nor additional parts of partially recognized objects.\n\n\\\n\nNevatia and Binford (1977] produced recognition of\ncomplioated articulated curved objects, using the a.ascription in\nterms of genera.lized cones described in Section 3.\nord~H\'\n\nFi!\'st, in\n\nto avoid a lengthy, detailed comparison with all models in\n\na large da tn base, a description code summarizing some important\nfeatures of the description is used to index into the data base\nto find a few\n\nmodels with Similar description codes.\n\nIn\n\npractice, dcscript:J.on codes based on the distinguiShed pieces are\nused.\n\nThe descriptors used are the connectivity of the\n\nd1st.inguishcd piece,\n\nwhethel\' it is distinguished because of its\n\nlength or because of its width, and whether its cone angle\nexceeds a t.hreshold.\n\nThen a detailed match against each model\n\nretrieved by indexing is performed, so that the best matching\nmodel can be chosen.\n\nIn this process, sim:l.lar distinguished\n\np1ecl9s are t.entatively m.atched flrst.\n\nThen the match 1s grown to\n\ninclude othel\' pieces, Ilccording to the connectivity relations and\nallowing for missing pieces.\nperformed.\n\nIn this way a tree search is\n\nThe best match Is chosen based on how well the\n\nconnectivity relations are preserved and how well the summary\ndescriptions of the matched pieces agree.\n\nIn test cases where\n\nt.he data base of mOdels consisted of a doll~ a toy horse, a toy\n\nI\n\nsnake, a glove, and a ring the system usually recognized the\nobjects correctly even when multiple objects were present in the\nscene, the limbs were variously articulated, and moderate amounts\nof occlusion were present.\n\nThe computer time required for\n\ndescription and recognition of a typical scene was from five to\nten mlnutes on a DEC KA-lO pl\'ocessor.\nIn ACRONYM (Brooks\n\n~~"\n\nand Blnford .e.t..aJ.. [1980)\n\n[1979], Brooks and Binford [1980]t\n\nan image-derived description based on\n\nribbons is mat.ched to a model based on generalized\nSections J.3 and 3.4)\n\ncones~\n\n(See\n\nA predictor and planner produces a t\\%-\n\ndimensional prediction graph from the model, and an edge mapper\npr\'oduces an observaUon gl\'uph from the image.\n\nThe matcher\n\nmatches the two graphs by finding globally consistent subsets of\nlocal matches, invoking the p:--edictol\' and planner agaj.n where\nnecessary.\n\nThe matching process is mapped\n\nback to three-\n\ndimensional models to ensure global consistency.\n\nACRONYN is able\n\nto detect mul Uple objects in a scene,\n\n\\~hel\'e\n\neach object is an\n\ninstantiation of a generic object model that has been Given to\nthe system as described ill Sectlon 7.\n\nIn earl y tests of the\n\nincomplete system i t has locat.ed aircraft in an aerial photograph\nof an ai rpor t.\n\n4-9\n\n5. TRACKING AND VElUFICATION\n\nThis section is devoted primarily to object tracking.\n\nA\n\ndiscllssion of verification vls:i.on is included because the\napproach to object recogniti.on in both cases is 51-roHar.\n\nThe\n\ngoal of object tracking is to pro(.!ess sequences cf images in r\'eal\nti1.. e to describe the motion of one or more objects in a scene.\nOften real time implies processing every huge from a TV camera\noperating at 30 Hz.\nfeatUl~es\n\nIn other words, an image is digitized,\n\nare extr\'acted from the image, the object or objects are\n\nlocated in the image, and position and velocity cstilllates al\'e\nuP4atod 30 times a secono, al. though in PI\'Bctice slightly slot-let\'\nrates are sometimes used.\n\nwhich achieve\n\nreal~till\'le\n\nAt the present time, tho approaches\n\nopel\'at:ton (-ely on simpl:lfying ass\\;.mptions\n\nabout tho natul\'C of\' tl1e scene f\n\nscene,\n\ntrack vcr-y few obj!;;ctu in a g.iven\n\nand incorporate var\'jring levels of special.,purpose\n\nhardt-Hu\'e, designed for the particular tracking algm"ithm.\n~rhEl\n\nfield of \')oject tracking has been surveyed by Nagel\n\n[1978] and Martin and Aggarwc:l [1978J.\n\nReal-time tracking\n\nprograms have been developed for a variety of applications.\nGriffJLn .sit. iJ1". [1978] use an obje.:1t-tracking prograYl to pr\'ovide\nfeedback\n\nfOl\'\n\nclosed-loop guldance of a breadboard Mars\xc2\xb7-rover\n\nVehicle.\n\nGi.1bert..rJ\'...al. [1980] developed a system for\n\nident:lfication and tracking of missiles and aj.rcl"aft.\n[ 19\'( 8:1 describes a\n\non\\:-came~a\n\nl\'Cal\n\ntime\n\nPinkney\n\nsyst em which tracks four artificial\n\nmarkers on an object to control a manipulator visually as it\napproaches an object to be grasped.\n\nTho intended application is\n\nto the manipulator on the Space Shuttle.\n\nA similar approach\n\nusing stereo cameras is propostl(i in Brooks (1980) for supervisory\ncontrol of a teleoperator manipulatol\'.\n\nChien and Jones (1975]\n\nrpported on the use of real-time tracking to aid in stacking\n\n5-1\n\nblocks !>TUh a manipulator anel inncrting a peg in a hole.\n(Nitzan\n\n.sa.t..eJ...\n\nSRI\n\n[1979]) is investigating using their vision module\n\nto track objects, such as a part which is suspended from a~\noverhead conveyor, for feedback to an industrial manipulator.\nTsugawa\n\n.~.t..aJ.,.\n\n[1979J describe a real-time stereo vision system\n\nf,Dr detecting certain road condi tiona to operate an automobile\nautonomously.\nThe fundamental problem in object tracking is to devise a\nrobust matching algor! thm which is able to repeatedly recognize\nthe same object\n\nor ob.1ects in successive images,\n\nand 13\n\ncc)mputa tionally feasible; i.e., the algori thm must execute in\napproXimately 1/30 second.\n\n.\n\nI\n\nIn general, matching algorithms\n\nconduct a search in a window believed to contain the object,\n~.()oking\n\nfor\n\nthe best registration betl-leen image featul"eS\n\ne):tracted from the window and features\n;i.nternal model of the ob.icct.\nslmplifie~l\n\nassociat.~d\n\nThe very nature of object tracking\n\nthis problem to a considerable extent.\n\nstill by no means trivial.\nsElcond apart in Ume, the\n\nwith an\n\nHowever, it is\n\nSince successive images are only 1/30\nappear~H!ce\n\nvery little from image to image.\n\nof the object will change\n\nThe object can be modelled\n\nadaptlvely as i t was last seen by the tracker\',\n\nI\n\nwi tll the\n\nexpectation that a good match between the object. model and the\nfea tUI\'es :In the current image is available.\n\nFurthermore, the\n\nlocation of the object in the image can be predicted very\naccurately by using the latest available position and velocity\nestimates coupled with the short elapsed time bet",een irdages.\n\nAs\n\na !\'esul t, the l\'learch ,.:tndo", need only be large enough to contain\nthe object up to a few pixels uncertainty.\n\nThis limits the\n\nrequired computa Uon to a manageRble level and, more importantly,\ngr1eatly l\'e(luces the probability of a false match occurt\'ing.\nReal-time implementations typi()ally rely on featUres which\n\ncan be cOlliputed directly from the image ldthout resorting to\n\n5-2\n\nI\n\nactual 3-D\n\nmeasurments of object features.\n\nused by Griffin\n\n.ru..\n\n.Ql"\n\n[19 r{8]\n\nThe object tracker\n\nuses gray-Ieve.l correlation\n\nimplemcn tl~d in soft war\'e tf) lilatch i.mages.\n\nThe signature of the\n\nobject is a small spatial sample of gray levels taken from an\narbitrary part of the object.\n\nThis s>.lmple is correIa ted over a\n\nsmall window in the current image l\n\nwith the matc:h determined by\n\nthe maximum value attained by the correlation funchon..\n\nA... though\n\ncorrelation is notorious for obtaining false matches, it works\nr~liably\n\ntn this application due to the small search window.\n\nWhile rotating objects can be tracked, tna rotation canout be\nmeasured on the basis of the correlation value, so only\ntransla ti()nal velocity\n\ni~\n\nmeasured.\n\nHirzinger and Snyder [1980] use a contoup-based a;)proach.\nTh\'~\n\nanalog video signal is processed by special puppose hardware\n\nto detect significilt contrast areas in the image.\n\nThis is done\n\nby t\'ecord:lng transitions as the v1dco level rises or falln past a\n\n.dth the processing taking place inside a programrn?,bl~\n"\ntraCKing window. The coordinates of eauh "contour" point are\ntlireshold\n\nrecorded, and tracking is based on foul\' values\nt~e\n\nhorizontal and vertical directions.\n\n-~\n\nthe extrema in\n\nThe position of th9\n\nobject is. taken to be the centroid of the rectangle defined b:,o\nthese four val ues.\nseem to\n\nb~\n\nThis is a v.ary simple apPl\'oach which wou:i.d\n\neasil y fooled in scenes of moderate complexity.\n\nTsugawa .ill .al. [1979]\n\nuse a similar video procflsslng aplJroach.\n\n1111 their ease, the analog video signals from two cameras, mou!1ted\none above the other and oriented so that the scan lines pre\nvertical, are differentiated and compared to obtain a stereo\nmatch of contrast edges.\n\nThe matched edges are used to estimate\n\nthe position of road features such as traffic cones, curbs and\nguard rails.\n\nThis informat:t.on is used to guide an auto,uobile to\n\nfollow a road and avoid obstacles.\n\nP1nkney\n\nfeatUres from the analog video signal.\n\n[1~78]\n\nIn this\n\nalso extracts\ncas~,\n\nit is\n\nnecessary to locate four high-contrast markers on BL obJect.\n\n5-3\n\nSpec.iRl .. purpoSG hardt-sere thre8hold~~ tha video in tour separatG\nw:tudo1>1s, one per 11iarlcGr, and rottu\'nl3 tho O(Hlt,\'oid 100s. tion of\neaoh mal\'leo!\'. Th:ts is Il highly specialized app~\xc2\xb7NI.Cr. whioh assumos\nvary high cc)Utrast between the markarB aoel the bi1.o1(ground and\nwhioh assumes that there are no otha~ pixels of similar\nbrightness in the window.\nThe systel11 in Gilbert\n\n.ru-.. ".\').1.,\n\n[1980] is distl\'ibuted over four\n\nprocessors, each procensor consisting of a\n\nm1o~oproDes8or\n\nand\n\nspeeial pm\'poB\'" 11111\'dware. One pl:\'vCeSB01\' classifies pixels as\nntar,[~etlV or !\'in\\.\'n~target" baaed on a histogram analysis of the\nilllage in a tl\'ackiIl6 w1ndol-s.\n\nA seoond prooessor computes two\n\north()gonal projections of the target pixels by summing the pixel\nvaluc~s\n\n(1 :: Il;arget, 0 :: non-target) along hori:zontal and vertical\n\nlioe~\n\nAssuming that the target hasbl1ateral symmetry (the\n\ntarget is a missile or\n\nalrplan~),\n\nthese projections uniquely\n\ndetsr\'.nine the identity of the target and call be used to ext.ract\nthe position and oriell<:.at.1on (in\n\nt~H)\n\nilllage) of the target.\n\nThe\n\nfsatu!\'0s computed trOla the 1)2 ojectlons are normalized to obtain\ntlcale invarlan(Hh\n\nAl.though the\n\nfe\xc2\xa3"tuN~S\n\nare not rotationally\n\ninvariant, they are nearly so for small rotations whioh occur\n\n.. o im~g{js. TiYd system is able to corl"eot fOI\' rotations\nby electronically rotating the vld~0 BCB~ pattern 80 that the\nobject 1)I.\'ientation is essent1alli const,ant. I\'liage rotation is\nnandJ.ed by a thir\'d processor \\,rl"1ch also t:ontr\'Ols camera pointing\nand :wom. The fourth processor evaluates the goodness of the\nmatch at eaoh traek1ng iteration and outputs parameters for\ncamel\'a contl\'fjl Md the size and location of the tracking window\nto the other processors.\nb~Jtt,:Den t~\n\nAt a higher level, a robust tracking p!\'ogram must deal wHh\nad ... eNle cond1.t:1.ons which occur :!.n dynamic scenes. One of these is\noccluflion, wl1ol\'e the object beco\'nes only partially visible\n\ncannc.t be\n\nse<m\n\nat all\n\nClS\n\nit pal3ses behind aoother\' objeot.\n\n5-4\n\nOr"\n\nIn the\n\nof\n\nca~)e\n\np{!l~tial\n\nocclusion, ;a traclcfng program han to be able to\n\ngenerate a match on the basis of an incomplete set of image\nfea.~.la\'os.\n\n/1 \'.. 0,\n\ntho ocoluding object\n\nI1lRY\n\ngenerl1te features \\ihich\n\nmust be l\'(lcogni,zed as not belonging to the object of intt!l\'est.\nEven if an object is in full view at bll times, feature\next.ra(~tion\n\nalgori thros such as thresholding and edge detection may\n\nproduce varhble resul ts due to changes in the background or\' due\nto changes in illumination (Le.,\naris\xc2\xb7~\n\nthe\n\nobject\n\ntranslationally and rotationally with\n\n~espect\n\nillumination)\nsource.\n\nwhich\n\nas\n\nthe angle of incident\nmoves\n\nboth\n\nto the light\n\nOf the examples discussed so far, only Hirzinger and\n\nSnyder [1980] attempt to deal with occlusion.\n\nTheir approach\n\ninvolves deteuting radical changeR in the relative values of the\nfeatures derived from the contour extrema.\n\nfOlll\'\n~\n\nThey state that\n\nmuch more robust solution is required to handle occlusion\n\nl\'eliably.\n\nGorreln tiOI1 t:-acking (Griffin .e1.M,. (1978]) is immune\n\nto background changes if\' the Signature mask is contained almost\nentirely in the object.\ntr,:~c~k:er ills~msitive\n\nUsing normalized corr&lation makes the\n\nto uniform chunges in illumination intensity,\n\nbut aoes not help for partial changes\nobject is movin3 into a shado,,!.\n\nsuch as occur if the\n\nGilbel\'t. ru.,al.. [1980] assign a\n\nconfidence weight to each match based on how well the fea tur~s\nagrei~\n\nIf a\n\nwith the eX(.J8cted values pl\'edictcd by the\n\nint~~\'nal\n\nmodel.\n\niow weight is assignad to the current imagd, then the\n\ntracker "coasts" through this image, basing tracking control\ndecl~ians\n\nmore heavily on previous higher-confidence images.\n\n\'ihis 1s intended to OVCl\'come changing background conditions such\nas t.he tars,at moving past a cloud.\n\nSaund.!ll. ill.\xe2\x80\xa2 [1981]\n\nt.rack\n\nobjects by means of features used in a least.-squares adjustment\nof the i.nternal model of the tracked object.\n\nThe program rejects\n\nextraneous t\'eatures on the basis of proximity of a particular\n\nfea ture to its eJ: oeoted loea t.ion based on the internal model.\nDue to the severe constraints on computing time, it is\n\n5-5\n\n---\n\n....\n\nvir-tually :I.mpossible to use all of these teolmiques in\n\nthe!l~\n\nfull\n\ngenera.lity in a real-time implel1.lentat:!.ot\'). Oil existing cmnputers.\n\nlin maullple of a more general, slover approaoh is tho pl"Ogram of\nROO,(lh and ilggarllal (1919J:\n\nworld.\n\nTheil\' program operates :1.0 the blocks\n\nImage sequencl\')s are generated by storing images of statio\n\nsce,nes containing vari(\'lusly shaped blocks which tarc moved by hand\nbet.\\I1een iWiilges.\n\nImages are then l\'etrieved in the seme sequence\n\narid processed as long as naces 138.\'-Y to extract all\nn6lc(!saary information and to perform matching.\n\nc(H1ltainsa description of each block uhich\ns(!ene.\n\nAn internal model\n\nhl~3\n\n110W\n\n.: ....\n\napPE>Qred in any\n\nIn matching two scenes, blocks :\'-n the curl\'ent image are\n\ne.1 ther recognized as blocks already In the modol or\nas\n\nof t.he\n\nand inserted In the model.\n\naNI\n\nlaballed\n\nAny bloo1\\. which was scen in\n\nthe previous image but is not present In the current imBge is\nlabelled aClcordingly.\n\nThere are three levels of matching.\n\nAt\n\nthl:l highe 3t. level, the program attempts to match each block in\n\nthe model with foatures in the imago which are present at a\nlocation predicted by the model based on previouspos:l.t1on and\nvelooity information.\n\nTho\n\nfeattll\'e~1\n\nuSCld tor matching are the\n\nnumber of vhdbl(~ odgas flnd visible sut\'face apea (in 2-D image\n\ncooIl\'dina tea).\natt~nnpts\n\nIf this fail s, tht:l second level is invo!<ed Mhioh\n\nto match objects on the basis of tho\n\nl~elat:ive\n\nposH1.ons\n\nof two or more objects using relations nuch aa left, right,\nabovc, and heIol"_\n\nThe t.hir\'<.I level at.teropt.$ to match individual\n\nfacEls of til() blocks on the basis of rel1\'lti va positions.\ndoml primuplly to disamb:l.gu().te\nOcclusion is infel\'l\'ilJd by the\n\nthat. the top of the\n\ntlTtl\n\nTlus io\n\nthe original segmentation.\n\npl:\'f:JSell~9\n\nof i\'!T-nodes"i it .is assumed\n\nbelongs to the occlud:1.ng object.\n\nt<latchirl{t is performed by trying\n\nVaI\'10US\n\ncorrespondenoes beh!een\n\nthe visible edges of the occl"ti0d object. and the model of the\nobje1ct which is Cl,pocted to be pl\'esent at that location.\nprogNlm\n\ni~:\n\nThi3\n\nfairly general in the sense that ooclusion is handled\n\nfairly well and there is no fundamental Ilm1t on the numbe)O of\nobjects in\n\nB\n\nsceno or on the numbor of objects which enter or\n\n5-6\n\n-~---\n\nleave tho soene in any given image.\nan idealized visunl domain,\n\n30\n\n1I0WOVOI\',\n\nthe blocks Horld is\n\ntilis approach is certainly not the\n\nfinal answel\'.\n\nFEmncma nnd Thompson [1979J developed a technique called the\n\nGradient IntensHy Transform t1ethod which differs from any of the\nother examples discussed so far.\n\nTime v.H\'iations in intensity\n\nand the spatial gradient (as measured by the output of the Sobel\noperator mentioned 1n Section\nthe image.\n\n2.~1)\n\narc recorded for\' each pixel in\n\nThe intensity and gradient variations place\n\nconstr\'aints on the possible directed velocity of an object imaged\n\nat any pixel.\n\nA Hough-transform method (see Section 2.5) is used\n\nto clustel\' points by parameteriz:lng velocity in terms of changes\nin gray\n\nlevel\n\nintensity\n\nand\n\norientation\n\nof\n\nthe gradient.\n\nClustel\'ing techniques applied to the parBmeter space of\n\nt.~e\n\nHough\n\ntransform are used to find regions of pixels with simH .. r\n\nvelocH.ies.\n\nIn this way, objects can be segmented from the scene\n\nas well as assigned a velocity.\n\nTo make this procedure work\n\nwell, the illlage is first smoothed with an averaging fil tero\n\na\n\nce~tain\n\nThus\n\namount of datail will be lost and the accuracy of\n\nposition mensul\'cments may suffer.\n\nIn verification vision the system knows what objects should\nbe present in the scene and their approximate position and\norientation.\n\nThe goal is to ver\'ify the pr\'esence of these objects\n\nand to refine the estimates\n[lol.~_es\n\nof their position and\n\noricntDtio~\n\n[1976J developed a vCI\'Hlcat.ion vision system that uses a\n\nset of opcl\'tor\'s to find featu.\'es in th{: scene aP9roximately at\n\nthe positions\n1nfo!\'mation.\n\n\\~hel\'e\n\nt.hese fcatur-}s are expected from the a priori\n\nThe system uses teaching and learning phases\n\ndescribed in Section 7 in which operators are selected and\nstntist:l.cs about them Brc gather-cd.\n\n5-7\n\nThen in what Bolles calls\n\nII\'planning titue" the :\'lystem ranks the opfH\'ators according to thoir\nexpo(~ted\n\ncontributIon to tht) solution, determines the expected\n\nncmber of operators to be needed.\nobtaJln111g tho solution.\n\nand predicts the cost of\n\nF1.nally, in l1execution tIme" the\n\n~ystem\n\napplies the operators one at aUmc and combines their rosults\ninto csti rna tc~s of confidence in the vedfica tion and pl-ccision of\nthe\n\n:~\xc2\xb7et\'1nement.\n\nFor this purpose toe pl"ob- bUHy distril:lutions\n\nof the resul ts of apply:1.ng eaoh opera-tol\' tbat were ga thel\'od in\nthe learning phase ara used in Bayes\' thoorem.\n\nThe rArined\n\nposHion and orientation estimate is obtained by a least-sq\'..lures\nadjustment p which includes an automatic editing feature for\nremoving those features that do not seem to agrpe\nothel\'s.\n\n~ith\n\nthe\n\nWhen the desired confidence and precisL"" or the cost\n\nU.mit has beem reached, no more operators are applied.\n\n5-8\n\n6.\n\nSTEREO\n\nIn stereoscopic vision, tr\'iangulation between\n\nt\\\'lO\n\nor more\n\nviews from different positions is used to detarrn5.nc distance.\nThis avoids the high degree of ambiguity inherent in tl\'ying to\ndetermine depth by other clues in monocular\nther\'~\n\nview~\n\nHowever,\n\nis still some ambiguity present in the process of matching\n\npoints 1n the different v;!.etHl C\'() that the triangulation can be\nsince a small portion of one image may be Similar to\n\ndone,\nsevel~al\n\nportions of another imag;,;.\n\nThis is especially true uhen\n\nthe l.oil3o le\'i"el is high, since sma.ll differl,mccs may be obscured\nby noise.\n\nAlthough using stereo makes the problem of extracting\n\nthre,e-dimensional information easier than it is \\>lith monocular\nvision, the hardest parts of the vision problem, description and\nrecognition, still\n\nremai~\n\nIt makes no essential difference for stationary scenes\nwhe thcr the roul tiple\n\nvie~\'1s al\'O\n\nobtained fi\'om separate cameras\n\nsimultaneously or froN one moving cameru p except that the\ncaHbra tion r>roblem might be different.\ndiscussed\n\nil!\n\n(Camera culibrs tion is\n\nSection S.)\n\nUsually only two camera pOSitions are used.\nseveral positions are used,\nambiguities becomes easier.\n\nthe problem\n\nHowover, if\n\nof resolving t.he\n\nIn the close-t.ogether vieus, things\n\nhave not shifted much betrleen views and thus\n\nUl\'C\n\neasier to match.\n\nThese results then can be used to resolve the ambiguities in the\nfurther-apart views, whose results produce greater accuracy.\nNevatia [19i6)\naccomplishing\n\nand Moravec [1980) have explored ~ays of\n\nthis.\n\nStereo techniques differ in the way in which matching is\ndone\n\nbe~,Heen\n\nthe pictures, especially in the kind of entities\n\n6-1\n\nthat are matched.\n\nOne common method is at\'ea correlation, in\n\nwhich sma,ll aN1BS ("Iindows) a few pi.ltels on a side are matohed by\nmaximizing the correlation coefflclent p minimizing the mean\nsquared d1fferencs g or using soma variant of these\nThis method usually works well\n\nproce~ses.\n\nhighly textured scenes, such\n\nfOl\'\n\na,s natura.l outdoor scenes.\nHe.~r.tah\n\n[1974] explored some of the basic properties of area\n\nQQrrelation and developed a region-growing method using it.\nGOlinery [1980] produced a refined correlation measure for area\n\n()orrelaUon and a search procedure that uses some local context\nto\n\nreducl~\n\nthe ambiguity in lllatching.\n\n(~orrelat:Lon\n\nLevine,gt\xc2\xb7 .a.1.. [1973] use a\n\nwIndow that varies :1.n size, so that it is small for\n\nh:lgh resolution where there nre large brightness variations but\n\nlarg~ elsewhere for good noise rejeotion.\n\nThey also first match\n\nsparsely spaced "tie points" wHn high iufor-matioo cont,ent, and\nthen use these points to c.:mstl"\'ain the search for matching the\nnearby points.\n\nYakimovsky Bnd Cunningham (l978] 0190 use a\n\ncorrela tiOIl tdndoH that varies lnsi:.le,\n\naccording to the\n\nIlJagni\'cude of the local autocorrelation value.\n\nThey use a sparse\n\nWindow i\'or spoed, then use a full windol~ at the five points with\nthe highest resulting correlation,\ncorrelation.\n\nr-1or-:!..\n\n.ftt.ru.\n\nthe Window by means of a\n\n[1973)\n\nto produce\n\nCOl~rect\n\n1.11\n\naccuratEl\n\nf"".\' distortiol1 uithin\n\npr\'edictiol1~correctlon\n\ntechnique.\n\nOn\n\neach iteration of this process, the depth map produced by the\npreviotl~.\xc2\xb7\n\niteration is used to correct t.he perspect:!.ve distortion\n\nwithin ElBCh\n\n\\Olindo\\~\n\nso that a bettnr match can be made.\n\nImtt0sd of using ordinary Ill\'ea correlation, Marl" l?J1d {loggio\n[1976] proposed a relaxation method that assigns a depth to each\n\npixel.\n\nThe met.hod assume:> that the depth is cont:lnuons except at\n\noccaslon~l\n\nboundaries.\n\nGrirason and Narr [1979] pr\'eduoed\n\nD.\n\nl!lcthod\n\nin which the images arf, b<Llld\xc2\xb7\'pasB f:U. tcred and the zero crossj.ngs\nof theresu1 ts are roa tcbed\n\nbetwe~m\n\n6-2\n\nthe images.\n\nVarious amounts\n\nof filtering are used.\n\nThe coarse zero croasings from the\n\nheavily smoothed images are used to resolvE) the ambiguities in\n\nthe high-resolution zero crossings from tho lightly smoothed\nimages.\nScenes of man-made objects often are not highly textured but\ncontain sharp brightness edges at boundaries of objects and at\nintersections of planar faces.\ndoes not work very well.\n\nFor such scenes area corr\'elation\n\nInstead, i t is usually better to detect\n\nfeatures in each image and to matcll these features.\nArnold [1978J produced a method that uses edge elements as\nthe features to be matched.\n~eans\n\nof the Hueckel\n\nHe first finds edge elements by\n\noperato~\n\nrelaxation process\n\nThen these are matched by a\n\nthat uses local\n\ncontext to resolve\n\nBaker [1980) matches edges by means of dynamic\n\nambiguities.\n\nprogramming, using a coarse-to-fine strategy.\nGanapathy [1975] detected straight edges that correspond to\nthe edges of polyhedra,\n\nthen matched these in order to\n\nreconstruct the polyhedra .in t.hree dimensions.\nRoth [1978] used a region-matching technique to extract\nthree-dimensional surfaces from a stereo pair of i mages.\n\nEach\n\nimage .is conVB1\'ted to a gradient. array based on local changes in\nintensity.\n\nThe gradient arrays are partitioned into regions of\n\nuniform intensity (zero gradient) and uniform change (similar\ngradient\n\norientation).\n\nsimllarl ty\ngradient.\n\nof shape J\n\nIni tisl region matching is based on\nSize,\n\naverage intensity and average\n\nFurther match evaluation imposes disparity constraints\n\nand uses occlusion clues. The matching algorithm makes or breaks\nmatche::;\n\nba~ed\n\non a confidence measure until a globally consistent\n\nhigh-confidence match is obtained.\n\n6-3\n\nSaund\nreatUl\'(~3\n\n.e.t.al.\n\n[1981] combi.no the mensut\'cd positions of\n\nfound in two camera viens\n\n~.nto\n\na single least-squares\n\nadjustment for the th1"ee-dimon:.:d.ortal position and orientation of\na known object.\n\nThus the steroo inform" tion is used impl1c1t.ly\n\nin the adjustment, rather than being explicitly computed for each\n\nfeatul\'El. Indeed, it is not necessary fo!\' any feature to be seen\nby both cameras; if enough features Elr>e seen in oach image, the\n(\'.onst.rat nts of the object model allow depth to be obta~ ~ed.\nWoodham [197 gal proposed a novel approach j.n which, instead\nof moving the camera to different known locations, the light\nsource illuminating the scene is moved to difforent known\nlocations in order to obtain different images.\n\nUnder some\n\nreasons.ble assumptions about the reflective nature of the\nsurfaces in the scene,\n\nthis allows the orlenta tion of the\n\nsurfaces in the scene to be determined unamb:l.guously.\n\nAlthough,\n\nstrictly speaking, this 1s not stereo vlsion f it j,s 8uff:1.c1.ent.ly\nsimilar\' so that the term "photol!\'letl."ic stereo" hal> been applied to\nit.\n\n7.\n\nTEACHING AND LE!\'JiNING\n\nComputer vision systems recognize objects in a scene by\nmatching image featu!"es t<1ith internal mOdels.\n\nThe models\n\nrepresent the vision system\'s knoHledge about the world.\n\nThe\n\nconcepts of teaching and learning relate to the ways in uhich\ngeneral-purpose systems incorpor-ate knoHledge into the data base\nof models.\n\nThe teaching/learning proces ... :l.mpHes a dialogue\n\nbet;ween the computer ann a human operator.\nsyt,tem a new object\n\n(i.e.~\n\nIf we show the vision\n\ncne that is not CUl\'l\'ently represented\n\nin th \xe2\x80\xa2 data base) and give it a oRme, and the system is able to\n.,\nrecognize the object when it is seen again p then\n\n\\-/e\n\nthe, system has learned to l\'ccognize the object.\n\nWe can also say\n\nthat the system was t ..ught\n\n,0\n\ncan say that\n\nr.ecognize the object, especially if\n\nthe human operator has given assistance in learning how to\nrecognize\n\nth\\~\n\nfor example.\n\nobject, such as by poinUng out important features,\nEven i f the operator comletely specifies the object\n\nmodel and does not show the system a training exan:ple at all,\nthi.s process can still be calle\xc2\xb7d "teachlng," as long as it\ninvolves a high-level interactive transfer of knowledge.\nOthcl\'wise, it might better\' be called "programming."\nOne approach to learning in computer vision has been to\nsimulate biological functions.\n\nThe neocognitron (Fukushima\n\n[1975J and Fukushima and Miyake [1980]) is a self-organizing\nclassifier for\' two-dimensional patterns constr\'ucted as a set of\nlayered two-dimensional "colI" arrays.\n\nThe cells are connected\n\nbetltJeen and wi thin layers by "synapses p " some of whose stl\'engths\novol ve with visual experience.\nunsupervl::>ed lear\'ning;\nit ::;ees most often.\n\nSynapse modification is through\n\nthe machine le\'lrns to recognize patterns\n\nThe cells in layers near the\n\nlayer" become featUre detectors,\nrepl~esented\n\n\xc2\xb7~photoreceptive\n\nI.hile the information\n\nwith lncreasing depth becomes more abstract.\n\n7-1\n\nThe\n\nneccogni tron\n\nj.B\n\nable to toler\'a te shifts in position,\n\nand distod.ion in the shape of pat. ttwns.\n\nrota tiona,\n\nHowever, this me thod is\n\ncomputationally extl"emely expensive, requiring thousands of cells\nand tens of thousands of synapses, so will\n\np~obably\n\nnot be of\n\npractical use until computf.tions can be performed in parallel for\neach cell.\nAt the simplest level, many computer vision systems can\nlearn to recognize specific objects.\nVision Bodula (Nitzan\n\nII Al. [1979])\n\nIn the CBse of the SRI\nand CONSIGHT (Ward.ru-...ill.\n\n[1979]), blob analysis is performed in a training mode and a\nrecord containing the features of the new object is\nlist of possible objects.\n\ntn a\n\nSeveral views of the object mny be\n\nused to obtain a statistical distribution of the\nvalues.\n\nstol~ed\n\nV1ewing distance and perspective\n\nal~e\n\nvariou~\n\nfeature\n\nconstant, so the\n\n()b,ject always appeC\'.Y\'s essentially the same up to translations and\nrotations in the image planE\'.\n\nThese systems do not bave to infer\n\nwhat the object. will look like for al\'bit1:\'ary translatione and\nrotations.\n\nPerkins [1978] used a similar teach-by-showing method\n\nto generate a concurve representation which includes a i.:ist of\nstatist:!.cal features extracted from the region enclosed by the\nbuter boundary and a measure of the rotational symmetry of the\nobject.\n\nHis program also assumes that scale and perspective are\n\n\xc2\xa2onstant~.\n\nUndeI"wood and Coates [197:>] developed a method of learning\nto recognize 3-D objects (convelC\nTheir .ethcd\n\nau~omatically\n\npolyhedl~a)\n\nfrom arbitrary viel-/So\n\ngenerates a 3-D description of an\n\nobject based on a sBQuence of images taken as the object is\nrotated :tn space.\n\nAn object is described in terms of its\n\nsurfaces and how they are interconn0cted, by matching successive\nvie\\Js to determine whdt has been seen before and \\--Jhat is new.\nIn ACRONYM (Brooks .t.1k Al. [1979] and Brooks and B.tnford\n\n7-2\n\n(1980\xc2\xbb, the user specifi-:lS models of objects, generic object\nclasses, and possible relationships among objects.\n\nA high-Iovel\n\nmodelling language is used with an interactive editor so that the\nuser can conveniently specify the generalized cones to be used\nand how they connect to fOl\'m objects.\n\n(See Section 1.3.)\n\nThe\n\nuser is aided by a libl\'ary of useful prototypes and a graphics\nmodule that provides visual feedback.\nThe next level of learning, which represents a considerable\nleap from that discussed above, involves being able to model\ngeneric classes of objects by being shown examples, with no help\nfrom the human teacher other than selecting an appropriate\nsequence of training examples.\n\nAs an example of this type of\n\ncapability, a program would be able to recognize any chair after\ns~e\'ng\n\na few examples of the various types of chairs.\n\nThis\n\nrequires the ability to det.et\'mine the l\'elevant components of a\nchair and theil\' relationships to each othel\', leading to. a\ndescript.ion such as "a chair has four legs and a back attached to\nopposHe sides of a seat."\n\nAn outstanding example of this type\n\nof capability is described next.\nWinston [1975b]\n\nprodu~ed\n\na pl\'ogram that learns concepts by\n\nbeing shown positive and negaUve examples.\n\nThe type of concepts\n\nused by IHnston involves struetur\'cs composed of simple objects.\nWhen it is shown a scene, the program constructs a description of\nthe scene consisting of a network indicating the relationships\namong the objects, as described in Section 3.3.\n\nlihen the scene\n\nis designated as a positive example of a certain concept, the\npr\'ogram uses the resulting descript.ion as its initial model of\nthe concept i f it had no previous model of it; otherwise it\ncompares the description to its model, notes the difference, and\ngeneralizes its model accordingly.\nas a negative. example of a\n\nw~rtain\n\nWhen the scene is designated\nconcept, the program compares\n\nthe description of the scone to it.s current model of the concept\n\n7-3\n\nIf a single difference in the\n\nand nc)tes the difference.\n\nstl\'uctul"al description is noted, the r-elationship missing In the\nnegative example is marked in the model as beine: mandatory, or\nthe relationship missing in the model is entercd into the model\nas being prohibited.\n\nI f there are mul tiple differences,\n\nof models is produced,\nexamples.\n\nThus the\n\na tree\n\nwhich can be disambiguated by later\n\nne~ative\n\nexamples that lire near- misses\n\nprovide the most information.\nAnother aspect. to learning is the selection of a recogniUon\nstrategy.\n\nThe binary decision tree lIsed 1n the SRI Vision Hodu.le\n\n(discussed in Section 4.2) is generated automatically after all\n\npar~s to be modelled have been present.ed to the system.\nthe observed statistical distributions of features,\nconstructed by selecting\n\n3.\n\nUsing\n\nthe tree is\n\nfeature and a threshold for values of\n\nthat featu1.\'e which most reliably parti tion the set of objects\ninto tHe disjoint subsets.\n\nThis 113 done recursively for each\n\nsubset oonta:!.n:!.ng more than one object. untH all subsets contain\nexaqtly one object.\nThe ver1fication vision system 01\' Bolles [1976J described in\nSeci,ion 5 incorporates some ability to learn and to be taught.\nIn what Bolles calls "programming time" the user interacts with\nthe system to specify confidence, precision, and cost constraints\nfor the task and to help in selecting operators for detecting\nfeatures in. the p:!.ctures.\n\nThe 8ystern finds features\n\n~nd\n\ndisplays\n\nU:em and their properties, and the user can accept, reject or\nmodify each operator and can specify additional operators.\n\nIn\n\nr\xc2\xb7\'training time" the system applies the chosen operators to sample\npictures and gathers statistical information about their\n\xe2\x82\xacIffect:l. VEmess.\n\n7-4\n\n8.\n\nCAMERA CONTRUL b.;lD CALIBRATION\n\nThis section de&ls with the control of camera parameters\nwhich allow a computer vision system to adapt to changes in\n\nviewing conditions and camera calibr :l.tion techniques whj.ch allow\naccurate measurement of 3-D object positions.\nIn order to deal with coving objects or to look at var1011s\nlocations in the environment, a pan-tilt head is necessary to\npoint the camert.s in the proper dlrection.\n\nTi1is is essentially\n\nan engineering probh.:n to build a suitable device, so we consider\nhere some of the important design requirements.\n\nFirst, i t should\n\nbe capable of very l\'apid movement so that the robot Can "glance\naround" to quickly check out sltuati0ns. Second, it should be\n~quipped\n\n~he\n\n\\1itb\n\npreci~e\n\nencoders so that information e:ctracted from\n\npictures can be referenced to a fixed coordinate system.\n\nthird, it should be c"pable of pre~ise servo cOI\'trci to keep a\nJ:n9v1ng ()bj(..ct centered in the field of view.\n~ngrees\n\nFourth, additional\n\nor freedom of camera moveruent Lrft desirable.\n\nFor\n\nexample, the ability to rotat"! each cam\xe2\x82\xac:ra of a stereo pair\nthat\n\ntheil\' princi p\'ll\n\nIljaxJ.mizes\n\nt~Je\n\naxes intersect\n\n130\n\nat any dt:sired range\n\ncommon field of VieH at that range.\n\n~enerally\n\nspeaking, image feature extraction\n\nper. \'ormbest Hhen iris nnd foel\\s settings\nthe highest-quali ty image.\n\n~re\n\nalgorithro~\n\nadj\'Jste:l. to obtain\n\nIf the vision system operates in a\n\ndynamically changing enVirOnLlent, automatic control of iris .nd\nfocus is necessary to adapt to variations in illuIDJ.nation and\nobject distal1ce.\nTho\n\nbe~t\n\nir\'h\n\nS\xe2\x82\xac\\;\\..;\'!lg\n\ntraxtl\'li?es the\n\nintcnsJu.es and is nominally\n\nobt~iljed\n\nrange of r.dxe.1\n\nby keeping the brightE.st.\n\npixel in thc image just below sa turatioa.\n\n8-1\n\ni.ill\'\'\'\'\'\'ic\n\nThis RpproBeh can 0e\n\nl\'ofined by applying it to a uin.:ioH\n\nor\n\nthe illlage containing tho\n\nobject of interest and allowing brighter regions (which arc\no\\wrent.ly being ignored) to satm\'ate"\n\nThis is the approach used\n\nill HIFEX r a special-pu,\'pose image featuro extraction dc\'dce built\n\nat JPL (Bskonazi and tHlf [1979]).\n\nTho maximum video level in a\n\nprogrammable rectangular window is available at 30 Hz to a\nmicrocomputer which ser\\\'os the l1".ls motor.\nFocus control is generally basad on maximizing the high-\n\nfroquency content of the image.\n\nIn a 3-D scene containing\n\nobjects at varying distances, the best focus depends on which\nobject is being\n\nThl\'S the high-frequency content should\n\nanalyzt.~d.\n\nbe maximized in a window of the irauga which contains the object\no,f\n\nOne Nay to\n\ninteN~st.\n\nme~sure\n\nhish-fl\'equency oontent ls to\n\nlook at tte magnitude of a gradient edge detection operator\n(8skclJazi and \\Hlf [19\'19]). For\' best: results? some quantity can\nbe lntegrnted over a \\lindow.\n\nThe system described by J ohnsol1 and\n\nGoforth [1974] focuses by integrating either thresholded\nbl\'ightness data or the results of using high-pass filter on the\nlmnge.\n\nI~or\n\nall of these methods,\n\n11\n\nhn l~climbine strategy\n\nused to drive the focus motor of the lens to the position\nulaxii;n:izes the parameter being l\'HilulUl\'ed.\nlJl;;u:ir~a\n\n1.3\n\ntb~t\n\nIn some cases local\n\nOldst that do not correspond to the COl\'l"6ct focus,\n\nbut if\n\nthe initial focus is sufficiently close to being correct, tho\nhill\n\n(~li!tlbing\n\nThe final\n\ntechnique will find the global maximum.\nCamSl"H\n\np2,l"amcter to be considered is focal length.\n\nVariations in objoct distanco or varying field of view\nreq~irement~ for different tasks can be best handled if it is\nOno appr.oach is\n\npossible to change the focal length of t.he lens.\nt.o\n\nmount\n\nseveral fixed-length lenses on a turret and to rotate\n\nthe appropriate one into place ns viewing conditions require.\nPingle and Tenenbaum [1971] used thNle lenses.\n\ntlpproach ls to use a\n\ncompute,\'~,controllQd\n\n8-2\n\nA more general\n\nzoom lens.\n\nThe\n\ndifficulty\n\nvith varying the focal\n\ncalibrat~on\n\n(to\n\nb~\n\ndiscussed below) changes.\n\nmultiplE:\' fixed-length lenses,\nfor a given lens.\nvar\'y continuously.\n\ntracking system\ncalibration.\n\nlength is that camera\nIn the case of\n\nthe calibl\'ation is at least fixed\n\nPOl" a zoom lens howeve:\',\n\nthe ca.libration will\n\nGibert.t1.t..a.l. [1980] use a zoom lens in thei r\nbut\n\ndo not\n\ndiscuss\n\nthe\n\nimpact\n\non\n\ncamera\n\nIt is worth noting here that changes in focus huve\n\na similar effect on calibration, although on a smaller scale, to\nchanges caused by a zoom\n\nlen~\n\nCamera calibration consists of determining a set of\nparameters which specifies the relationship between 3-D points in\niEl\n\nscene and theil\' projections onto t.he 2-D image plane.\n\nHlliIe\n\nt.here are "arious \\-lays of formulating tllif. relationship, in the\ncase of a central projection it is generally equivalent to\nknowing the location of the lens center,\n\nthe ol\'ientation of t.Ile\n\nprincipal axis of the lens, and tho distance from the lens center\nto\n\nthe\n\nimage plane.\n\nCameras are\n\n(1)tel\'!llining tho image coordinates of\n\ntypically\nfi\n\ncalibl\'ated\n\nby\n\nset of reference points\n\nahd solving for the calibration parameters.\n\nWe are concerned\n\nher\'c \\dth calibl\'ution methods Hhich allow gClwral 3-D position\nmeasurements and stereo matching, as opposed to methods used in\nIlysten\'~l\n\nsuch as CONSIGHT (Hard ..c...t. .sl..\n\n(1979]) which assut1e\n\n()\'Onstant vil1w:tng distance and perspective.\nIn hand-eye systems, a target on tho manipulator can be used\n\nas a caHbration point.\n\nBy moving the manipulator to several\n\ndifferent posHions and locating the tal\'get in the :tmage each\ntime, a set of 3-D points (obtained through manipulator pOSition\nfeedback) and their images arc obtnined which can be used to\nsolve for t.he calibration parameter\'s.\n\nThis is the method Ilsed by\n\n\'ehe JPL hand-eye system (Yakimovsky and Cunningham (1978]).\n\nThe\n\ntarget is a small light bulb on the hand which can be located\neasily and reliably.\n\nOne of the advantagtCs of this approach is\n\n8-3\n\n\'\\\\\n\nthat systemaUo orro .. s in the camera calibration relative to the\nmanipulator calib:-aUon are eliminated.\nIn order to obta1.ntiocurnte position informat.ion from an\nimage, t.he transforma t.ion from three-\xc2\xb7dimensional space to the\ntwo-dimensional image plane must be known.\nassumed to be a centl\'al projeotion.\n\nThis Is usually\n\nHowever, cameras often have\n\ndist.ortion caused by the lens or by the scanning me c hatl i\ncauses the true projection to depart fl\'om this ideal.\n. a distortion calibration may be necessal"Y.\n:lUch a calibration is to take\n\ntil\n\ndots,\n\nthat\n\nTherefore,\n\nOne way of performing\narl~ay\n\npicture of an\n\npositions are accurately known.\n\nSill\n\nof dots whose\n\nA program then can find tho\n\ncompare their positions in the image\n\nto\n\npositions, and fit a d:l stortioD correc:tion function\ntuo-dilillensional polynomial) to the discrepancies.\n\nthe ideal\n(pe~hapB\n\na\n\nMoravec [1980]\n\ndescribes a way of\' finding the dots in the image.\nIn using the stereoscopic vision techniques described in\nSection 6 t it ls highly desirabh, to know BCCUl\'ately the relaU va\nposition and orientation of the cameras which pr0duced the\nroul Upla vie,,\' &, because this knoli ledge constrains th e se arch for\'\nmatching point.s in the images, and because it\ndistances to be computl\'?:d from the matches.\ncamera\'s post tion and orientation have\n\n~)nablN;\n\nabsolute\n\nOf course, if each\nbeen\n\nprece.libl:\'ated\n\nrelntive to some common coordinate system, the l\'clative position\nand or:lentation are easily obtained.\n\nHowever, sometimes this\n\nindividual calibt\'ation is insufficiently RCCUl\'ate ot\' is absent.\n\nIn such cases it is possible to obtain the desired relative\ncnlibl\'a.tion by using unknown points in the actual images, so that\nno special\n\ncali~ration\n\ndata is needed, except that the distance\n\nbetween the cameras cannot be so obtained.\n\nIf at least five\n\npoints in genernl position are matched in two images, they can be\nused\n\nt~,\n\ncomput.e the five parlUlleters that define the po.\'3ition and\n\norientation of one camera relative to tho other, except for\n\n8-4\n\n.,..\n\n\\\' .\n\ndistance.\n~;tereo\n\nGennery (1980) provides n way of performing such a\n\ncamera calibraUon,\n\nwhich obtains the mat.ched points by\n\nusing a method of Moravec (1980), performs a leost-squares\nadJustment 30 thut more than five pOints can be used effeoUvely,\nlndividual.ly we.1.ghts each p\')int. based on its estimated accuracy,\nIlnd autolliatically edits out points that. have been mismat.ched.\n\nThe dist.ance information is usually available \\dth sufficient\n\naccuracy from other sources, and, even if it is not,\ndllmensional information (except\ncomputed from a storeo pair of\n\n8-5\n\nfOl\'\n\ntlr~c\xc2\xad\n\na scale fact.or) can still be\n\npicLuro~\n\n9.\n\nSYSTEM ARCHITECTURE\n\nIn t.he simplest computer vision systems, a scene description\n\n1.s obtained in a sequential process.\n\nA TV image is input to a\n\nfeature \xe2\x82\xac!xtractor whose output goes to a recognizer\n~/hich\n\nin turn outputs a scene description.\n\n01\'\n\ncla3sifier\n\nThis characterization\n\napplies to fairly simple (and practical) vision systems such as\nthe SRI 171s100 Module and CONSIGHT described in Section 1.3. The\nbasic assumption in this type of approach is that there is a\nolean d1:3tincUon between the processes of fsatm\'c extx\'action and\nlr\'ecognit:lon, and that feature extraction can operate reliably in\n\nthe absence of knowledge stored in the model that is used for\nr.cognitlo~\n\nThe strict sequential approach makes it fairly\n\nstraightforward to partition the prooessing into logically\n\ndistinct units and to implement these computational units in\n:;ipecial,\xc2\xb7pul"pose hardware Hhel\'e :;peed is cr\'itical.\n\nThe approach described above has proven to be useful in\nhighly organized environments"\n~nadequt\\te \\~twn\n\n3-D\n\nSCI)n0S\n\nHO\\H~Verl\n\nit is t-loefully\n\napp1ied to natUl\'al outdoor scelles or even general\n\nof man-made (i.e., industrial) objects.\n\nIn developing possible architectures for more general\ncomput~lr\n\nvision syst ems,\n\nwe must oonsider what\n\ntypes\n\nof\n\ncomput,ational tusks Hill be performed and what structures are\nbest su:Lted to perform them.\n\nNo one knows yet how powcl\'ful high-\n\nlevel understanding and visual analYDis will work, so we have\nvery few hints ~s to how to design a system to do high-level\n\nvision.\n\nBut there are some insight::. into\n\n\\~hat. :!,.~\n\nrequired of\n\nlow-level visio~ Low-level vision must extraot an economical\ndescription of B scene from a raw intensity image, without\n\n9-1\n\nnecessarily recognizing objects or understanding much aho\'lt tho\nscene.\nMuch of the reseal\'ch that has beN} done in low-level vision\n(for\' example BarroH and Tennenbaum [19\'(8), Hanson and Riseman\n[19780] I and Brady and tHelinga [l9\'(8)\n\nindicates that a numbe!"\n\nof images of a scene in variouG stages of processing should be\nmaintai.ned concurrently, because these e.xplicitly represented\niVlages interact with each\n\nothel~\n\nat; procl;!ssing proceeds.\n\nThe actual computations of lot.-level\n\nand with higher and lower levels\n\nv.ision are usually local to one portion of an image, both td thin\nand between levels.\n\nOften the actual computing is by way of\n\nrelaxution processing, whereby local constraints within and\nbetween images are used to arrive at a globally consistent result\n(as, for example, with Zucker (1978]).\nmight\n\nb~~\n\nThus p 10\\<,-level vision\n\nwell served by an architecture consisting of a large\n\nnumber of registered image buffers accessible by processing\n."laments liol"king in parallel.\nAn example of this kind of architecture for lOVl-level vision\nprocessing ia the stack organization proposed by Barrow and\nTenenbaum (1978J\n\n(also described by Tenenbaum.eJi.\n\n~\n\n[J.979]).\n\nIn this orga.nlzation eaeh level of the stack holds an iconic (in\nthe form of an image) representation of various\nof the scene, called intrinf;ic images.\nbrightnoss,\ndistance.\nlevel\n\nillumlnation~\n\ncharacterist5.~s\n\nFor example, these can be\n\nreflectance, orientation, and\n\nl\'here:1s comllJunication betNeen nearby pixel.s in. each\n\nof\' tho stack to enforce assumptions about the continuity\n\nof each chpracteristic, and there is communication betweon\nc()l\'l\'csponding pixels at d.ifferent levels of the stack to enforce\ntlhe assumed r\'ela tionships among\n\nth(~\n\nvarious characteristics.\n\nBy\n\nan effectively parallel iterative computation based on these\nassumptions,\n\nthe intrlnsic images are t\'Ccovcl\'od.\n\nhardware could be bull t\n\n(Special\n\nfor implementIng this scheme,\n\n9-2\n\nas\n\ndescribed in Section 9.2, but it can be implemented on any\ngeneral-purpose computer with sUff1cient memory and speed.)\nA possible al\'chitecture for performing somE\' low-level vislon\n\ntasks Is the cellular automaton, in which simple operations are\npel\'formed at each step on eaeh pixel as a function of the\nneighbot\'1ng pixels at the previous step. (It thus is simHal\' to\none level of the Barrow and Tenenbaum method described above.)\nSuch methods are\n\ndiscussed by Rosenfeld\n\n[l979b).\n\nThey can be\n\nimplemented efficiently by the single-instruction-stream\nmul tiple-data-strcam hru\'dw<1rc described in Section 9.2.\nAnothel\' computational structure that has received much\nattention is the "recogt:lition cone" (Uhr [1972]) and its\nvar\':Lants. Tllis is a hieral\'chical approach tilth several layers of\nI\nprocessing organized similarly to the pyramid data structure\nUhr proposes a "parallel-serial n\n\ndiscussed in Section 2.8.\n\ncomputer apchitecture (Uhr [1978]).\n\nEach layer Ls vicvled\n\n?S\n\na\n\nparallel processor which tr\'ansforms (and shrinks) the data at Olle\nlevel to the next higher level.\n\nThere may be several transforms\n\n(oper\'ator\'s) at each level which operate. in pat\'allel.\n\nThe various\n\nlayers arc pK\'ocessed serially in both a bottom-up and top-down\nfashion.\n\nThis implies feedback to featur\'e extractors b-""cd on\n\npariial recognition results, something absent in the simple\n\ni\n\n.\n\nviSion system architecture described at the beginning of this\nsection"\nHanson and Riseman [l978b] propose a hierarchical processing\nconc computa tional model for 10\\1-1eve1 vision processing such as\nextracting line end region data.\n\nIn thei r model, there may be\n\nsevel\'al planes of data at any given level represenUne processf\'d\noutputs fron the level below.\n\nThe pl\'ocessing at each level\n\ncarried out by an array of local processes.\n\ni~l\n\nIn addi lion to top-\n\ndown and bottom-up processing, there would be communication\n\n9-3\n\nbetween prooesses at the same level, adding lateral control\ndecisions to t.he computational structure.\n\nAll of\' this processing\n\ncould t8ke place in parallel p leading to a host of unknown\nc:omputaUorial methods m,raiting much further research.\n\nThe basic hardware device necessary for digital image\nprocessing is an 8.nalog-to-digitnl (AID) converter and a computer\ninterface for access to the digital image.\n\nAdvances in\n\nsemiconductor technology have led to fast AID converters and fust\nrandom-access memories which\n\nBllo~\n\ncontinuous cight-bit\n\nd.igitization of 5 i2-by\xc2\xb7\xc2\xb7512 (or larger) images with full frame\nbuffer\'ing at the standard video frame rate of 30 H:c..\n\nFor t.he\n\nmost flexibility, the computer should have random access to any\npixel in the image without disrupting the d1git1zation and\nbuffering.\n\nOne of the first devices to offer this\n\ncapabHit~r\n\nHas\n\n.al. [1976 J). RAPID digitizes (8 bits/pixel)\nand buffers 192-by-240 images HhHe providing COnClH\'rent computer\na()cess to any pixel in the frame buffer in ~ microsecond:3. This\nRJ\\"PID (Yakimovsky\n\nd~~vice\n\n~.t.\n\nenabled the implementation of the real-time correlation\n\ntx\'acker discussed in Section 5 (GrHfin .li.t...?J.. [1.9\'78]).\nIn Qrder to achieve reasonable competenco,\nenormous c..ilJounts of computational power.\nexisting sequential computer comes\n\n~li thin\n\nvision requires\n\nIt is possible that no\nsix orders of magnitude\n\nof\' being powerful enough to see as well as a human being.\n\nEven\n\nthe modest performance of some of the existing systems requires\nseveral minutes of computing in ordel\' to analyze a single scene.\nAl though the speed of processors 1>1111 increase, it is apparent\n\nthat a different architecturo than the s:i.ngle general-purpose\nprocessor will be required in or\'der to produce the large gains\nneeded.\n\nTwo pl\'incipal possibHities are spocial-purpose har\'dwCll\'e\n\ndevices dedicated to computing certain operations needed in\n\n9-4\n\nvision much faster than a general-purpose computer oan, and\npal\'(ll1el computation in general purpose computers.\n\nSpecial-\n\npurpose hardware can produce large gains in speed but it is\nlimited to low-level operations at present.\n\nAt the higher\n\nlevels, tho greater complexity needed may cause it to remain\nnoncompetitive with general,-purpose hardware.\ncomputaUon can be used in a\n\ns,pecial~purpose\n\nAl though pal\'allel\ndev;i.ce, i t can also\n\nbe used in a general-purpose oomputer, so that. large gains in\nspeed can be achieved without loss of fledbility.\n\n(Some of the\n\npossible hardware architFlctUl"CS for comptlter vision have been\nsurveyed by Reddy and Hon (1979).)\nOne\n\nof\n\nthe\n\nsimplest\n\nimage prepl\'ocessing\n\nsteps is\n\nthresholding, which can be done ei ther digitally or in analog.\nIn the analog case, the thl\'esholdel" is essentially a one\xc2\xb7;b1t AID\nconverter.\n\nThe JRI Vision Module (Nitzan .\xc2\xa7Lt. \'\xc2\xa3\\1" [1979]) operates\n\nin either mode, obtaining binal\'Y images C.t frame rates.\nbit frame buffer\n\nallo~lsstorage\n\nA 16 K-\n\nof two blnar\'y images taken f:\'om\n\none or more 128-by-128 cameras.\n\nAddHJ.onal special hardi.are\n\nC~~.\n\naccess this memory to convert the rastel\' image to run-length code\n\nand to compute the al\'ea and f:l.rst;\xc2\xb7>order moments (sum\nblobs.\n\nX,\n\nsum y) of\n\nAll of this processing is confined to a programmable\n\nrectangular window so that analysis can be restricted to a single\nblob.\n\nThe run-length code is processed by & general-purpose\n\nmiorocomputer (DEC LSI-11/02) to extract additional blob\nfeatures.\nMany low-level image processing algorithms convolve the\nimage with a square or rectangular windol..\n\nThe \\\'lindows typically\n\nrange in size from 3 by 3 to 7 by 7,\n\nlarger windows being\n\nused ocoasionally.\n\n~dth\n\nMost of these algorithms could be implemented\n\nin a pal\'allel array processor consisting of\' M ti mes N identical\ncomputational units to pr\'ocess an M\xc2\xb7\xc2\xb7by-N image.\noutput of conventional TV\n\ncamera~\\\n\n9-5\n\nHOrlever, the\n\nis serial, which means that the\n\nprocessor\'s lIouId be idle fot\' most of the 1/30 second frame time.\n1I.n alternative approoch is to process the image serially in real\ntime\n\nby\n\neffectively scanning\n\n(~omputat:lonal\n\nunit.\n\nthe image\n\nwith a single\n\nFor an l1-by-n operatol\', this 15 accomplished\n\nby buffering the last n-1 lines and accessing an n-by-n window\nfrom the current line and the buffered lines in pal\'allel, using a\npipeline architecture to perforDl the necessary computations, with\nnew windo,.s being accessed at the pixel rate.\n\nHhile an entire\n\nframe time is required to process an image, the net result\napproaches the efficiency of parallel arrEJ processing, since the\nprocessing is going on concurrently with the acquisition of the\ni.mage by the camera.\n\nThe effective process:!.ng time is thus the\n\ndHference between the time when the last pixel is scanned by the\nf\n\ncamera and the time\n\n~1hen\n\nlast pix,al is out.put.\n\nthe processed value corresponding to the\nClocking data through a computational\n\nunit at pixel pates results in\n\na difference, or pipelino delay\n\nof (n-l)/ 2 Une ti roes (standard video line if mo is apprmdmntely\n63 micro seconds) plus possibly a fel" pixel times for an n-by-n\noperator.\n\nAn\n,\n\nexample\n\nof this type of pipeline processor is a device\n\ncalled H1FEX built at JPL (Eskenazi and IvUf [19\'79]).\n\nA video\n\ninput. si.gnal is digitized and processed b)r four computational\nun! ts.\n\nT\'he flrst. is a\n\n3~bY-3\n\ngr\'adisnt\n\n~ytiel\'ator\n\nwhich enhances\n\ncontrast edges, outputting the magnitude (8 bit$) and orientation\n(quantized to 45-degree intervals) of the gradient.\nis a thinning\n\nalgo~ithm\n\nThe second\n\n(3-bY-3) which fil tel\'s the gradient\n\noutput by passinG only those pixels whose magnitude is greater\nthan either of its two nearest orthogonal neighbors in a 3-bY-3\nne.ighbor\'hood (e.g., the top and bot tom neighbor\'S of a horizontal\nedge).\n\nThe thinned gradient image is thresholded to obtain a\n\nbinary ed,ge map_\n\nA second thinning algorl thrn deletes edges fr\'ora\n\nthe binary edge map which are not necessary to maintair1 global\nconnectivity, by exami.ning the eight nearest neight>;:,rs of each\n\n9-6\n\nedge in a 3-bY-3 windoH.\ntl~ansferI\'ed\n\nThe thinned binary edge map is\n\nto a block of memory :1.n a DEC LSI-11 \xc2\xb703 p which\n\nporforms furthc:\' processing.\nNudd I I .al. [1979\n\nJ have experimented with hardwal\'c\n\nimplementation of several low-level algorithms usicg chargcicoupled device (CCD) technology.\ntheir\n\n\\~ork\n\ns:lngle\n\nceo\n\nOne of the primary goals of\n\nis to integrate the image sensor and proceSSOl\' on a\nchip.\n\nFunctionally, the approach is thE: same as that\n\nfor IMFEX in that the imago is processed serially as it is\nscanned by the camera.\n\nMost of the operators they have\n\nimplemented (Sobel operator, Laplacian, spatial filter, Bnd\nunsharp masking,\n\nfor example) are 3 by 3.\n\nimplemented 5-by-5 and 7-bY-7\n\nThey havc also\n\nprogrammable masks and a 26-by-26\n\ncc)l1volution operator.\nOna possible type of parallelism that may be especially\nsuited to low-level vision is an array processor using a singleinptructic::>n~stream\n\nreutiple--data-stream (SIND) architecture.\n\nSuch\n\na system uses an array of Simple processors (usually one per\np:j.~el) that all perform the sam"" functions simultaneously under\n\ncohtrol of a master processor.\n\nEach cell in the array usually\n\ncan communicate directly only with its neighbors in the array.\nTh~\n\nmaster processor is similar to an ordinary computer.\n\nIt\n\ndecodes the instructions in its program, and causes the urray of\npirocessors to execute them.\n\nSince each cell is much simpler than\n\na central processing unit of an ordinal"Y comuter, a high degl\'ce\nof parall\xc2\xb7elism can be achieved at low co::t.\n\nHowever,\n\nthe kinds\n\nof algorithms which can use this sert of parallelism are limited.\nSevel\'al SHlD devices have been bu il t.\n\nThey differ greatly\n\nin the complexity of the processors in tho array and in the\namount of data stored at each cell in the array.\n\nGolay [1969]\n\ndesigned a device that performed simple operations on binary\n\n9-7\n\nimages based on the values of the six neighboring cells in a\nhexagonal\n\n!:ll"l"Il;j.\'o\n\n.II. faw bitf.i POl\' cell ue.t\'e\n\nstof\'ed. The ILLI1l.C-III\n\ncomputer (McCormicl{ [1963]) performed V\'Ol\'Y simple operations at\neach\n\ncell of eitherILLIAC,~IV\n\nwhepeas the\n\nIi\n\nl"octangulaf\' array or a hexagonal array,\n\ncompute!:" (Ba!"\'nOR\n\n~tJ..i?J".\n\n[1968]) can perform\n\narithmetical calculations ou data that DaD be accBssed in a\nfairly flexible way; but it has only 6l.! processor\'s.. (The ILLIACIV was not intended fop vislo!"I.)\n96-by~96\n\nrectanguJ.al" array of pr:ocessors, each Of1rlhich\n\n,~omllunicate\n\nwl tl1 its uight nearoot::,t neighbors and can perform\n\nuses a\n\n(1&"1\n\nThe CLIP4 system (Duff [1978])\n\nboolean operations, from \\.;hiah Ill\'itnmetic operations can be buH t\nwith coftuare.\n\nEach cell can store 35 bits.\n\nProbably the most\n\nambitious project of this sort; so far is the Massively Parallel\n\nProcessor (Sohaefer [1980]) being developed by NASA.\ncontain\nstor~s\n\na\n\n128~by-\'28\n\nrectangular array\n\n1024 bits of data,\n\not cells.\n\nIt will\nEach cell\n\nperforms logical Bud arithmetic\n\nopera.tions (both fixed-~Jo.int; and floating-point) 9 and\ncOrllrtHll1icates with its fOUl\' nearest neighbors.\nB1t-ser\'ial\nIH\'!t!"Il!Wt.tC\n\n:ts used.\n\nThus some paralleHsll! is sacl;"J.ficed in ordc!"\n\nto keep the cost down enough\n\nso that the large amount of\n\nparallelism in the al\'ray is economically pract:l.cal.\nAnother type of\n\nparallelism is a multiprocessor using a\n\nmultiple-instruction-stream mUltiple-data-stream (MIND)\naroh:l.tect;u!\'e.\n\nSuch a system uses a n.umber of oElntral processing\n\nunits that independently execute different instructions.\n\nIt\n\nwould be possj.ble to have these connected only to their neighbors\nin an arrAY as in the SIMD devices, but this would waste the\ngonerality of the processors.\ncommunication 1.3 needed.\n\nSome more general type of\n\nPreferably,\n\nit is desj.red to have all\n\nof the procesl:..":ll\'s able to communicate directly with each other\n(tdthout the delays that using a common bus would\n\ninvolve).\n\nThe above direct communication can be aChieved by meanl:\' of a\n\n9-8\n\n(\n\ncrosnh::.r s\\dtch.\n\nTo interconnect n items in this manner requires\n\n).12 swi.tching circuits.\nsystem buil t\n[19"(2].).\n\nAn example of such a system is the C.mmp\n\nat Carnegie-Mellon University 01ulf and Bell\n\nIt connects sixteen\n\nPDP~11/ iWE\n\n256 K memory modules by means of\' a\n\ncomputers to sixteen\n\nsixtee~-by-sixteen\n\ncrossbar-.\n\nSince the amount of circuitry in each switching circuit ia\nconsiderably less than that in each processor, it probably is\npract1aa:to connect B few hundred processors in this manner.\nusing current semiconductor teohnology.\nAs semiconduct or technology improves,\n\nit Hill become\n\npractical to use a much greater number (perhaps millions) of\nprocessors in a computer.\n\nTo connect such a large number by\n\nf\n\nmeans of a crossbar probably will be impractical, since the\nnumber of components is proportional to the squape of the number\nof units to be connected.\n\nHowever, Moravec [1979] has proposed a\n\nmethod based on the Batch(;)l\' sorting network in which the number\nof components increases much less rapidly.\n\nFull interconnection\n\nis r,etained$ but there is a slight loss of speed, since a message\nsont; through the netHol\'k must go through a numbtJl\' of stages of\ncireui t:ry pr\'oportional to the logar.i. thm of the numgep of units to\nbe connected.\n\n(Because of pipelining the bandwidth is\n\nthe latency is fairly long.)\n\nhigh~\n\nbut\n\nThus with this method i t would be\n\nmost appropriate for each processor to have its own memory, uhich\ni t woul.d access most of the Hmo, \xe2\x80\xa2\xe2\x80\xa2 ith less frequent messages\n\nbell1g Bent to and from other processors or memory modules.\nAl though elaborate systems software may be needed, once it is\navailable the complexity of the system can be largely transpar\'ent\nto the applica tions programme!.\'.\nIn cases wher\'c the mlmber of pl\'ocessors is too great for the\nuse of a crossba!\' and it is desired to avoid the complexity of\'\nthe sorting network,\ntailored for\n\n&.\n\na more limited interoonnection scheme\n\nparUcular type of task might be used.\n\n9-9\n\nFor\n\n... -- ..\n\n,-\'\n\nc~xample,\n\nfleveral processors could be co nne Ot-\n\nform an image processing unit that\n\n~lOuld\n\nhy a crossbar to\n\noperate on the cl\'mtcnts\n\nI:>f one i.mage buffer, and several of these combinationtl could be\n,oonnected by serial image transfer betueen image buffer\'s through\n;a\n\ncrossbar,\n\nso\n\nthat\n\nprocessing\n\non\n\ndiff~l"ent\n\niconic\n\nrepresentations could occur simultaneoulsy, corresponding to\ndifferent stages of processing.\n\nAs anothel\' example, the stack\n\norganiza tion of Barrow and TenenLaum for recovel\'ing intrinsic\n:lmages (described in Section 9.1) could be implemented by havlng\nprocessors in each level of the\n\n~)tack\n\nthat could communicate with\n\ntheir neighbors in that level and idth the processors at the same\nposition in all other levels.\n\nAn existing system tiith limited\n\ninterconnections is the emu system built at Carnegie-Mellon\nUniversity (Swan\n\n.ft.t..ru...\n\ncbnnected in clusters.\n\n[1977J).\n\nJ:t contains 48 LSI-11 computers\n\nIt must be emphasized p however, that\n\nwhere the ccmplete interconnection of processor\'s is praotical it\n\n1s better to use such a general system and to put it into the\n~!onfigur\'ation\n\nof these examples under software control, rather\n\nthan to build hardwal\'e for these specialized interconnections.\n\nA\n\ni,~ood rule to follow is not to build a special-purpose devlce if a\n$eneral-pu~pose\n\ndevice can be built almost as cheaply and\n\nperform almost as fast.\n\n9-10\n\nca~\n\n10.\n\nTlw\n\nCONCLUSIONS\n\nstatement tIV5..sion is hal\'d" is found often in the\n\ncomput:er vision literature.\ndiff1cul ty.\n\nThero are several reasons for the\n\nIn the first place p an image contains an enormous\n\namount of infor\'!lltttion, much of it\nand it j,s an\n\ni[aperfco~\n\nto the task at hand,\n\npl\'ojection of\' the real\n\n\\~orld,\n\ncontaining\n\nFrom this the relevant information must be\n\nnOise and distortlon.\n~~xtl"act.ed.\n\nir~elev:lnt\n\nIn the second placcs the transformation from the\n\nimage to the real\n\n\\o101\'1d\n\nis highly ambiguous.\n\nThus world\n\nknowledge must bo r\'el1ed on to resolve the ambiguities.\n\n(This is\n\nthree-dim~nsional\n\nscenes,\n\nbut it is also true to a lesser (;}\'.:tent in stereo ,riSiOn.)\n\nIn the\n\nlespecially tl\'ue in monocular vislon of\n\nthi.rd plane, an object seen may onlj\' vaguely !\'csemble others of\nI\n\nits generic t.ype or even itself at other tilllec or under other\ncondHJow3.\n\nIn the fourth place, :til a pOHer\'ful vision system an\n\nobject must be recognized out of a large number of possible\n\nobjects or generic types.\nThese facts appear to manifest themsolves in two ways in\npract:lce.\ncomputing.\nne(H~ed\n\nFil\'St.~\n\nvision\n\nSecond p it\n\nrequi)~es\n\nseem~\n\nan enormous amount of\n\nthat the computational methods\n\nare very complicai:ed, and it is unknown todal- Hhat the\n\nright me theds I,<ill be.\n\nEven th<nlgh the above blo aspects of the problem are b.oth\n\nimportnnt l there is a trade-off between them.\n\nFor example,\n\nrecognition could be done in prinCiple by comparin,g the image to\nall possible views of all possible objects.\n\nThis ir a simple\n\ntochnique, but it is completely prohibitive in computational\n\ncost.\n\nHore complex, smarter methods can reduce the computation\n\n10\xc2\xb7\xc2\xb7 ,\n\nt.he other\n\nAt\n\nenorEOUS.l.Y.\n\none might hope that\n\nextpfll:lltt!p\n\nan\n\nex\'cremely clever meth.:>d might be invented that. lIould make the\n\namount of computing quite small.\nbec~uuso\n\nthough,\n\nThis doesn\'t seem llkelYf\n\nof the large amount of infox\'[1jstion in an imago p\n\nth.:: large numbor of posslbili ties :til\n\nIi\n\nviewed\n\nSCtme,\n\nand tne fact\n\nthat biologicnl evolution has not boon able t.o come up with such\na uethod.\n\n(The human ;,rain devot.es bHlions of neurons to the\nThus, t.o match the capability of human vision\n\nta:sk of vi-sion.)\n\nwill probably roquire several ordors of magnitude times the\ncomputing power of today\'s most powerful computers.\ncu.rrent\n\nprogl\'ess\n\nin\n\nelectronics\n\ntechnology\n\n(If the\n\ncontinues,\n\nsu.fficiently powerful parallel computet\'S eventually will hecome\nBvclilable, as discussed in Section 9.)\nOne\n\nmig~t\n\nhope also that some powerful simplifying\n\nprlnciples might be discovp.red that would eliminate the need for\nmuch of the complexity,\n\nevldenc~\n\nthat such\n\nStudy of the human brain has not be<1n\n\nprlnciples exist.\nhel~\n\nbut there is no\n\n01\'\n\nmUCk)\n\nin this regard or in regard to finding less powerful but\n\nprncl-ical pl\'inclples. since neuI\'ophyslologists Hnd psychologists\n\nhav\'.e barely\n\n~\\(~:\'a:\n\nched the surface .in understand!ng hOH it \\wl"ks.\n\nof the cUI\'rent\n\n(SComa\n\nkno\\~ledge\n\nis SUIll!J1ar\'ized by Gr\'sham [1965],\n\nJulesz [19711. and Cartol\'etto and Friedman [1975].)\nUS~\n\nSince the\n\nof the te0hniqu8s that ultimately will be successful probably\n\nwill require much computing, these techniques cannot be developed\nuntil sufflci0ntly powerful computers are available with which to\n\nexp()riment.\n\nThus,\n\nmuch research usi.ng these powerful computers\n\nmay be l\'equ1J\'t1d before we lear\'n\nIn\n\nsp1tt~\n\nho\\~\n\nto use tLem at fectlvely.\n\nof the above problems, some pr\'ogl\'css has been made.\n\nSome highly specialized systems have actually performed uHeful\n\ntasks in restricted domains.\ndegre~\n\nof\n\ndimensiona,l\n\ngenerali~y\nobj(~cts\n\nS~ma\n\nlaboratory systems have a\n\nin the dorua:ln of rccognit:ton or\n\ntHo-\n\nunder llcll-controlled lighting, because of\n\n10-2\n\nthe le:\'35Cr amount of umbigu,Hy anct comple;ci.ty in this domain.\nSome cxpcl\'imlJntal systems hold pr\'ol!Jisc fot, recognition of generic\nthroe-dlmensional\n\nobjects~\n\nof computing time on\n\nis becoming\n\nhard\\~arEl\n\nHI though they reClllit\'e\n\ncxis~inG\n\ncomputers.\n\n",vailabJ.e~\n\nf!\n\nla1\'l?;e amount\n\nSome special-purpose\n\nwhich enables\n\ncomputations to be performed rapidly,\n\ntWIllC\n\nvery low-level\n\nEven in these cases,\n\nhowever, a varie\'ty of technlques are in lwe, I-lith no consensus\n\nabout which are the beeL\n\nThis be comeR even truer as we move to\n\nthe higher-level, more general. or more advanced areas.\nF\'urth{lrmo .... ~, many of the\n\nhoc, with\n\nlitt~~\n\napp.~o"ches\n\nthat. havo been usod are ad\n\npromise of generality.\n\nSome of the issues that seem impot\'tant in compllter\n\nV18l.0n\n\nwill be summarized.\n\nresear~::1\n\nIn recognition,\nbot tom-up manner\',\n\nit is possible to proceed eitrICI\' in a\n\ndetecting low-level\n\nfea tU!\'CS first,\n\nand\n\norganizing these into ever higher-level strucLurcs until the\n\nscene is completely\n\nanalyzed~\n\n01\xc2\xb7\n\nin a top-dO\\H1 manner\', starting\n\nwith a hypothesized object and ti"y1ng to find its features 1n\n\nscene.\n\nA combi na lion of both of these\n\nmost vision tasks.\n\nappr\'oach~!s\n\ntrlC\n\n:!.s needed in\n\nAn important issue 1s the proper balance\n\nbetween these two apprc,\'lches and how i t vades \\41 th the na ture of\n\ntho t,ask.\nAt the\n\nlO~H"st\n\n,iconic (:tn the\n\nfO\\",ffi\n\nlevel in v:tsion the scene t\'cpresentation is\nof an image), uher\'eas at. the highest level\n\nthe representation is symbol:lc.\n\npl\'oper level\n\nThe\n\nfor\n\nthe\n\ndividinej line betlH)en the two t.ypes of repl\'esentation and how\n\n:much they\n\n~hould\n\noverlap is an issue.\n\n(Funt f.l97\'rJ touches on\n\nthis question in the domain of problem solving.\ndiscussed by Barrow and Tenenbaum [1981\n\n\'0\xc2\xb7\xc2\xb73\n\nJ.)\n\nIt is also\n\nA sepat\'ate but related issue j,s the specific) representations\nthat should be used.\n\nThat iS f what 80rt of taatures should be\n\nextracted from the scene (edges,\n\ncorners,\n\nregions~\n\nsurface\n\nol\'ientation, and so forth), and hOIl should objects be modelled\n(t-Jil\'e\xc2\xb7-frmue models, generalized cylinders, a.nd so forth)?\n\nAt the\n\nhighest level this issue is pa.rt of the general knowledge\n\nrepresentation problem in artificial intelligence.\nIf\' there is a very largf\'l number of models 1.n the data base,\n\nthe pt\'oblem of\n\nto index efficiently into it is important.\n\nhON\n\nAnother issue is whether parall.el methods such as relaxation\nare merely a pr\'ogl"amming style as ch.ill\'f!d hy\n\n~1arr\n\n[1978], or\n\nwhether they lead to inherently clHfcl\'ent algori thros than\nsequential methods, and if so, which are more appropriate to\n\nuLic;;h types of\n\ntD.<1k~).\n\nThel\'e arc often several t.ypes of i.nformet:i.on available in\nportions of a vision task.\n\nFor example, depth informat:l.on can be\n\nobtained stereoscopically and by means of various monocular\ncll\\o~;.\n\nAlso, infot\'ruB Uon obtai.ned from a sense e)f touch or from\n\nothc:l" lnfol"lTlat.ion in an intelligent robot may be available, in\n\nadd:!.t.ion to vlsion.\n\nMeans of\' combining such diffel\'ent. types of\n\ninfOl."mCit!on need to ba expla\'oo.\nI\n\nAt. the lower levels, rola}caUon\n\npro?esses such as advocated by Bal\'l"ow and Tenenbaum [1981 J may be\nappl\'cpl\xc2\xb7iate.\n\nAt the higher levels,\n\n"blnckboBI\'d"\n\n(~l\n\ncent.l\'al\n\none possibility is the\n\ncomfUunication\n\nmedium\n\nfor\n\nthe\n\nrepresentation of hypotheses l partial solutions, and pending\nact.ivi UesJ\n\napP1~oach\n\nusea in the Hearsay speech-understanding and\n\nkno\\~ledge-based exp0r~\n\nsystems (Reddy .tlt. .ill. [1973J, Erman.e.t.a.1"\n\n[1980J, and Balzer .Qi.El.. [1980].)\nOnce a strategy is chose n for the above general issues, the\n\n10-4\n\nQuustion remains as to what particular metbods should be used in\neach casc.\n\nThis is a problem at all levels,\n\nparticularJ.y \\vide open at the high levels.\n\nbut it is\n\nIndeed,\n\nat the\n\nhighest levels vision merges into the rest of the field of\n81\'tifil;)iaJ intelligence.\n\nThLls the question or how high-level\n\nprocess1ng should work cannot be limited to vision only but is\npart of the problem of how any high-level processIng might be\ndone no matter what StlllSory mechanisms an intelligent machine\npossesses.\nAnother issue concerns means for the vision system to learn\nobject models by being shown the objects and to be taught object.\nmodels by means of a convenient use!\' interface.\n\nAn even more\n\ndJ.fficul t pI\'oblem is the learning and teaching of generic types\n(for example, learning the concept or a chail\' by being ShOHn\nexamples of ohait\'s).\n\nA I\'clat.ed issue is how to make the system\n\nversatile by having i t programmable at a very high level.\nIt is possible that research in vision would be greatly\nhelped by the availability of a very-high-Ievel programming\nj\n\nlanguage especially designed for vision.\n\nVery little has been\n\n(Iione along this Hne.\nFilially, the type of hardware to be used is impor\'\n\n1\\\n\nspecific question in this regard is how much parallelism alid what\nkind of paralltJlism should be used.\nd~scussed\n\n(Some of the options were\n\nin Section 9.)\n\nA JPL vision system that can be developed in the next few\nyears must operate in a restricted\n\n~omain,\n\nbecause of the limited\n\nadvancement cf the state of art of computer vis10n that can be\nexpected in thrt time.\n\nIt is expected that the system will be\n\n(Ulpable\n\nrecognizing and tracl:.l.ng p perhaps :I.U roal time,\n\nI)f\n\n()bjoots tl\'mt\n\nCt"XI\n\nkno~m\n\nbe modelled by t.he composition of a few oillple\n\ngeometrical shapes.\n\nTlH~\n\nobject,\'3 can be se,l.ected fJ."oKil a\n\nreasonably large set of possible objects and can have arbitrary\n1:.hrae-diillek1s1nal position and m\'ientation.\nnot necessarily achievable until\ncould be\n\npresent~\n\nluter~\n\n!t is des.ll\'able f\n\nbut\n\nthat multiple objects\n\nsome partiRlly obsouring others.\n\nIt ruay be\n\nneoessary in somEl cases at f\'il\'Si:; to have objects identif\'lod by\n\nme:ans of specia). colors or lllal\'kinss,\nt:a\'ught by the UMH"\'p\n\nvisl-on.\n\nThe\n\n\'fhe object\n\nrnodel~\n\n"an be\n\npOI\'haps ca.n be lecU\'l"led by mEl/.ms of\n\nand\n\nvision system Hill produce data 13ult.able for\n\ngrasptng and l1\'IanipuJ.at.:tng objetlts.\n\nIn order to make the above capabiU.ty ach.ievablc,\nhardw\'al~e\n\nThe camet\'as should hm!e ~~t least 240\n\nw11l be requil\'ed.\n\nnon-intElrlaced\n\xe2\x82\xac\'Quivalel\'1t\n(light~bit\n\nlin8s of vertical rsaolutioD and roughly\n\nhorizontal resolution\n\nQf\'\n\nmonoclll\'omatio pictursf3,\n\nc:apablHt.y should be available.\nbe used,\n\n(H~i"tain\n\nThey should\n\nbette!\'.\nlAnd\n\np~\'od\\lcO\n\nsome sort of color\n\n3i110(3 stf;;reoscoplc vision w111\n\nat leas t two cameras are \xc2\xa5\'aqu:ll"od.\n\nThe cameras O\'3I1Duld\n\nbe l1lount.l;)d on a s!lJoothly\'\xc2\xbboperating pan-t.ilt head equ:tpped with\nPNlClso position\n\nen{loders.\n\nSpeoial hardware for performing some low-level vis10n\noperations at high speed should be availablo. Tbis would be\nsiroilal\' to the present H1FEX but p1.\'Obably mueh moroe pOHerful and\nversatile.\nIn ordor\' to pel\'fol\'m the t\'emainlng computatiol1 at or\' neaI\'\nreal\n\ntime,\n\neither an extremely powerful prooessor or many\n\npI\'oeessors will be needed.\nmainframe computel\'.\nmicroproce~lSOl\'S\n\ncrossbar), and\n\nIi\n\n000 possibility is a roul Uprocessor\n\nAnother possibility\n\noperating in\n\npa:rall~\'l\n\nsingle-processor mainframe\n\n10-6\n\nis a\n\nfelr! hundred\n\n(perhaps conn\xc2\xb7oeted by a\ncomput~~r.\n\nIt remains\n\nI~O\n\nbe seen what combination Hill produce the most computing for\n\nthe money.\n\nIn any case sufficient memol\'Y will be needed to\n\nstOl~C\n\nlarge pr\'ogratns and many images at various st.ages of processing at\n\none tin\\e.\n\nA large on-line disk storage system will be needed for\neonvenifmt storage of programs, images, and other data.\n\nGood\n\nprogramming pract.ice t\'equires that progratns be tested on stored\n:tmages, so that reproducible results can be obtained.\nInteractive graphics display taroinals will be needed for\nth(1 usep interface, so that info;:\'Dlat:l.on concerning opjcct models\n\ncan easily be entered and intermediate results of computations\nc~an\n\nbe displayed.\nA system such as described above will allow significant\n\ncontributions to the state of the art of computer vision to be\nmade at JPL, and will allow the development of techniques that\nNASA Hill find useful in the future use of robots in space.\n\n10-7\n\nREFE.1ENCES\n\nThe following abbreviations for a\nconference proceedings arc used:\n\nfe~\n\njournals and\n\nAI\n\nArt.ificial Intelligence\n\nCGIP\n\nComputer Graphics and Imr<ge Pt\'orcssing\n\nCACM\n\nCommt\'nications of .the Association for Computing\nMachinery\n\nJACM\n\nJournal of the Association for Computing Hachincry\n\nT-C\n\nIEEE Transactions on Computers\n\nT~PAMI\n\nIEEE Transactions on Pattern Analysis and Machino\nIntelligence\n\n1AAAI\n\nFirst Annual National Conference on Artificial\nIntelligence, The American Association for Artificial\nIntelligence, Stanford University, August 1980\nSecond International Joint Conference on Pattern\nRecognition, Copenhagen, August 197 Jj\n\n3ICPR\n\nThird International Joint Conference on Pattern\nRecognition, San Diego p Novembel\' 1976\n\nlllCPR\n\nFourt.h International .Ioint Confez\'enoc on Pattern\nRecognition, Tokyo, Novcm ber\' 1978\n\n~;;rCPR\n\nF:l.fth International Conference on Pattern Recognition,\nMiaruj. Beach, December 1980\n\n~!IJCAI\n\nSecond International Joint Conference on Artificial\nIntel.ligence, London, Septem ber\' 1971\n\n3:IJCAI\n\nThird International Joint Conference on Artificial\nIntelligence, Stanford University, August 1973\n\n4IJCAI\n\nFourth International Joiut ConfercncA on Artifio1al\nIntelligence, \'fbilisi USSR, Sept em bel" 19\'(5\n\n5IJCAI\n\nFifth International Joint Conference on Artificial\nInte.lligence, Cambridge, Mass., August 1977\n\n6IJCAI\n\nSixth International Joint Conference on Artificial\nIntelligence, Tokyo, August 1979\n\nR-1\n\n,,..,~"",\',\'."\n\n~,~ .~,\n\n.\xe2\x80\xa2..\n\n,~ggarllal \xe2\x80\xa2 \xe2\x80\xa27.K q\nDuda~ R.O., ~md\n.c.~:C 11.ru:.!l~~ J.J\\ ~tm .AMJ.:t.r:J\';\\.[~,1\n\nHcnenfd(t,\n\nA. (cds.) [1977J \xe2\x80\xa2\n\nJl.!:EE P";;::~;s & Hiley.\n\nAgin, G.J. nnd D,1nford p T.O. (19 (3/. "Comp,,:\\;<l:J!\' Descpiptlona of\nV\n\nCurved Object!3,tI 3LL(,JU:,\n\npp. G2!H5 1-10.\n\n11.gln, G.J. und Duda, R.O. (197\'5J.\niVSRI Vil,lion Research for\nIl d van C \xe2\x82\xacI d Aut oma ti 0 n, I~ .fuw.v...nU J!\':\';l.A:::.Ilfi,1W.Jl .G9l11Dll.tJ\\U! ,!;.Q~.nCJ1.,\n"i[\'okyo, August 19\'{5, pp. 113-117.\n\nIlH, H., Mar\'Un, H.N., and Agsal"ual, J.K. [197 9]. "Color-Ba.sed\nComputer Analysis of Aerial PhotOgl\'Qphs,1Y ,r:;.\\:JJ~ 9, pp. 282-293.\n}.rnold, H.D. [19\'(8). "Local Cc.mtoxt :in Hat.ch,1.ns; ::::dges fOl\' Stm\'oo\nVil3ion," in Rr~;.d1ng~ ]..!J.u"\'J.~ JLr~<llilX:\':lj::~llruLi,~, 11..2.E:1~R, Defcnoe\nAdvanced nassar\'oll Pr\'oject,s Ago~lCJI\'r Cambridgt" Hass., May 1978\n(Science Applications, Ino., Hopo!\'!; No. 8AI-\'19\'~7!!9-tH,), pp. 65-\n\n7\'2.\nH. [1980 J. flTbree-Dimenl3ional Scone llnaly sls, 11 5lJ.lP.J1, pp.\n1964-1074.\n\nEiajC3 y,\n\nEiaker, H.ll. [1977].\n61\n19-655.\n\nI\'IThl"ee-Dil1lcnsional\n\nHodellil1g~W\n\n\'s\'l.J..CJJ., PP.\n\nH.H. (1980]. "Edge Based Star\'eo CO!:\'A\'el.\'ltio!1~\'~ In\nJ..ml:.r,l;,(t jLuri1il2::~J,(.QJ:1./;ttrllq;, MS\'...r.l\xc2\xa3J.J,h.9..!2, D e f 0 n s e Ad van c e d\nIieseal\'ch Projects l\\.g,!)l1cYr Balt.:l.!llol"\'!!1 April 19f30 f pp. 168.,.175.\n\nBaker,\n\n~J:.Cl.r,,!ili;tl..tiKl\xc2\xa31.,Q.t\n\nBal1ca\'d g\n\nD.H.,\n\nBrOtHl,\n\nC.M.,\n\n"Hld Feldman,\n\n,1.,Ii..\n\nApproach to Knot~ledGc \xe2\x80\xa2\xe2\x80\xa2 D:lr\xc2\xb7eGted Image Aflt\',ly\'si8$\'1\nlUs0l1lan [1978a], pp. ,~71~\'28l.\n\n[1978J.\n\n"An\n\nill Hanson and\n\nBalz~,r, :R., Erman, LeD., London, P., and Wi1liruos, C. [1980].\n\'tHear<3ay\xc2\xb7\xc2\xb7III: A Domain-Independent l."ramcwor\xc2\xb7k for Expert\n\nSystems,"\n\nJAW, pp. 108-110.\n\nBarnes, G.H., Bro\'lm, R.M., Kato r H., Kuck, J)"J., Slotn:J.ck, D.1..&\nand Stt)kos, fl.A. [1968J. "Th13 ILLltiC IV CQwputer,"l..-:::..c.\npp.\n\nn,\n\n71~6-757.\n\nBarrot.. p !i.a., Ambler\', !l.P., and Burstall, H.N. [1972]. I1Some\nr 3chrl1.ques for\' Recogniz:tne; Structures in PictUl"0t1," in E.!:Ql~..m\nj\n\n.Q.t: l\'.AW..r..n ..IlM,Q.\\Ul.;lS.1Clh S. Wat.anabe (ed.), Academ.1c Pres s~ pp. 129. (Also in Aggal\'i1ul ..ill 11l. (19TrJ,\n\npp.\n\nBi:trrO\\>1, H.C\',. and Tenenbaum, J.M. [19\'78].\n\n397\'~425.)\nI~HecoV(H\xc2\xb7.1..ng\n\nIntrinsio\n\nScene Chnracter1stics from Imuges,11 in Bam3011 and Hi,seman\n[1978aJ, pp. 3-26.\n\nBarrow, H.G., and Tenonbaum, J.I1. [1980 l.\n\n"Intel\'pret:!.ng Lin6\n\nDrawings .as Three-Dimensional Surfaces,!l lJtA,A.;!:, pp. 11- 14.\nfl-2\n\nBar\'f\'OW, HoG. a.nct Tenenbaum, J.M. [1981 J. "Computational Vi:3ion,"\n.nf. .t.l:lft ~J;;~ 69, pp. ,72-595.\n\n\xc2\xa3.r~&l1;l.rt~\'l\n\nBinford, T.O., Brooks, R.A.,and Lowe, D.G. [1980].\nUnderstullding Via Geometric Models," .5.I.W, pp. 364-369.\nBlUIiJ,\n\nH.\n\nri96\'rJ.\n\n"A Transformation for Extracl;ing New\n\nin ..M.oJi!;>J..a !fl.r: ..tJ)Jl j~~..t.1rul. Sit. ~eM .aru1\nJ:\'ru:..m, W. Wathen-Dunn (ed.)p MIT P!\'ess. (Also in Aggarwal\n\nDescdpt;ors of\n,.v:.~:t.\n\n"Image\n\nShl~pe,n\n\n.JiLt..al.. (1917], pp.\n\n153~171.)\n\nBobrow, D.~ and Winograd, T. [1977]. "An Overview of KRL, a\nKnowledge Heprestlntatlon Languagc,li .G.rur..u.ll1.v.e. ~ 1; pp. 3116.\n\n:Bo11es, R.C. [1976]. "Ver:!.ficaUon\xc2\xb7 V:tsion l\'lithln a Pl\'\'Ogt\'ammable\nAssembly Systom,iI AIH-295, STAN-CS-77-591, CoruputerScience\nDept., Stanford University.\nBolles, R.C. [1980].\n\nIiLocaUl1g PF.u-tially Visible Obje(\'ts: The\n\nLocal Feature Focus Hethod," .1.8JJ.AI., pp.\n\n4l-1~3.\n\nBrady, J .\xe2\x80\xa2 M. and tViel:i.ngfl, 8.J. (1978]. "Reading the Writing\nthe viall," in Hanson and Hiseman [19\'r8a], pp. 283~301.\n\n011\n\nBrice, C.R. and Fennema, C.L. [1970]. "Scene Analysis Using\nHeg1ons," JJ. 1, pp. 205\xc2\xb7 226. (Also. in Aggarwal.f:\'....t..al. [1977], pp.\n\'l\'9-100.)\nw\n\nBrook.s, H.Ii. and Binford, 1\'.0. [1980]. "rnterpl\'etive Vis5.on and\nRestrtction Gra;>hs." .lAMI, pp. 21\xc2\xb7\xc2\xb727.\n\nBrool~8, H.A., Greiner, R., and Binford, 1\'.0. [1979]. "The ACRONYM\nModei~Based Vision Sy~.tern," UreAl, pp. 105-113.\nBrooks, T.l.. [1980]. "Supel\'visory Nanipulation Based on the\nConcepts of Absolute vs. Relative and Fixed V~. Hoving Tasks,"\n\'\xc2\xa3\'~...1..u~.ll. Sl!. .tllit lWL:m!J.<;!"Q12f.t.l .QJ\'.nm..JJ.t&J:: l\'.er..luJ,QlQ.G\'..Y .G.ruIJ\':fl~p\nsponsored by ASME, San Francisco, August 1980, pp. 185-196.\n\nBurr, D.J" and Chien, R.T. [19T7J. fiJI System for Stereo Computer\nV:lsion with Geome tric ~lodels," .5.LLC.Al., p. 583.\nCarterette, E.C. and Friedman, H.P. (cds.) [1975).\nV~, Academj.c Press.\n\n~.Q.!\n\n.Ellr..c\xc2\xa3tDjd..Qll, Vol.\n\nCederberg, H.L.T. [1978J. "An Iterative Algorithm for Angle\nDeLee tior! on Digital Curves, fI E...\'tCRll, pp. 576-,578.\n\nChien, R.T. and Jones, V.C. [1975].\nI\'IAoquisitjon of li9ving\nObjects and Hand-eye Coordination,il .!l.lJ..W. pp. 737-,\'741.\n\nR-3\n\nClo~!es, f>i.B.\nDavi8~\n\n[1971].\n\nt. [1975].\n\n"On Seeing\n\nThitl~l\';,11\n\nA! 2, pp. 79-116.\n\nITA SUl:"\'I~Y c:f Edge Detection techniqucs,fI .cJ.i1\xc2\xa3\n\nAI t pp. 248-270.\nDuda., R.O. and Hnrt, P.E. [1972].\n\n"Use of the Hough Transform to\n\nDetect 1.1nes and Curves in Pictures,w.Q.A.G.M 15, pp. 11~15. (Al::;o\n\nin\n\nAggal~wal\n\n.e.t..al. (1977), pp. 204-208.)\n\nDuda, R.O. and Hart, P.E. [1973J \xe2\x80\xa2 .f\xc2\xa3.lJJLru:.n .R.!i.G..~ \xc2\xa3Jl.Q. ~Si\nWiley.\n\n.Anal:wa,\n\nDuff, M.J.B. [1978]. "A User\'s Look at Parallel Prooessing,"\npp. 1 072-1 075.\n\n,U,c.e;a,\n\nEberlein, R.B. [1976]. "An Iterative Gradient Edge Deteo\'Cion\nAlgolrithm,lf\n\n~\n\n5 f pp.\n\n2J~5-253.\n\nErma.n, L.D., Hayes~Roth, F., Lesser, V.R. p and Reddy, D.R.\n[1980].\n"The Hearsay.~II Speech-Understanding System:\nIntegrating Knowledge to Resolve Uncertainty," .Q.Q~,1.n~ .SJ.ir..\'li~\n12, pp. 213-253.\nEskcnazi, R. and t1 i l f D J.M. [\'197 9]. "LON-Level Processing for\nFleal\xc2\xb7\xc2\xb7time Image Analysis," JPL Report 79-79.\nFalk, G. [1972].\nThre(~~\xc2\xb7Dilllensional\n\n"Interpretation of Imperfect Line Data as a\nScene," Al3, pp. 101-144.\n\nFaugeras, 0.0. [1980]D\n"An Optlmization Approach for Using\nContElxtual Information in ComputeX\' Vision," .lAA.U, pp. 56-60.\nFenmlma, C.l.. and Thompson p vl.B. [1979].\xc2\xb7 "Velocity Determination\nin Soenes Containing Several Hoving Objeots~!I !:.rill 9, PP. 30i315.\nFischler, M.A. and Elschlager, R.A. [1973]. "The Representation\nand Hatching of Plotorlal St.rllctul <ls." ~ 22, PP. 67\xc2\xb7\xc2\xb792. (Also\nin Aggarwal.lU<..r.J.. [1977], PP. 31-56).\nFram f J.R. and Deutsch, E.S. [1976 J. "On the Evalua tion of Edge\nDetection Schemes and Their Comparison with Human\nPerformance," .I::.C. 21.1, PP. 616..;628.\nr~reelUan,\n\nH.\n\n[197 1\n1].\n\nImages," ,C&mput,J,nz.\n\n"Computer Processing of Line-Dra"ling\nPP. 57-97.\n\n~ll 6~\n\nFreeman, H. and Davis, L. [1977]. !fA Corner-Finding Algorithm\nfor Chain-Coded Curves," .I.::.C. 26, PP. 297-303.\n\nFrei, W. and Chen, C.-C. [19TlJ. If Fast Boundary Detection:\nGeneralizaUon and a New Algol\'ith.tn," 1.:::L~ 26. pp. 988-998.\nFreuder, E.C. [1980].\n\nA\n\n"Information Needed to Label a Scene,"\n\nlAltAl.t pp. 18-20.\nPu, LS. and Swain, P.H. (196?j.\nliOn Syntactic Pattern\nRe cogn i.t ion, II in 1?.Q.f..t\\iE.r.~ En\xc2\xa3\xc2\xa31.11?2!tr..itUI. J. T. Tou (ed.). ACed em i c\nP N\' S s, p p. 1 55 -1 82. ( A1 S 0 in P. gg a i\' Wa 1. .\xc2\xa7..t. ~j,., [1 97 7 ], p p. 369-\n\n396.)\nFukushima, K. [1975]. "Cognitron: A S-a1f-Or\xc2\xb7g.,nizing Multilayered\nNtJul\'al Netwock,lI 13J.2..l..oJIj..Q.2.l .c.\'l12.,t,U:.!1Sl1~ 20, PP.121\xc2\xb7\xc2\xb7126.\nFukushima, K. and Miyake, S. [1980],\n"Neocognitpon: SelfOrganizing Net\'lor!< Capable of P()sition-Invariant Recognition of\nPatterns," .s.J;J;.PJl, pp. J~59-lj63.\nFunt, n.v. [1977]. "Whisper: A Problem-Solving System Utilizing\nDiagrams and a Parallel ProccBaing Retina," !U.JE.f.\\..1. pp. 1\n159- 1\n164.\nGanapathy, S. [19\xc2\xb7{5J.\n"Reconstruction of Scenes Containing\nPolyhedra from Stereo Pairs of Views,n AIM-272i Computer Science\nDept., StanfOl"d University.\nGenn()ry. D.B. (1980]. "Nodelling the Environment of an Exploring\nVehicle by Means of Stereo Vision," AIM-339, STAN-CS-BO-B05,\nComputer\' Science Dept., Stanford Univer<lity.\nGilbert, A.L q Giles, H.K., F\'lachs, G.H" Rogers, !LB., and U,\nY.H. [1930]. ItA lieal~Titlle Video Tracking System," :r..::.RA.al 2, pp.\n47-56.\n\nA.L. (1979]. "The Peroeption of Surface Blacks and\nWhites,n ~.lll..i[;LQ. luD~r..;I..Jl.arJ. 240, No.3, pp. 1 i2-121~t (March\n1979) \xe2\x80\xa2\n\nGil~hrist.\n\nGolay, I1.J.E. (1969). "Hexagonal Par~:!l.lel Pattern\nTransformations," ~ 18, pp. ,(33\xc2\xb7\xc2\xb77 l ,O. (Also in Aggarwal et M.\n[19TrJ, pP. 172-179.)\nGraham" C.H. (ed.) [1965J.\n\nJ!i.JJ1...Q.11 iLllQ\xe2\x80\xa2\n\n.Y.1.2.!~ hr.:.QQPtj,OD,\n\nWiley.\n\nGrape, G.R., [1973J.\n"Hodel Based (Intel\'mediate Level) Computel\'\nVision," AIM-201, Computer Science Dept., Stanford Universit~\n\nGl\'11\'1\'io, M.D., Cunningham, n.:!\'., and Eskenazi, R. [1978J.\nnVision-Ba3ed Guidance of an Automated Roving Vehicle," paper 78129 1j, ~edings IlllVi .Q.!dl.sL~J..ru;&. .i-\\n.ii .G_Q.n1J::Q..l S&DfeL!l~, 1\'a10\nAlto, August 1978.\n\nR-5\n\n(\n\nGl\'im30n, W.E.L. and 11a1"r-, D. [1979]. "A Computer Implementation\nof a Theor\'y of Human rtareo Vislon," in \xc2\xa3LQ.\xc2\xa3SJllL;\\Jlg.~ ~\n~.r.OilJianQ..1.!.1&. J:LmlL\\L9.JL. Defellse Advanced Research Projects\nAgency, Palo Alto, April 1979, pp. 41-47.\nGuzman, A. [\'1968]. I\'IDecomposition of a Visual Soene into ThreeDimensional Bodies," in l.\'LQ.QQ.<;l.\xc2\xa3lj,.lll:lli. Qf A~ ~~"LU .J.Qlpt ,~~\n,I&DJ:!Jr~n.~_ 33, Dec. 1968, pp. 291-30 1 (Also in Aggarwal at $.1..\n\xe2\x80\xa2\xe2\x80\xa2\n[19T(], pp. 324-33".)\n\nHannah, M.J. [1974]. "Computer Matching of Areas in Stereo\nImages," &IM-239, Computer Science Dept., Stanford University.\nHanson, l.R .. and Riseroan, E.M. (cds.) [1978a] \xe2\x80\xa2.Q,f2..mll.\\~1..0J: lis191l\nAc\xc2\xa3\\delllic Press.\n\n.slli\'~illliS,\n\nHan~lon, A.R. and Riseman, E.H. [1978b).\n"Segmentation of Natural\nScenes s " in Hanson and Riseman [1978a], pp. 129-163.\n\nHartson, A.R. and Rissman, E.M. [1978c]. "VISIONS: A Computer\nSystem for lnterpreting Scenes,1I in Hanson and Hiseman [1978a],\npp. 303-333.\nHaralick, R.M. [1978]. "Statistical and Structural Approaches to\n!U.l2fll., pp. 45-69.\n\n~ext,u.re,n\n\nHit-zinger, G. and Snyder, W. [1980 ] \xe2\x80\xa2. "Analysis of Time-Varying\nImager,), for Tracking Moving Objects," . .rJ:Q..Q.!;~ .Qf. . the\nl~ltt.:i\xc2\xa3L\\fJ.t.;LQJ!nl .c_Q.I\'!ill.lJ.!&.r. ls\',.e hnol.Q&Y kQ1).fe.r:Q.l.lQ\xc2\xa7., sponsored by ASH E,\nSan Franci3co, August 1980, pp. 26-33.\nHOl\'n, B.. K.P. [19\'(4]. "Determining Lightness from An Image,1\'1 .Qiill\'..\n3, pp. 277\xc2\xb7,299.\nHorn, B.K,P. [1975). "Obtaining Shape from Shading Information,"\nin 1Hnston [1975a], pp. 115-155.\nHorn, B.K.P. [1917). "Understanding Image Intensities," I I 8, pp.\n201-231.\nHorowitz, S.L. and Pavlidis, T. [1974]. "Picture Seglllentatio\'n by\na Directed Split-and-Heloge Procedure,lt~, pp. 424-433. (Also\nin Aggal\'wal llM. [\'1977], pp.\n101\xc2\xb7\xc2\xb7110.)\nHough, P.V.C. (1962). "Method and Means for Recogniz:Lllg Complex\nPat.tern::!," U.S. Paten t 3,069,654.\nHueckel, H.B. [1971], "An Operator Hhi,ch Locates Edges in\nDigHized Pictures," J..\'i..Q.M. 18. pp.113-125. (Also in Aggarwal II\naJ.... [1977]" pp. 191-203.)\n\nR-6\n\nHueckel, M.H. [1973J. "1 Local Visual Operator Which\nEdges and Lines;" .sULQ.M 20, pp. 634-6W(.\n\nR3cognizes\n\nHuffman, D.Il. [1971].\n"Impo.sslble Objects as Nonsense\nSentenC\xe2\x82\xaclS," in M~Qb:!\'lJe J;Jl.\\(QlJ..igence .6., B. Heltzel\' and D. Michie\n(cds.)" Halsted Pr>33s, pp. 295-323. (Also in Aggarwal .~ ll.\n[19\'77], pp. 338~366.)\n\nHummel, B.A. and Zucker, S.W. [1980]. "On the Foundations of\nHelaxat;ion Labelling Processes," .5..lQJ2.B.\xe2\x80\xa2 pp. 50=53.\nInokuchi, S. and Nevatia, R. [1980].\nill.fii, pp. 1301-1303.\n\nqBoundary Detection in\n\nRa.nglD Pictures,"\n\nJohnson, E.T. and Goforth, L.J. [1974).\n"Hetaphase Spread\nDeteet.i.on and Focus Using Closed Circuit \'I\'elevision,iI .Tl1~ ~J,.\ns,\'.i:. l1L&tQ~b.wJJ.il\'.Y. \xc2\xa3llil. .Qx.t...Q.9.ll\xc2\xa71~ 22, pp. 536 - 5115.\nJ u 1. e 8 :~,\n\n11.\n\n[1 9 7 1 ]. J::..QJ,alL<L~ .Q.fG \'[9 .J. 0 ~.11\n\nr.e r\n\nQ\n\ne ~ll,\n\nUniversity of Chicago Press.\nKanada,\n\nT. [1978]. "Region Segmentation:\n\nSignal\n\nV8,\n\nSemantlcs,n\n\n11l..cJ:Il., pp. 95\xc2\xb7\xc2\xb7 105.\nKelly, M.D. [1971].\n\n"Edge Detection in Pictures by Computer\n.6., B. N e It z e l\' and\n(A180 in Aggal\'l<al\n\xc2\xa3lJi..U. (1977], pp. 228-244.)\nUis 5. n g Pl an:" i ng ," in .li.i:!Q.h.lllSl. .1l.lt_tl~L1J?;.QrL~\nD.Michie (cds.), Halsted Pl\'ess, pp. 397\xc2\xb7~409.\n\nKrLlse, B. and !\'lao, C.V.K. [1978J. ,,/\\ Matched Filtering Technique\nfO!\xc2\xb0 COJ\'ner Detection, ti lli.\xc2\xa3.!l, pp. 642-644.\nLand, E.H. [1971].\nJ.h.~\n\n"Lightness and ReUnex Tht:lory,1i ll:.ru:lr.llil.l Qf.\nAm.~.rl.Q.a 6\', p p. 1- 1 1.\n\nQQJ<...w.l. .fu?JU-.Q.U. P..i..\n\nLeviner M.D \xe2\x80\xa2. [1978]. "A Knowledge-Based Computer Vision\nin Hanson and Riseman [1978a], pp. 335-352.\nLevine, M.D., O\'Handley, D.A., and Yagi, G.H. [1973].\nDet.ermination of Depth Maps." .QiU.\xc2\xa3. 2, pp. 131- 150.\n\nSysteru,~\n\n"Computer\n\nLewis, R.A. and Johnston, A.H. [1977].\n"A Scanning Laser\nRangefinder fOl~ a Robotic Vehicle," ill~.l, pp. 762-768.\nMarl\', D. [1978J. "Representing Visual Information,\xc2\xab in Hanson and\nRiseman (1978a], pp. 61~\xc2\xb780.\nMarl\', D. and Hildreth, E. (1979]. "Theory of Edge Detection," AI\nMemo No. 518, Artificial Intelligence Laboratory,\nMass.\nInstitute of Technology, April 1979.\n\n11-7\n\nMarr, D. Bnd rDagio, T. [1976].\nJ.i~12&Jl!-..~ 1911~\n\nStoreo D.i.Bp<\'wHy 1 !l\n\n"An Application of U(;Urit.lti<l Search Methods\n\n!1artelU., fa. [197Gl.\n\nto Edge\n\nf.oihQ\n\nAggn!\'wf>,\xc2\xb7 ~j;,\nr<!I.H\'tln~\n\nGontour\' Dot,(\'lCticHl,l1 .QA.CJl\n,~.. [\'19\'77) , 1)p. 2 W \xc2\xb7\xc2\xb7221\'.)\n\nB.~L\n\nand AggarHal 1\n\nt-4cCormicl~,\n\nB.H.\n\n(1963J.\n\nrLLIAC II!jtt\n\ntHlgrBnle\n\nD.L.\n\nDescription~" .c.s~u:.1;.\n\nJ.K.\n\n\'.1),\n\npp. 73-83. (Alao\n\n[19\'[3].\n\n1.0\n\n"Dynamic Sc(we\n\n356~1111.\n\nAnall\'sis,".Q.G,U.1, pp.\nGOl:lpl\\t~.\n\n\xc2\xb7Co0peratlve Computation of\npp. 233-281.\n\n!~~.\n\n11Th/) HUnoin Pattorll Recognition\n12, pp. 791\xc2\xb7\xc2\xb7813.\n\nf,19\'l9J. nConstru(!tirlg\n11 p 13&~99.\n\nT:"H3fl\n\nfor\n\nRegion\n\nMilgram, D,L. an\\1 Bjorklund, C.H. [1980].\nWHango Image\nProcess:!.r.,;: Planal\' SUE\'faca Extraction p " 5~, pp. 912-\xc2\xb7919.\ntHnsky,\n\nM. [19\'75J. ,,;\\ FramaHork fOI\' Flepr\xe2\x82\xac!l3011t1ng Knol<11edgc," in\n\nWinston [19758], pp. 211-217.\n\nHOl"llvec, H.P. [1979]. IIFully Intorconnoc:t.illg t1ultlplo Computers\nl>Jitll Pipelti1&(\\ Sort.irt(,> Net:l/\' I:::.Q.28, pp. 19:\')-793.\n"lor&"eo, H.!!. [1980]" !lO!i::\'ltacJ.e P,volcw.nc\\?I and Naviga.tion in the\nReal World by ... Sew:l.ng Robot n(.,vm\', <l AH~"34C, STJH~~Gs\xc2\xb7.80-8Df\nCompllt(H~\n\n~lod$\n\nSciG\\1.ce\n\nDcpt.~\n\nX_, K:l.dc,do,\n\nH.~\n\n~\xc2\xb7tanfo!"d\n\nUnivef\'s1ty.\n\nand Asada,\n\nPrediction anti COl\'t"6ct;lon Method for\n~J:. 2, pp. 393- !I(l 1.\n\nNagel, H.-H. [19\'(8].\n.!1.1;J;Jill t PP, 1136 - 2 1 1.\n\nH.\n\n[~9\'n].\n\nI\'[\\n\n\nIterati.vo\n\nlH!t.~~ll:tic ~tt1r\'eoCOl!\'ip(H"i:\'JoYlII\'\n\ntfAnalY3is Techniques\n\nfCl\'\n\nImage Sequences,"\n\nNeumann, B. (1978). "Int.erpretat.ion of Ii!l:~f\'ect Object\nfor Ident.ifio,~tion and \'l\'r\'acking,1I .~ill.B., a:lJ\'. 691-693.\n\nNevat.ia. R. [1976J. i1Dupth Measltr\'6ment by a\\:otion S\\~or~o,"\nP\':o 203-214.\n\nContot!r~\n\n\xc2\xa3oll 5,\n\nUevatia, 11. (19771. rtf! Color Edge Detec\xc2\xb7;tlM" and Ita Use in Scene\nSegmentation,1I .:rJ\';J;;1~ Ir.i.J.Jl:w.gJJ.Q!1,;!. illl :iY.at&lll:\xc2\xa7t~ kUill. lMl~ !;YJ?~J,,1,mt\n\'r, pp. 320\xc2\xb7\xc2\xb7826.\nNevat\'"a, R. and Babu, K.R. (1979). I\'ILlnear l\\\'eature Extl\'<.lct.ion\nDescription," .fi.llffiU, pp. 639-641.\n\na.~d\n\nNevatia, R. a.ud B1r.1\'oI"6, T.O. [19l7\'1lJi. IVDescription and\nRcc:ogn1t.i.on of Cur\'veo Obj~t:t5," Al. 8, p~. \'117-98.\n\nR-8\n\nr1ni+~~~~~~~rr:l~\xc2\xb7~~~~~:0~\'}r~~\'~~~t~~i?~~\\;;).!f\xc2\xb7,%~~1~\'*:\xc2\xa3,~;~~8Z~~!~~~~~:J~:~fmw,~~;~~~~;~:~+~\\~%-rr.;~;?{f~F\';\'J~??~~~r:rt;~:.~0?J!:?~t[?~~~r.~~,~~~~~;\xc2\xb7,~;~\xc2\xb7\xc2\xb7:~:\':,\n\xe2\x80\xa2\xe2\x80\xa2 ""\n\nNevatla, R. And Price, K. [1978],\nImages," m~, pp. 686-f90.\nN11 S :; 0 n \xe2\x80\xa2 N\xe2\x80\xa2 J \xe2\x80\xa2 [1 9 80 ] \xe2\x80\xa2\n\n"Locating Structures in Acrial\n\nfA~...lQUJ;lj,JtJ1 91.\n\ntU\' t it\' 1 ~ 1 a.l l.!:!..t&JJ...t..\xc2\xa7UlJl.(;;tQ.,\n\nTiosa Publishing Co.\nNitzan, D., Brain, II.E., and Duda, n.o. (1977). "The 11easuI\'oment\nand Use of fleg\'.~)torod Reflectance and Ranga Data in S0snc\nAnl\\lyals,ll Er.!l~,,,qru1.1.n.rul .Qi .tJlil l..EIili. 65, pp. 201J-2;?O.\nN!.t:.1..r.II, D" Roson, C., Agin, G" Bolles, R., Glca:lOo, G., Hill,\nJ., McGhie, D., Pl\'ajoulC, R., Pnrk, Wq Ilnd Swot\'d, A. [\'1979].\n"Muohine Intelligence Hasaarch Ap~l1od to Industrial Automatioll K\n9th Report, SRI International, August 1979.\n\nNI.\\dd, a.fI., Fouso, S.D., NU3smchlr, T.A .. Hnd Nyg\':H~rd, {J.A.\n[1979]. "Developmpnt of Custom-Designed Integratod C1rouit9 for\nImago lIndor3tl.!.nding," in Nev\'ltia, R. and Saw o !1\\.ic!,. II.A.,\n~Samiannual technical Report," USCIPI Naport 910, ImBge\nProcessing Irwtltut0, Univorsity of Southern Callfol\'nia, Sept.\n1979: pp. 120-1\'t5.\nOhll\'lnder, R., Price, Yo., and Reddy, D.R. (1978].\nIIpictI.J.I\'0\nSegmllntnt!oli Using a lll\'3cursl\\lo Region splitt.ing l1otIJod," .Q.\\ilJ: 8,\npp. 313-333.\nOhta, Y., Kanadll, T., and SaKai, T. [1978]. \' "An Analysi/) SYBt\',~m\nfor Scanes Contail~ing ObjeC\'t\' \\<lith Substl\'uoturo8," lU.Q.rll, PI\'.\n752-\'154.\nOtau,\n\nN.\n\n(1978).\n\nSeleotion\'"~i\n\n~DiscriminBnt\n\npp,\n\nPavlidis, T. [1977].\nVerlag.\n\nand Loast Squares Throshold\n\n592-596.\n~ ~ ~.lUlt,!l., Springol\'-\n\nPavlidi8, T. [1978J. HA Review of Algorithms for Shape AnalYSis,"\n.Q..Q..\'U. \'(, pp. 243- 2 58.\n\nPorkjns, W.A. [1978).\n"A Model-Based Vision Syst.om for\nIndustrial PSl\'ts,"H 27, pp. 126-1/l3.\nPerkins,\n\nW.A. and Binford, T.6. [1973].\n\nVisual Feedhaclc," A1H-,214,\nDept" Stanfol\'d University.\nPingle, I<,K. and Tenenbuum,\nFoUowl\'lI\',r, 2..L!.lli. pp. l-\'f.\n\n"A ~ornel\' Finder\n\nS\'1\'A~-CS-73-386,\n\nJ.H.,\n\n11-9\n\nr 1971].\n\nf(F\n\nComputer Science\n\n"An Accomruodati.ng Edge\n\n, \xe2\x80\xa2\xe2\x80\xa2 " .. :. \xe2\x80\xa2\xe2\x80\xa2\xe2\x80\xa2 ;,-\'! \xe2\x80\xa2\xe2\x80\xa2 ; .....\'.,:.~\\,:~\n\nPinkn~y. IL~\'.L. [1978]. ll\'l\'IH10f\'Y nnd iltlVclopm8!lt. (..)1\' lHl On-Lina 30\nHz Video PhotogrBmmetry System for neal-Time 3-D1manmional\nContt\'ol,11 \xc2\xa3J.:9..9Sl..{UU.JlLl1!. ill:. J.Jl~ l,St ~JSJi.(;1~.1.\\ll;;! .Qll. 11!.u.ii5W.JlliV,9..sll"t\'s. X.si.J:.\nl!JSll.i..li.tl:l:, Stoo!(holl:il, lWkjul.lt 19\'{5.\n\n[1976]. I~ChlJ.n(l;6 Dutelot.ion and fl0l~ly8is in 11ulti-\n\nPf\'io{), 1\\,\n\nSpectral Imuges," Ph.D. TheSiS,\n\nCarn~Bi8-HellD~\n\nUniversity.\n\nn\'Hldy, D.H., ErrnR1l1 L.n., Fennoll, R.D., fw(1 Neoloy, R.B. [1973J.\n"The IItliu\'tHi.Y Spetlloh Undt}I\'Btallding Syst;(H"l; An gy,8rnplo of tho\nlIeoognition Pr\'OOtlM,"\n\n.lL.tJ.;;.U, pp.\n\n185~193.\n\nHoddy. D.n. and Bon, NoW. [19\'f91. I\'JCou.putar AI\'ohitoot.\\1I\'08 (01\'\nVi 3.1 0 n I If in f&.llllW.J.: lU-..U1m luui .s..ru~a.l;l.tlJI.rt. .ilQ WA, G. O. Dod d\nand L. Rossol (ods.), Pltmuill ProBs, pp. 169-11l6.\n\nflisemnn, E,M. and Ar\'bib, M.A. [19\'l7 1. I\'IComput.e,t;!onnl Toohniqu~3\nin t.ho Vi,lUlll Sogmentllt.ioll of Statio SCOrHH:l f I7 ~l.!l? 6, pp. 221-\n\n276.\n\nRoachl J.W. and l\\gt~iu\'wal, J.!~. [19\'79J. ~lCot1pu::\'(lr Tr~okine; of\nObject3 Moving in Space," I.::J:\'ll.,tU. 1, pp. 127~135.\nRebel\'ts, L.G. [~965]. Mt1nchillo PfJ:\'t:Hilptl,(H\\ of \'I\'!u\'(l,j~nit!le!l~ional\nSo 11 d s \xe2\x80\xa2 \\I .;. n .QJU,.J.uRl I:tll,s,i. .l~lD.Rt.rj}.:::.op,j;, i,9J\\tl j"D.tllfLW,\\;j,k!.L\\ 2J..:s.l.(LflJ:lli.iU[.-l.,\nJ.T. TippoI\'. .lil..k nJ.\xe2\x80\xa2 (lids.), tUT fir\'eso. pp. 159-19\'/\'. (Al"~o in\nAge;ar\'~I[lJ .9.1 .tAl. [19\'(\'71, pp. 2t)5~323.)\n\nRosonbtH"g, L\'" 1..\'.\\111n6, N.D., and ZUClH)!\', S.H. (19\'{I3J. flComptltin~\nRolatho [)epth HehUonohip3 fl\'OU! OOOlUS10il GU00,11 !U~hi~,li, pp.\n\n\'{65-769.\nRosQnfeld,\n\nA.\n\n[\\9693.\n\n~llrull.tHM ..:L~\n\nIIPtotUI\'f:l Procetuling by Computer\',VI\n\n1, pp. 11\n17-1\'{6.\n\nRosonfold, A. [19\'12].\n\n"Plot-tire Pr\'oceaslng: 1972,\'1 !;.QJ...f. 1. pp.\n\n394-4 HI,\nRoe(mf\'~\'ld,\n\nA. (19\'[3]. "Progrl\'l33 inPioture Processing, 1969-71,1\'1\n!;, PP. 61-108.\n\n~JAQ..~,~J,U:_Y..ftL\'l.\n\nRosflnfeld, A. (l9\'rll\n\nJ.\n\n"Picturl) t\'I\'ooesslng: 19\'{ 3." s;Jlll\'. 3, pp.\n\n178-\'194.\nROS(Hlfold, A. [19\xc2\xb71~;;]. ilPi()t~Ir\'G f\'r\'o~H}s!:\'line;:\n\n197 /4," .cLUJ?, 4, pp.\n\n133-155,\nHotltmft}ld, A.\n\n215-231.\n\n[19\'76).\n\n"PiotIU\'O PI\'OOE!S3ing: 19\'[5," .c.\xc2\xa3JJJ:. 5, pp.\n\nR-10\n\nIlostlnfeld, It. (1,\'771. I\xc2\xb7Piet.Ul\'O P:"ocoMiing: 1976,11\n157-183.\nRoser~feld,\n\n~\n\n6, pp.\n\nA. [1978,,,). "Piotur\'o i\'I\'O(lIHlslng: 19\xc2\xb717,".G.Qll 7, PP.\n\n2i 1-242.\nRosenfeld, A. [1978b]. "Relaxallon I-lethoda in Imago\nand Anulyal.3,11 mRJ.l, pp. 181-185.\nI\\oscnt\'old, A. [1979;;;).\n\nI\'IP1et.~ro\n\nProc(la~ing\n\nPI\'oc(,ssing: 1970, 11 .G.ruJ: 9, pp.\n\n3?1l~393.\n\nRos~m{\'eldr\n\nA. (1980a]. "1\'lcture Pr"OC63s!ng: 19\'1\'1," k\xc2\xa3lll 13, pp.\n\n46-\'/9.\nRO\'Jenfeld, A. [198Gb]. i\'Qua.dtrl\'Jes and Pyramid;;l for Pat torn\nR(Jcognition and Imago Processing," 5l.W, pp. 802\xc2\xb7\xc2\xb7811.\n\nRosenfeld, fl.. (1981). 17Pict.ul\'s Proce;3sing:\n\n1geO~I\'.c.!U1.\n\n16, pp.\n\n~2-89.\n\nRosenf{;)ld, A. and H(~3Zk(l, J\',S. (1975J. flAn It,pro\',;~d Hlilt-hod of\nAngle Detection :I n Digital CUI\'ves, n 1& 24, pP. 940,\xc2\xb794 \\.\n\nRoUtt S,D. (1978). \'~SttH\'eo 3 .. D Ih.n"C\'option for n Robot," Ph.D.\nThe81fl. ea l11\'orniu InBt Hute of Technology.\n\nSamet, H. Bnd Rosenfeld, A. [1980].\nBinary lnla.gc3," .!il.C.~1l, pp. 815~8i8.\n\n"Qu~dtrae\n\nRepresentation of\n\nSaund, E" G~mnerYI D.B., and Cunninghalll, R.T. [1981]. I1IViSUlll\nTra c Ie i liB inS t er flO," J..Q.tn.t. lU.Ll9..1\'1!l.t..tQ. .i&.1JJ..J:.QJ. ~\xc2\xa321ILQL~lHL~ t\nsponsored by ASHE, University of Virgjn1a, June 1981.\nS{~haeft\\r,\n\nD.H. [19130J. "NASA End-lo-End Data Syst.em Ha!:l3ivcly\nParallel Proce~sor.~ internal memo, Computer Development Section,\nGoddard Spaoe Flight Center, Groenbelt, Nd., May 30, 1930.\nShapiro,\n\nSUI\'vey,l!\n\nL.G. [1979].\n\n"j)atD. St.ructllros for PictUl\'0 Proc(lssing: A\n\n!:\'Qlll1. pp. 162-184.\n\nJ.D., ~1IJlgC\'ankal\', P.G., and Hnralick,\n0 s, and 810 b s: A \'fin\' e e - Di III e n al 0 n a 1\nObject Rept\'osentation for Scene Analysis," J.l1AAl., pp. 28-30.\n\nShapil\'o, L.G.,\nR. H ., [1 980 ) \xe2\x80\xa2\n\n~lot\'iarty,\n\nIts ti c k:;l.\n\n1\'11.1 t\n\nShaw, G.B, (1979). "Local and Rog.ional Edgo Detector8: Some\nComparisons," .G.Illl 9, pp. 135-1119.\nShir\'at, Y. (19\'75]. "Analyzing Intl\\n3Hy IH\'t\'ays Using Knowledge\nAb()~t ScenCtl," in \\>limlt-on (19\'{SIl], pp. 93-114.\n\nH-11\n\nShirai, Y. [1978a]. "Rscent\npp. 66-94.\n\nAdvano~s\n\n1n 3-D Scono Analysia,n\n\nllW,\n\nShirai., 1. [197Gb). "Racognitillll of R0/},1-World Objects Using Edge\n\nCue," 1n Hanson and DiDoman [19780.], pp. 353-362.\nStefanelli, R. and ROBonfald, A. (1971). "8orno Parullel Thinning\nAlgorithms for Digital P.i.ctures," AIAQi 18, pp. 255-26 1\n1.\nSwan,\n\nR.,\n\nFuller,\n\nS.,\n\nand\n\n816W101\'6k,\n\nModul.ar, MuHi-IUcl"0Pl\'OCf)":lor," liruJ,.9.ruU.\npp. 637-644.\n\nD.\n\n[1977]. "CmE! -- A\n\ns.;s~ .l&jl~\n\n46,\n\nTanimoto r S.L. and Pavlldls, T. [1975). "A Hierarchical Data\nStructu/\'e for Pidm\'<) i?roc0ssj.ng," ~ II, pp. 104-\' 19.\nTenenbaum, J.M. and Burrow, H.G. (1976]. "IGS: A Paradigm folr\'\nInt.egrating Image SGgmantation and Intol\'pretation," .ll.C.PJl, p1\'.\n504-513. (Also in 1l[~I.H\'Nal .!l.t.. 1M-. [197\'rJ, pp. 435- 1\n11111.)\nTtl!\'ltlnbaul!l, J.H., BIH\'I\'OW, iI.G., and Bolles, R.C. [1979j.\nIlProspocts fot\' Incust.r\'ial Vitlion," in .c..QJ;!iJ21J1\xc2\xa3\xc2\xa3. .\'l.1tLiQJ! W, ";;fJn"?~u::::\nPJiAW.J! .M.Q.QJ:..D., G.G. Dodd Ilnd L. Hossol (eda.), Plenum Pr4HHl, pp.\n\n239-259.\nTsugawn. S.p Yatab\xe2\x82\xaclf\' T., Hirose, Tq and HatslllllotO. S. [1979].\n"An Auto[ilobile with hr\'tUtcla} Intolligence," illJ111, pp. 893"\'\n\n895.\nUhr, L. (1972]. "Layeri.~d \'Recognition Cone t N\'Jtworiul\nPI\'aCH\'ocoSS, ClassHy, and Descr!bo,1I .I.~ 21, pp. "58~768.\n\nthat\n\nUhr, L. (1978). tiiRo,~ozn1tion Conos,\' and SOlne Test Results; the\nImminent Arrival of Well\xc2\xb7"Structul~ed Parallel\xc2\xb7\xc2\xb7Serial Computorsj\nPOSitions, and P08ition~ on POSitions," in Hanson and Hiaoman\n[19788), IlP. 363-3\',\'{.\nUllman,\n\nS. [19791.\n\nLocal Processcs,H\n\nIIReluxo.tion and Constrained Optimization by\n10, pp. 115-1~5.\n\n~,~\n\nUnder\'Hood, S.ft., and Coatas, C.L, [1975]. "Visual Loarning f,\'orn\n\nMultiple View3," I:::.C. 24, pp \xe2\x80\xa2. 651-661.\n\nVamos, \'f" Bathor\', H., and Hero, L. (1979J. "A Knowledge-Based\nInteractive Robot-Vision SY8tem," UJ.kAl, pp. 920-922.\nVanderBrug, a.J., Albus, J.S., and Uarkmeyer, E. r 1919). "\'A\nVialon System fOt\' Real Time Centrol of 1l0bOt.,:1," .9.tlll11!&.r.lli!.1.1.Qfu11\n.s.yJl\'~ 2ft ~.t.r.lilJ.. l!.Q1l.Qtli.\xe2\x80\xa2 Washington, March 1979, pp. 213;~32\n\n\xe2\x80\xa2\n\nH-12\n\nWaltz, D. [1915]. 1l1lnd{H\'standing Line DI\'IHling:; of SoonotJ uith\nin tHnst.(ln (19758], pp. 19-91.\n\nStJl).d()~13,"\n\nHur\'d, H.R., Rontqol, L\'I Holland, S,H., anti D.Hlnr, R. [1919J.\n"CONS1GII\'l\': A i\'r\'aclic.ml Vision-f)lI::Ied rlouot GIJ:ldr..ilCI.l Syst."m," !llh\nlD.W\'l.CD.(;\\..UQ.n.U J;i.\'lIlUI.$.lll1y.ru illl lJ1illL1.i<J::j,lll 11.QhQJ\'1l, t~ 8 5 II i ng ton, M r<~ h\na\n1979, pp. \\9~;-212,\nWochsler\', II. find f3klansky, ,J. [197\'lL tlFinding the Rib Cag" jn\nChest llad!ogr\'aplH!," ,l\'1lt..1&r11 .Rfl.i.<.QJ\'J.J.ilJ..Q.!l 9, pp. 21\'~30.\nW(1<lloy, M.A., Lozallo-Por\'(Jz. Toe Liebol\'mUrl, L.L, Lavin, [\xc2\xb71.lI., and\nGr\'oSSrnIAn,. D.O. (1950), riA GtiOlJJ0tr\'!c Nodeling Syst.tHU for Automutlld\n\nl\'iecil<llli.cal Assembly," .J.l,3li\n\nJLillll:..~!V. Qf. rl.2\xc2\xa3L~h\'\\t.Qll\n\nilll!.!.lli2.Yill.Q1?)?l.mlt 2 1\n1,\n\npp. 6 11-74.\nMeRl.ka , J.S. [1978].\n";A Survey of Thre~;hold\n\'fechnj,QlICls," 1:.cu..\xc2\xa3. \'f I pp. 259,\xc2\xb7265.\n\nSeleotlon\n\nwilt\', ,I. and Cunnin3111Hllp II. (1979). "Computing Rtlgion Homenttl\nI" J PI. Publication 19- 1\n19.\n\nfrolll Bounctal\'Y RtlPI\'~l:Hl!lta Uons\n\nW!naton,\n\nP.11.\n\n(ed.) [197 ~ia].\n\n.l:.I\'m .f..iilXMJ,.Q.t1..<,lKll. .21\n\n.G!2J~\'\\1.IJ.t!il,r. .V...j~~Jm,\n\nNeGI\'Ul<J"liill.\n\nWlnatOll, P.Ii. (1975b].\'IILesrnlng Structural Desoriptions from\nr~lWlllpll\'N,\'f\n\nin \\Hnst.ml [19\'15a], Pl>.\n\n1~i7~209.\n\nWoodham, R.J. [19Tf].\niiA COopcl"Lltille Algorithm fOl\' Dotel\'IDlning\nSUI\'fact) Or\'i<mtation t\'1\'om a Sinele Vi.e~i,1l 5"lJ.GJU, pp. 635\xc2\xb7\xc2\xb76!11.\n\nWoodham, R.J. [1979a].\nIlAllf:llyzing Clll\'Vt)d SlId\'neo:; U:-ling\nll~fleet!lncH Map Tochnique::!," in .Ar..t.U:.ir.t,,\\;;})~ l.J.itKLl,U1UlD.Q..Q.: 1m\n~J::.nltQ.QJJ.j\xc2\xa3Q. P.H. WiMtoll and R.B. BI\'OHIl \xc2\xab~ds,), NIT (11\'0133, pp.\n\ntu:r\n\n161-182.\nWoodham, R.J. [1979b]. nRelating PI\'opel\'ties of SUl\'face CUl\'vatul\'c\nt.o Image Intensity,li ,fJJ..J..C_Al, pp. 9\'{1-9H.\n\nWul!\', W. Hnd noll, e,G. [t9\'T2].\n"C.mmp _ .. a Multl-HiniProc ICS$(J!\'," in .\xc2\xa3.r.g\'\\\'~i:.l!.gi,ll!l.\xc2\xa7. Q!. lruJ. f:JAll .t.!.Q1.{11 .\\&1tJJIJJ.1.\xc2\xa3)X, kILQ[9J.:QiW..2.\nlil 11, rp. \'756-\'77\'[.\nYuohhla, M., lI<odo, H., and Tsuji, S. [19\'70,],\n"II Knowledge\nDir\'oettid Lino Find{H\' for\' I\\llalysi:~ of Complex Sounea," .QJ..J\'\xc2\xa3Al, pp.\n\n98 1\n1-991.\nYakimov!,ky,\nEx lor\'uo l.i ng\n\nY.\n\nand Cunningham,\n\nR. l1978J.\n"A SystElffi fOl\'\nmens:! ona 1 HellSlJI\'CI1l01l t:l fl\'Co:!! a Stel\'oo Pall\' of\n\'l, pp. 195~ \'" 1 O.\n\nThl\xc2\xb7t)e~l)i\n\nTV Camtlt\'n~,\n\nIf\n\n.Q.G1J~,\n\nR-13\n\nInkimovsky, Y. and FeldAan, J.A. [1973]. "A SsoBntic8-BaBod\nDeclsion \'rb",or\'~r flogton ,f,naJ.)!zor,rl ,1IJJl!.J.l., pp. 580-583. (I,loo in\nIIggapwal \xc2\xa3it.. JU. (1977 J, pp. 1426- 113i.!.)\nYal\'illlovakji\', Y., Rayfield, H., and Eskenazi, R. (1976].\n\n"RAPID\n\nv.\n\nA Random AacGas Picture Digitizer, Display, Bnd Memory Syatem,W\nJPL TM 33-\'1\'72,\n\nYllmarl!oto,\n\nH.\n\n(1979).\n\ntil\\. f\xc2\xb7tot.l1od\n\nof Deriving CompatibUHy\n\nCooffic:!.entrJ fol\' Holil;v.ntimi Operat~or\'sl \\\'l ~lC. 10. pp. 256-271.\nZuckej~,\n\nS.H.\n\n[19\'1\'6e-.].\n\nIlRegion\n\nGrowing:\n\nChlldhood and\n\nMolasoemH),1i .Q.GJR ~j! pp. 382 399.\na\n\nZlIck.sf\', S.\\]\' [19\'{6b .i. 11Helaxation Labelling and the Reduction of\nLoonl. Amoir;uHios,1\'I .3JJ.}.lm, PII. 852-861. (AlBO in Aggarwal 1Th ;:11,..\n[19\'f7], pp. 445- 1154,)\nZucker, S.W. [19781. IlVertic;al and Horizontal Processes 1n Lmc1\nLevd Vision," ill 118,03011 and Risemarl (19\'f8a.J, pp. HI7 \xc2\xb7195.\nw\n\nR-111\n\nEnd of Document\n\n'