b'(NASA-CR-199563) C MODIS, SeaWIFS,\nAND PATHFINDER FUNDED ACTIVITIES!\nSemiannual Report (Miami Univ.)\n42 p\n\nN96-13372\nUnclas\nG3/61\n\n0073755\n\nNASA-CR-199563\n\n/flJ\n\nMODIS SEMIANNUAL REPORT\n- JULY 1995 UNIVERSITY OF MIAMI\nRSMAS/MPO\nDR. ROBERT H. EVANS\nNAS5-31362\nDue to the interlocking nature of a number of projects, this and\nsubsequent reports will contain coding to reflect the funding source.\nModis funded activities are designated with an M, SeaWIFS with an\nS_, and Pathfinder with a P. There are several major sections within\nthis report; Database, client/server, matchup database, and DSP\nsupport.\n\nA.\nB.\nC.\nD.\n\nNEAR TERM OBJECTIVES\nOVERVIEW OF CURRENT PROGRESS\nFUTURE ACTIVITIES\nPROBLEMS\n\nA. NEAR TERM OBJECTIVES\nA.I Modis Objectives (\n\nM)\n\nA. 1.1.\nContinue to develop and expand the processing\nenvironment\na. increase computational efficiency through concurrent\noperations\nb. determine and apply more efficient methods of data\navailability for processes\nA. 1.2. Begin extensive testing using global CZCS and AVHRR GAC\ndata with database processing to test the following:\na. algorithm capability\nb. machine and operating system stability\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\nc. functionality required for the processing and analysis\nenvironment\n\nA.2 SeaWIFS Objectives (\n\nSI\n\nA.2.1. Continue testing of processing methodology.\nA.2.2.\nContinue to develop relationship between database and insitu environment.\nA.2.3. Continue to expand the in-situ database.\n\nA.3 Pathfinder Objectives (\n\nP)\n\nA.3.1. Expand matchup database as applicable.\nA.3.2. Continue testing of methodology.\nA.3.3 Train and integrate new personnel into Matchup Database\nprocessing scheme.\n\nA.4 DSP Objectives (\n\nM)\n\nA.4.1. Continue testing of processing methodology.\nA.4.2. Continue to expand the number of sites supported.\nA.4.3. Expand the supported hardware/software platforms\n\nB. OVERVIEW OF CURRENT PROGRESS\nB.I Automatic Processing Database (\n\nP)\n\nB. 1.1 Operational Testing\nB 1.1.1 January Operational Testing\nJanuary Operational Processing\nData for 1991 is now available on our new digital tape library. A\nlarge number of new pieces of equipment have been added to the\nprocessing environment, and the processing slowed while these were\nintegrated into the processing.\nA new 4-processor DEC 2100 computer was tested as the primary\nprocessor, but numerous problems were encountered. Near the end\nof the month, the processing was returned to the single-processor\nalphas.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\nB. 1.1.2 February Operational Testing\nProcessing continued on the 1991 time period, but was slow due to\nsever disk and interface problems.\nB. 1.1.3 March Operational Testing\nProcessing continued in the 91 time range, covering 91160-91250,\nusing the yearly coefficients for the atmospheric correction. This\ncovered, for the first time, the post-Pinetubo time period. This\nprocessing stream was terminated when it became clear that the\nyearly coefficients were not producing acceptable results for this\nperiod.\nProcessing was discontinued on Modis, the DEC 2100, when it became\nclear that disk controller problems were severe, and would not allow\ncontinuous use during the processing. Processing was returned to\nfour single-processor Alphas.\nTwo more single-processor alphas were added to the stable of\nmachines processing orbits, totaling six. Subsequently, the pace of\nthe processing increased.\nThe time period 91001-91166 was recalculated, using the new\ntechnique of monthly coefficients for the atmospheric correction step.\nB.I. 1.4 April Operational Testing\nThe new, monthly coefficient method was continued extending last\nmonth\'s 91001-91166 out to 91305. At this point, the coefficients\nwere changed, and the time period 91150-920450 was calculated.\nAfter another change, 91001-91200 was again rerun.\nB.I. 1.5 May Operational Testing\nEquipment problems were quite severe until a disk reorganization\nnear the end of the month, which alleviated most of the disruptive\neffects.\nDuring the month, a new, 3-SST algorithm was implemented (see\nMay Development). Days 91001-91324 were calculated.\nB.I.1.6 June Operational Testing\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\nUsing the new processing scheme, (implemented early in June), the\npf3 files (3-SST estimates per file) continued, calculating days 91325\nthrough 93222, or nearly two years for the month.\nB.I.2 Development\nB.I.2.1 January Development.\nThere were numerous changes, both small and large, to accommodate\nthe new equipment, which included a 4-processor Sable computer, a\ndigital tape library (used both for spooling input data and backup of\noutput files), and a large amount of new disks.\nHowever, the increase in capabilities also caused a commensurate\nincrease in system problems. In particular, the problems previously\nencountered with "drop out" of NFS-mounted disks became\nuntenable when Modis was used for processing. The most damaging\npoint was the *.sh and *.dsp files that are written by the VMS\nAPServer and read by the UNIX processor. While there had\npreviously been occasional dropout at this point., this step was\nfailing 3-5% of the time. A new technique was implemented,\nwhereby the APServer writes the *.sh/*.dsp files to a local disk,\nrshells a job to the processing computer, which transfers the\ncommand files to one of its local disks. This method did overcome\nthe problems at this step.\nSince the input data files will now be supplied by the DLT device\n(digital tape library) on UNIX, a number of new procedures and\ncommand files were developed to spool the data off, and copy it to\nthe VMS side.\nAs we develop experience with the new paradigm, more changes will\nbe needed. For example, modifications will be needed to eliminate\nthe need to copy the input file to the VMS disks. Currently, the\nGETSCAN program extracts the scan lines of the pole crossings, and\nstores this information in a flat file containing information for a\nwhole year for a given satellite. This scan line information is then\nextracted from the flat file by the ADDREC program, which decides\nthe pieces to be processed, using the asc/dsc pole crossings, and a set\nof rules for piece size. This information is used to add the processing\nrecords to the database.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\nWe are developing a version of GETSCAN that combines elements of\nboth the current GETSCAN and ADDREC. It uses the pole crossing\ninformation to find the scan lines of the pole crossings, breaks the\npass up into a few pieces, and writes an ingester input file for each\npiece.\nTo fuse the two systems, changes will need to be made to GETSCAN\nand to ADDREC. Much of the functionality, exclusive of the actual\nrecord addition, must be moved to GETSCAN, to eliminate the need\nfor a copy of the input file. These include\nExtracting the exact ingester name corresponding to a scan line.\nIncorporating the full set of rules to define orbit segments.\nExtract any other information from the datafile that is needed.\nWhile the list is small, the information is not so easily defined. We\nwill need to examine ADDREC to select only those programs sections\nthat are currently needed.\nCurrently, the presence of the input file starts the GETSCAN/ADDREC\nprocess. We will have the new GETSCAN put out one ASCH file that\ncontains the information needed for record addition. This file will be\nrcp\'d to the VMS input directory where its appearance will start the\nADDREC process. This file will be used by a new _VERY_ streamlined\nversion of ADDREC to add the processing records to the database.\nSummary:\nCurrent\n\nDevelopment Fused\n\nread asc/dsc file ^GETSCAN GETSCAN GETSCAN\nfind scan lines of pole crossings\nV\nGETSCAN GETSCAN GETSCAN\nfind filename of that scan line\nV\nGETSCAN GETSCAN\nstore sen In/flnm of pole crossing\nGETSCAN\nread sen In/flnm pole crossing info\nADDREC\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\ndecide on pieces to be created\nADDREC\n\nGETSCAN GETSCAN\n\nstore information on pieces\nGETSCAN\n\nGETSCAN\n\nread information on pieces\nADDREC\nadd records to db\n\nADDREC\n\nThese changes will be implemented in the next few months.\nB.I.2.2 February Development\nMost development work in this time period still related to the\nintegration of the new equipment, and modifying the processing\nmethods to both make best advantage of the new capabilities and to\novercome problems.\nProcessing this month continued on the 4-processor Sable, Modis, but\nmany more adjustments were needed.\nFile transfers using rep were becoming unreliable, therefore the code\nand command files will need to be changed to use ftp for file\ntransfer.\nA major revision of the command files and procedures is in progress.\nThese will be covered in the next month\'s report, when they are\ncomplete.\nB.I.2.3 March Development.\nAll file transfer was changed from rep call to ftp.\nThere has been considerable consolidation and shortening of\ncommands.\nMany of the commands can be issued from any computer - i.e., even\nchecking and control of the server status can be done from UNIX.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\nThere used to be a large number of single-use command files - many\nof these (but not all) have been consolidated into single command\nfiles that interpret input parameters. These changes will be covered\nin a separate section.\n\nThe new system will not seem much different. The major differences\nOPERATIONALLY are changes in the daily and weekly job triggering,\nchanges in some directories, and changes in how mcp is started.\n\nMCP:\nThe old need for different mcp binaries for each job type has\n(finally) been eliminated. A single mcp is used, and the \'psa\'\ncommand has been modified to show the command line in the ps\ngrid, showing which job type is being run.\nThe mcp-t job, which ran the recipe called GAC_PTB, has been\nchanged to reflect its function - it is now mcp/orbit, and the recipe\nname is GAC_ORBIT.\nPreviously, there were separate files to start each job or combination\nof jobs (starti, startul, startust, etc.). There is now one \'start\'\ncommand file that takes a single parameter, the type of jog or jobs to\nstart. Currently, the choices are:\nSingle: i, ul, si, o, d, w\nCombined: uso - ul, si & o\nus -ul &sl\nThe start command file can be rsh\'ed to the machine you want to\nstart from andrew. I do not have comparable versions of the files\nlike startenu, startkel, startall and loadenul, etc.\nDIRECTORIES\nThe pass_time and asc/dsc files are now in a directory pointed to by\nap_etc, instead of mcp_etc. The ap_autoproc_computer_##.sh .dsp\nand .rpt files, as well as the data transfer files for the record adder\nnow go into dsp_usr2:[ap.tmp.alexis]. (Or in\ndsp_usr2:[ap.tmp.mariah] for the mariah system).\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\nDAILY/WEEKLY TRIGGERING\nPreviously, when all passes for a given yearday were done, the daily\njob for two days before was triggered. This permitted daily jobs to\nrun before all passes for that day were processed, causing stray\norbits to pop up at times.\nThe new triggering is:\nWhen each orbit is done, the server checks to see if that day is\ncomplete. If not, no\ntriggering occurs. If so, then:\nThree day periods are checked to see if a daily job is ready.\nFor example, say day n\nhas just been completed:\nCheck if day n-1 is done. If so, check if day n-2 is done. If n,\nn-1 and n-2 are done, trigger daily for n-1.\nCheck if day n+1 is done. If so, check if day n+2 is done. If n,\nn+1 and n+2 are done, trigger daily for n+1.\nDays n-1 and n+1 were checked. If n-1, n and n+1 are all done,\ntrigger daily for day n.\nWeekly:\nWhen a daily job completes, the server checks to see if all days of\nthat week are done. If so, the weeklyl job is triggered.\nWhen the weeklyl job is done, the server checks to see if the\nprevious and next weeks are done. If so, the weekly2 job is\ntriggered.\nCompletion of the weekly2 job triggers the weekly 3 job, which is\nallowed to run only on the alpha servicing the vol set for that week.\nCompletion of the weekly 3 job triggers the weekly4 job.\nVMS Commands\nThe old way to start the VMS batch jobs has been shortened a bit.\nThe old \'@ap_com:submit_apserver\' command has been replaced by a\nsimple \'apserver1.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n8\n\nAll the new commands to start UNIX are:\n$ apserver(was: @ap_com:submit_apserver)\n$ addrecgac(was: @ap_com:submit_addrecgac)\n$ getscangac(was: @ap_com:submit_getscangac)\n$ fixscangac(was: @ap_com:submit_fixscangac)\n$ mvgetscan(was: @ap_com:submit_mvgetscan)\nAlso as before, the MCP control is in the dbrequest_* and run_*\nlogicals, with the DBREQUEST_STATUS controlling the mcps from all\nprocessing machines., and the RUN_abrv controlling the mcps from a\nsingle machine (i.e., RUN_KEL controls KELSO).\nHowever, now a single command file can manipulate both the\ndbrequest_* and run_* logicals. It is \'mcp.com\'. If you type only\n\'mcp\', the current run parameters are listed. If you type \'mcp ?\' a\nshort explanation is printed. To change the global value, input the\nchange as the first input parameter. (To stop mcp\'s , type \'mcp stop\'.\nTo change the values for only one computer, use \'mcp option\ncomputer\'. You can use either the full computer name or an\n"accepted" abbreviation. (The "accepted abbreviations are listed in\nthe db loading file ap_dbdef:computer_load.sql. This file can be found\nAFTER invoking the home:ap_build.com command file, which defines\nthe directories for the db and server.)\nFor checking the db records, there are still a number of *.sql files\nthat can be used inside SQL, or are called by a DCL command file.\nHowever, they are all called by a single command file, ck.com, which\nalso has a symbol defined, therefore from ANY directory, you simple\ninvoke ck and input a parameter. This ck command file first checks\nto see if the parameter is one of its "known" commands. If it is, ck\ncalls the right command file in SQL. If the input parameter is not\nrecognized as a command, it is assumed to be the name or\nabbreviation of a computer, and the jobs assigned to that computer\nare checked. The queries that are recognized are:\nMAINLESfK (can input a main_link, or be prompted)\nDAILY\nDSPA\nINIT\nORBIT\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n9\n\nORBIN (BOTH ORBIT AND INIT)\nSUB\nHSUB\nUNF\nWEEKLY\nWEEKLYlorWl\nWEEKLY2orW2\nWEEKLY3orW3\nWEEKLY4orW4\nFOURWK orFW\nWEEKLYSUB\nNote that the MAINLINK query can take a main_link as the second\ninput parameter, but that ck prompts for it if omitted from the\ncommand line.\nVMS/UNIX CROSSOVER\nBoth mcp and ck can be issued from any UNIX machine, as well as on\nthe VMS server. The "mcp" command is just passed directly to the\nserver machine. However, there are a number of "ck"-type\ncommands that are also performed on the UNIX side, and these are\ntried first, then the ck command is passed to the VMS server if the\nUNIX command file doesn\'t recognize the input parameter.\nUNIX Commands\nThis leads to the UNIX command files. First, they no longer reside in\nthe ap directory, they are now in a /usr/dsp/com2 directory (just as\nthe executables are in /usr/dsp/bin2).\nThe pathgac* , *ingest* and rcp_control.sh files are used by the\nprocessing, not interactively. The ap.defs files just sets up the\nenvironmental variables for the processing. That leaves just three\nfiles:\nexa - runs the full examin on an image (to retrieved full\nheader)\nstart - starts the processing on various machines\nck - performs various kinds of checks\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n10\n\nThe start command file should take two parameters: the type or\ntypes of mcps to start, and the computer to start them on. The\nremote start is not quite working. The type(s) of mcps to start are:\nul\nwl\nu2\nus\n3uso\n\nsi\no\ni\nd\nw2 w3 w4 fw ew\nu3 u4 s2\nuso ii iii\n4uso 4u2so usoii usoiii\n\nthe ck command file checks for a number of options to check on the\nUNIX side. If the command is not recognized as one it knows, it\npasses the whole command line to the VMS side.\nProcessing Overview\nThe input dataset consists of a stream of datafiles representing\n(roughly) orbits of a satellite. As the satellite moves forward, its\nsensor scans left and right, recording two scans per second (for GAC)\nThe satellite orbits the earth in about 100 minutes. Each orbit is\nrecorded on tape recorders that provide an approximate 5 minute\noverlap between the end of one recording and the initiation of the\nnext. This overlap needs to be identified and eliminated from the\nresulting products.\nAfter about 14 orbits, the earth has rotated once (i.e., one day has\npassed). This means that the satellite has taken data over the entire\nearth TWICE, once on an ascending (south to north) leg and once on a\ndescending (north to south) leg. For the NOAA polar orbiters, the\nascending leg corresponds to daytime and the descending to night.\nOn the archive device, these data files are stored in increments of a\nyearday (the first five digits of the filename), and the various jobs\nthat store, retrieve and access the data are usually organized in the\nmanner. To date, this has been the most convenient arrangement,\nwith one day\'s worth of data fitting comfortably on the staging disks\nwhile still "occupying" the processing streams.\nThe processing scheme can be though of as addressing a number of\ntasks, which can be sorted into characteristic time and/or space\nscales, and the tasks or tasks that must occur at each of these scales,\nand the order in which they must occur. Each level has a dominant\nscale, but that scale may be either temporal or spatial or both.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n11\n\nIn the AVHRR GAC processing, the tasks and their dominant scales\nare\nTask Increment Components\n1. Spooling data: yearday 14 orbits\n2. Autoproc entry: orbit self-contained\n3. Ingest/atmospheric corr: orbit->6 pieces @ 2400 scan lines\n4. Spacebin: each orbit segment\n5. Orbit: construct from orbit segments\n6. Daily: 3 yeardays!4 +2 orbits for data day\n7. Weekly 1: 1 week <- 7 daily files\n8. Weekly2: 3 weeks <- 3 weekly files\n9. Weekly3: 1 week <- weekly reference file\n10. Weekly4: 1 week <- cloud-masked files\n1. Spooling data: This job acts as a daemon, checking to see if files\nare needed, and that disk space is available. If so, it copies one day\'s\nwork of files from one device to another. Most of the spooling jobs\nare submitted once and recycle in increments of one day.\n2. Autoproc entry: This job notifies the db that a data file exists and\nis ready for processing. It deals with a single file at a time.\n3,4,5. Ingest/atcor and spacebin: These jobs work on individual\npieces from a single orbit file. They can be thought of as a set of\ntasks that must be performed in sequence to a single piece. We need\nto separate the tasks so that parallelism occurs, that is, one piece is\nbeing ingested while the last piece that was ingested is being atm.\ncorrected, and the piece just corrected is being spacebinned. (See\nshort section later for explanation of each of these steps.)\n6. Orbit: When all pieces of an orbit file have been finished (through\nspacebinning) a job is run that gathers the pieces into single files for\ntransfer to a remote disk. This consolidation produces (usually) one\nascending and one descending file for the given orbit, plus POSSIBLY\na third file with data to be included in either the previous or next\nday. (Orbit segments that cross the 180\xc2\xb0\nmeridian will produce\nresults for adjacent "data-days").\n7. Weekly 1: When all seven days of a give week have been created,\nthe ascending and descending data are combined into weekly asc and\ndsc files.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n12\n\n8. Weekly2: When the weekly files for three weeks in succession\nhave been created, these are combined into 3-week asc and dsc files,\nand these files are run through a gap-filler. These are called the asc\nand dsc reference files for the middle week of that three-week\nperiod.\n9. Weekly 3 & 4: After the reference files for a given week have\nbeen produced, these are used to cloud-mask each daily file for that\nweek (asc ref used on asc dailys, dsc on dsc dailys). The cloudmasked daily files are then recombined into cloud-masked weekly\nfiles, and a large number of product files are extracted from the daily\nand weekly declouded files.\nIngest/AtCor/SpaceBin: Ingest refers to the process of extracting a\npart of an input orbit and storing it in a dsp-format file, including the\nnavigation format the orbit file itself. After ingest, a series of\nprocedures is run on the ingested file to apply various corrections to\nthe navigation (this is called the sector process, which is actually a\nseries of processes). No new file is produced in the sector process.\nThe atmospheric correction part takes the initial data (radiance in\nfive different frequency bands) arid produces an SST estimate at\neach point in the input ingest file. These files are still at the 4 km\nresolution, and are in what is called "satellite perspective", i.e., the\nsuccessive scan lines. The spacebin job takes the input satellite\nperspective data and bins it into a global 9km equal area grid. Note\nthat these files contain entries only for bins with data. Successive\njobs combine or treat the data using these bins.\nDatabase description\nThere are three sets of tables in the processing database. One set\ncontains three tables that store information on the processing,\ndefining the steps and what is to be done in each of the steps.\nAnother set has two tables that track each of the processing entities\nand the jobs associated with them, and a third set contains various\ntables that provide ancillary information for definition and validation\npurposes.\nThese types contain these tables:\nPROCESSING RECIPE TABLES:\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n13\n\nRECIPES\nPROCESS_STEPS\nPARAMETERS\nJOB ENTRY TABLES:\nMAIN\nPROCESS_CONTROL\nMISC. DB TABLES\nBOOKJCEEP\nCOMPUTERS\nDAYBSfFO\nSATELLITES\nSATSEN\nSENSORS\nUSER_GROUP\nWEEKINFO\n\nPROCESSING RECIPE TABLES RECIPES/PROCESS_STEPS/PARAMETERS:\nThere are three tables that are used to define the processing stream:\nthe RECIPES table, the PROCESS_STEPS table and the PARAMETERS\ntable. (Future implementations will combine these into either one or\ntwo tables.) The RECIPES table contains an entry for each integral\nstep in the processing stream. That is to say, a RECIPE defines a step\nor set of steps that are to be performed as a unit. The\nPROCESS_STEPS table contains a set of entries for each RECIPE,\ndefining the processing steps, and the order in which they are to be\nperformed. The PARAMETERS table provides additional definitions\nthat may be used in the PROCESS_STEPS table.\nRECIPES Table:\nA processing RECIPE may contain more than one processing step.\nThe steps defined by a RECIPE are to be performed as a unit, without\ninterruption, and the results of the processing transmitted to the\nprocessing db at the end. The fields of the RECIPE table are used to\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n14\n\nassign characteristics and control some aspects of the job triggering.\nThe fields are:\nTable RECIPES\nrecipe_code: Code number for keyword retrieval\nrecipe: Recipe name\ndef_priority: Default priority to assign to procedure\nprocess_class: All jobs with the same "svctype"\ncomputer_class: When one job is assigned to a computer, all\nare\n\ntrigger_class: Trigger_class of this recipe\nclass_to_trigger: Trigger_class to trigger when no more sub or\nfin records\nValues for these fields are:\nCD RECIPE\nPRI PROCESS_CLS COMPUTER_CLS TRIGGER_CLS CLS_TO_TRIG(\n1 \'GAC_INIT\'\n1 \'INIT\n\'INGATSB1\n\'INIT\'\n\'INGATCO1\n1\n2 \'GAC_INGATCOR\' 1 \'UNLIMITED \'INGATSB\'\n\'INGATCOR\'\n\'NONE\'\n3 \'GAC_SPACEBIN\' 1 \'SBIN1\n\'INGATSB\' \'SINGLEREC\'\nTEVIEBIN\n1\n4 \'GAC_ORBIT\'\n1 \'ORBIT\n\'INGATSB\'\nTIMEBIN\'\n\'DAILY\'\n1\n1\n5 \'GACJDAILY\n1 \'DAILY\n\'WEEKLY\'\n\'DAILY\'\n\'NONE\'\n1\n6 \'GAC WEEKLY 1\' 1 \'WEEKLY 1\'\n\'WEEKLY\'\n\'WEEKLY1\n\'WEEKLY2\nThe process_class field refers to the job type. That is, when mcp\nrequests a job, it requests a job with a particular process_class. This\nwas originally intended to be used if one mcp would be allowed to\nrun different types of jobs, but has operationally become limited to a\nsingle type of job for each mcp. In the example, there are six\ndifferent process_classes representing five mcp types: mcp-i, mcpul, mcp-sl, mcp-o, mcp-d and mcp-wl.\nThe computer_class is used to control which computer performs the\nprocessing. For example, the processing of a single orbit should all\noccur on the same computer, as the input file must be copied to a\nlocal disk, and this should be done only once. When an orbit is\nassigned to a computer, all tasks with the "INGATSB" computer class\nwill only be run on that computer. In the example, when the INIT\njob is assigned to a particular computer, all other jobs with the same\ncomputer_class (INGATCOR, SPACEBIN and ORBIT) are also assigned\nto that computer.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n15\n\nThe trigger_class and class_to_trigger fields are used in the\ntriggering of follow-on jobs. When a job completes successfully, the\nprocess_status for that collection of jobs (i.e., all process_control\nrecords with the main_link) is checked. If there are no submitted or\naborted jobs, then the "class_to_trigger" field is checked for the\nrecipe just completed. If it is "NONE" no triggering of this type is\nperformed; otherwise, all records with the specified trigger_class are\nsubmitted for processing. In the example, when the INIT job\ncompletes, all INGATCOR jobs for that orbit will be submitted for\nprocessing.\nPROCESS_STEPS Table\nThis table defines the information retrieval, workspace definition,\nand command files to be run, and their order, for each recipe to be\nused in a processing stream. The fields of the PROCESS_STEPS table\nare:\n!\n!\n!\n!\n\nRECIPE: Steps are assigned to this procedure\nprocess_step: Process step number\ncommand: Command to execute\njump: Jump to this step if appropriate\n\nEach recipe will have a number of steps defined for it.\nPROCESS\nRECIPE\n\'GAC_INIT\',\n\'GAC_INIT\',\n\n_STEP\n1,\n2,\n\nCOMMAND\n\'NAME_MAKE\',\n\'pathgacjnit,\n\nJUMP\n0\n0\n\n\'GACJNGATCOR\',\n\'GAC_INGATCOR\',\n\'GAC_INGATCOR\',\n\'GACJNGATCOR\',\n\'GACJNGATCOR\',\n\n1,\n2,\n3,\n4,\n5,\n\n\'NAME_MAKE\',\n0\n1\n\'GET.WEEKINFO ,\n0\n1\n\'SETJNGEST ,\n0\n\'WSO:nlmc\',\n0\n\'pathgac_ingatcor\', 0\n\nThere are three type of items that can be defined in a step.\n1: Certain commands (such at SET_INGEST or GET_ASCDSC) direct the\nserver to retrieve information from the database, and write out\nworkspace variables. (Examples: Steps 1 in GAQJNIT and 1-3 in\nGAC_INGATCOR above.)\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n16\n\n2: A command may be simply the name of a dsp command file to\nexecute. (Examples: Steps 2 in GAC_INIT and 5 in GAC_INGATCOR\nabove.)\n3: A step can be used in conjunction with the PARAMETERS TABLE to\nassign a particular value to a workspace variable. (Example: Step 4 in\nGAC_INGATCOR above - see also PARAMETERS below.)\nPARAMETERS Table\nThe PARAMETERS table contains three fields:\ncommand\nwork_space\ndata_value\n\ncommand for which variable is defined\nworkspace variable to define\nvalue to assign to variable\n\nand sample values are:\nCOMMAND\n\'WSO:nlc\'\n\'WSO:nlsst\'\n\'WSO:nlmc\'\n\nWORKSPACE\n\'SSTTYPE\'\n\'SSTTYPE1\n\'SSTTYPE1\n\nDATA_VALUE\n\'nlc1\n\'nlsst\'\n\'nlmc\'\n\nIn the PROCESS_STEPS example, step 4 in GAC_INGATCOR is\nrequesting that a workspace variable, \'SSTTYPE\', be assigned a value\nof \'nlmc\' before the dsp command procedure \'pathgac_ingatcor.dsp\' is\nrun.\n\nJOB ENTRY TABLES:\n\nMAIN Table\nThis table tracks the "entities" that require processing. There is one\nentry for each "class" of jobs that need to be run. for example, there\nis one record for each satellite orbit to be processed, and the\nfile_name is the input orbit file name. There is another entry for all\njobs that need to be run on a daily basis (i.e., jobs that produce files\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n17\n\nin increments of one day), and another for weekly jobs, etc. The file\nnames of these are yyddd, yyww, etc.,\nThere will be at least one record in the PROCESS_CONTROL table for\neach record in the MAIN table. If multiple jobs are to be run on the\nsame "entity", there will be one PROCESS_CONTROL record for each\njob.\nField\n\nComment\n\nrecord:\nMain record number\nfile_name:\nLink to several relations\n:\nFile number on archive medium\nraw_data_link: Link to RAW_DATA table\narchive:\nValidate with ARCHIVE table\narchivejabel: Link to ARCH_INFO table\nformat:\nValidate with FORMAT table\nsatsen code: sat/sen code number\nsatellite:\nType of satellite - validate with SATELLITE table\nsensor:\nType of sensor - validate with SENSOR table\ntransmission: Transmission - validate with TRANSMISSION table\nChannels in input file - validate with CHANNEL table\nchannel:\nSatellite orbit number\norbit:\nTimestamp at beginning of pass\npass_time:\nTime of last scan line in the pass\npass_end:\nyearday:\nYearday of file\nNumber of scan lines in scene\nscans:\nmiss_scan:\nNumber of missing scan lines in scene\nData source - validate with SOURCE table\nsource:\nProject - validate with PROJECT table\nproject:\nMain record to notify upon completion\nrelease_link:\nNo. of release_recs this is waiting for\nrelease_recs:\nrelease_done: No. of releasejrecs done\nprocess_recs: No. of process_control recs for this entity\nprocess_done: No. of process_control records completed\nmap:\nBitmap of 10 X 10 degree coverage\nQC_status:\nStatus of quality control\nwho_code:\nWho modified; Validate with USER_GROUP table\nlast_mod:\nDate of last record modification\naudit:\nDate of record creation\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n18\n\nPROCESS_CONTROL Table\nThis table stores information on individual jobs through the\nautomatic processing system.\nFieldComment\nrecord:\nmain_link:\nrecipe:\nprocess_step:\nsatsen_code:\nsatellite:\nsensor:\ncomputer:\n\nInternal record number of file to process\nLink to MAIN relation\nRECIPE to be executed, Validate with RECIPE table\nLast process_step completed (obsolete)\n\nValidate with SATELLITE table\nValidate with SENSOR table\nComputer assigned to process this PCR;\nValidate with COMPUTER table\ncomputer_class Used to restrict jobs to one computer\nprocess_status: Is the hob is in HOLD, SUB, FIN or DSPA status\nprocess_class: MCP-type class of this job\nrec_to_trigger: PC Record to trigger when this completes\nif zero, this is triggered by another\nif -1, neither triggers nor is triggered\ntrigger_class: The trigger_class of this job\nclass_to_trigger The class to be triggered when this\nclass has completed\npriority:\nPriority to assign to job\ntotscan:\nTotal scans in WHOLE SCENE\nbegscan:\nBeginning scan line of this piece\nendscan:\nEnding scan line of this piece\nyearday:\nYearday from MAIN_LINK\'s input file\nmiscinfo:\nMiscellaneous information (varies)\nsource_file:\nOutput file for this PCR.\nsource_directory Directory of input file.\nwho_code:\nValidate with USER_GROUP table\nlast_mod:\nlast record modification\naudit:\nrecord creation\n\nMISC. DB TABLES\nBOOKJCEEP Table\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n19\n\nThe BOOK_KEEP table is a special-purpose table used to keep track of\nthe current number of entries in those tables that are permitted to\n"grow. The three fields in the BOOK_KEEP table are:\nrecord\nrelation_name\nmax_record\n\nrecord number in this table\nname of relation\ncurrent number of records\n\nand INITIAL entries are:\nRECORD RELATION_NAME\n1 \'BOOK_KEEP\n2 \'RAW_DATA\'\n3 \'MAIN1\n4 \'PROCESS_CONTROL\'\n\nMAX_RECORD\n4\n0\n0\n0\n\nThe BOOK_KEEP entry has an initial value of 4 because four tables are\ncurrently used in this manner - the three "data" tables and\nBOOK_KEEP itself.\nWhen an new entry is added to any of these tables, the BOOK_KEEP\nvalue for MAX_RECORD for that table is first incremented, then that\nvalue assigned as the record number for that table. This is the\nAPServer\'s method of assigning distinct record numbers to these\ntables.\nCOMPUTERS Table\nThe COMPUTERS table is used to validate computer names using the\nAPServer system, and to provide information about them. The fields\nin the COMPUTERS TABLE are:\nFieldComment\ncomputer\nValid keyword value\nabbrv\nAbbreviation\nos\nOperating system\nsite\nLocation of computer\n*The following fields are not currently being used.\nrun_status\nRunning status of computer (run, pause, finish,\nstop)\nalarm_status Whether the start/stop alarm is to be used (n/y)\nalarm_start\nWhen to begin processing (hhmm) (LOCAL time)\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n20\n\nalarm_mcps\nalarm_stop\n\nWhich mcps to start (list of start files, sep by\ncomma)\nWhen to finish up processing (hhmm) (LOCAL time)\n\nand typical entries are:\nCOMPUTER\nMARIAH\nandrew\nenuka\n\nABBRV\nmar\nand\nenu\n\nOS\nVMS\nUNIX\nUNIX\n\nSITE\nRSMAS\nRSMAS\nRSMAS\n\nThere are also a number of fields that have not yet been\nimplemented, that will be used to automatically start and stop\nprocessing on a given machine.\n\nDAYINFO Table\nThis table is used to define the start the ascending and descending\ndata-days for each satellite. This table also assigns a week to each\nday (which can be defined separately by satellite). The fields are:\nField\n\nComment\n\nyearday\nsatsen_code\nweek\nasc_beg\ndsc_beg\n\nyearday\nsat/sen code number\nWeek to which this day is assigned\nBeginning of day for ascending data\nBeginning of day for descending data\n\nand typical entries are:\nSATSEN_\nYEARDAY CODE WEEK ASC_BEG DSC_BEG YEARDAY CODE WEEK ASC_BEG\nDSCBEG\n\n88308 1 8845883080111248830713511988308 2 884588308044643\n88307...\nEntries need only be made for a particular satellite for the life of that\nsatellite, not for all days defined in the table.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n21\n\nSATELLITES Table\nThis table is used to validate satellite names and store associated\ndata. The fields are:\nField\n\nComment\n\nsatellite\nextension\nsat_id\nprefix\n\nsatellite name\nfile extension for ingested files\nNORAD satellite number\nprefix for processed files\n\nand typical entries are:\nSATELLITE\n\'NOAA-9\'\n\'NOAA-101\n\nEXTENSION SAT_DD PREFIX\n,\'NO9\',\n15427, \'K1\n,\'NIO\',\n16969, T\n\nThe SATELLITES table is linked to the SENSORS table by the\nSATSEN CODE table.\n\nSENSORS Table\nThis table is used to validate satellite sensors.\nFieldComment\nsensor\n\nValid keyword value\n\nSENSOR\n\'AVHRR1 \'HIRS2\' \'MSU\' \'SR\'\n\'VHRR\'\n1\n1\n\'CZCS\n\'DCS\n\'ALT\' \'HCMR\' \'MSS\'\n\'OLS\'\n\'SAR\' \'SCAT\' \'SMMR\' TM\'\n\'VAS\'\n\'VIR\' \'VISSR \'SEAWIFS1\nSATSEN Table\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n22\n\nThis table is used to validate satellite/sensor combinations, and\nassign a specific code to each pair. It is used to link the SATELLITES\nand SENSORS\ntables.\nField\n\nComment\n\nsatsen_code\nsatellite\nsensor\n\nsat/sen code number\nsatellite name\nsensor name\n\nSATSEN\n_CODE SATELLITE\n1\n\'NOAA-1T\n2\n\'NOAA-9\'\n\nSENSOR\n\'AVHRR\'\n\'AVHRR1\n\nUSER_GROUP Table\nThis table is used to validate members of the user USER_GROUP.\nField\n\nComment\n\ncode\nCode number for keyword retrieval\nuser_name\nComputer user_name ID\nfull_name\nUsers\' full name\ntelephone\nPhone\nsite\nWhere the user is\nemail_address E-mail address\ntelemail address TELEMAIL address\n\nNote: The autoprocessing interface automatically loads the\nUSER_NAME into this table when an new user first runs the system.\nAll other information (full name, site, etc.,) must be loaded\nseparately.\nCode User_Name Full_Name\n1. VICKI\n\nTelephone\n\nVICKIM. HALLIWELL\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nSite\n\n305-361-4178 RSMAS\n\nVl.OO\n\n23\n\nCode User_Name email_address\n1. VICKI\n\ntelemail_address\n\nvicki@miami.rsmas.miami.edu\n\nNONE\n\nWEEKINFO Table\nThis table is used to define the 4-week and 8-week time periods, and\nthe directory for the daily files for each week.\nField\n\nComment\n\nweek\nfourwk\neightwk\nwkdir\n\nThe week\nThe 4-week interval for this week\nThe 8-week interval for this week\nDirectory for the daily files by week\n\nWEEK FOURWK EIGHTWK WKDIR\n0 104 108 7(disk)/wk/wk01\'\n1 104 108 7(disk)/wk/wk01\'\n2 104 108 7(disk)/wk/wk02\'\n3 104 108 7(disk)/wk/wk03\'\n...(entries omitted)\n\nThe triggering is in the db_report subroutine.\n1. When the end of a job is reported to the database, the value of\n"status" and the existence of an error message is checked. If either\nof these indicate an error, then the process_status for that\nprocess_control record is set to \'dspa\', and no triggering occurs.\nOtherwise, process_status is set to Tin\', and the triggering is tested.\n2. If the rec_to_trigger for this process_control record is greater than\nzero, it is marked \'sub\' (submitted for processing).\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n24\n\nExample - Completion of Ingatcor triggers Spacebin:\nrecord\n\nrecipe\n\nfilerec_to_trigger\n\n1001\n1002\n\nIngatcor 90123123456.datal002\nSpacebin 90123123456.data-l\n\nThe completion of record 1001 will trigger the submission of record\n1002.\n3. If the rec_to_trigger is less than 1, the "class_to_trigger" for that\nrecord is checked. If it is "none", no further class triggering is done.\nOtherwise, the process_control records for that main record are\nchecked. If any records are marked \'sub\' or \'exe, no triggering\noccurs. Otherwise, all process_control records associated with that\nmain record with the matching trigger_class are submitted for\nprocessing.\nExample - Completion of Init triggers multiple Ingatcors:\nrecord\n\nrecipe\n\ntrigger_class\n\nclass_to_trigger\n\n1000\n1001\n1003\n1005\n1007\n1009\n1011\n\nInit\n\nInit\nIngatcor\nIngatcor\nIngatcor\nIngatcor\nIngatcor\nIngatcor\n\nIngatcor\nNone\nNone\nNone\nNone\nNone\nNone\n\nIngatcor\nIngatcor\nIngatcor\nIngatcor\nIngatcor\n\nIngatcor\n\nWhen the Init job complete, all six of the Ingatcor jobs will be\nsubmitted.\nThree special cases:\nIf the process_class is "orbit", the orbits for that yearday are\nchecked. If any are unfinished, no triggering occurs. If all are\nfinished, the previous and succeeding days are checked. If all are\nfinished, then the rec_to_trigger of the middle day is submitted. The\nprevious and succeeding three-day periods are also checked if\nneeded.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n25\n\nIf the process_class is "daily", all the daily jobs for that week are\nchecked. If any are unfinished, no triggering occurs. If all seven\ndays for that week are done, then the first weekly job (WEEKLY 1) is\nsubmitted.\nIf the process_class is "weekly2", the "weekly 1" jobs for that week,\nthe previous week and the succeeding week are checked. If any are\nunfinished, no triggering occurs.\nIf all are finished, then the\nrec_to_trigger for the middle week is submitted. The previous and\nsucceeding 3-week periods are also checked.\nB.1.2.4 April Development\n\nMost of the database processing effort in April was devoted to\noperational processing.\nMuch new equipment was installed during this time period, which\nnecessitated minor changes to accommodate the processing.\nHowever, in some cases, the equipment continued to cause problems.\nB.1.2.5 May Development\n\nAfter the tests of the monthly coefficients, a test was designed to\ncalculate the SST three ways in a single pass. During the first half of\nthe month development centered on accommodating the programs\nand command files to handle these calculations. Many minor changes\nwere needed in almost all programs and command files used in the\nprocessing, such changes as adding the ability to refer to different\nSST values (i.e., using "SST" as a default type, and adding "hemsst"\nand "mnlsst" as additional SST types in a single file).\nDuring the last half of the month, a new method of adding processing\nrecords to the database was designed. In the old method, the input\nfile had to be copied to a VMS disk, where information was extracted\nfrom it by a batch job on VMS. In the new model, a daemon on the\nUNIX side will extract the necessary information, which will be\ntransferred to the VMS side in a simple ASCII file.\nIn this new paradigm, a set of programs and procedures on the UNIX\nside reads the input data file, determines the segments that are to be\nprocessed, ingests these segments (i.e., creates a separate file with\nonly data to be processed as a unit), and runs a series of procedures\nthat associated the navigation and calibration with the ingested file.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n26\n\nThe processing recipes were also modified to copy the ingested files\nto the processing computer (instead of the single input file), and skip\nthe sectorization (navigation/calibration addition).\nNote that these changes were only in development, and had not yet\nbeen incorporated into the operational processing scheme. A\ncomparison of the old and new calculation scheme follows.\nOld\n\nNew\n\n*PATHGAC_INIT\n\n*NEWGAC_DSfIT\n\nFTP the input pass file to the local\ngacinp directory\n\nFTP the ingested pieces of\nthe pass to the local gacing\ndirectory.\n\nThis job triggers a separate INGATCOR\njob for each piece of the pass.\n\nThis job triggers a separate\nSATCOR job for each piece of\nthe pass.\n\n*PATHGAC_INGATCOR\n\n*NEWGAC_ATCOR\n\nThis job ingests a piece, runs sector\nperforms the atmospheric correction.\n\nThis job performs the atmospheric\ncorrection. It also stores the dataday\ninformation on that piece into a\ntemporary pass/scan info file.\n\nThis individual job triggers a single\nWhen ALL of the ATCOR jobs for a\nSPACEBIN job to bin the single piece.\npass are complete, a single SPACEBIN\njob is run to bin all the pieces.\n\n*PATHGAC_SPACEBIN\n\n*NEWGAC_SPACEBIN\n\nThis job bins one L2 piece into a 9km\nfile\n\nThis job bins all pieces for the pass pst\nfiles, using the dataday information\nretrieved from the temp, scan file.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n27\n\nWhen ALL of the SPACEBIN jobs for a\npass are complete, the ORBIT job is\ntriggered.\n\nThe single SPACEBIN job triggers the\nORBIT job.\n\n*PATHGAC_ORBIT\n\n*NEWGAC ORBIT\n\nThis job collects the SPACEBIN\npieces, executes the ORBIT job\nftp copies the results to the\ncollection machine, deletes input\nfiles.\n\nThis job performs a ftp copy\nof the ORBIT file to the\ncollection machine, deletes\ninput files.\n\nB.1.2.6 June Development\nThe processing scheme changes developed last month were\nimplemented into the operational systems. Additional development\noccurred to accommodate the change in type of input file at the data\ntime 92076 (NOAA Lib tape format to direction telemetry format).\nFiles after this data were obtained directly by the RSMAS group, and\nthe differences in file header information requires the use of a\ndifferent scanner and ingester. Other development during the month\ncentered on adjusting command files and programs to the new\nprocessing paradigm. While most problems have been cured, there\nare still some problems that occur in the scan/ingest section that\nmust be resolved.\nB.I.3.1 Other activity\nRan 1988 (Jan-NOV) using algorithm coefficients and model\npresented at Science Working Group meeting in March.\nProcessing rate, 7.5 days for 140 data days.\nA new program path filler uses Laplacian relaxation to fill cloud\nareas. Use of Reynolds 1 deg, 1 week analysis as a quality control\nreference map does not provide a reasonable average reference\nvalue for areas with high gradients, e.g., South Atlantic Bight to Gulf\nStream in Winter, Spring. Using filler program on good 3 week data\nto produce global filled 9km reference map, then run cloud mask\nprogram to check data validity, then produce new filled reference\nand run cloud mask.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n28\n\nWarner converted jukebox software to run on alpha\nVicki converted process control server to run on alpha\nExpect that processing rates could double with faster archive access\nand network delivery, faster process control server response could\nimproved present 15-20 data days/day to 30-40 data days/day.\nVicki processed 1987 and 1988, generated global products at 1 deg,\n36, 18 and 9 km, distributed\nUsing matchup data base and radiative transfer modeling to examine\nlimitations in present SST retrieval equations\nMatchup database testing for N-l 1 from Nov. 88 until June 91.\nFound change in sensor coinciding with Pinatubo eruption, effects\nglobal data by -0.3C.\nStarted trial N-l 1 processing to examine transition from N-9 to N-l 1.\nDue to difference in nodal time, approximately 1 orbit checking buoy\nrecord to determine amount of heating due to time difference, ~0.25c\n\nB.2 Client/Server Status (\n\nS)\n\nB.2.1 Client/Server Development\nThe following is a list of accomplishments for the 1st half of 1995\nconcerning Client/Server processing:\n1. The ingester output file name assignment was been modified. In\nthe past, when given a start line and an end line, the ingester output\nslightly different file names from those the input control specified.\nAs modified the ingester will force a file name by passing the name\nto ingester through an environment variable. Although workable,\nthis modification was not generally acceptable; the current solution is\nto run the ingester as usual and then acquire the new file name from\nthe output directory and append the info the\nthe scan-info file.\n2. A scan program for scripp format on Modis, named scripp_geninp\nwas completed.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n29\n\n3. The program that computes the dataday starting and ending\nstrings is finished and tested; the following provides some test\nresults:\nfile_stem aday dday asc_beg\nasc_end\nDSCJBEG\nDSC_END\n91001001234 91000 91001 90365025126 91001024237 90365141022 91001140220\n91001012234 91000 91001 90365025126 91001024237 90365141022 91001140220\n4. A self contained program, pathgac_spacebin.dsp, to compute the\ndata day time strings has been created; it has been made into a mice\nprogram so that time strings can be accessed from inside the dsp\ncommand procedure.\n5. The first cut of the AVHRR Processing documentation has been\ncompleted and is being circulated internally for comment. The\ndocuments on the web is roughly presentable, although incomplete,\nand contains an explanation of data handling. This documentation\nwill be linked to the algorithms (from Matchup documents) and to\nscheduling (from autoproc documents).\n6. After cleaning up the code, the scan programs have been checked\nin for release control. Included in the changes are different satellite\ntypes.\n7. Conversion of the program to Fortran90 has been discussed; this\nextension will be pursued after the creation of a GUI for the ap\nprogram.\n\nB.3 Matchup Database\n\n(P)\n\nDuring the first half of the year we completed version 18 of the\nAVHRR Pathfinder Oceans Matchup Database for the period 19851993. The database was delivered to JPL for public distribution. A\ndocument was prepared describing the compilation of the matchup\ndatabase and its contents. This version was circulated for comments\nto L. Smith (Old Dominion University), P. Cornillon (URI) and J.\nVazquez (JPL). The document was reformatted as an HTML file which\ncan be accessed through the World Wide Web. JPL is in the process of\nadding the appropriate links to their Pathfinder WWW page.\nEfforts to expand the temporal and spatial coverage of the matchups\ncontinued with the acquisition of a new data set including\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n30\n\nobservations collected by moored buoy in the northeast Atlantic.\nThese data were acquired from the UK Met Office. We also started\nthe collection and reformatting of data for 1994. With regards to data\nprior for the period 1981-1984 (NOAA-7), all the in situ data were\nformatted and extraction lists were generated. The extraction of\nAVHRR data for those years will begin as soon as the GAC data are\nobtained from NASA-GSFC. With regards to 1981 in situ observations,\ndrifting buoys from MEDS were missing in the available data set for\nJuly-December 1981, which we had originally obtained from NASAGSFC. The missing drifter data were ordered directly from MEDS and\nadded to the existing databases.\n\nB.4 DSP Support (\n\nM)\n\nB.4.1 Testing:\nNone listed\nB.4.2 Modifications/Additions to DSP:\nTIRPACK: New ingester to convert level-Ib disk files ftp\'d from\nNOAA to DSP header disk files that can be ingested using tiros.\nRemoved unused variables from all source files for SGI Power (64bit) machines.\nUse only single quoted strings in format statements.\nChange Hollerith strings to single or double quoted strings per\ncontext.\nIMGFILE parameter must be of correct type, can\'t use explicit\nconstant.\nLOADCOL: New program to read HIST line average files and create a\ndsp imag file (ala loadnohed) with one column per line average.\nB.4.3 Problems fixed:\nSEAWiFS support:\nSMAP9-HDF:\nPut remap parameters in command line.\nPigment, chlor, and k49 bands were mixed up.\nUse WIFSROOT definition from make.prog.\nChange the default for binning algorithm to seawifs style.\nFix different versions of flag handling.\nAdd third argument to bin9kminit.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n31\n\nUpdate for use in smap9-dsp to output dsp images instead of hdf 13m\nfiles.\nAdd binning model type to the associated data block.\nUse only single quoted strings in format statements.\nTake xspace and yspace out of command line since they aren\'t used\nfor pst files.\nSSBIN-HDF:\nUse gsfc v4.2 i/o routines, add new temp/satz test,\nfix binning to use left and right edge of bin instead of centers.\nUse WIFSROOT definition from make.prog.\nChange the default for binning algorithm to seawifs style.\nFix different versions of flag handling.\nAdd third parameter to bin9kminit.\nAdd binning model type to the associated data block and the\ncommand line;\nadd extension to input file name in "infiles".\nUse only single quoted strings in format statements.\nSTBIN-HDF:\nUse tilt; both gsfc and miami quality determination;\nchanges for gsfc v4.1 i/o routines.\nUse gsfc v4.2 i/o routines.\nUse WIFSROOT definition from make.prog.\nChange the default for binning algorithm to seawifs style.\nFix different versions of flag handling.\nANLY8D:\nAdd optimization for epsilon-model choice across scan.\nStart modifications for parameter file inputs.\nParameter file input complete.\n(Needs to be rationalized against required input parameters.)\nRemove unnecessary files.\nAdd documentation on parameter inputs.\nAdd checks to file opens to preclude invalid file names.\nIncrease maximum size of full filenames to 128 characters.\nUpdate documentation for new arguments and parameter file input.\nFix typo in generation of La670 and La865.\nAlways treat 670 as aerosol band.\nAdd calhdf parameter for sensor calibration file.\nAdd method to specify sensor calibration filename from command\nline.\nPrint out selected sensor calibration filename.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n32\n\nAdd diagnostics for epsilon carry-over algorithm function.\nChange command-line syntax to allow \'SUNGLESfTl =0.005\'.\nMove the make.prog include up so that WIFSROOT is defined.\nUse $DSPROOT instead of/usr/dsp.\nReturn both La670/Lw670 to caller.\nChange loops to only calculate items that will be used later (mostly\ncleanup).\nTau calculation uses reflectance instead of radiance.\nFix makefile use of DSPLIB.\nRearrange cocco-algorithm coefficents to match preferred equation\nform.\nChange LwXXX to nLwXXX to match cocco-algorithm.\nAnother change in parameter order and default values for coccoalgorithm.\nAdd third parameter to bin9kminit.\nAdd include file for bin9kminit model type.\nUse 9km not isccp model.\nAdd CVS headers to some files.\nUpdate copyright notices.\nDon\'t pass explicit 0, put in variable of correct type and pass that\ninstead.\nAdd routines to parse input parameter MSKFLG into equivalent\noutput bit values.\nUpdate to support wang2.f interface changes (flags2_pc).\nExplicitly time execution of each of the four tests.\nPass in \'in_files\' output value to L2 open.\nAdd MSKFLG parameter.\nRename NMCx and TOVSx parameters to METx and OZONEx\n(respectively).\nAdd additional diagnostic flags to epsilon carry-over optimization.\nDecode MSKFLG input string (though not used in subsequent tests).\nRename NMCx and TOVSx to METx and OZONEx.\nConstruct in_files and proc_con documentation strings\nfor L2 file.\nUpdate output text for additional (flags2_pc) diagnostic flags.\nAdd new routine - splitandappend.rat for filename processing.\nImplement proc_log output variable.\nChange usage of in_files output variable.\nIncrease precision of intermediate variables in rho_a_sub_quad\nto stabilize epsilon calculation (problem found by G. Fu).\nForce delta phi input value into canonical range of [-180,+180].\nRemove unused arguments from call to get_lla_openf (trailing 5\nvariables).\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n33\n\nANLY,ANLY2D,ANLY6D,ANLY7D,ANLY8D: Change image file variables\ntype from int to IMGFILE.\nCOLORSHR7:\nAdd routine to allow passing of climatology file names from\ncommand line.\nAdd additional climatology file entries.\nCorrect typo in handling of TOVS2 file.\nRearrange code to simplify all file handling.\nPrint out names of climatology files.\nPointer must be valid before string can be checked.\nImage file variables are type IMGFILE, not type int.\nOnly build ephs/reflec/raylei/sunang2 once (they are in SPHLIB).\nLimit status values from get_ancillary to 4 bits in the resulting\ncomposite status returned by get_climatology.\nCOLORSHR: Image file variables are type IMGFILE, not type int.\nOnly build ephs/reflec/raylei/sunang2 once (they are in SPHLIB).\nCOLORSHR8: Image file variables are type IMGFILE, not type int.\nOnly build ephs/reflec/raylei/sunang2 once (they are in SPHLIB).\nForce delta phi (angle) into canonical range of [-PI.+PI],\nCOLORSHR5: Only build ephs/reflec/raylei/sunang2 once (they are in\nSPHLIB).\nLIB/DISPLYSHR/GETCMD.C: Exit with last reply status if last\n\'command\' fails.\nLIB/HDF/DFGR.C: Fix syntax error in if statement. Had \'=\'\n(assignment)\nPathfinder/MODIS support:\nPATHNLC:\nUse a coefficient file for all satellite/date combinations.\nAdd new temp/ satz test. Use <=0.7 and <=1.8 instead of <.\nChange allb from logical to 0 for just sst, 1 for all bands, 2 for some\nbands (bright4, brightS, ch4m5, maskl, mask2, sst, hemsst, mnlsst);\nchange some debugs.\nUse different coef files.\nUse only single quoted strings in format statements.\nChange Hollerith strings to single or double quoted strings per\ncontext.\nCONVRT: Fix string handling.\nPATHTIME: Add comments.\nAdd binning model type to the associated data block.\nUse only single quoted strings in format statements.\nQRMPACK: Exit with good status.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n34\n\nSCRIPP: On unix, don\'t exit if yzO is not defined.\nAdd line number to "check registration" debug.\nInitialize variable.\nGet year from header in some Sea Space files.\nLIB/IO/AUTOOPEN.C,GET.C,PARSER.C:\nAdd support for parfile= keyword\nLIB/IO/GET.C: Clear all nodes before reparsing, not just the leftpointing ones.\nLffi/IO/ASSOC.C: Fix incomplete comment.\nLffi/IO/BADIMGCHK.RAT: Image file variables are type IMGFILE and\nnot int.\nLIB/IO/GET.C: Exit to shell with non-zero status if error status and\nno CALLER.\nrNGEST/LIB/READLEVELlB.RAT: Add read routine for raw NOAA\nLevel-Ib disk files.\nRemove SCRIPP specific functionality. Correct conversion errors.\nTIROS,TIROSSCAN,RLREAD,NMFS: Increase size of variables used\nwith\nsatellite library.\nPATHBESf: Add ISSCP binning algorithm.\nAdd third argument to bin9kminit (model type: MDL_9KM [1] or\nMDLJSSCP [2]).\nFirst argument to bin9kminit is tiny bin resolution (use 16 for 9km)\n~ must be a power to 2 to be MODIS compliant, routine will accept\nany positive value.\nUpdate test program to completely test both the 9km and ISSCP\nroutines.\nUse \'make test9km\' to build test program.\nAdd third parameter to bin9kminit.\nAdd more complete test program (try9km.rat) for bin9kmf.rat.\nTest both 9km and ISSCP modes for all routines.\nAdd additional argument range checks to bin9kminit.\nAdd CVS headers to some files.\nUpdate/add copyright headers.\nAdd binning model type to the associated data block and command\nline; change allb from logical to 0 for just sst, 1 for all bands, 2 for\nsome bands (bright4, bright5, ch4m5, maskl, mask2, sst, hemsst,\nandmnlsst).\nIncrease AABINS to allow either Miami or ISCCP algorithms at\n9km.\nCorrect name to ISCCP from ISSCP.\nPut constant in variable of correct type instead of passing a constant.\nUse only single quoted strings in format statements.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n35\n\nUse float(ii) just like float(jj).\nPST2OA: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nPATHSPC: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block and command\nline.\nUse only single quoted strings in format statements.\nFix to handle up to 6 bands to sum (instead of just sst)\nPATHMOS: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nPATHMAP: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nUse only single quoted strings in format statements.\nPATHFLT: Add third parameter to bin9kminit.\nUse not(###) instead of !### inside and(x,y).\nAdd binning model type to the associated data block.\nPATHFILL: Add third parameter to bin9kminit.\nChange \'!###\' to \'not(###)\'.\nAdd binning model type to the associated data block; allow for\nsome bands (more than just sst) in input file.\nOA2PST: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block and command\nline.\nUse only single quoted strings in format statements.\nIMGFILE parameter must be of correct type, can\'t use explicit\nconstant.\nFix binning to use left and right edge of bin instead of centers.\nMOSAIC9: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nType of image file pointer should be IMGFILE and not int.\nChange image file variables type from int to IMGFILE.\nIMG2PST: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block and command\nline.\nUse only single quoted strings in format statements.\nFix binning to use left and right edge of bin instead of centers.\nIMG2BIT: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block and command\nline.\nPut constant in variable of correct type instead of passing a constant.\nUse only single quoted strings in format statements.\nGSFCBIN9: Add third parameter to bin9kminit.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n36\n\nAdd binning model type to the associated data block and command\nline.\nUse only single quoted strings in format statements.\nCZCSMAP9: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nCSBESf: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nUse only single quoted strings in format statements.\nCMOS: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nPut constant in variable of correct type instead of passing a\nconstant.\nChange image file variables type from int to IMGFILE.\nCMAP9: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nBIT2OA: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nBIT2IMG: Add third parameter to bin9kminit.\nAdd binning model type to the associated data block.\nPut constant in variable of correct type instead of passing a\nconstant.\nMAKE-BSD: Add target for \'Power\' series SGI machines.\nUse target for \'Power\' series SGI machines.\nAdd C compile option to allow 64-bit build on SGI \'Power\' series.\nFix incomplete comment consumed code to remove leading blanks.\nConsistently use $(MAKE) instead of \'make\'.\nRemove files not used to build a localized version of \'pmake\'.\nAVHRRSHR5: Change image file variables type from int to IMGFILE.\nUse only single quoted strings in format statements.\nOnly build ephs/reflec/raylei/sunang2 once (they are in SPHLD3).\nVHRR: Change \'call GETADR(x.y)\' to \'x = IADDR(y)\'. More portable.\nChange \'call GETADR(x,y)\' to \'x = IADDR(y)\'. More portable.\nUse only single quoted strings in format statements.\nRemove duplicate (decodr) directory (lib is correct one to keep).\nLocalization change.\nAllow \'old-style\' ingest files to be accessed as \'read-only\'.\nRATFOR: Add missing return value to \'caslab\'. Fake return value in\n\'emalloc\'.\nAdd symbol \'SGI_64\' for SGI Power (64-bit) machines.\nTerminate a \'non-CHARACTER\' text string with a NULL byte for SGI\nPower-series.\nMICE: Correct syntax error (had GenC instead of generateC near line\n233).\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n37\n\nPUTNLPPT7: Use \'iostat=ios\' instead of \'end=\' to detect end of file on\nread.\nXFBD: Add lines to SGI Power series (XtoX[hl] functions).\nCopy plane sizing into return packet (_GetPlaneSize).\nCorrect usage of callbackList2.\nWas setting it up and then using callbackList instead of\ncallbackList2.\nPATHCLOUD: Add binning model type to the associated data block.\nPATHCOMP: Add binning model type to the associated data block.\nUse only single quoted strings in format statements.\nFix to handle any number of input bands, instead of just sst.\nPATHMASK: Add binning model type to the associated data block.\nPATHREF: Add binning model type to the associated data block.\nTQ2023: Move to correct directory.\nTQ2024: Move to correct directory.\nTROUTC,WMEAN,STATS,SHRINK,PIXRD,PATHDR,KEY8,COMPARE,JfflST,\n9KLM2EVIG,HIST:\nPut constant in variable of correct type instead of passing a\nconstant.\nWMEAN: Use only single quoted strings in format statements.\nSMOS: Change image file variables type from int to IMGFILE.\nTESfYBDSf: Change image file variables type from int to IMGFILE.\nDMPCNT: Set FORTRAN LUN value non-zero.\nGETCOM: Put constant in variable of correct type for image file value.\nText in format statements should be \'text\' and not "text".\nRename \'access\' to \'accessfile1 to avoid RTL conflict,\ninstead of \'==\' (comparison).\nDMPHDR: Change Hollerith strings to single or double quoted strings\nper\ncontext.\nMERGEG: Change IMAGED and GRAPHICO to generic \'IMAGED\' and\n\'GRAPHICO\' in\nerror msgs.\nNEWTMAGE: Modify lat/lon bounds code to work (better) for\nRobinson projection.\nChange adjustment to scaled real value in case output line is not\n1024 pixels.\nLIB/VMSFORLIB: Don\'t build getadr.c or idate.c.\nRename access and unlink to not conflict with unix RTLs.\nSHPSPH: Rename \'unlink\' to \'unlinkfile1 to remove RTL conflicts.\nRename fnminl/fnmaxl to mmin2/fnmax2 to remove conflict with\nSPHLIB.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n38\n\nMCSST: Don\'t include ephs/reflec/raylei/sunang2 if already\navailable in SPHLffi.\nAES: Input statement is requesting two input values.\nUpgrade missing line handling code to latest method.\nInsert held line after missing line gap.\nSome little fixes for vms/unix differences.\nAES 10: Input statement is requesting two input values.\nSeparate out modules used only by VMS.\nUpgrade missing line handling code to latest method.\nInsert held line after missing line gap.\nSome little fixes for vms/unix differences.\nMACE2: Check for invalid image start date.\nTRAVEC: Correct decode/format statements to work on PMV input\nfile.\nAdd some conditional debug statements.\nAdd error output with line counting to locate bad input records.\n\nB.5 Direct Project Support\nMODIS, Pathfinder- Interface with Navy to explore near real time\naccess to in situ data sources: Our group met with G. Mason and D.\nMay representing NAVOCEANO to define potential options to access\nexisting data sets and examine possible extensions to these data sets.\nIn turn our group will provide NAVOCEANO with present Pathfinder\nSST programs. Together our groups will define and implement\nprocedures to generate equation coefficients for real time SST\nproduct generation and quality control.\nMODIS ocean team members have been asked to submit updated\nalgorithms and input/output requirements. The updated algorithms\nwill be included in the programs submitted for the next Beta release.\nThe input and output requirements will be used to define the\nproduct files.\nGridding, Data Day Issues - Discussions concerning selection of\nappropriate Level 3 grids were undertaken at the Spring MODIS\nmeeting and continued at the Sante Fe IWG. Our group and the\nCERES team are conducting a series of tests to determine effects of\nthe grid definition when data at one resolution is converted to\nanother resolution. We are studying the problem by directly\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n39\n\ngenerating fields of SST (both cloudy and valid SST values) at low\nand high resolution. The high resolution data is then combined to\nform a field at the lower resolution and the two low resolution fields\nare compared after each is mapped to a common map projection.\nInitial discussions with the CERES team suggest that selection of a\n"data day" definition also will be a contentious issue. Selection of a\n"data day" should reflect the individual product requirements. A\nsingle definition for EOS would not reflect current practice or\ngeophysical reality.\ninitial beta delivery- SeaWiFS programs for oceancolor products,\nSeaWiFS programs use SeaWiFS HDF I/O for LI, ancillary fields, and\noutput products.\nmeeting with ocean support group of SDST in Miami\ndefine needs for input (Lib, cloud, land/water boundary, ancillary\nfields [surface wind speed, u,v; atmospheric pressure, relative\nhumidity, ozone], geometry, latitude, longitude, satellite and solar\nzenith angle, azimuth angles), access to PCF, HDF output files for\nproducts and quality fields.\nPathfinder SST program requires HDF I/O\nPathfinder SWG meeting to discuss post Mt. Pinatubo processing.\nProcessing prior to the eruption used algorithm coefficients that\nspanned a several year time frame and included a linear correction\nin time to partially account for long term drift. The rapid changes in\nabsorbing aerosols following the eruption introduced errors that\nexceeded those seen in prior years. A procedural change was\nintroduced where equation coefficients are recomputed on a monthly\nbasis. The approach reduced both long term and seasonal errors.\nThe present NOAA NLSST equation used in the Pathfinder SST\nprocessing utilizes the blended Reynolds analysis to provide the\nreference SST. Dick Reynolds (NOAA) was asked and has delivered\nmaps for a one year period showing the location of the in situ data\nthat is incorporated in his analysis. The location data is being used\ntogether with an analysis of the magnitude of the magnitude of the\nReynolds-Pathfinder difference to help understand the relative\nbehavior of the fields. The fields tend to agree well where a\nsignificant number of in situ points have been included in the\nReynolds analysis. The fields differ the most when the Reynolds\nanalysis relies substantially on the NOAA satellite SST.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n40\n\nThe following hardware has been acquired to support MODIS\nprocessing\nDisk Expansions -\n\n22 4 GB Barracuda\n- 88 GB\n24 8 GB Elite 9 - 192GB\n280GB\n1 PCI RAID controller for 2100 Server\n2 ISA RAID controllers for 2100 Server\n\nTape Expansion - 1 DEC 5 TB Tape Store\nComputer Expansion - 2 DEC 2100 Servers [4 275 Mhz processors, 512\nMB memory each]\nNetwork Expansion -\n\nFDDI Expansion 1 DEC Concentrator 500 Additional 8 port Card\n5 DEC PCI FDDI Adapters for workstations and\n\nservers\n4 DEC Turbochannel FDDI Adapters for\nworkstations\nATM Expansion 4 DEC quad line cards for GigaSwitch/ATM\n4 DEC Turbochannel ATM Adapters for\nworkstations\n2 DEC PCI ATM Adapters for workstations\nISDN Expansion\n4 Etherner/ISDN Adapters\nThe following software has been acquired to support MODIS\nprocessing\nDEC OSF1 V3.2 has been installed on most processing platforms.\nDEC OSF1 V3.4 [beta] has been installed on some processing platforms.\nThe following support has been acquired to support MODIS\nprocessing\nSybase support has been renewed.\nTGV support has been renewed.\nDEC hardware maintenance has been renewed.\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVl.OO\n\n41\n\nExpected:\nComputer Expansion - 5 DEC Alphastations 600 5/266 [266 Mhz\nprocessor, 128 MB memory each] will arrive in Q3.\nDEC OSF1 V4 [beta] will arrive in Q3.\n\nC. FUTURE ACTIVITIES\nFuture activity will focus on evolution of the initial Beta software\ndelivery from a SeaWiFS algorithm suite supported by SeaWiFS I/O\nroutines to use of prototype MODIS algorithms using the MODIS API\nas these routines become available.\nWe will receive beta versions of new operating systems for both SGI\n(the 64 bit system) and DEC, FORTRAN 90 compilers for both\nsystems, and enhanced ATM communications software and\nhardware. Results form these tests will communicate to the SDST.\nWe will explore the possibility of using elements of the HUGHES/EOS\nprocess control environment in Miami to implement an EOS\ncompliant processing framework. Discussions concerning this\napproach have been initiated.\n\nMODIS REPORT 2Q 94\n\nNAS5-31362\n\nVI.00\n\n42\n\n'