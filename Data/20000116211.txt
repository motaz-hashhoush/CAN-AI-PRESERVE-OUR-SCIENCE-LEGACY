b'The FTIO\nFrederick\n\nC.\n\nBenchmark\n\nFagerstrom\nDecember\n\nChristopher\n27,\n\nL.\n\nKuszmaul\n\n1999\n\nContents\n1\n\nIntroduction\n\n2\n\n2\n\nDesign\n\n2\n\nImplementation\n3.1\nOverview\n...............................................\n3.2\nTools ..................................................\n3.2.1\nMPI\n..............................................\n3.2.2\nFFTW\n.............................................\n\n3\n3\n3\n3\n4\n\n3.2.3\n3.9.4\n\nperfex\n............................................\nPBS\n..............................................\n\n4\n4\n\na.a\n3.4\n3.5\n\nInput Parameter\n...........................................\nInitialization\n.............................................\nDFT Series\n..............................................\n\n4\n.5\n5\n\n3.6\n3.7\n\nTransposition\n"verification\n\n5\n6\n\n4\n\nFTIO\n\n5\n\nFTIO\n5.1\n5.2\n5.3\n\n.............................................\n..............................................\n\nBenchmark\nPerformance\n\nMeets\non\n\nCriteria\nSGI\n\nOrigin2000\n\n6\n6\n7\n7\n7\n7\n\n5.4\n\n5.3.3\nSecondary\nGoal .........................................\n5.3.4\nResults\n............................................\nBenchmark\nResults\n..........................................\n\n7\n7\n7\n\n5.5\n6\n\nI/O Fraction\n.............................................\nCycles per flop\n............................................\nDetermining\nthe Input Parameter\n..................................\n5.3.1\nHypothesis\n..........................................\n5.3.2\nMethod\n............................................\n\nSpecified\n\nMatrix-Size\n\nBenchmark\n\nResults\n\nConclusion\n6.1\n\nAcknowledgments\n\n.............................\n\n8\n8\n\n...........................................\n\n8\n\nAbstract\nWe introduce\na new benchmark\nfor measuring\nthe performance\nof parallel\ninput/ouput.\nThis benchmark\nhas\nflexible initialization,\nsize. and scaling proporties\nthat allows it to satisfy seven criteria\nfor practical\nparallel\nI/O benchmarks.\nWe obtained\nperformance\nrcsuhs while running (m the, a SGI Origin2000\ncomputer\nwith wmous numbers\nof processors:\nwith 4 processors,\nthe performance\nwas 68.9 Mflop/s 1 with .52 of the time spent on I/O. with\n8 processors\nthe performance\nwas 139.3 Mflop/s\nwith .50 of the time spent on I/O, with\nperformance\nwas 173.6 Mflop/s\nwith .43 of the time spent on I/O. and with 32 processors\nwas 259.1 Mflop/s\nwith .47 of the time spent on I/O.\n\n1\n\n16 processors\nthe\nthe performance\n\nIntroduction\n\nThe NAS _ Parallel Benchmarks\n[11 have set the standard\nfor measuring\nperformance\nof distributed\ncomputer\nsystems.\nThese benchmarks\ndo not measure\nI/O. A small extension\nof the NAS Benchmarks,\ncalled NHT-1\nI/O [2], has provided\na valuable,\nif limited window\nfurther\nextended\nthe NAS Benchmarks\nto include\n\ninto the performance\nof I/O on parallel systems.\nWe have\na full out-of-core\nimplementation\nof the FT Benchmark.\n\nIn [3], six criteria\nare presented\nas characterizing\nan ideal I/O Benchmark.\nFor parallel\ncomputing,\nthe absolute\nI/O performance\nmatters,\nbut relative\nI/O performance\nis often as important.\nA subset of the\ncriteria in [3] and two additional\ncriteria\nare given for a practical\nI/O Benchmark\nof relative I/O performance\non parallel\nsystems:\n\xe2\x80\xa2 The\n\nbenchmark\n\nshould\n\nprovide\n\ninformation\n\n\xe2\x80\xa2 The benchmark\n\nshould\n\nscale\n\n\xe2\x80\xa2 The benchmark\n\nshould\n\nnot favor\n\none particular\n\n\xe2\x80\xa2 The benchmark\n\nshould\n\nmaintain\n\na tight\n\nwell both\n\nabout\n\nin terms\n\nany performance\n\nof the number\nsystem\n\nweakness\n\nof processors\n\narchitecture\n\nin the system.\n\nand the size of the problem.\n\nover another.\n\nspecification.\n\nTwo criteria\nfrom [3] that are not suited for a parallel\nI/O Benchmark\nare that the benchmark\nshould\nbe I/O limited,\nand that the benchmark\nshould be useful for predicting\nperformance\nfor a wide range of\napplications.\nThe benchmark\nshould stress I/O, but not be I/O limited.\nI/O is rarely\ndone alone, without\ninterspersed\ncomputations\nor parallel\ncommunication,\nand therefore\na benchmark\nthat strives to return relevant\nperformance\ndata should use I/O similarly\nto how it is actually\nused by applications.\nAlthough\nit would be desirable\nfor an I/O benchmark\nto be useful for predicting\nperformance\nof a wide\nvariety of applications,\nsystems\nare generally\nused for a specific application\nand optimal\nI/O performance\nI/O performance\nfor that application\nmatters\nmost.\nA more focused\nbenchmark\nwill give more relevant\nresults.\nIn addition,\nwe value following criteria:\nThe benchmark\nshould not be independent\nof the balance between\ncomputation,\ninterprocessor\ncommunication\nand I/O speeds. Rather than having the benchmark\nI/O-bound,\nit should give an upper bound of the performance\nof out-of-core\napplications.\nThe benchmark\nshould report\nrelative\nperformance---the\nsystem balance is almost as important\nas the absolute\nperformance,\nsince balance\nspeaks\n\n2\n\nto scalability.\n\nDesign\n\nIn practice,\na good I/O benchmark\nindicates\nthat one I/O system is better\nthan another\nfor a specific type\nof computation.\nThe FTIO benchmark\ngauges the relative\nperformance\nof I/O to non-I/O\noperations\nwhile\nperforming\na 2-dimensional\nDiscrete\nFourier Transform\n(DFT). The FTIO stores most data out-of-core\nand\nreads in and operates\non only small segments\nof the data at once.\ntMflop/s is million floating point operations per second.\n2NAS is Numerical Aerospace Simulation Facility\'.\n\nA 2-dimensional is defined\nDFT\nasfollows\nwhere\n$(m,n)\n3Ix.V\n\ninput\n\nmatrix\n\nand\n\n._:\xc2\xa2A\'. l) specifies\n\nspecifies\nthe element\nat position\n(k, l) of the 3,[xN\n\nthe element\n\nM - I N-\n\nat position\n(rn, n) in the\noutput\nmatrix:\n\nt\n\n(i)\nrn=l\n\nrt=0\n\nwith\n[vl\'M = e -\xc2\xa2\'z-i12\'r/M)\nW,v = e -\'/--T{\'\'_/\'\xc2\xa2)\nThus, to perform\na 2-dimensional\nDFT, it is sufficient\nto perform\ntwo sets\non the input matr}x\'s\nrows and then one on the matrix\'s\ncolumns\nor vice versa.\nBasing the FTIO on the DFT is reasonable.\nThe FTIO Benchmark\'s\ngoal\nmance during physical\nmodeling\nand simulation\ncalculations\nthat involve data\ncore. Large numerical\ncalculation\nproblems\nrely on reading\nin small portions\nmay be done sequentially,\nbut are often not, and therefore\nfactoring\nin the cost\n\nof 1-dimensional\n\nDFTs,\n\none\n\nis to gauge the I/O perforthat must be stored out-ofof data at once. The reads\nof alternating\nbetween\nseek\n\noperations\nand read/write\noperations\nis important.\nThe 2-dimensional\nDFT is well-suited\nfor an implementation that involves both seeking and sequential\nreading/writing\nof coherent\nchunks of data.\nFurthermore,\nthe i-dimensional\nphase involves interprocessor\ncommunication\nand calculation\nas would the computation\nphase of a more general class of algorithms\nthat would include many used for physical\nmodeling\nor computational fluid dynamics.\nAlthough\nthe topologies\nof communication\nor the pattern\nof file access in any specific\ncomputation\nmay differ from that of the DFT, the similarity\nin algorithms\nmakes the results\nrelevant.\nOne implementation\nfor the 2-dimensional\nDFT is to perform\na series of 1-dimensional\nDFTs--one\nto\neach row of the matrix,\ntranspose\nthe matrix,\nand perform\nanother\nseries 1-dimensional\nDFTs to the rows\nof the matrix.\nGiven that ,_(m, n) specifies the input matrix,\nthe output\nmatrix\nis specified\nby ._.\'(l, k), that\nis, the transpose\n\n3\n3.1\n\nof the output\n\nmatrix\n\ngiven\n\nin (1).\n\nImplementation\nOverview\n\nThe FTIO Benchmark\nperforms\na 2-dimensional\nFourier transform\non a large set of data partitioned\namong\nthe various\nprocessors\nused for computation.\nThis section\nincludes\nmention\nof the Tools (3.2) used to\nimplement\nthe FTIO, explanation\nof the FTIO\'s\ninput parameter\n(3.3) and discussion\nof the implementation\nfor each section of the FTIO computation:\nInitialization\n(3.4), DFT Series (3.5), Transposition\n(3.6) and\nVerification\n(3.7).\n3.2\n\nTools\n\nThe FTIO Benchmark\nwas written\nin C using the Message Passing\nInterface\n(MPI) and the Fastest Fourier\nTransform\nin the West (FFTW).\nThe program\nperfex\nwas used to collect cycle and floating point operation\n(flop) count data for the FTIO Benchmark,\nand the Portable\nBatch System\n(PBS) was used to submit\nFTIO\nto the SGI Origin2000\nCluster.\n3.2.1\n\nMPI\n\n*IPI is a library\nclusters.\nUsing\n\nspecification\nMPI, data\n\nstandard\nfor message-passing\non massively parallel machines\nand on workstation\nis explicitly\ndistributed\namong the processors.\nThe MPI standard\nand related\n\ndocuments\nare available\n[5]. FTIO uses MPI\ncommunication\nand I/O.\nData-transfer\nfor the Transposition\nphase\nplement\nsinmltaneous\ndata-exchanges\nbetween\n\nto transfer\n\ndata\n\namong\n\nprocessors\n\nis done using MPI_Sendrecv_.replace()\nprocessors.\nDuring the verification\n\nand\n\nto time\n\ncomputation,\n\nwhich is used\nphase, right before\n\nto imFTIO\n\nexits,MPI_Send()\nandMPIAtecv() reused transfer erification\na\nto\nv\nandoutputdatato processor FFTW\n0.\nDFT duringthe DFT Seriess theonly other place where interprocessor\ni\ncommunication\nis used.\nTiming\n\nis done\n\nbased\n\non wall time,\n\nnot processor\n\ntime.\n\nThe\n\nfunction\n\nMPI_Wtime()\n\nis used\n\nbefore\n\nand\n\nafter tile region of code that is going to be timed.\nBecause\ninterprocessor\ncommunication\nand [/O reads\nand writes 3 are blocking,\nthe timip.g data is accurate.\nThe runtime\nof the FTIO progrant\n(lifters from the\nruntime\nreturned\nas part _,f the benchmark\nbecause\nthe benchmark\ndoes not include overhead\nfor program\nstartup\n\nand shutdown\n\nfor running\n\n3.2.2\n\nFFTW\n\nFFTW\nroutines\n\nis a C subroutine\nlibrary\nfor computing\nthe DFT\n\nFTIO\n\nwhich\n\nfor computing\nof a complex,\n\nincludes\n\nMPI_Init\n\n() and\n\nMPI_.Finalize().\n\nthe DFT of coinplex or real vectors.\n1-dimensional\nseries of data distributed\n\nFTIO uses the FFTW\namong the processors\n\nusing MPI. Good FFTW\ndocumentation\nis available\n[4].\nFFTW uses a data-structure\ncalled a plan to perform a DFT. The plan is constructed\nto perform a forward\nDFT which means that II.x. = e -v --_12,r/N) rather than II\'x = e \'/=r{\'-\'w\'v). is used in the transform:\n7t\'(k) =\n}--7_;,=t -\\\'(n)tI\',,_ k. Estimation\nrather than measurement\nis used to determine\nthe fastest\nthe DFT. Since only two DFTs are performed,\nthe time to perform\nthe measurement\nincrease in performance\nit would yield. Also, using measurement\nmay result in a plan\ndata among the processors\nin a manor incompatible\nwith the transpose\nalgorithm.\n3.2.3\n\nplan for performing\nis greater\nthan the\nthat distributed\nthe\n\nperfex\n\nThe utility perfex\ncan be used to obtain information\non hardware\ncounters.\nDuring\nthe development\nand\ntesting of FTIO,\nwe used perfex\nto obtain the number\nof cycles and flops used by the executing\ncode. To\ninsure the flop count returned\nis right and does not undercount\ndue to the presence\nof a MADD 4 instruction\non SGI Origin2000\narchitecture,\nFTIO is compiled\nwith the option -TARG:madd=0FF.\nAlso, using perfex\nrequired\na flag in the PBS script.\nThe perfex\ncommand\nis executed\nas follows to count both cycles and flops:\nperfex-mp\n-e 21\n3.2.4\n\nPBS\n\nPBS\n\nis a flexible\n\nbatch\n\nqueuing\n\nsystem\n\n[6]. An example\n\nscript\n\nfor queuing\n\na job is given\n\nbelow:\n\n#PBS -I ncpus=64\n#PBS -i walltime=1200\n#PBS -i hpm=l\ncd $TMPDIR\nmpirua\n\n-np 64 perfex\n\n-mp -e 21 /u/fredf/finftio/ftio\n\n8\n\nThe actual number\nof processors\nused (ncpus=64)\nand the number of processors\nperceived\nby MPI (-np\n64) are both 64; the perceived\nand actual number should be the same for FTIO benchmarking.\nThe walltime\nis in seconds.\nThe hpm=l is required\nby perfex.\nThe $TMPDIR should be the location\nof the disk where the\nprocessors\ntemporary\nfiles will be kept. The FTIO Benchmark\nwill test I/O performance\nof the I/O-space\nspecified by $TMPDIR. The command\n/u/fredf/finftio/ftio\n8 executes\nthe benchmark\nand passes it the\ninput parameter\n8.\n\n3.3\n\nInput\n\nParameter\n\nThe input parameter\ndetermines\nthe width/height\nof the square matrix\nused by the FTIO Benchmark.\nThe\ninput parameter\nis passed in as a command-line\nargument,\nand determines\nthe width/height\nof the matrix\nN. Let i be the input parameter,\nand let c be the number\nof processors\nused (perceived\nby MPI). Then\naOutput\n\nis flushed\n\n_.MADD\n\nis a combined\n\nwithin\n\nthe\nmultiply\n\nwrite\nand\n\ntiming-blocks.\nadd\n\nin one\n\ninstruction.\n\n.\\r = ilc2.\nBecause\nthe FFTW\nplan must specify that data be distributed\nevenly among the processors,\ni\nand c must satisfty the two assertions:\neli" and i s ___ If either assertion\nc.\nfails, the FTIO Benchmark\nwill not\nrun. If i-" is too small or if i2 is not divisible, then FFTW does not consistently\ndistribute\nthe date correctly.\n3.4\n\nInitialization\n\nDuring the initialization\nphase, each processor\ncalculates\nWith the matrix\nsize N specified\nby the input parameter,\ninput matrix\nwhere i is the colunm\nand j is the row:\n\n?_(i. j ) = e v\'---T,-\'il/x\nwith\n\n1 <i<\n\nN, l_<j_<.V,\n\n+ e_-_("-,_l/,_"\n\nand saves to disk its portion of the input matrix.\nthe function\nY:(i.j) defines the values of the Nx.V\n\n+ imp(i,\n\nj) ,- .spike(i,\n\nj)\n\n(2)\n\nand\nimp(i,j)=\n\n0\n1\n\nspike_i.j)=\n\n0\n1\n\notherwise\nifj =(i+l)\n\nmod.V\n\notherwise\nif (i = 0) AND\n\n(j\n\n= _)\n\nThe given function\ndoes not become sparse during computation:\ntherefore\na system that can take advantage of simple compression\nof all-zero data arrays in I/O is not favored.\nThere is also a quickly-calculatable\nfunction\nthat returns\nthe values of the output\nmatrix which is used for Verification.\n3.5\n\nDFT\n\nSeries\n\nA DFT series is used after initialization\nto calculate the DFT of each row of the matrix,\nand then again after\ntransposition\nto calculate\nthe output\nmatrix.\nDuring the DFT series, each row\'s DFT is calculated:\nEach processor\nreads in its section of the row and\nuses an FFTW\nroutine\nto calculate\nthe DFT of the row. The DFT calculation\nis in-place;\nthus after the\nDFT\n3.6\n\neach\n\nprocessor\n\ncontains\n\nits portion\n\nof the result\n\nin-core.\n\nThe\n\nprocessor\n\nthen\n\nsaves\n\nthe result\n\nto disk.\n\nTransposition\n\nThe transpose\nis done by dividing\nthe matrix\nthen the Squares themselves\nare transposed.\n\nM =\n\nC\n\nD\n\ninto Squares.\nThe algorithm\n\n==* "_Ir =\n\nThe elements\nin each Square are transposed,\nis based on an extension\nof the implication\n\nBy\n\nDr\n\nand\n(3).\n\n(3)\n\nwhere A, B, C, and D are rectangular\nsub-regions\n(matrices)\nthat tile s M\nTransposing\nthe elements\nin a Square is done without\ninterprocessor\ncommunication\nbecause each Square\nresides on a single processor,\nand is carried out by compartmentalizing\nthe elements\ninto Mini-Squares,\nas\nillustrated\nin Figure 1. Each Mini-Square\nis read into memory, transposed\nand then written out to the proper\ntransposed\nlocation:\ntransposing\nthe elements\nof a square is also based on the implication\n(3). A temporary\nbuffer is used to read in the Mini-Square\nthat has not yet been transposed,\nwhile its transposed\nconjugate 6\noverwrites\nit. Any Mini-Square\nthat is its own conjugate\nties along the Main Diagonal and is written\nto the\nsame location\nfrom which it was read.\nOnce the elements\nin each Square have been transposed,\nentire Squares\nare exchanged.\nEvery processor\nmust specify which of its Squares\nto exchange\nand with which processor\nto exchange;\nthus a scheme based\non Diagonals\nis used.\n(Figure\n1 contains\nan example\nof the use of Diagonals.)\nEach processor\niterates\nthroughout\nthe Diagonals,\nand a _ven Diagonal\nspecifies which Square will be exchanged.\nIf the Square to\nexchange\nis number\ni, then the processor\nwith which to exchange\nis processor\nnumber\ni. MPI is used to\nexchange\ndata.\n5A set of sub-regions\ntile a matrix\nM if every element\nof ,lI is in one and\n6The conjugate\n(.Mini-)Square\nof a (Mini-)Square\nat location\n(x,y)\nis the\n\nonly one sub-region.\n(Mini-lSquare\nlocated\n\nat\n\n(y,.r).\n\n3.7\n\nVerification\n\nDuring\nthe verification\nphase, each processor\nuses the verification\nfunction\n(4) to calculate\nthe difference\nbetween\nthe output\nvalue in the matrix\nand the expected\nvalue.\nThe total difference\nis reported\nin the\noutput\nand can be used to gauge the accuracy\nof the system\'s\ncalculations.\nThe function\nexpected(i.j)\ndefines an .VxN alatrix\nwhere i sp<_:ifies the cohmm and j specifies the row.\n\nexpected(i,\nwith\n\n1 <i<\n\nN.\n\nj l = e -\'/=-r(\'\'-_"/\'v\n\ndiag(i.j)\n\n=\n\ne - v -_1(\n\nBenchmark\n\nif(i+j)\notherwise\n\nmod\n\nj)\n\n(4)\n\nN=0\n\nif(i=\n1) AND\nif(i=0)\nAND\notherwise\n\n(j=0)\n(j=l)\n\n2 :tj ),/N\n\n0\n\nspikes(i,\n\nFTIO\n\nj) + spikes(i,\n\n1 <_j <_.V. and\n[\n\n4\n\n+ diag(i,\n\nMeets\n\n{,\n\nj) =\n\n1\n0\n\nCriteria\n\nThe I/O-time\nratio returned\nwill indicate\nhow much I/O is slowing down the computation.\nFor example,\nif\nthe I/O Fraction\nis significantly\nabove .5, then an emphasis\nshould be placed on increasing\nI/O performance.\nFTIO is designed\nnot to take advantage\nof the performance\non any specific system.\nFFTW\nestimate\nis\nused rather\nthan measure\n_o provide\na moderate\nlevel of system-tailored\nperformance\nenhancement.\nThe\nrest of the code. however,\nis written\nto make it difficult for one system\nto do unusually\nwell due to some\nnarrow optimization.\nFTIO scales well in terms of the number of processors\nand the size of the problem.\nBecause FTIO results\nare consistent\nthroughout\na range of matrix\nsizes, it is not necessary\nto run extremely\nlarge-scale\nruns, as\na sufficiently\nlarge run is much smaller.\nAlso, the FTIO may" be run on an arbitrary\nnumber\n(within the\nconstraints\nof MPI) of processors\ngreater\nthan 1. The matrix\nsize can also be made smaller\nor larger by\nvarying the input parameter.\nThe FTIO Benchmark\nis fixed and specified.\nSpecification\nof running\nenvironments\nand system characteristics\nmust be included\nwhenever\nreporting\nresults of the FTIO Benchmark.\nThe FTIO returns\nthe I/O Fraction\nwhich is a measure\nof I/O\'s relative\nperformance.\n\n5\n\nFTIO\n\nPerformance\n\non\n\nSGI\n\nOrigin2000\n\nFTIO\nwas run using 4, 8, 16, and 32 processors\non an SGI Origin2000\nCluster\nwith 64 195 MHZ IP27\nprocessors\neach having 250 .MB of memory.\nThe disks available\nfor I/O were two 100 GB scratch-space\ndisk\narrays.\nEach disk array was set up to be equally accessible\nby any processor\nin the cluster.\nTo determine\nwhether\nit would be possible to obtain representative\ndata by running\nFTIO on relatively\nsmall matrices,\nwe\nran FTIO using a range of input parameters\nto observe how the I/O Fraction\n(5.1) and Cycles per flop (5.2)\nchange with the matrix\nsize. We estimated\nthe optimal\nmatrix size based on results from 5.1 and 5,2, and\nassembled\nbenchmark\nresults\nfor the various numbers\nof processors\n(5.4). We also developed\na benchmark\nsize-speciL\'iag\nfunction,\nassembled\nresults\nusing it and compared\nthem to the optimal\nresults (5.5).\n5.1\n\nI/O\n\nFraction\n\nFigure 2 shows the I/O Fraction\nobtained\nfrom running\nthe FTIO on 4, 8, 16 or 32 processors\nwith varying\ninput matrix\nsizes.\nThe data points graphed\nrepresent\nthe averages\nof anywhere\nfrom 1 to 4 runs, and therefore\nanomalous\nI/O-performance\nwill not \'affect them as much as if they were all data points from single runs.\nFor all the matrix sizes the I/O Fractions\nobtained\nfrom the runs stay within certain bands\nmore than .23 in width.\nThe data points obtained\nwhile running\non 4 processors\nstay within\n\nthat are not\na band from\n\n.44to .67. With 8 processors, datapointsstaywithin a bandfrom.42to .59.The 16-processor\nthe\ndata\nstay" ithina bandfrom.37to .57.And the 32-processor data are in a band from .37 to .47.\nw\n5.2\n\nCycles\n\nper\n\nflop\n\nA pattern\n_,mergos in the graphs of _\'vcles per flop in Figure 3. Averages of the input data are used as in the\nprevious\nsection.\nThe number of cycles per flop gives an estimation\nof how many cycles were spent on I/O or interprocessor\ncommunication\nas opposed to floating point computations.\nThe graphs suggest asymptotic\nconvergence.\nThe\nsmaller matrix sizes have less FTIO related computation\nto do and are therefore\nmore affected\nby transient\nI/O conditions\nand program\nstartup/shutdown\noverhead.\nExcluding\nthe small matrix\nsizes the data stay within bands no wider than 121. With 4 processors,\nthe\nall data points except the first are between\n16 and 55. With 8 processors,\nexcluding\nthe data point, data all\nfall between\n19 and 46. With 16 processors,\nexcluding\nthe first data point the band is much larger, spanning\nfrom 22 to 143. And with 32 processors,\nexcluding\nthe first data point, the band is from 38 to 62.\nBecause\nthere are bands that the data _tay within and the graphs indicate\nasymptotic\nconvergence,\nit\nmay be possible to find the I/O Fraction\nthat the FTIO would converge\nto by running\nthe FTIO using a\nsmaller\ninput parameter.\n\n5.3\n5.3.1\n\nDetermining\n\nthe\n\nInput\n\nParameter\n\nHypothesis\n\nThe hypothesis\non which the FTIO is based is that there is some I/O Fraction\nthat characterizes\na system\'s\nrelative\nI/O performance\nSince the data presented\nusing various input sizes have I/O Fractions\nthat vary, it\nmay" be presumed\nthat the hypothesis\ndoes not hold perfectly.\nYet there is some convergence\nand regularity\nto the I/O Fraction\ndata and cycles per flop data obtained.\nI/O Fraction\nbands (5.1) suggest that some\nrepresentative\nI/O Fraction\nexists.\n5.3.2\n\nMethod\n\nThe goal is to select a data point that is close to the middle of the band to find a representative\nI/O Fraction.\nData points with larger matrix sizes should be preferred\nover data points with smaller matrix\nsizes if their\nI/O Fraction\nvalues differ significantly.\nHowever, if they are the same, the smaller matrix\nsize will allow the\nI/O Benchmark\nto run in less time.\n5.3.3\n\nSecondary\n\nGoal\n\nFFTW DFT is based on code that runs faster or slower depending\non the prime factor decomposition\nof\nthe input parameters.\nThus FFTW DFT introduces\nanother\nlevel of variation\ninto the I/O Fraction data\nobtained.\nTherefore,\nas a secondary\ngoal the matrix sizes one chooses should result in input parameters\nthat\nhave similar prime factor decompositions.\n5.3.4\n\nResults\n\nWe select the third data point of the 32-processor\nrun data because\nit is the largest\ninput value available.\nThe third data point for 32 processors\ncorresponds\nto an input parameter\nof 24, which is an input parameter\nthat is associated\nwith a valid input for each other number of processors,\nAnd thus, to satisfy the secondary\ngoal of having similarly\nprime factors for each input parameter\nto make performance\ncomparison\nbetween the\ndifferent\nnumbers\nof processors\nsignificant,\nwe use 24 as the input parameter\nfor every number of processors.\n5.4\n\nBenchmark\n\nA more accurate\nI/O\nanalyzing\nthe results.\n\nResults\nFraction can be obtained\nby running\nthe benchmark\nmultiple\ntimes and then statistically\nUsing the input parameter\n24 determined\nin the previous section, we measured\nthe I/O\n\nFraction\nmultipletimes\nforeach\nnumberf\no\nI/O\n\nFraction\n\nI Number\n\nfor the number\n\nof processors.\n\nof Processors\n\nprocessors.\nThe average of the I/O\nTable 1 contains\nthe results.\n\n4\n\nI 8\n\n16\n\n24\n.52\n\n24\n: .50\n\n24\n.43\n\n24\n.I7\n\ni Total\n\n68.9\n\nla9.a\n\n173.6\n\n259.1\n\n1: I/O\n\nFraction\n\nis the representative\n\n32\n\nEstimated\nInput Parameter\n[ Average of I/O Fractions\n\nFractions\n\nJ\n\nMttop/s\n\nk\n\nTable\nGraphs\n\nof the data\n\ncollected\n\nfor 4 processors.\n\nBenchmark\n\n8 processors,\n\nResults\n\n16 processors\n\nand\n\n32 processors\n\nare in Figure\n\n4.\n\n5.5\n\nSpecified\n\nMatrix-Size\n\nBenchmark\n\nResults\n\nGraphing\nthe I/O Fractions\nfor various input parameters,\nthen picking an input parameter\n(and thus matrix\nsize) large enough\nto yield accurate\nenough results takes time and relies on human judgment.\nIt would be\nbetter to have a way to pick the input parameter\nto directly\ncalculate\nthe I/O Fraction.\nWe hypothesize\nthat the following function\nwill give input parameters\nthat yield good I/O-Fraction\nresults:\n\ninputParameter(c)\n\n= the lowest\n\nwhere c is the number\nof processors.\nWe collected\nI/O Fraction\ndata using\n16 processors,\nand 32 processors.\nGraphs\nin Table 2.\nNumber of Processors\nSpecified Input Parameter\nAverage of I/O Fractions\nDifference\nError\n\nvalid\n\ninput\n\nthe input-parameter\nof the data obtained\n\n14\n18\n4\n] 4\n.58\n.51\n.06\n.01\n11.5c7c\n2.0%\n\n16\n8\n.56\n.13\n30.2%\n\nTable 2: I/O Fraction\nSpecified\nMatrix-Size\nResults.\nhere and the corresponding\nI/O Fraction\nin Table\nFraction\nfrom Table 1.\n\n6\n\nparameter\n\ngreater\n\nthan\n\nor equal\n\n(5)\n\nto v_ + 1\n\nspecified\nby (5) on 4 processors,\n8 processors,\nare in Figure 5 and the I/O Fraction\ndata is\n\n32\n8\n.39\n-.08\n17.0%\nDifference\nis the difference\nError is the Difference\n\n1.\n\nbetween\nthe I/O Fraction\ndivided\nby the actual I/O\n\nConclusion\n\nWe have introduced\ncriteria for a benchmark\nthat returns\nI/O performance\nrelative\nto the other operations\nrequired\nfor parallel\ncomputation\nsuch as interprocessor\ncommunication\nand floating\npoint calculation.\nWe\ndiscuss the design and implementation\nof the FTIO Benchmark\nand conclude\nthat it meets the criteria\nfor\nmeasuring\nrelative\nI/O performance\ndata. We test the performance\nof a SGI Origin2000\nCluster,\nand in the\nprocess develop a function\nthat specifies\nan input parameter\nthat yields an I/O Fraction\nwithin 30% of the\nactual benchmark\nvalue.\nWe look forward to having\nthe benchmark,\nplease contact\n\n6.1\n\nothers try the FTIO\nfyodor\xc2\xa9nas.nasa.gov.\n\nBenchmark\n\non a variety\n\nof systems.\n\nTo obtain\n\na copy\n\nAcknowledgments\n\nWe thank\nMRJ Technology\nWong, and Louis Zechtzer\nFFTW.\n\nSolutions,\n,Jeffrey Becker,\nEdward\nHook, Bill Nitzberg,\nDoug\nfor their support,\nand Matthew\nFrigo and Steven\nG. Johnson\n\nSakal, Parkson\nfor developing\n\nof\n\nprocessor\n0\n\nprocessor processor\n1\n2\n\n,"\n_i.\'.._.._\'x.._::"\n::\n:4":\'.\nSquare 0\n\n_\':,-,\'\\ ,_N\':::\':\',%"\n\n,"\n\nprocessor\n\n/\n16x16 Square\n\n,"\n\n,\nSquare 1\n\n,\n\n..\n\n,\'"\n\n:::"\n....\n\n..\'"\n\n_,_\n[_\n\nSquare\n\n2\n\nI\n\n4x4 Mini-Square\n\n-\'""\n_-_\n\n\xe2\x80\xa2 .-.\n.\n,\n\n3\n\n/\n\nMain Diag\xc2\xb0nal\n\nI\n\n,\'"\n\n/\n\nes\n\nS\n\nJ\n/\n\n....\n.. \'"\'\n\n,," "\n\n."\n\n.\n\n\xe2\x80\xa2\n\n0\n\n---\n\nDiagonal\n\n1\n\nDiagonal\n\n2\n\nDiagonal\n\nSq uare 3\n\nDiagonal\n\n3\n\n\xe2\x80\xa2\n\nFigure\n1:64x64\nMatrix\non 4 processors.\nAn illustration\nof the the distribution\nof data among the processors\nand organization\nused for transposing.\nEach processor\nstores one column of Squares.\nThe width of a Square\nis 16 = 64/4, the width of the entire matrix\ndivided\nby the number\nof processors.\nA Square is composed\nof Mini-Squares\nwhich have width 4 = v/_, the square\nroot of the Square\'s\nwidth.\nThe Main Diagonal\nof\nthe entire matrix,\nor of a Square is indicated\nby shading.\nAnd the Diagonals\nused to organize\ninterprocessor\ncommunication\nare indicated\nby lines. For example,\nDiagonal\n0 prompts\nthe following actions:\nSquare 0\non processor\n0 remains\nstationary:\nSquare 3 of processor\n1 is exchanged\nwith Square\n1 of processor\n3; and\nSquare 2 of processor\n2 remains\nstationary.\n\n4-Processor\n\nI/0 Fractions\n\n07\n065 \'\n\n5\n\n0.6\n\n\xc2\xa20\n\n0.55\n\no\n\n0.5\n045\n04\n\n1\n\nI\n\n5e+07\n\nI\n\n8-Processor\n0.6\n\n[\n\nI\n\n! e+08\n1 5e+08\nMatrix Size (number of elements)\n\nr\n\nI\n\n2e+08\n\n2 5e+08\n\nI/0 Fractions\n\nI\n\nI\n\nl\n\n_\n\nI\n\n0.58\n0.56\n\ng\n\n0.54\n0.52\n\nLI.\n\no\n\n0.5\n0.48\n0,46\n0.44\n0.42\n\nI\n\n0\n\nI\n\n2e4-07\n\nA\n\n4e+07\n\n6e+07\n8e+07\nle+08\n12e+08\nMatrix Size (number of elements)\n\n16-Processor\n\n,to\n\n058\n0.56\n0.54\n0.52\n0.5\n0.48\n0.46\n044\n042\n0,4\n0.38\n0.36\n\nI\n\nI\n\n5e+07\n\n1.4e+08\n\n1 6e+08\n\n1 8e+08\n\nI/0 Fractions\n\nI\n\nI\n\nI\n\nI e+08\n15e+08\n2e+08\nMatrix Size (number of elements)\n\n2.5e+08\n\n3e+08\n\n32-Processor I/0 Fractions\n0.47\n\n!\n\nI\n\nI\n\nI\n\nI\n\ni\n\n046\n045\n0.44\n0.43\n0.42\n041\n0.4\n0.39\n0,38\n0.37\n\nI\n\n0\n\n5e+07\n\nI\n\nle+08\n\nI\n\nI\n\nI\n\n1.5e+08\n2e+08\nMatrix Size (number of elements)\n\nFigure\n\n2: Estimation\n\nusing\n\n10\n\nI\n\n25e+08\n\nI/O\n\n3e+08\n\nFractions\n\n3.5e+08\n\n4-Processor\n\nCycles/flop\n\n7O\n60\n0.\n\nS\n\n50\n\nLL\n\n40\n30\n(3\n20\nlo\n5e+o7\n\no\n\n_ e\xc3\xb7o8\n1 5e+o8\nSize ;f Matrix (number of elements)\n\nB-Processor\n200\n180\n\ni\n\n_\n\n2.5e+08\n\n2e+o8\n\nCyclesJflop\n\nF\n\ni\n\ni\n\ni\n\nl\n\nI\n\nI\n\ni\n\nl\n\ni\n\n160\n0..\n\no\n\n140\n\nu_\n\n120\n100\n8O\n\n(3\n\n60\n4O\n2O\ni\n\n0\n0\n\nl\n\n2e+07\n\n4e+07\n\nI\n\n16-Processor\n350\n\nI\n\n1.4e+08\n\n6e+07\n8e+07\n1 e+08\n1 2e+08\nSize ot Matrix (number of elements)\n\nt 6e+08\n\n18e+08\n\nCycles/flop\n\ni\n\ni\n\nI\n\ni\n\nI\n\ni\n\n3OO\n[3.\n\no\n\n250\n\nU_\n\n2O0\n\nQ.\n\n(3\n\n150\n100\n50\n@\nI\n\n0\n0\n\nI\n\n1e+08\n1 5e+08\n2e+08\nSize of Matrix (number of elements)\n\n5e+07\n\n32-Processor\n\n2.5e+08\n\n3e+08\n\nCycles/flop\n\n2O0\n180\nn\n\no\n\n160\n140\n120\n1O0\n\n1\n\ni\n\nI\n\nI\n\ni\n\n1\n\ni\n\nI\n\nI\n\n80\n(3\n\n60\n4O\n\n.@\nI\n\n2O\n0\n\n5e+07\n\n1 e+08\n\nI\n\n2.5e+08\n1.5e+08\n2e+08\nSize of Matrix (number of elements)\n\nFigure\n\n3: Estimation\n\nusing\n\n11\n\n3e+08\n\nCycles/flop.\n\n3.5e+08\n\n4-Processor\n\nBenchmark\n\n075\n07\n0.65\no\n_\n\n06\n0.55\n0.5\no\n0.45\n\nS\nI\n\n04\n4.6e+06\n\nl\n\n48e+06\n\nI\n\n5e+06\n\ni\n\n52e+06\nMa_ix\n\ni\n\ni\n\nJ\n\n56e+06\n\n58e+06\n\n6e+06\n\nSize(numberofelements)\n\n8- Processor\n0.65\n\nI\n\n5.4e+06\n\nl\n\nBenchmark\n\nI\n\nI\n\nI\n\nI\n\nI\n\n0\n06\ne.\n9\n"5\n\n0\n0\n\n0.55\n\n0\nQ\n\n0\n\n05\n0 45\n\n0.4\n19e+07\n\ni\n\n1\n\ni\n\n2e\xc3\xb707\n\n196e+07\n\n20_..37\n\nI\n\nQ\n\n21e+07\n\nMatrix\n\nSize\n\ni\n\n(number\n\n16-Processor\n0.55\n\ni\n\ni\n\n1\n\nI\n\n0\n\n22e+07\n\nt\n22_+07\n\ni\n23e+07\n\n235e+07\n\nof elements)\n\nBenchmark\no\n\ni\n\n]\n\ni\n\ni\n\no\n\n0.5\n\n-_\n\nI\n\n215e+07\n\nO.45\n\n0.4\n\no\n\n0.35\nQ\n03\n7.6e+07\n\nJ\n7Be+07\n\nA\n8e+07\n\ni\n82e+07\n\ni\n8.4e+07\n\nMarx\n\nSize\n\nI\n8,6e+07\n\n(number\n\n32-Processor\n\nJ\n8.8e+07\n\ni\n9e+07\n\nI\n92e+07\n\n94e+07\n\nof elements)\n\nBenchmark\n\n056\no\n\n0.54\n_"\nQ\n_\nLL\n\n052\no\n0.5\n048\n\n04s\n0.44\n3e+08\n\n$\ni\n3.te+08\n\ni\n3.2e+08\n\n_\n\n_1\n\n3.3e-,-08\nMat_x\n\n3.4e+08\nSize\n\n(number\n\nFigure\n\ni\n3.5e+08\n\nJ\n3.6e+08\n\nof elements_\n\n4: Benchmark\n\n12\n\nData.\n\ni\n37e+08\n\n38e+08\n\n4-Processor\n1\n\ni\n\nSpecified.input\n\nu\n\nBenchmark\n\n_\n\nb\n\nu\n\no9\n08\n0.7\nLL\n\no\n\nO6\n\nO\n\n0.5\n04\n03\n\ni\n\n36o0\n\nI\n\nI\n\n3700\n\n3800\n\n3900\n\nI\n\nI\n\nI\n\n1\n\nB-Processor\n\nSpecified-Input\n\nI\n\n4300\n\n4000\n4100\n4200\nMatrix Size(numberofelements)\n\n44OO\n\nI,\n\n4500\n\n4600\n\nBenchmark\n\n09\n0.8\n\n8\n\n0,7\n0.6\n0.5\n0.4\n0.3\n14500\n\nl\n\n15000\n\n15500\n\nI\n\nI\n\nI\n\n16000\n16500\n17000\nMatrix Size (number of elements)\n\n16-Processor Specified-Input\n\nI\n\n17500\n\n18o0o\n\n185oo\n\nBenchmark\n\n065\n06\n055\nu_\n0\n\n0.5\n0.45\n0.4\n900000\n\nI\n<_\ni\nle+06\n1 05e+06\n1 .le+06\nMatrix Size (number of elements)\n\ni\n\n950000\n\n32-Processor\n\nI\nI. 15e+06\n\n1.2e+06\n\nSpecified-Input Benchmark\n\n0.55\nI\n\n1\n\nOI\n\nI\n\nI\n\nI\n\nl\n\n0.5\n0.45\n\n$\n\n0.4\n0\n\n035\n0\n\n03\n025\n37e+06\n\nC,\n\nJ\n3.8e+06\n\nL\n3.9e+06\n\nI\n\nI\n\n4e+06\n\nI\n\n41e+06\n42e+06\n4.3e+06\n4.4e+06\nMaerix Size (number ot elements)\n\nFigure\n\n5: Specified-Input\n\n13\n\ni\n\n4.5e+06\n\nBenchmark\n\nI\n\n4.6e+06\n\nData.\n\n4.7e+06\n\nReferences\n[1] D. H. Bailey, E. Barszcz..J.T.\nBarton.\nD. S. Browning,\nR. L. Carter,\nD. Dagum,\nR. A. Fatoohi.\nP. O.\nFrederickson.\nT. A. Lasinski.\nR. S. Schreiber,\nH. D. Simon, V. Venkatakrishnan,\nand S. K. Weeratunga.\nThe NAS Parallel\nBenchmarks.\nThe International\nJournal\nof Supercomputer\nApplications.\n5(3):63-73,\nFall 1991.\n[2] Russell Carter.\nBob Ciotti.\nRND-92-016.\nNAS Systems\n[3] P. M. Chen\nbenchmarks,\n[4] Matteo\n[5] http\n\nFrigo\n\nSam Fineberg,\nand Bill Nitzberg.\nDivision,\nNASA Ames, November\n\nNHT-1\n1992.\n\nI/O\n\nand D. A. Patterson.\nA new approach\nto I/O performance\npredicted\nI/O performance.\nACM Transactions\non Computer\nand\n\n: //www-unix.\n\nSteven\n\nG..Johnson.\n\nmcs. an].\n\nhttp://www.fftw.org.\n\ngov/mpi/index,\n\nhtml.\n\n[6]http://pbs .mrj. corn/.\n\n14\n\nbenchmarks.\n\nTechnical\n\nevaluation\n- self-scaling\nSystems,\n12.4:309-339,\n\nReport\n\nI/O\n1994.\n\n'