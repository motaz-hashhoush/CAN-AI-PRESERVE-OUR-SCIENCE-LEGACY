b'8-13\n\nAugust 2013\n\nTechnology Focus\nElectronics/Computers\nSoftware\nMaterials\nMechanics/Machinery\nManufacturing\nBio-Medical\nPhysical Sciences\nInformation Sciences\nBooks and Reports\n\nINTRODUCTION\nTech Briefs are short announcements of innovations originating from research and development\nactivities of the National Aeronautics and Space Administration. They emphasize information considered likely to be transferable across industrial, regional, or disciplinary lines and are issued to\nencourage commercial application.\n\nAdditional Information on NASA Tech Briefs and TSPs\nAdditional information announced herein may be obtained from the NASA Technical Reports Server:\nhttp://ntrs.nasa.gov.\nPlease reference the control numbers appearing at the end of each Tech Brief. Information on NASA\xe2\x80\x99s\nInnovative Partnerships Program (IPP), its documents, and services is available on the World Wide Web\nat http://www.ipp.nasa.gov.\nInnovative Partnerships Offices are located at NASA field centers to provide technology-transfer access to\nindustrial users. Inquiries can be made by contacting NASA field centers listed below.\n\nNASA Field Centers and Program Offices\nAmes Research Center\nDavid Morse\n(650) 604-4724\ndavid.r.morse@nasa.gov\n\nJohnson Space Center\nJohn E. James\n(281) 483-3809\njohn.e.james@nasa.gov\n\nDryden Flight Research Center\nRon Young\n(661) 276-3741\nronald.m.young@nasa.gov\n\nKennedy Space Center\nDavid R. Makufka\n(321) 867-6227\ndavid.r.makufka@nasa.gov\n\nGlenn Research Center\nKimberly A. Dalgleish-Miller\n(216) 433-8047\nkimberly.a.dalgleish@nasa.gov\n\nLangley Research Center\nMichelle Ferebee\n(757) 864-5617\nmichelle.t.ferebee@nasa.gov\n\nGoddard Space Flight Center\nNona Cheeks\n(301) 286-5810\nnona.k.cheeks@nasa.gov\n\nMarshall Space Flight Center\nTerry L. Taylor\n(256) 544-5916\nterry.taylor@nasa.gov\n\nJet Propulsion Laboratory\nDan Broderick\n(818) 354-1314\ndaniel.f.broderick@jpl.nasa.gov\n\nStennis Space Center\nRamona Travis\n(228) 688-3832\nramona.e.travis@ssc.nasa.gov\n\nNASA Tech Briefs, August 2013\n\nNASA Headquarters\nDaniel Lockney,\nTechnology Transfer Program Executive\n(202) 358-2037\ndaniel.p.lockney@nasa.gov\nSmall Business Innovation Research\n(SBIR) & Small Business Technology\nTransfer (STTR) Programs\nRich Leshner, Program Executive\n(202) 358-4920\nrleshner@nasa.gov\n\n1\n\n8-13\n\nAugust 2013\n\n5\n5\n5\n6\n6\n\nTechnology Focus:\nMechanical Components\nRadial Internal Material Handling System (RIMS) for\nCircular Habitat Volumes\nConical Seat Shut-Off Valve\nImpact-Actuated Digging Tool for Lunar Excavation\nFlexible Mechanical Conveyors for Regolith Extraction\nand Transport\n\n17\n\nPhysical Sciences\n\n17\n\nCRUQS: A Miniature Fine Sun Sensor for\nNanosatellites\nOn-Chip Microfluidic Components for In Situ\nAnalysis, Separation, and Detection of Amino Acids\nSpectroscopic Determination of Trace Contaminants\nin High-Purity Oxygen\nMethod of Separating Oxygen From Spacecraft Cabin\nAir to Enable Extravehicular Activities\nAtomic Force Microscope Mediated Chromatography\n\n17\n18\n19\n\n7\n\nElectronics/Computers\n\n19\n\n7\n\nRemote Memory Access Protocol Target Node\nIntellectual Property\nSoft Decision Analyzer\nDistributed Prognostics and Health Management\nWith a Wireless Network Architecture\nMinimal Power Latch for Single-Slope ADCs\n\n21\n\nInformation Technology\n\n21\n21\n22\n\nSample Analysis at Mars Instrument Simulator\nAccess Control of Web- and Java-Based Applications\nTool for Automated Retrieval of Generic Event Tracks\n(TARGET)\nBilayer Protograph Codes for Half-Duplex Relay\nChannels\nInfluence of Computational Drop Representation in\nLES of a Droplet-Laden Mixing Layer\n\n7\n8\n8\n\n11\n\nManufacturing & Prototyping\n\n11\n\nBismuth Passivation Technique for High-Resolution\nX-Ray Detectors\n\n13\n\n23\n\nMaterials & Coatings\n\n13\n14\n\n22\n\nHigh-Strength, Superelastic Compounds\nCu-Cr-Nb-Zr Alloy for Rocket Engines and Other\nHigh-Heat-Flux Applications\nMicrogravity Storage Vessels and Conveying-Line\nFeeders for Cohesive Regolith\n\n14\n\nThis document was prepared under the sponsorship of the National Aeronautics and Space Administration. Neither the United States Government nor any person acting on behalf of the United States Government assumes any liability resulting from the use of the information contained\nin this document, or warrants that such use will be free from privately owned rights.\nNASA Tech Briefs, August 2013\n\n3\n\nTechnology Focus: Mechanical Components\nRadial Internal Material Handling System (RIMS) for Circular\nHabitat Volumes\nThe novelty of this system is its configuration as a circular habitat.\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nOn planetary surfaces, pressurized\nhuman habitable volumes will require a\nmeans to carry equipment around\nwithin the volume of the habitat, regardless of the partial gravity (Earth, Moon,\nMars, etc.). On the NASA Habitat\nDemonstration Unit (HDU), a vertical\ncylindrical volume, it was determined\nthat a variety of heavy items would need\nto be carried back and forth from deployed locations to the General Maintenance Work Station (GMWS) when in\nneed of repair, and other equipment\nmay need to be carried inside for repairs, such as rover parts and other external equipment.\nThe vertical cylindrical volume of the\nHDU lent itself to a circular overhead\ntrack and hoist system that allows lifting\nof heavy objects from anywhere in the\nhabitat to any other point in the habitat\ninterior. In addition, the system is able to\nhand-off lifted items to other material\nhandling systems through the side\nhatches, such as through an airlock.\nThe overhead system consists of two\nconcentric circle tracks that have a movable beam between them. The beam has\n\nM\nMHS outer\ntrack\nt\nU\nUnderside of\nfold-down\nf\ns\nstowage units\nM\nMHS inner\ntrack\nt\nC\nCross beam\nwith hoist\nw\nH\nHDU module\nwith\nintegrated\nsubsystems\n\nThe HDU Material Handling System and stowage system installed on the ceiling of the habitat.\n\na hoist carriage that can move back and\nforth on the beam. Therefore, the entire\nsystem acts like a bridge crane curved\naround to meet itself in a circle.\nThe novelty of the system is in its configuration, and how it interfaces with the\nvolume of the HDU habitat. Similar to\nhow a bridge crane allows coverage for\nan entire rectangular volume, the RIMS\nsystem covers a circular volume.\n\nThe RIMS system is the first generation of what may be applied to future\nplanetary surface vertical cylinder habitats on the Moon or on Mars.\nThis work was done by Alan S. Howe of\nCaltech; and Sally Haselschwardt, Alex Bogatko, Brian Humphrey, and Amit Patel of\nthe University of Michigan for NASA\xe2\x80\x99s Jet\nPropulsion Laboratory. For more information,\ncontact iaoffice@jpl.nasa.gov. NPO-48293\n\nConical Seat Shut-Off Valve\nThis valve has applications in high-pressure and high-flow conditions.\nStennis Space Center, Mississippi\nA moveable valve for controlling flow\nof a pressurized working fluid was designed. This valve consists of a hollow,\nmoveable floating piston pressed against\na stationary solid seat, and can use the\nworking fluid to seal the valve. This\nopen/closed, novel valve is able to use\nmetal-to-metal seats, without requiring\nseat sliding action; therefore there are\nno associated damaging effects.\nDuring use, existing standard highpressure ball valve seats tend to become\ndamaged during rotation of the ball.\nAdditionally, forces acting on the ball\n\nand stem create large amounts of friction. The combination of these effects\ncan lead to system failure. In an attempt\nto reduce damaging effects and seat failures, soft seats in the ball valve have\nbeen eliminated; however, the sliding action of the ball across the highly loaded\nseat still tends to scratch the seat, causing failure. Also, in order to operate,\nball valves require the use of large actuators. Positioning the metal-to-metal\nseats requires more loading, which tends\nto increase the size of the required actuator, and can also lead to other failures\n\nin other areas such as the stem and bearing mechanisms, thus increasing cost\nand maintenance.\nThis novel non-sliding seat surface\nvalve allows metal-to-metal seats without\nthe damaging effects that can lead to\nfailure, and enables large seating forces\nwithout damaging the valve. Additionally, this valve design, even when\nused with large, high-pressure applications, does not require large conventional valve actuators and the valve stem\nitself is eliminated. Actuation is\nachieved with the use of a small, simple\n\nsolenoid valve. This design also eliminates the need for many seals used with\nexisting ball valve and globe valve designs, which commonly cause failure,\ntoo. This, coupled with the elimination\nof the valve stem and conventional\nvalve actuator, improves valve reliability\nand seat life.\nOther mechanical liftoff seats have\nbeen designed; however, they have only\n\nresulted in increased cost, and incurred\nother reliability issues. With this novel\ndesign, the seat is lifted by simply removing the working fluid pressure that\npresses it against the seat and no external force is required.\nBy eliminating variables associated\nwith existing ball and globe configurations that can have damaging effects\nupon a valve, this novel design reduces\n\ndowntime in rocket engine test schedules and maintenance costs.\nThis work was done by Bruce Farner of\nStennis Space Center, (U.S. Patent\n#8,336,849), and is available for licensing. For more information contact the SSC\nOffice of the Center Chief Technologist at\n(228) 688-1929 or by e-mail SSC-Technology@nasa.gov. Refer to SSC-00264.\n\nImpact-Actuated Digging Tool for Lunar Excavation\nJohn F. Kennedy Space Center, Florida\nNASA\xe2\x80\x99s plans for a lunar outpost require extensive excavation. The Lunar\nSurface Systems Project Office projects\nthat thousands of tons of lunar soil will\nneed to be moved. Conventional excavators dig through soil by brute force, and\ndepend upon their substantial weight to\nreact to the forces generated. This approach will not be feasible on the Moon\nfor two reasons: (1) gravity is 1/6th that\non Earth, which means that a kg on the\nMoon will supply 1/6 the down force\nthat it does on Earth, and (2) transportation costs (at the time of this reporting)\nof $50K to $100K per kg make massive\nexcavators economically unattractive.\nA percussive excavation system was\ndeveloped for use in vacuum or nearvacuum environments. It reduces the\n\ndown force needed for excavation by an\norder of magnitude by using percussion\nto assist in soil penetration and digging.\nThe novelty of this excavator is that it incorporates a percussive mechanism\nsuited to sustained operation in a vacuum environment.\nA percussive digger breadboard was\ndesigned, built, and successfully tested\nunder both ambient and vacuum conditions. The breadboard was run in vacuum to more than 2 times the lifetime of\nthe Apollo Lunar Surface Drill, throughout which the mechanism performed\nand held up well. The percussive digger\nwas demonstrated to reduce the force\nnecessary for digging in lunar soil simulant by an order of magnitude, providing reductions as high as 45:1.\n\nThis is an enabling technology for\nlunar site preparation and ISRU (In Situ\nResource Utilization) mining activities. At\ntransportation costs of $50K to $100K per\nkg, reducing digging forces by an order of\nmagnitude translates into billions of dollars saved by not launching heavier systems to accomplish excavation tasks necessary to the establishment of a lunar\noutpost. Applications on the lunar surface\ninclude excavation for habitats, construction of roads, landing pads, berms, foundations, habitat shielding, and ISRU.\nThis work was done by Jack Wilson, Philip\nChu, Jack Craft, Kris Zacny, and Chris Santoro of Honeybee Robotics Ltd. for Kennedy\nSpace Center. For further information, contact\nthe Kennedy Innovative Partnerships Program Office at (321) 861-7158. KSC-13398\n\nFlexible Mechanical Conveyors for Regolith Extraction\nand Transport\nJohn H. Glenn Research Center, Cleveland, Ohio\nA report describes flexible mechanical\nconveying systems for transporting fine\ncohesive regolith under microgravity\nand vacuum conditions. They are totally\nenclosed, virtually dust-free, and can include enough flexibility in the conveying\npath to enable an expanded range of extraction and transport scenarios, including nonlinear drill-holes and excavation\nof enlarged subsurface openings without\nlarge entry holes.\nThe design of the conveyors is a modification of conventional screw conveyors such that the central screw-shaft\n\n6\n\nand the outer housing or conveyingtube have a degree of bending flexibility, allowing the conveyors to become\nnonlinear conveying systems that can\nconvey around gentle bends. The central flexible shaft is similar to those\nused in common tools like a \xe2\x80\x9cweed\nwhacker,\xe2\x80\x9d consisting of multiple layers\nof tightly wound wires around a central\nwire core.\nUtilization of compliant components\n(screw blade or outer wall) increases the\nrobustness of the conveying, allowing an\noccasional oversized particle to pass\n\nthough the conveyor without causing a\njam or stoppage.\nThis work was done by Otis R. Walton and\nHubert J. Vollmer of Grainflow Dynamics Inc.,\nand Ali Abdel-Hadi of Tuskegee University for\nGlenn Research Center. Further information is\ncontained in a TSP (see page 1).\nInquiries concerning rights for the commercial use of this invention should be addressed\nto NASA Glenn Research Center, Innovative\nPartnerships Office, Attn: Steven Fedor, Mail\nStop 4\xe2\x80\x938, 21000 Brookpark Road, Cleveland, Ohio 44135. Refer to LEW-19015-1.\n\nNASA Tech Briefs, August 2013\n\nElectronics/Computers\nRemote Memory Access Protocol Target Node\nIntellectual Property\nGoddard Space Flight Center, Greenbelt, Maryland\nThe MagnetoSpheric Multiscale\n(MMS) mission had a requirement to\nuse the Remote Memory Access Protocol\n(RMAP) over its SpaceWire network. At\nthe time, no known intellectual property\n(IP) cores were available for purchase.\nAdditionally, MMS preferred to implement the RMAP functionality with control over the low-level details of the design. For example, not all the RMAP\nstandard functionality was needed, and\nit was desired to implement only the portions of the RMAP protocol that were\nneeded. RMAP functionality had been\npreviously implemented in commercial\noff-the-shelf (COTS) products, but the\nIP core was not available for purchase.\nThe RMAP Target IP core is a VHDL\n(VHSIC Hardware Description Lan-\n\nguage) description of a digital logic design suitable for implementation in an\nFPGA (field-programmable gate array)\nor ASIC (application-specific integrated\ncircuit) that parses SpaceWire packets\nthat conform to the RMAP standard.\nThe RMAP packet protocol allows a network host to access and control a target\ndevice using address mapping. This capability allows SpaceWire devices to be\nmanaged in a standardized way that simplifies the hardware design of the device, as well as the development of the\nsoftware that controls the device.\nThe RMAP Target IP core has some\nfeatures that are unique and not specified in the RMAP standard. One such\nfeature is the ability to automatically\nabort transactions if the back-end logic\n\ndoes not respond to read/write requests\nwithin a predefined time. When a request times out, the RMAP Target IP\ncore automatically retracts the request\nand returns a command response with\nan appropriate status in the response\npacket\xe2\x80\x99s header. Another such feature is\nthe ability to control the SpaceWire\nnode or router using RMAP transactions\nin the extended address range. This allows the SpaceWire network host to\nmanage the SpaceWire network elements using RMAP packets, which reduces the number of protocols that the\nnetwork host needs to support.\nThis work was done by Omar Haddad of Goddard Space Flight Center. Further information\nis contained in a TSP (see page 1). GSC16467-1\n\nSoft Decision Analyzer\nAn in-depth insight of a communication system\xe2\x80\x99s receiver performance is provided in a variety\nof operating conditions.\nLyndon B. Johnson Space Center, Houston, Texas\nThe Soft Decision Analyzer (SDA) is\nan instrument that combines hardware,\nfirmware, and software to perform realtime closed-loop end-to-end statistical\nanalysis of single- or dual-channel serial\ndigital RF communications systems operating in very low signal-to-noise conditions. As an innovation, the unique SDA\ncapabilities allow it to perform analysis\nof situations where the receiving communication system slips bits due to low\nsignal-to-noise conditions or experiences constellation rotations resulting in\nchannel polarity in versions or channel\nassignment swaps. SDA\xe2\x80\x99s closed-loop detection allows it to instrument a live system and correlate observations with\nframe, codeword, and packet losses, as\nwell as Quality of Service (QoS) and\nQuality of Experience (QoE) events.\nThe SDA\xe2\x80\x99s abilities are not confined to\nperforming analysis in low signal-tonoise conditions. Its analysis provides in-\n\nNASA Tech Briefs, August 2013\n\ndepth insight of a communication system\xe2\x80\x99s receiver performance in a variety\nof operating conditions.\nThe SDA incorporates two techniques\nfor identifying slips. The first is an examination of content of the received data\nstream\xe2\x80\x99 s relation to the transmitted data\ncontent and the second is a direct examination of the receiver\xe2\x80\x99s recovered clock\nsignals relative to a reference. Both techniques provide benefits in different ways\nand allow the communication engineer\nevaluating test results increased confidence and understanding of receiver\nperformance. Direct examination of\ndata contents is performed by two different data techniques, power correlation\nor a modified Massey correlation, and\ncan be applied to soft decision data\nwidths 1 to 12 bits wide over a correlation depth ranging from 16 to 512 samples. The SDA detects receiver bit slips\nwithin a \xc2\xb14 bits window and can handle\n\nsystems with up to four quadrants\n(QPSK, SQPSK, and BPSK systems). The\nSDA continuously monitors correlation\nresults to characterize slips and quadrant change and is capable of performing analysis even when the receiver\nunder test is subjected to conditions\nwhere its performance degrades to high\nerror rates (30 percent or beyond). The\ndesign incorporates a number of features, such as watchdog triggers that permit the SDA system to recover from\nlarge receiver upsets automatically and\ncontinue accumulating performance\nanalysis unaided by operator intervention. This accommodates tests that can\nlast in the order of days in order to gain\nstatistical confidence in results and is\nalso useful for capturing snapshots of\nrare events.\nSlip and quadrant performance are displayed in real time in addition to being\nlogged for later analysis. The SDA pro-\n\n7\n\nvides methods of evaluating the significance of BER (bit error rate) test results as\nwell as techniques to characterize imbalances due to inter-symbol interference or\ninter-channel interference. Techniques\nemployed in the SDA provide a means to\nstatistically characterize receiver performance efficiently using a minimum of accumulated test results with a definable level\n\nof error. These advanced techniques have\nbroad application to other fields that rely\non evaluation of binomial experiments\n(pass/fail, true/false, go/no-go), and\nallow evaluators to extract more information from fewer trials.\nThis work was done by Glen Steele,\nChatwin Lansdowne, Joan Zucha, and Adam\nSchlesinger of Johnson Space Center. For fur-\n\nther information, contact the JSC Innovation\nPartnerships Office at (281) 483-3809.\nThis invention is owned by NASA, and a\npatent application has been filed. Inquiries\nconcerning nonexclusive or exclusive license\nfor its commercial development should be addressed to the Patent Counsel, Johnson Space\nCenter, (281) 483-1003. Refer to MSC24798-1.\n\nDistributed Prognostics and Health Management With a\nWireless Network Architecture\nDistributed architectures prevent total system failure during emergencies, allowing parts of the\nsystem to continue to function, and making overall system recovery faster.\nAmes Research Center, Moffett Field, California\nA heterogeneous set of system components monitored by a varied suite of sensors and a particle-filtering (PF) framework, with the power and the flexibility\nto adapt to the different diagnostic and\nprognostic needs, has been developed.\nBoth the diagnostic and prognostic tasks\nare formulated as a particle-filtering\nproblem in order to explicitly represent\nand manage uncertainties in state estimation and remaining life estimation.\nCurrent state-of-the-art prognostic\nhealth management (PHM) systems are\nmostly centralized in nature, where all\nthe processing is reliant on a single\nprocessor. This can lead to a loss in functionality in case of a crash of the central\nprocessor or monitor. Furthermore, with\nincreases in the volume of sensor data as\nwell as the complexity of algorithms, traditional centralized systems become \xe2\x80\x94\nfor a number of reasons \xe2\x80\x94 somewhat\nungainly for successful deployment, and\nefficient distributed architectures can be\nmore beneficial.\n\nThe distributed health management\narchitecture is comprised of a network\nof smart sensor devices. These devices\nmonitor the health of various subsystems or modules. They perform diagnostics operations and trigger prognostics operations based on user-defined\nthresholds and rules. The sensor devices, called computing elements\n(CEs), consist of a sensor, or set of sensors, and a communication device (i.e.,\na wireless transceiver beside an embedded processing element). The CE runs\nin either a diagnostic or prognostic operating mode. The diagnostic mode is\nthe default mode where a CE monitors\na given subsystem or component\nthrough a low-weight diagnostic algorithm. If a CE detects a critical condition during monitoring, it raises a flag.\nDepending on availability of resources,\na networked local cluster of CEs is\nformed that then carries out prognostics and fault mitigation by efficient distribution of the tasks. It should be\n\nnoted that the CEs are expected not to\nsuspend their previous tasks in the\nprognostic mode. When the prognostics task is over, and after appropriate\nactions have been taken, all CEs return\nto their original default configuration.\nWireless technology-based implementation would ensure more flexibility in\nterms of sensor placement. It would also\nallow more sensors to be deployed because the overhead related to weights of\nwired systems is not present. Distributed\narchitectures are furthermore generally\nrobust with regard to recovery from\nnode failures.\nThis work was done by Kai Goebel of Ames\nResearch Center, and Sankalita Saha and\nBhaskar Sha of Mission Critical Technologies, Inc.\nInquiries concerning rights for the commercial use of this invention should be addressed to\nthe Ames Technology Partnerships Division at\n1-855-NASA-BIZ (1-855-6272-249). Refer to\nARC-16450-1.\n\nMinimal Power Latch for Single-Slope ADCs\nA CMOS implementation for remote sensing applications results in further reduction of power\nconsumption and noise.\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nColumn-parallel analog-to-digital converters (ADCs) for imagers involve simultaneous operation of many ADCs.\nSingle-slope ADCs are well adapted to\nthis use because of their simplicity. Each\nADC contains a comparator, comparing\nits input signal level to an increasing reference signal (ramp). When the ramp is\n\n8\n\nequal to the input, the comparator triggers a latch that captures an encoded\ncounter value (code). Knowing the captured code, the ramp value and hence\nthe input signal are determined. In a\ncolumn-parallel ADC, each column contains only the comparator and the\nlatches; the ramp and code generation\n\nare shared.\nIn conventional latch or flip-flop circuits, there is an input stage that tracks\nthe input signal, and this stage consumes switching current every time the\ninput changes. With many columns,\nmany bits, and high code rates, this\nswitching current can be substantial. It\n\nNASA Tech Briefs, August 2013\n\nwill also generate noise that may corrupt\nthe analog signals. A latch was designed\nthat does not track the input, and consumes power only at the instant of latching the data value.\nThe circuit consists of two S-R (setreset) latches, gated by the comparator.\nOne is set by high data values and the\nother by low data values. The latches are\ncross-coupled so that the first one to set\nblocks the other. In order that the input\ndata not need an inversion, which\nwould consume power, the two latches\nare made in complementary polarity.\nThis requires complementary gates\nfrom the comparator, instead of complementary data values, but the comparator only triggers once per conversion, and usually has complementary\noutputs to begin with.\nAn efficient CMOS (complementary\nmetal oxide semiconductor) implementation of this circuit is shown in the figure, where C is the comparator output,\nD is the data (code), and Q0 and Q1 are\nthe outputs indicating the capture of a\nzero or one value. The latch for Q0 has a\nnegative-true set signal and output, and\nis implemented using OR-AND-INVERT\nlogic, while the latch for Q1 uses positive-true signals and is implemented\nusing AND-OR-INVERT logic. In this im-\n\nNASA Tech Briefs, August 2013\n\nC\n\nQ0\n\nC\n\nQ1\nD\n\nQ1\n\nD\n\nQ1\n\nQ0\n\nQ0\nQ0\n\nQ1\n\nQ1\n\nQ0\n\nC\n\nC\n\nAn implementation of the Minimal Power Latch using complex logic gates.\n\nplementation, both latches are cleared\nwhen the comparator is reset. Two redundant transistors are removed from\nthe reset side of each latch, making for a\ncompact layout.\nCMOS imagers with column-parallel\nADCs have demonstrated high performance for remote sensing applications. With this latch circuit, the power\nconsumption and noise can be further\nreduced. This innovation can be used\nin CMOS imagers and very-low-power\nelectronics.\nThis work was done by Bruce R. Hancock of\nCaltech for NASA\xe2\x80\x99s Jet Propulsion Laboratory.\n\nFurther information is contained in a TSP\n(see page 1).\nIn accordance with Public Law 96-517, the\ncontractor has elected to retain title to this invention. Inquiries concerning rights for its commercial use should be addressed to:\nInnovative Technology Assets Management\nJPL\nMail Stop 321-123\n4800 Oak Grove Drive\nPasadena, CA 91109-8099\nE-mail: iaoffice@jpl.nasa.gov\nRefer to NPO-48007, volume and number\nof this NASA Tech Briefs issue, and the page\nnumber.\n\n9\n\nManufacturing & Prototyping\nBismuth Passivation Technique for High-Resolution\nX-Ray Detectors\nGoddard Space Flight Center, Greenbelt, Maryland\nThe Athena-plus team requires X-ray\nsensors with energy resolution of better\nthan one part in 3,000 at 6 keV X-rays.\nWhile bismuth is an excellent material\nfor high X-ray stopping power and low\nheat capacity (for large signal when an\nX-ray is stopped by the absorber), oxidation of the bismuth surface can lead to\nelectron traps and other effects that degrade the energy resolution. Bismuth\noxide reduction and nitride passivation\ntechniques analogous to those used in\nindium passivation are being applied in\na new technique. The technique will enable improved energy resolution and resistance to aging in bismuth-absorbercoupled X-ray sensors.\n\nNASA Tech Briefs, August 2013\n\nElemental bismuth is lithographically\nintegrated into X-ray detector circuits.\nIt encounters several steps where the Bi\noxidizes. The technology discussed\nhere will remove oxide from the surface of the Bi and replace it with nitridized surface. Removal of the native\noxide and passivating to prevent the\ngrowth of the oxide will improve detector performance and insulate the detector against future degradation from\noxide growth. Placing the Bi coated\nsensor in a vacuum system, a reduction\nchemistry in a plasma (nitrogen/hydrogen (N2/H2) + argon) is used to remove the oxide and promote nitridization of the cleaned Bi surface. Once\n\npassivated, the Bi will perform as a better X-ray thermalizer since energy will\nnot be trapped in the bismuth oxides\non the surface.\nA simple additional step, which can be\nadded at various stages of the current\nfabrication process, can then be applied\nto encapsulate the Bi film. After plasma\npassivation, the Bi can be capped with a\nnon-diffusive layer of metal or dielectric.\nA non-superconducting layer is required\nsuch as tungsten or tungsten nitride\n(WNx).\nThis work was done by James Chervenak\nand Larry Hess of Goddard Space Flight Center. Further information is contained in a\nTSP (see page 1). GSC-16383-1\n\n11\n\nMaterials & Coatings\nHigh-Strength, Superelastic Compounds\nA new ordered intermetallic compound reduces costs, increases performance, and prevents\ncracking and distortion during thermal processing.\nJohn H. Glenn Research Center, Cleveland, Ohio\nIn a previous disclosure, the use of 60NiTiNOL, an ordered intermetallic\ncompound composed of 60 weight percent nickel and 40 weight percent titanium, was investigated as a material for\nadvanced aerospace bearings due to its\nunique combination of physical properties. Lessons learned during the development of applications for this material\nhave led to the discovery that, with the\naddition of a ternary element, the resulting material can be thermally processed\nat a lower temperature to attain the\nsame desirable hardness level as the\noriginal material. Processing at a lower\ntemperature is beneficial, not only because it reduces processing costs from\nenergy consumption, but because it also\nsignificantly reduces the possibility of\nquench cracking and thermal distortion,\nwhich have been problematic with the\noriginal material. A family of ternary\nsubstitutions has been identified, including Hf and Zr in various atomic percentages with varying concentrations of Ni\nand Ti.\nIn the present innovation, a ternary\nintermetallic compound consisting of\n57.6 weight percent Ni, 39.2 weight percent Ti, and 3.2 weight percent Hf\n(54Ni-45Ti-1Hf atomic percent) was prepared by casting. In this material, Hf\nsubstitutes for some of the Ti atoms in\nthe material. In an alternate embodiment of the innovation, Zr, which is\nclose in chemical behavior to Hf, is used\nas the substitutional element. With either substitution, the solvus temperature\nof the material is reduced, and lower\ntemperatures can be used to obtain the\nnecessary hardness values.\nThe advantages of this innovation include the ability to solution-treat the material at a lower temperature and still\nachieve the required hardness for bearings (at least 50 Rockwell C) and superelastic behavior with recoverable strains\ngreater than 2%. Most structural alloys\nwill not return to their original shape\nafter being deformed as little as 0.2% (a\ntenth of that possible with superelastic\nmaterials like 60 NiTiNOL). Because\n\nNASA Tech Briefs, August 2013\n\nThe Modified NiTiNOL being machined in a lathe.\n\n13\n\nlower temperatures can be used in the\nheat treatment process, less energy will be\nconsumed, and there will be less dimensional distortion and quench cracking.\nThis results in fewer scrap parts, less material waste from large amounts of material\nremoval, and fewer machining steps to rework parts that are out of specification.\nThis material has a combination of\nproperties that have been previously un-\n\nobtainable. The material has a Young\xe2\x80\x99s\nmodulus of approximately 95 GPa (about\nhalf that of conventional steels), moderate density (10 to 15% lower than conventional steels), excellent corrosion resistance, and high hardness (58 to 62 HRC).\nThese properties make this material\nuniquely suited for advanced bearings.\nThis work was done by Malcolm Stanford,\nRonald Noebe, Christopher Dellacorte, Glen\n\nBigelow, and Fransua Thomas of Glenn Research Center. Further information is contained in a TSP (see page 1).\nInquiries concerning rights for the commercial use of this invention should be addressed\nto NASA Glenn Research Center, Innovative\nPartnerships Office, Attn: Steven Fedor, Mail\nStop 4\xe2\x80\x938, 21000 Brookpark Road, Cleveland,\nOhio 44135. Refer to LEW-19029-1. t\n\nCu-Cr-Nb-Zr Alloy for Rocket Engines and Other High-HeatFlux Applications\nApplications include high-temperature, high-efficiency industrial heat exchangers, welding\nelectrodes, and head gaskets for automobile racing engines.\nJohn H. Glenn Research Center, Cleveland, Ohio\nRocket-engine main combustion chamber liners are used to contain the burning\nof fuel and oxidizer and provide a stream\nof high-velocity gas for propulsion. The liners in engines such as the Space Shuttle\nMain Engine are regeneratively cooled by\nflowing fuel, e.g., cryogenic hydrogen,\nthrough cooling channels in the back side\nof the liner. The heat gained by the liner\nfrom the flame and compression of the gas\nin the throat section is transferred to the\nfuel by the liner. As a result, the liner must\neither have a very high thermal conductivity or a very high operating temperature.\nIn addition to the large heat flux (>10\nMW/m\xc2\xb2), the liners experience a very\nlarge thermal gradient, typically more than\n500 \xc2\xb0C over 1 mm. The gradient produces\nthermally induced stresses and strains that\ncause low cycle fatigue (LCF). Typically, a\nliner will experience a strain differential in\nexcess of 1% between the cooling channel\nand the hot wall. Each time the engine is\nfired, the liner undergoes an LCF cycle.\nThe number of cycles can be as few as one\nfor an expendable booster engine, to as\n\nmany as several thousand for a reusable\nlaunch vehicle or reaction control system.\nFinally, the liners undergo creep and a\nform of mechanical degradation called\nthermal ratcheting that results in the bowing out of the cooling channel into the\ncombustion chamber, and eventual failure\nof the liner.\nGRCop-84, a Cu-Cr-Nb alloy, is generally recognized as the best liner material\navailable at the time of this reporting.\nThe alloy consists of 14% Cr2Nb precipitates in a pure copper matrix. Through\nexperimental work, it has been established that the Zr will not participate in\nthe formation of Laves phase precipitates\nwith Cr and Nb, but will instead react\nwith Cu to form the desired Cu-Zr compounds. It is believed that significant improvements in the mechanical properties\nof GRCop-84 will be realized by adding\nZr. The innovation is a Cu-Cr-Nb-Zr alloy\ncovering the composition range of 0.8 to\n8.1 weight percent Cr, 0.7 to 7.2 weight\npercent Nb, 0.1 to 1.5 weight percent Zr,\nand balance Cu.\n\nThe alloy combines two known\nstrengthening mechanisms \xe2\x80\x94 dispersion\nstrengthening by Cr2Nb precipitates\n(GRCop-84), and precipitation strengthening by CuxZr (AMZIRC) \xe2\x80\x94 to produce\na synergistic increase in the capabilities\nof the alloy with the goal of achieving\nproperties greater than either of the\nmethods could achieve alone. The anticipated advantages of the alloy are higher\nstrength at temperatures up to 700 \xc2\xb0C,\nimproved creep strength, and significantly higher LCF lives relative to\nGRCop-84. The thermal expansion, thermal conductivity, and processing of the\nalloy are anticipated to remain largely\nunchanged relative to GRCop-84.\nThis work was done by David L. Ellis of Glenn\nResearch Center. Further information is contained in a TSP (see page 1).\nInquiries concerning rights for the commercial\nuse of this invention should be addressed to\nNASA Glenn Research Center, Innovative Partnerships Office, Attn: Steven Fedor, Mail Stop\n4\xe2\x80\x938, 21000 Brookpark Road, Cleveland, Ohio\n44135. Refer to LEW-18136-1.\n\nMicrogravity Storage Vessels and Conveying-Line Feeders for\nCohesive Regolith\nThis design may provide a reliable, robust method for filling pharmaceutical capsules with fine,\ndry powders.\nJohn H. Glenn Research Center, Cleveland, Ohio\nUnder microgravity, the usual methods of placing granular solids into, or extracting them from, containers or storage vessels will not function. Alternative\n\n14\n\nmethods are required to provide a motive force to move the material. New\nconfigurations for microgravity regolith\nstorage vessels that do not resemble ter-\n\nrestrial silos, hoppers, or tanks are proposed. The microgravity-compatible\nbulk-material storage vessels and exitfeed configurations are designed to reli-\n\nNASA Tech Briefs, August 2013\n\nably empty and feed cohesive material to\ntransfer vessels or conveying ducts or\nlines without gravity. A controllable motive force drives the cohesive material to\nthe exit opening(s), and provides a reliable means to empty storage vessels\nand/or to feed microgravity conveying\nlines. The proposed designs will function equally well in vacuum, or inside of\npressurized enclosures.\nTypical terrestrial granular solids handling and storage equipment will not\nfunction under microgravity, since almost all such equipment relies on gravity to at least move material to an exit location or to place it in the bottom of a\ncontainer. Under microgravity, there effectively are no directions of up or\ndown, and in order to effect movement\nof material, some other motive force\nmust be applied to the material. The\nproposed storage vessels utilize dynamic\ncentrifugal force to effect movement of\nregolith whenever material needs to be\nremoved from the storage vessel. During\nsimple storage, no dynamic motion or\nforces are required. The rotation rate\nduring emptying can be controlled to\nensure that material will move to the desired exit opening, even if the material is\nhighly cohesive, or has acquired an electrostatic charge.\nThe general concept of this Swirl Action Utilized for Centrifugal Ejection of\nRegolith (SAUCER) microgravity stor-\n\nNASA Tech Briefs, August 2013\n\nage unit/dynamic feeder is to have an\neffective slot-hopper (based on the converging angles of the top and bottom\nconical section of the vessel) with an\nexit slot around the entire periphery of\nthe SAUCER. The basic shape of such a\nunit is like two Chinese straw hats\n(douli) \xe2\x80\x94 one upside down, on the bottom, and another on top; or two wokpans, one upright on the bottom and\nanother inverted on top, with a small\ngap between the upright and inverted\npans or hats (around the periphery). A\nstationary outer ring, much like an unmounted bicycle tire, surrounds the gap\nbetween the two coaxial, nearly conical\npieces, forming the top and bottom of\nthe unit.\nWhen the entire unit is spun around\nits axis, centrifugal forces will exceed the\ncohesive arch strength of the regolith inside (at some rotational speed), and\nsome material will be ejected through\nthe peripheral slot into the surrounding\nstationary ring. Multiple small brushes\nor blades will sweep the extruded material around inside the enclosing stationary ring (tire). A circular hole in the\nouter ring allows the swirling material to\npass through the outer ring wall and\ninto an attached screw conveyor or other\nunit. Because the opening in the outer\nring is circular, there is no preferred orientation for an attached screw conveyor,\nother than that it would work best if its\n\naxis lies in a plane tangent to the outer\ncircumference of the ring. The ring and\nscrew conveyor remain in a fixed orientation, while the top and bottom cones\nof the SAUCER are connected together\n(with a gap between them) and rotate\nabout their common axis to produce the\ncentrifugal force, enabling the material\ninside the SAUCER to be ejected\nthrough the outer slot or gap into the\ndispensing ring. The screw conveyor\npicks up the material swept through the\nhole in the outer ring.\nWithout an externally supplied motive\nforce, a cohesive granular solid will not\nmove under microgravity, but will remain in an open container, independent\nof the container\xe2\x80\x99s orientation, until an\nexternal force causes the material to\nmove. The controllable centrifugal force\nof the proposed SAUCER design provides a rational solution for storage and\nsubsequent emptying of vessels containing cohesive granular solids under microgravity or low-gravity conditions.\nThis work was done by Otis R. Walton and\nHubert J. Vollmer of Grainflow Dynamics, Inc.\nfor Glenn Research Center. Further information\nis contained in a TSP (see page 1).\nInquiries concerning rights for the commercial use of this invention should be addressed to\nNASA Glenn Research Center, Innovative\nPartnerships Office, Attn: Steven Fedor, Mail\nStop 4\xe2\x80\x938, 21000 Brookpark Road, Cleveland,\nOhio 44135. Refer to LEW-19016-1.\n\n15\n\nPhysical Sciences\nCRUQS: A Miniature Fine Sun Sensor for Nanosatellites\nSize, mass, and power make the sensor suited to small satellite applications, especially nanosatellites.\nGoddard Space Flight Center, Greenbelt, Maryland\nA new miniature fine Sun sensor has\nbeen developed that uses a quadrant\nphotodiode and housing to determine\nthe Sun vector. Its size, mass, and power\nmake it especially suited to small satellite\napplications, especially nanosatellites. Its\naccuracy is on the order of one arcminute, and it will enable new science in\nthe area of nanosatellites.\nThe motivation for this innovation\nwas the need for high-performance Sun\nsensors in the nanosatellite category.\nThe design idea comes out of the LISS\n(Lockheed Intermediate Sun Sensor)\nused by the sounding rocket program on\ntheir solar pointing ACS (Attitude Control System). This system uses photodiodes and a wall between them. The\nshadow cast by the Sun is used to determine the Sun angle. The new sensor\n\ntakes this concept and miniaturizes it. A\ncruciform shaped housing and a surfacemount quadrant photodiode package\nallow for a two-axis fine Sun sensor to be\npackaged into a space \xe2\x89\x881.25\xc3\x97l\xc3\x970.25 in.\n(\xe2\x89\x883.2\xc3\x972.5\xc3\x970.6 cm). The circuitry to read\nthe photodiodes is a simple transimpedance operational amplifier. This is much\nless complex than current small Sun sensors for nanosatellites that rely on photoarrays and processing of images to determine the Sun center. The simplicity\nof the circuit allows for a low power draw\nas well.\nThe sensor consists of housing with a\ncruciform machined in it. The cruciform walls are 0.5-mm thick and the center of the cruciform is situated over the\ncenter of the quadrant photodiode sensor. This allows for shadows to be cast on\n\neach of the four photodiodes based on\nthe angle of the Sun. A simple operational amplifier circuit is used to read\nthe output of the photodiodes as a voltage. The voltage output of each photodiode is summed based on rows and\ncolumns, and then the values of both\nrows or both columns are differenced\nand divided by the sum of the voltages\nfor all four photodiodes. The value of\nboth difference over sums for the rows\nand columns is compared to a table or a\npolynomial fit (depending on processor\npower and accuracy requirements) to\ndetermine the angle of the Sun in the\nsensor frame.\nThis work was done by Scott Heatwole, Carl\nSnow, and Luis Santos of Goddard Space Flight\nCenter. Further information is contained in a\nTSP (see page 1). GSC-16551-1\n\nOn-Chip Microfluidic Components for In Situ Analysis,\nSeparation, and Detection of Amino Acids\nThis innovation can be integrated in a lab-on-a-chip device for biological and\nanalytical instruments.\nGoddard Space Flight Center, Greenbelt, Maryland\nThe Astrobiology Analytical Laboratory\nat GSFC has identified amino acids in meteorites and returned cometary samples by\nusing liquid chromatography-electrospray\nionization time-of-flight mass spectrometry (LCMS). These organic species are key\nmarkers for life, having the property of\nchirality that can be used to distinguish biological from non-biological amino acids.\nOne of the critical components in the\nbenchtop instrument is liquid chromatography (LC) analytical column. The commercial LC analytical column is an over250-mm-long and 4.6-mm-diameter\nstainless steel tube filled with functionized\nmicrobeads as stationary phase to separate\nthe molecular species based on their\nchemistry. Miniaturization of this technique for spaceflight is compelling for future payloads for landed missions targeting astrobiology objectives.\n\nNASA Tech Briefs, August 2013\n\nA commercial liquid chromatography analytical column consists of an\ninert cylindrical tube filled with a stationary phase, i.e., microbeads, that has\nbeen functionalized with a targeted\nchemistry. When analyte is sent\nthrough the column by a pressurized\ncarrier fluid (typically a methanol/\nwater mixture), compounds are separated in time due to differences in\nchemical interactions with the stationary phase. Different species of analyte\nmolecules will interact more strongly\nwith the column chemistry, and will\ntherefore take longer to traverse the\ncolumn. In this way, the column will\nseparate molecular species based on\ntheir chemistry.\nA lab-on-chip liquid analysis tool was\ndeveloped. The microfluidic analytical\ncolumn is capable of chromatographi-\n\ncally separating biologically relevant\nclasses of molecules based on their\nchemistry. For this analytical column,\nfabrication, low leak rate, and stationary\nphase incorporation of a serpentine microchannel were demonstrated that\nmimic the dimensions of a commercial\nLC column within a 5\xc3\x9710\xc3\x971 mm chip.\nThe microchannel in the chip has a 75micrometer-diameter oval-shaped cross\nsection. The serpentine microchannel\nhas four different lengths: 40, 60, 80,\nand 100 mm. Functionized microbeads\nwere filled inside the microchannel to\nseparate molecular species based on\ntheir chemistry.\nThis microscale analytic chip is designed to integrate with miniaturized liquid chromatography/mass spectrometry\nfor in situ analysis, separation, and detection of biologically relevant classes of\n\n17\n\nmolecules, which may provide clues\nabout the presence of past or extant biology. GSFC has successfully demonstrated that the microfluidic analytical\nchip is able to separate the amino acids\nglycine and leucine, as well as the chiral\namino acids L-valine and D-valine.\nThe microscale liquid chromatography analytic column is suitable for\nminiaturized liquid chromatography\nand mass spectrometry. Its serpentine\nmicrochannel in the microfluidic chip\n\nprovides up to 100-mm length for analyte molecules interacting in the column. The 100-mm length of microchannel\nis\ncompatible\nwith\ncommercial analytic column for better\nseparation. It is easy to integrate other\nelectronic devices on the chip such as a\nmicro heater and temperature sensor\nto monitor and control liquid temperature. The chip can stand up to 4,000 psi\n(\xe2\x89\x8827.6 MPa) pressure, which is much\nhigher than a polymer-made lab-on-a-\n\nchip. Silicon and Pyrex microchannels\ncan be used in a wide range of solutions, including strong acid and base\nsolutions. It will not contaminate the\nanalyte molecules. Also, the cost of the\nmicroscale analytic column is much less\nthan a commercial column.\nThis work was done by Yun Zheng, Stephanie\nGetty, Jason Dworkin, Manuel Balvin, and\nCarl Kotecki of Goddard Space Flight Center.\nFurther information is contained in a TSP\n(see page 1). GSC-16517-1\n\nSpectroscopic Determination of Trace Contaminants in\nHigh-Purity Oxygen\nA glow discharge emission system is used to detect and quantify trace amounts of argon\nin pure oxygen.\nLyndon B. Johnson Space Center, Houston, Texas\n\n18\n\nComputer\nJaz\xe2\x84\xa2\nSpectrometer\nGlow Discharge\nPlasma Tube\n\nOxygen\n\nVacuum\nThrottle Valve\n\nVariable\nLeak Valve\n\nVacuum\nPump\n\n5 kv Power Supply\n\nFigure 1. A schematic diagram of the Glow Discharge System.\n\n10,000\nPure O2\n\n8,000\nIntensity, Counts\n\nOxygen used for extravehicular activities (EVAs) must be free of contaminants because a difference in a few\ntenths of a percent of argon or nitrogen\ncontent can mean significant reduction\nin available EVA time. These inert gases\nbuild up in the extravehicular mobility\nunit because they are not metabolized or\nscrubbed from the atmosphere. A prototype optical emission technique capable\nof detecting argon and nitrogen below\n0.1% in oxygen has been developed.\nThis instrument uses a glow discharge in\nreduced-pressure gas to produce atomic\nemission from the species present. Because the atomic emission lines from\noxygen, nitrogen, and argon are discrete, and in many cases well-separated,\ntrace amounts of argon and nitrogen\ncan be detected in the ultraviolet and\nvisible spectrum. This is a straightforward, direct measurement of the target\ncontaminants, and may lend itself to a\ndevice capable of on-orbit verification of\noxygen purity.\nA glow discharge is a plasma formed\nin a low-pressure (1 to 10 Torr) gas cell\nbetween two electrodes. Depending on\nthe configuration, voltages ranging from\n200 V and above are required to sustain\nthe discharge. In the discharge region,\nthe gas is ionized and a certain population is in the excited state. Light is produced by the transitions from the excited states formed in the plasma to the\nground state. The spectrum consists of\ndiscrete, narrow emission lines for the\natomic species, and broader peaks that\nmay appear as a manifold for molecular\nspecies such as O2 and N2, the wave-\n\n0.1 Percent Argon\n0.05 Percent Argon\n0.001 Percent Argon\n\n6,000\n\n4,000\n\n2,000\n800\n\n805\n\n810\n\n815\n\n820\n\nFigure 2. Region around 811-nm argon shows Peak for Pure Oxygen and 0.1, 0.05, and 0.01 percent\nargon in oxygen.\n\nNASA Tech Briefs, August 2013\n\nlengths and intensities of which are a\ncharacteristic of each atom. The oxygen\nemission is dominated by two peaks at\n777 and 844 nm.\nFor testing, a quartz capillary tube\nwith stainless steel end fittings forms the\nglow discharge tube. The sample gas is\nintroduced into the glow discharge cell\nusing an adjustable vacuum leak valve.\nFrom the glow discharge cell, the sample\ngas passes a vacuum gauge, the downstream valve, and then the vacuum\npump. During operation, the pressure\nin the glow discharge cell is maintained\nbetween 0.5 and 10 Torr using the adjustable leak valve and the downstream\nvalve. Light from the discharge is collected by a lens and coupled to a UV-visible fiber-optic cable. This cable directs\nthe light from the glow discharge into a\n\nspectrometer. The spectrometer detects\nin the 200- to 850-nm region with a spectral resolution of 1.5 nm using a 25-\xc2\xb5m\nentrance slit. The spectrometer is connected to a data acquisition computer\nvia a USB cable. For this work, Ocean\nOptics\xe2\x80\x99 SpectraSuite\xc2\xae software was used\nfor the data acquisition, setting parameters such as wavelength range, integration times, and scans to average.\nFor a peak to be at the detection limit,\nit must be recognizable as a peak, be resolved from other peaks, and have a\npeak intensity three times the standard\ndeviation of background noise in the region of the peak. The peak corresponding to 0.01% argon is just above the\nbaseline of pure oxygen (see Figure 2),\nand the signal-to-noise ratio is 2.6, indicating the detection limit is between\n\n0.05 and 0.01%.\nThis work represents a proof-of-concept investigation into using a glow discharge emission system to detect and\nquantitate trace amounts of argon in\npure oxygen. A similar analysis will need\nto be done for nitrogen. Optimization of\nexperimental parameters such as operating pressure, discharge current, voltage,\nand spectrometer integration time\nneeds to be further investigated. A redesigned discharge cell that will use a\nlower-voltage DC power supply with a\nhigher discharge current is being designed to provide a spectrally brighter,\nlower-noise glow discharge.\nThis work was done by Steven Hornung of\nJohnson Space Center. Further information is\ncontained in a TSP (see page 1).\nMSC-25116\n\nMethod of Separating Oxygen From Spacecraft Cabin Air to\nEnable Extravehicular Activities\nLyndon B. Johnson Space Center, Houston, Texas\nExtravehicular activities (EVAs) require high-pressure, high-purity oxygen.\nShuttle EVAs use oxygen that is stored\nand transported as a cryogenic fluid.\nEVAs on the International Space Station\n(ISS) presently use the Shuttle cryo O2,\nwhich is transported to the ISS using a\ntransfer hose. The fluid is compressed to\nelevated pressures and stored as a highpressure gas. With the retirement of the\nshuttle, NASA has been searching for\nways to deliver oxygen to fill the highpressure oxygen tanks on the ISS.\nA method was developed using lowpressure oxygen generated onboard the\nISS and released into ISS cabin air, filtering the oxygen from ISS cabin air using\n\na pressure swing absorber to generate a\nlow-pressure (high-purity) oxygen\nstream, compressing the oxygen with a\nmechanical compressor, and transferring the high-pressure, high-purity oxygen to ISS storage tanks. The pressure\nswing absorber (PSA) can be either a\ntwo-stage device, or a single-stage device,\ndepending on the type of sorbent used.\nThe key is to produce a stream with oxygen purity greater than 99.5 percent.\nThe separator can be a PSA device, or a\nVPSA device (that uses both vacuum and\npressure for the gas separation). The\ncompressor is a multi-stage mechanical\ncompressor. If the gas flow rates are on\nthe order of 5 to 10 lb (\xe2\x89\x882.3 to 4.6 kg)\n\nper day, the compressor can be relatively\nsmall [3\xc3\x9716\xc3\x9716 in. (\xe2\x89\x888\xc3\x9741\xc3\x9741 cm)].\nAny spacecraft system, or other remote location that has a supply of lowpressure oxygen, a method of separating oxygen from cabin air, and a\nmethod of compressing the enriched\noxygen stream, has the possibility of\nhaving a regenerable supply of highpressure, high-purity oxygen that is\ncompact, simple, and safe. If cabin air is\nmodified so there is very little argon,\nthe separator can be smaller, simpler,\nand use less power.\nThis work was done by John C. Graf of Johnson Space Center. Further information is contained in a TSP (see page 1). MSC-24806-1\n\nAtomic Force Microscope Mediated Chromatography\nTrace-chemical and microfluidic analyses are taken to higher precision.\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nThe atomic force microscope (AFM)\nis used to inject a sample, provide sheardriven liquid flow over a functionalized\nsubstrate, and detect separated components. This is demonstrated using\nlipophilic dyes and normal phase chromatography. A significant reduction in\nboth size and separation time scales is\nachieved with a 25-micron-length col-\n\nNASA Tech Briefs, August 2013\n\numn scale, and one-second separation\ntimes. The approach has general applications to trace chemical and microfluidic analysis.\nThe AFM is now a common tool for\nultra-microscopy and nanotechnology. It\nhas also been demonstrated to provide a\nnumber of microfluidic functions necessary for miniaturized chromatography.\n\nThese include injection of sub-femtoliter\nsamples, fluidic switching, and sheardriven pumping. The AFM probe tip can\nbe used to selectively remove surface layers for subsequent microchemical analysis using infrared and tip-enhanced\nRaman spectroscopy. With its ability to\nimage individual atoms, the AFM is a remarkably sensitive detector that can be\n\n19\n\nused to detect separated components.\nThese diverse functional components of\nmicrofluidic manipulation have been\ncombined in this work to demonstrate\nAFM mediated chromatography.\nAFM mediated chromatography uses\nchannel-less, shear-driven pumping.\nThis is demonstrated with a thin, aluminum oxide substrate and a non-polar\nsolvent system to separate a mixture of\nlipophilic dyes. In conventional chromatographic terms, this is analogous to\nthin-layer chromatography using normal\nphase alumina substrate with sheardriven pumping provided by the AFM\ntip-cantilever mechanism. The AFM detection of separated components is accomplished by exploiting the variation\nin the localized friction of the separated\ncomponents. The AFM tip-cantilever\nprovides the mechanism for producing\nshear-induced flows and rapid pumping.\n\n20\n\nShear-driven chromatography (SDC) is a\nrelatively new concept that overcomes\nthe speed and miniaturization limitations of conventional liquid chromatography. SDC is based on a sliding plate\nsystem, consisting of two flat surfaces,\none of which has a recessed channel. A\nfluid flow is produced by axially sliding\none plate past another, where the fluid\nhas mechanical shear forces imposed at\neach point along the channel length.\nThe shear-induced flow rates are very reproducible, and do not have pressure or\nvoltage gradient limitations.\nSDC opens up a new range of enhanced separation kinetics by permitting the sample confinement with submicron dimensions. Small, highly\nconfined liquid is advantageous for\nchromatographic separation because\nthe separation rate is known to scale according to the square of the confined\n\nsample diameter. In addition, because\nshear-driven flows are not limited by\nfluid velocity, shear-driven liquid chromatography may provide up to 100,000\nplate efficiency.\nThis work was done by Mark S. Anderson\nof Caltech for NASA\xe2\x80\x99s Jet Propulsion Laboratory. For more information, contact\niaoffice@jpl.nasa.gov.\nIn accordance with Public Law 96-517,\nthe contractor has elected to retain title to this\ninvention. Inquiries concerning rights for its\ncommercial use should be addressed to:\nInnovative Technology Assets Management\nJPL\nMail Stop 321-123\n4800 Oak Grove Drive\nPasadena, CA 91109-8099\nE-mail: iaoffice@jpl.nasa.gov\nRefer to NPO-48647, volume and number\nof this NASA Tech Briefs issue, and the\npage number.\n\nNASA Tech Briefs, August 2013\n\nInformation Technology\nSample Analysis at Mars Instrument Simulator\nA novel tool will optimize and validate science operation plans of the instrument on the surface\nof Mars with a turnaround time of a few hours instead of multiple days.\nGoddard Space Flight Center, Greenbelt, Maryland\nThe Sample Analysis at Mars Instrument Simulator (SAMSIM) is a numerical model dedicated to plan and validate\noperations of the Sample Analysis at\nMars (SAM) instrument on the surface\nof Mars. The SAM instrument suite, currently operating on the Mars Science\nLaboratory (MSL), is an analytical laboratory designed to investigate the chemical and isotopic composition of the atmosphere and volatiles extracted from\nsolid samples. SAMSIM was developed\nusing Matlab and Simulink libraries of\nMathWorks Inc. to provide MSL mission\nplanners with accurate predictions of\nthe instrument electrical, thermal, mechanical, and fluid responses to scripted\ncommands. This tool is a first example\nof a multi-purpose, full-scale numerical\nmodeling of a flight instrument with the\npurpose of supplementing or even eliminating entirely the need for a hardware\nengineer model during instrument development and operation.\nSAMSIM simulates the complex interactions that occur between the instrument Command and Data Handling\nunit (C&DH) and all subsystems during\nthe execution of experiment sequences.\nA typical SAM experiment takes many\nhours to complete and involves hundreds of components. During the simulation, the electrical, mechanical, thermal, and gas dynamics states of each\nhardware component are accurately\n\nmodeled and propagated within the simulation environment at faster than real\ntime. This allows the simulation, in just a\nfew minutes, of experiment sequences\nthat takes many hours to execute on the\nreal instrument.\nThe SAMSIM model is divided into\nfive distinct but interacting modules:\nsoftware, mechanical, thermal, gas flow,\nand electrical modules. The software\nmodule simulates the instrument\nC&DH by executing a customized version of the instrument flight software in\na Matlab environment. The inputs and\noutputs to this synthetic C&DH are\nmapped to virtual sensors and command lines that mimic in their structure\nand connectivity the layout of the instrument harnesses. This module executes,\nand thus validates, complex command\nscripts prior to their up-linking to the\nSAM instrument. As an output, this\nmodule generates synthetic data and\nmessage logs at a rate that is similar to\nthe actual instrument.\nThe mechanical module simulates the\nactions of a number of mechanical components of the SAM instrument. This\nmodule contains the valves, the pumps,\nand the Sample Manipulation System\n(SMS). The response of each of these elements is modeled to produce outputs\nof state variables (velocity, position,\nforce, etc.) that duplicate the behavior\nof the real elements.\n\nThe thermal module simulates the action of \xe2\x89\x8860 heaters and their local thermal impact on the instrument. It also\npredicts the individual temperatures\nsensed by \xe2\x89\x8870 thermistors and transmitted to the C&DH.\nThe gas flow module simulates the gas\ndynamics (time-dependent pressures\nand gas flows) in the Gas-Processing System (GPS) of SAM. The conductance of\neach gas transfer element (pipe, manifold, leak, pump, etc.) is dynamically\ncomputed as a function of the component dimension, gas composition, pressure, and temperature.\nThe electric module captures the electrical behavior of motors, control boards,\nBayard-Alpert gauges, detectors, valves,\nheaters, and all components that contribute to the instrument power profile.\nThe behavior of each element of the\nSAMSIM model is reconstructed by accounting for all the relevant modules to\nthat element. Complex components like\npumps integrate contributions from\nmodules to simulate the evolution of\ntheir command logic, rotor speeds, currents, temperatures, and throughputs.\nThis development was conducted by Mehdi\nBenna of the Center for Research and Exploration in Space Science & Technology\n(CRESST) at Goddard Space Flight Center and\nTom Nolan of Nolan Engineering, LLC. Further information is contained in a TSP (see\npage 1). GSC-16566-1\n\nAccess Control of Web- and Java-Based Applications\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nCybersecurity has become a great\nconcern as threats of service interruption, unauthorized access, stealing and\naltering of information, and spreading\nof viruses have become more prevalent\nand serious.\nApplication layer access control of applications is a critical component in the\noverall security solution that also includes encryption, firewalls, virtual pri-\n\nNASA Tech Briefs, August 2013\n\nvate networks, antivirus, and intrusion\ndetection. An access control solution,\nbased on an open-source access manager augmented with custom software\ncomponents, was developed to provide\nprotection to both Web-based and Javabased client and server applications.\nThe DISA Security Service (DISA-SS)\nprovides common access control capabilities for AMMOS software applica-\n\ntions through a set of application programming interfaces (APIs) and network-accessible security services for authentication,\nsingle\nsign-on,\nauthorization checking, and authorization policy management.\nThe OpenAM access management\ntechnology designed for Web applications can be extended to meet the\nneeds of Java thick clients and stand-\n\n21\n\nalone servers that are commonly used in\nthe JPL AMMOS environment. The\nDISA-SS reusable components have\ngreatly reduced the effort for each\nAMMOS subsystem to develop its own\naccess control strategy.\nThe novelty of this work is that it leverages an open-source access management\nproduct that was designed for Web-\n\nbased applications to provide access control for Java thick clients and Java standalone servers. Thick clients and standalone servers are still commonly used in\nbusinesses and government, especially\nfor applications that require rich graphical user interfaces and high-performance visualization that cannot be met by\nthin clients running on Web browsers.\n\nThis work was done by Kam S. Tso and\nMichael J. Pajevski of Caltech for NASA\xe2\x80\x99s Jet\nPropulsion Laboratory. For more information,\ncontact iaoffice@jpl.nasa.gov.\nThe software used in this innovation is available for commercial licensing. Please contact Dan\nBroderick at Daniel.F.Broderick@jpl.nasa.gov.\nRefer to NPO-48435.\n\nTool for Automated Retrieval of Generic Event Tracks (TARGET)\nA generalized algorithm implementation is applied to scientific data sets for establishing events,\nsuch as tornadoes, both spatially and temporally.\nGoddard Space Flight Center, Greenbelt, Maryland\nMethods have been developed to identify and track tornado-producing\nmesoscale convective systems (MCSs) automatically over the continental United\nStates, in order to facilitate systematic\nstudies of these powerful and often destructive events. Several data sources\nwere combined to ensure event identification accuracy. Records of watches and\nwarnings issued by National Weather\nService (NWS), and tornado locations\nand tracks from the Tornado History\nProject (THP) were used to locate MCSs\nin high-resolution precipitation observations and GOES infrared (11-micron)\nRapid Scan Operation (RSO) imagery.\nThresholds are then applied to the latter\ntwo data sets to define MCS events and\ntrack their developments.\nMCSs produce a broad range of severe\nconvective weather events that are significantly affecting the living conditions of\nthe populations exposed to them. Understanding how MCSs grow and develop could help scientists improve their\nweather prediction models, and also\nprovide tools to decision-makers whose\ngoals are to protect populations and\ntheir property.\n\nAssociating storm cells across frames\nof remotely sensed images poses a difficult problem because storms evolve,\nsplit, and merge. Any storm-tracking\nmethod should include the following\nprocesses: storm identification, storm\ntracking, and quantification of storm intensity and activity.\nThe spatiotemporal coordinates of\nthe tracks will enable researchers to obtain other coincident observations to\nconduct more thorough studies of these\nevents. In addition to their tracked locations, their areal extents, precipitation\nintensities, and accumulations \xe2\x80\x94 all as\nfunctions of their evolutions in time \xe2\x80\x94\nwere also obtained and recorded for\nthese events. All parameters so derived\ncan be catalogued into a moving object\ndatabase (MODB) for custom queries.\nThe purpose of this software is to provide a generalized, cross-platform, pluggable tool for identifying events within a\nset of scientific data based upon specified criteria with the possibility of storing identified events into a searchable\ndatabase. The core of the application\nuses an implementation of the connected component labeling (CCL) algo-\n\nrithm to identify areas of interest, then\nuses a set of criteria to establish spatial\nand temporal relationships between\nidentified components. The CCL algorithm is used for identifying objects\nwithin images for computer vision. This\napplication applies it to scientific data\nsets using arbitrary criteria.\nThe most novel concept was applying\na generalized CCL implementation to\nscientific data sets for establishing events\nboth spatially and temporally. The combination of several existing concepts\n(pluggable components, generalized\nCCL algorithm, etc.) into one application is also novel. In addition, how the\nsystem is designed, i.e., its extensibility\nwith pluggable components, and its configurability with a simple configuration\nfile, is innovative. This allows the system\nto be applied to new scenarios with ease.\nThis work was done by Thomas Clune of\nGoddard Space Flight Center; Shawn Freeman, Carlos Cruz, and Robert Burns of\nNorthrop Grumman; Kwo-Sen Kuo of\nCaelum Research Corporation; and Jules\nKouatchou of TetraTech AMT. Further information is contained in a TSP (see page 1).\nGSC-16665-1\n\nBilayer Protograph Codes for Half-Duplex Relay Channels\nThe proposed code is constructed by synthesizing a bilayer structure with a protograph.\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nDirect to Earth return links are limited by the size and power of lander devices. A standard alternative is provided\nby a two-hops return link: a proximity\nlink (from lander to orbiter relay) and a\ndeep-space link (from orbiter relay to\nEarth). Although direct to Earth return\n\n22\n\nlinks are limited by the size and power of\nlander devices, using an additional link\nand a proposed coding for relay channels, one can obtain a more reliable signal. Although significant progress has\nbeen made in the relay coding problem,\nexisting codes must be painstakingly op-\n\ntimized to match to a single set of channel conditions, many of them do not\noffer easy encoding, and most of them\ndo not have structured design.\nA high-performing LDPC (low-density\nparity-check) code for the relay channel\naddresses simultaneously two important\n\nNASA Tech Briefs, August 2013\n\nissues: a code structure that allows low\nencoding complexity, and a flexible ratecompatible code that allows matching to\nvarious channel conditions. Most of the\nprevious high-performance LDPC codes\nfor the relay channel are tightly optimized for a given channel quality, and\nare not easily adapted without extensive\nre-optimization for various channel conditions. This code for the relay channel\ncombines structured design and easy encoding with rate compatibility to allow\nadaptation to the three links involved in\nthe relay channel, and furthermore offers very good performance. The proposed code is constructed by synthesizing a bilayer structure with a protograph.\nIn addition to the contribution to relay\nencoding, an improved family of protograph codes was produced for the pointto-point AWGN (additive white Gaussian\nnoise) channel whose high-rate mem-\n\nbers enjoy thresholds that are within 0.07\ndB of capacity.\nThese LDPC relay codes address three\nimportant issues in an integrative manner: low encoding complexity, modular\nstructure allowing for easy design, and\nrate compatibility so that the code can\nbe easily matched to a variety of channel\nconditions without extensive re-optimization. The main problem of half-duplex relay coding can be reduced to the\nsimultaneous design of two codes at two\nrates and two SNRs (signal-to-noise ratios), such that one is a subset of the\nother. This problem can be addressed by\nforceful optimization, but a clever\nmethod of addressing this problem is via\nthe bilayer lengthened (BL) LDPC\nstructure. This method uses a bilayer\nTanner graph to make the two codes\nwhile using a concept of \xe2\x80\x9cparity forwarding\xe2\x80\x9d with subsequent successive decod-\n\ning that removes the need to directly address the issue of uneven SNRs among\nthe symbols of a given codeword. This\nmethod is attractive in that it addresses\nsome of the main issues in the design of\nrelay codes, but it does not by itself give\nrise to highly structured codes with simple encoding, nor does it give rate-compatible codes. The main contribution of\nthis work is to construct a class of codes\nthat simultaneously possess a bilayer parity-forwarding mechanism, while also\nbenefiting from the properties of protograph codes having an easy encoding, a\nmodular design, and being a rate-compatible code.\nThis work was done by Dariush Divsalar of\nCaltech, and Thuy Van Nguyen and Aria Nosratinia of the University of Texas at Dallas for\nNASA\xe2\x80\x99s Jet Propulsion Laboratory. For more information, contact iaoffice@jpl.nasa.gov.\nNPO-47539\n\nInfluence of Computational Drop Representation in LES of a\nDroplet-Laden Mixing Layer\nFor numerical simulations of such flows, fine-grid LES is not as accurate as coarse-grid LES.\nNASA\xe2\x80\x99s Jet Propulsion Laboratory, Pasadena, California\nMultiphase turbulent flows are encountered in many practical applications including turbine engines or natural phenomena involving particle\ndispersion. Numerical computations of\nmultiphase turbulent flows are important because they provide a cheaper alternative to performing experiments\nduring an engine design process or because they can provide predictions of\npollutant dispersion, etc. Two-phase\nflows contain millions and sometimes\nbillions of particles. For flows with volumetrically dilute particle loading, the\nmost accurate method of numerically\nsimulating the flow is based on direct\nnumerical simulation (DNS) of the governing equations in which all scales of\nthe flow including the small scales that\nare responsible for the overwhelming\namount of dissipation are resolved.\nDNS, however, requires high computational cost and cannot be used in engineering design applications where iterations among several design conditions\nare necessary. Because of high computational cost, numerical simulations of\nsuch flows cannot track all these drops.\nThe objective of this work is to quantify the influence of the number of computational drops and grid spacing on\n\nNASA Tech Briefs, August 2013\n\nthe accuracy of predicted flow statistics,\nand to possibly identify the minimum\nnumber, or, if not possible, the optimal\nnumber of computational drops that\nprovide minimal error in flow prediction. For this purpose, several Large\nEddy Simulation (LES) of a mixing\nlayer with evaporating drops have been\nperformed by using coarse, medium,\nand fine grid spacings and computational drops, rather than physical drops.\nTo define computational drops, an integer NR is introduced that represents the\nratio of the number of existing physical\ndrops to the desired number of computational drops; for example, if NR=8,\nthis means that a computational drop\nrepresents 8 physical drops in the flow\nfield. The desired number of computational drops is determined by the available computational resources; the\nlarger NR is, the less computationally intensive is the simulation. A set of first\norder and second order flow statistics,\nand of drop statistics are extracted from\nLES predictions and are compared to\nresults obtained by filtering a DNS database. First order statistics such as Favre\naveraged stream-wise velocity, Favre averaged vapor mass fraction, and the\ndrop stream-wise velocity, are predicted\n\naccurately independent of the number\nof computational drops and grid spacing. Second order flow statistics depend\nboth on the number of computational\ndrops and on grid spacing. The scalar\nvariance and turbulent vapor flux are\npredicted accurately by the fine mesh\nLES only when NR is less than 32, and by\nthe coarse mesh LES reasonably accurately for all NR values. This is attributed\nto the fact that when the grid spacing is\ncoarsened, the number of drops in a\ncomputational cell must not be significantly lower than that in the DNS.\nResults indicate that for large NR values, the fine-grid LES is not as accurate\nas coarse-grid LES, besides being computationally more intensive. This is attributed to the fact that a fine-grid LES\nused in conjunction with a reduction in\nthe number of followed drops from the\nphysical to a computational drop field\nimplies that there is necessarily a smaller\nnumber of drops in a computational cell\nthan in DNS; this aspect naturally influences the flow development and biases it\nfrom the filtered DNS. The key to success seems to be having approximately\nthe same and not a significantly smaller\nnumber of drops in the computational\ncell volume in LES as compared to those\n\n23\n\nin DNS. Thus, the notion that smooth\nstatistics are all that is required in the\nchoice of the number of computational\ndrops does not hold. This is because unlike particles in a Monte-Carlo calculation where the number of these tracked\nparticles would be increased to obtain\n\n24\n\nconvergence of results, drops are not\nstochastic particles as they obey a deterministic trajectory that is only modulated by turbulence. This finding also\nhighlights the importance of obtaining\ndrop-number experimental data in combustion chambers or natural flows.\n\nThis work was done by Josette Bellan and\nSenthilkumaran Radhakrishnan of Caltech for\nNASA\xe2\x80\x99s Jet Propulsion Laboratory. For more information, contact iaoffice@jpl.nasa.gov.\nNPO-48202\n\nNASA Tech Briefs, August 2013\n\nNational Aeronautics and\nSpace Administration\n\n'