b"NASA/TM\xe2\x80\x932014-218532\n\nMADS Users\xe2\x80\x99 Guide\nDaniel D. Moerder\nLangley Research Center, Hampton, Virginia\n\nOctober 2014\n\nNASA STI Program . . . in Profile\nSince its founding, NASA has been dedicated to the\nadvancement of aeronautics and space science. The\nNASA scientific and technical information (STI)\nprogram plays a key part in helping NASA maintain\nthis important role.\n\n\xe2\x80\xa2\n\nCONFERENCE PUBLICATION.\nCollected papers from scientific and\ntechnical conferences, symposia, seminars,\nor other meetings sponsored or cosponsored by NASA.\n\nThe NASA STI program operates under the\nauspices of the Agency Chief Information Officer.\nIt collects, organizes, provides for archiving, and\ndisseminates NASA\xe2\x80\x99s STI. The NASA STI\nprogram provides access to the NASA Aeronautics\nand Space Database and its public interface, the\nNASA Technical Report Server, thus providing one\nof the largest collections of aeronautical and space\nscience STI in the world. Results are published in\nboth non-NASA channels and by NASA in the\nNASA STI Report Series, which includes the\nfollowing report types:\n\n\xe2\x80\xa2\n\nSPECIAL PUBLICATION. Scientific,\ntechnical, or historical information from\nNASA programs, projects, and missions,\noften concerned with subjects having\nsubstantial public interest.\n\n\xe2\x80\xa2\n\nTECHNICAL TRANSLATION.\nEnglish-language translations of foreign\nscientific and technical material pertinent to\nNASA\xe2\x80\x99s mission.\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\n\xe2\x80\xa2\n\nTECHNICAL PUBLICATION. Reports of\ncompleted research or a major significant phase\nof research that present the results of NASA\nPrograms and include extensive data or\ntheoretical analysis. Includes compilations of\nsignificant scientific and technical data and\ninformation deemed to be of continuing\nreference value. NASA counterpart of peerreviewed formal professional papers, but\nhaving less stringent limitations on manuscript\nlength and extent of graphic presentations.\nTECHNICAL MEMORANDUM. Scientific\nand technical findings that are preliminary or of\nspecialized interest, e.g., quick release reports,\nworking papers, and bibliographies that contain\nminimal annotation. Does not contain extensive\nanalysis.\nCONTRACTOR REPORT. Scientific and\ntechnical findings by NASA-sponsored\ncontractors and grantees.\n\nSpecialized services also include organizing\nand publishing research results, distributing\nspecialized research announcements and feeds,\nproviding information desk and personal search\nsupport, and enabling data exchange services.\nFor more information about the NASA STI\nprogram, see the following:\n\xe2\x80\xa2\n\nAccess the NASA STI program home page\nat http://www.sti.nasa.gov\n\n\xe2\x80\xa2\n\nE-mail your question to help@sti.nasa.gov\n\n\xe2\x80\xa2\n\nFax your question to the NASA STI\nInformation Desk at 443-757-5803\n\n\xe2\x80\xa2\n\nPhone the NASA STI Information Desk at\n443-757-5802\n\n\xe2\x80\xa2\n\nWrite to:\nSTI Information Desk\nNASA Center for AeroSpace Information\n7115 Standard Drive\nHanover, MD 21076-1320\n\nNASA/TM\xe2\x80\x932014-218532\n\nMADS Users\xe2\x80\x99 Guide\nDaniel D. Moerder\nLangley Research Center, Hampton, Virginia\n\nNational Aeronautics and\nSpace Administration\nLangley Research Center\nHampton, Virginia 23681-2199\n\nOctober 2014\n\nThe use of trademarks or names of manufacturers in this report is for accurate reporting and does not constitute an\nofficial endorsement, either expressed or implied, of such products or manufacturers by the National Aeronautics\nand Space Administration.\n\nAvailable from:\nNASA Center for AeroSpace Information\n7115 Standard Drive\nHanover, MD 21076-1320\n443-757-5802\n\nAbstract\nMADS (Minimization Assistant for Dynamical Systems) is a trajectory optimization code\nin which a user-speci\xef\xac\x81ed performance measure is directly minimized, subject to constraints\nplaced on a low-order discretization of user-supplied plant ordinary di\xef\xac\x80erential equations.\nThis document describes the mathematical formulation of the set of trajectory optimization\nproblems for which MADS is suitable, and describes the user interface. Usage examples are\nprovided.\n\n1\n\nContents\n1 Introduction\n\n3\n\n2 Problem Formulation and Software Interface\n2.1 Excursus: Custom Problem Formulations in MADS . . .\n2.2 Subroutines To Be Provided By The User . . . . . . . .\n2.3 Producing and Operating On A MADS Solution . . . .\n2.3.1 Formats for MADS Solution Data . . . . . . . .\n2.3.2 Matlab Functions for Operating On MADS Data\n2.4 Setting Up and Executing a MADS Run . . . . . . . . .\n2.4.1 Autodi\xef\xac\x80erentiation for MADS . . . . . . . . . . .\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n\n4\n6\n7\n11\n12\n13\n18\n20\n\n3 Tutorial Examples\n3.1 Linear System Minimum Time to Origin . . . . . . . . . .\n3.1.1 Baseline Problem . . . . . . . . . . . . . . . . . . .\n3.1.2 Break the problem into two phases . . . . . . . .\n3.1.3 Introduce variable discretization step size . . . . .\n3.1.4 Eliminate the Bangs . . . . . . . . . . . . . . . . .\n3.1.5 Problem Summary . . . . . . . . . . . . . . . . . .\n3.2 Goddard Problem . . . . . . . . . . . . . . . . . . . . . .\n3.2.1 Obtaining an Initial Guess . . . . . . . . . . . . . .\n3.2.2 Simple Solution with Dynamic Pressure Constraint\n3.2.3 A Penalty Function to Smooth Out Singular Jitter\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n\n24\n25\n25\n28\n30\n33\n35\n36\n39\n42\n48\n\n2\n\n1\n\nIntroduction\n\nThis document describes the user interface and provides a usage tutorial for the MADS (Minimization Agent for Dynamical Systems) trajectory optimization tool. MADS comprises a\nFORTRAN95 subroutine that organizes and executes trajectory optimization computations,\nand a set of Matlab functions that manipulate MADS input and output data. MADS casts\na trajectory optimization problem as direct cost function minimization subject to a set\nof constraints that include a temporal discretization of the \xef\xac\x81rst-order ordinary di\xef\xac\x80erential\nequations that govern the user\xe2\x80\x99s plant dynamics, boundary conditions, and miscellaneous\nconstraints imposed on the trajectory between boundary conditions. The resulting nonlinear programming problem (NLP) is solved by the NLP software SNOPT [1], which must be\navailable in order to run MADS.\nThe user provides four problem-speci\xef\xac\x81c subroutines that realize the system state rates,\nthe boundary conditions, the trajectory path constraints, and the cost function. Given\nthe maturity and bene\xef\xac\x81t of autodi\xef\xac\x80erentiation (AD) software, MADS assumes the presence\nof autodi\xef\xac\x80erentiated versions of the four user routines to supply derivatives. MADS\xe2\x80\x99 user\nsubroutine interfaces assume the use of the TAPANADE [2] AD package.\nThe approach taken in MADS to posing and solving trajectory optimization problems\nis to encourage robust convergence to a solution by using a low-order discretization and\na control parameterization which can gracefully accommodate the temporal discontinuities\nwhich can appear on the interior of trajectory arcs when exploring an optimal control\nproblem. The low-order discretization and control is normally accompanied by a fairly \xef\xac\x81ne,\nuniformly distributed, mesh of time points over which the problem is solved.\nThis emphasis on simplicity and accommodation of nonsmooth control behavior places\nMADS somewhat out of the mainstream of emerging numerical optimal control technology,\nmuch of which has been emphasizing pseudospectral techniques [3] \xe2\x80\x93 high-order quadrature of orthogonal polynomials, with adaptive temporal discretization mesh logic. These\nemerging techniques show very good performance and high accuracy on temporally smooth\nproblems, but graceful treatment of nonsmooth behavior remains an area of active research.\nSection 2 describes the family of optimal control problems that can be solved with\nMADS, and describes its software interface and that of the user-supplied routines. It also\ndescribes the Matlab utility functions that are used for manipulating MADS initial guesses\nand solutions.\nSection 3 sets up and solves two simple, classic optimal control problems, both of which\nexhibit nonsmooth temporal behavior issues, several di\xef\xac\x80erent ways. Simple measures are\ndescribed for varying the discretization density over the trajectory, and for constraining\naspects of the control trajectory\xe2\x80\x99s behavior.\n\n3\n\n2\n\nProblem Formulation and Software Interface\n\nMADS operates on trajectories of the form\ndxk\n= f (xk , uk , p), t \xe2\x88\x88 [0, 1], k = 1, ..., nph\n(1)\ndt\nthat is, for trajectories which may (when nph > 1) consist of multiple subarcs, or \xe2\x80\x9cphases.\xe2\x80\x9d\nIn each k th phase, xk \xe2\x88\x88 Rnxk are states, and p \xe2\x88\x88 Rnp is a vector of \xe2\x80\x9cstatic\xe2\x80\x9d free parameters;\nthat is, parameters to be chosen by the optimization process, and which do not vary with\ntime. Note that while xk and uk are speci\xef\xac\x81c to the k th phase in (1), all of the elements of\np are visible to all nph phases of the trajectory. Each uk (t) is assumed to be an integrable\nnu-dimensional functional de\xef\xac\x81ned on the interval t \xe2\x88\x88 [0, 1]. The integrability assumption\nis more-or-less moot, since MADS recasts the problem in discrete time. It is, however, the\ncase that if the user attempts to solve a problem for which an integrable optimal solution\ndoes not exist, numerical di\xef\xac\x83culties will ensue. Subsection 2.2 of the Tutorials gives an\nexample where optimal control leads to a nonintegrable \xe2\x80\x9coptimal\xe2\x80\x9d control solution, and\ngives approaches for compensating for the nonintegrability. It should also be noted that\nthe unity duration of the subarcs in (1) does not restrict the user from posing variable-time\nproblems. There are a number of easy ways to do this, and literally all of the examples in\nthe Tutorial involve free terminal time. The very simplest is to use an element of p to scale\ntime. Restricting to nph = 1 and p scalar for simplicity, transform t to \xcf\x84 via \xcf\x84 = pt so that\ndx\n= pf (x, u, p), \xcf\x84 \xe2\x88\x88 [0, 1]\n(2)\nd\xcf\x84\nAlternatively, an element, say u\xcf\x84 , of u can be used as a time scaling parameter; that is,\n\xcf\x84 (t) = u\xcf\x84 (t), giving\ndx\nd\xcf\x84\n\n1\n\n= u\xcf\x84 f (x, u, p), \xcf\x84 \xe2\x88\x88 [0,\n\nu\xcf\x84 (t)dt],\n\nu\xcf\x84 \xe2\x89\xa5 c\xcf\x84 > 0\n\n(3)\n\n0\n\n\xcf\x84 =u\xcf\x84 (t)\n\nwhere c\xcf\x84 is a user-speci\xef\xac\x81ed constant. This latter formulation permits the \xef\xac\x82exibility of variable time steps, at the cost of some additional complexity. The Tutorial includes problems\nusing both approaches.\nFree parameters in the trajectory \xe2\x80\x93 state boundary values, control functionals, and the\np vector are chosen to minimize a Mayer-type cost function\n\xcf\x86(x10 , x1f , x20 , x2f , . . . , xnph0 , xnphf , p),\n\nxk0\nxkf\n\n=\n=\n\nxk (0)\nxk (1)\n\n(4)\n\nThe cost function \xcf\x86 is minimized subject to a discretization of (1) and, optionally, boundary\nconditions\n\xcf\x88j (x10 , x1f , . . . , xnph0 , xnphf , p)\n\n= 0, iebcvec(j) = 0\n\xe2\x89\xa5 0, iebcvec(j) = 1\n\nj = 1, . . . , nbc\n\n(5)\n\nwhere nbc is the dimension of \xcf\x88 and iebcvec(j) is a user-speci\xef\xac\x81ed \xef\xac\x82ag that controls\nwhether the jth element of \xcf\x88 is to be treated as an equality or inequality constraint. Again\noptionally, constraints can be imposed on the trajectory between boundary conditions using\na discretization of trajectory constraints of the form\ncj (xk , uk , p)\n\n= 0, iecv(j) = 0\n\xe2\x89\xa5 0, iecv(j) = 1\n\nk = 1, . . . , nph, j = 1, . . . , nck\n\n(6)\n\nwhere iecv is a user-speci\xef\xac\x81ed \xef\xac\x82ag. Note that the number of trajectory constraints in each\nof the nph subarcs, or \xe2\x80\x9cphases\xe2\x80\x9d may vary from phase to phase.\n\n4\n\nMADS computes optimized trajectories by direct minimization of the cost function \xcf\x86,\nusing \xef\xac\x81nite-dimensional approximations of the state and control trajectories, the former obtained via low-order collocation. Each k th trajectory arc in (1) is broken into ndk equal time\nsubintervals and the state trajectory across each subinterval is approximated by collocation:\nxj+1 \xe2\x88\x92 xj = F (xj , xj+1 , uj , p),\n\nj = 1, . . . , ndk\n\n(7)\n\nwhere uj is constant, i.e., zero-order hold (ZOH) across the discretization intervals. Note\nthat, while each k th discretized phase has one value uj per discretization interval, for a total\nof ndk values, there are ndk + 1 corresponding values of xj , since each phase has an initial\nand terminal state.\nThe overall organization of constraints in MADS is\n\xef\xa3\xae\n\n\xef\xa3\xb9\n\xef\xa3\xb9\n\xef\xa3\xae\nz1\ny1\n\xef\xa3\xaf . \xef\xa3\xba\n\xef\xa3\xaf . \xef\xa3\xba\n\xef\xa3\xaf . \xef\xa3\xba\nZ = \xef\xa3\xaf . \xef\xa3\xba , zj = \xef\xa3\xb0 . \xef\xa3\xbb , yi =\n.\n\xef\xa3\xb0 znph \xef\xa3\xbb\nyndj\n\xcf\x88\n\nFij\nCij\n\n(8)\n\nwhere Fij is the discretization (7) for the ith time step of the j th phase, and Cij is the\ncorresponding constraint from (6).\nThere are currently three discretization expressions implemented, and the MADS input\nparameter kode=kodev(k) controls which of them is used to discretize the k th phase of the\ntrajectory:\n1. Midpoint Euler (ME) (kode=0)\nxj+1 \xe2\x88\x92 xj =\n\n1\nf\nndk\n\nxj + xj+1\n, uj , p\n2\n\n(9)\n\nThis is the most e\xef\xac\x83cient discretization, since it achieves second-order accuracy with\nonly one state derivative computation per time step.\n2. Second-Order Runge-Kutta (RK2) (kode=1)\nxj+1\n\xce\xb71\n\xce\xb72\n\n\xef\xa3\xbc\n= xj + (1/4)(\xce\xb71 + 3\xce\xb72 )\n\xef\xa3\xbd\n= (1/nd)f (xj , uj , p)\n\xef\xa3\xbe\n= (1/nd)f (xj + (2/3)\xce\xb71 , uj , p)\n\n(10)\n\nThis Runge-Kutta discretization requires twice as many state derivative computations\nas the ME, but has the property that the discretization is not dependent on xj+1 .\n3. Fourth-Order Runge-Kutta (RK4) (kode=2)\nxj+1\n\xce\xb71\n\xce\xb72\n\xce\xb73\n\xce\xb74\n\n=\n=\n=\n=\n=\n\n(1/6)(\xce\xb71 + 2\xce\xb72 + 2\xce\xb73 + \xce\xb74 )\n(1/nd)f (xj , uj , p)\n(1/nd)f (xj + (1/2)\xce\xb71 , uj , p)\n(1/nd)f (xj + (1/2)\xce\xb72 , uj , p)\n(1/nd)f (xj + \xce\xb73 , uj , p)\n\n\xef\xa3\xbc\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xbd\n\n(11)\n\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xbe\n\nThis RK4 requires four times as many state derivative computations as the ME, but\nhas a clear advantage in the fourth-order accuracy with which it discretizes the state\ntrajectory.\n\n5\n\n2.1\n\nExcursus: Custom Problem Formulations in MADS\n\nAt \xef\xac\x81rst glance, the user may balk at MADS\xe2\x80\x99 apparent crudity, most clearly exhibited in\nthe zero-order hold (ZOH) imposed on the control variable. As the user\xe2\x80\x99s experience with\nMADS grows, however, this should mature into appreciation for MADS\xe2\x80\x99 \xef\xac\x82exibility. The\nZOH is actually more of a \xe2\x80\x9cfeature\xe2\x80\x9d of MADS, rather than a limitation. MADS is primarily\nintended to be used with the ME discretization and relatively small time steps. The use of a\nlow-order discretization and small time steps encourages robust convergence to the problem\nsolution, and the small time steps allow the ZOH to closely approximate the continuous-time\noptimal control trajectory.\nAll that being said, as stated in the Introduction, MADS is intended to provide a convenient \xe2\x80\x9cblank sheet\xe2\x80\x9d environment in which the user can formulate a wide range of trajctory optimization problems without being particularly shackled by canned dynamical model\nstructures, or presumptions about the temporal behavior of the control trajectory.\nIn order to illustrate this, we consider adjustments to the standard MADS problem\nformulation that permit control trajectories more complicated than ZOH. Since the ME\nonly samples the control trajectory at one point per discretization interval, why might a\nuser want to complicate the control parameterization? Two reasons are to achieve higher\nnumerical precision, or to obtain a control solution that accommodates known characteristics\nof the hardware that would actually realize the implement the control being optimized..\n\xe2\x80\xa2 The RK4 discretization may be used to check the validity of a ME-based solution\nby re-solving the problem on the set of time points used for the MEs solution and\nverifying that the RK4 and ME solutions are \xe2\x80\x9csu\xef\xac\x83ciently close.\xe2\x80\x9d Since the RK4\nsamples the control trajectory at four points rather than one, \xef\xac\x81delity to the continuoustime optimal control trajectory can be improved by choosing a more complicated\ncontrol parameterization that varies over the discretization interval.\n\xe2\x80\xa2 Optimal control trajectories are typically unrealistic in the sense that, while actual\nimplemented controls are the response of \xef\xac\x81nite-bandwidth actuators to commands,\nactuation dynamics are not typically included in plant models for trajectory optimization. The control parameterization examples described below all involve the use of\nstate variables. With these in hand, the user can easily constrain or penalize unrealistic control features, such as \xe2\x80\x9cinstantaneous\xe2\x80\x9d jumps that would require very expensive\nactuators to implement. The \xef\xac\x81rst solution example includes a demonstration of this\ntype bandwidth-limited control.\nReturning to speci\xef\xac\x81cs, suppose, for example, that the user would prefer a piecewise linear\ncontrol history, rather than the default ZOH. In that case, rewrite (1) as\nx = f (x, \xce\xb3, p)\n\xcb\x99\n\n(12)\n\nand de\xef\xac\x81ne a state to propagate the control variable \xce\xb3(t):\n\xce\xb3=u\n\xcb\x99\n\n(13)\n\nx\n\xce\xb3\n\n(14)\n\nand append it to the plant state xplant\nx=\n\nso that the value of piecewise constant u on the j th discretization interval is the slope of \xce\xb3\nover that interval. If a discontinuous \xef\xac\x81rst-order hold (FOH) control variation is preferred,\nde\xef\xac\x81ne a state to model time variation inside the discretization interval:\nxt = 1,\n\xcb\x99\n\nxt (0) = 0\n\n6\n\n(15)\n\nand de\xef\xac\x81ne the interval time as\ntj = xt \xe2\x88\x92 j/nd\n\n(16)\n\nwhere both j and nd are passed to the user\xe2\x80\x99s plant dynamics subroutine through the calling\nargument. The FOH control, then, is\n\xce\xb3j (tj ) = c0j + c1j tj\n\n(17)\n\nwhere c0j , c1j appear in the problem formulation as elements appended to the vector uplant\nthat contains whatever controls, if any, are modelled as ZOH:\n\xef\xa3\xae\n\xef\xa3\xb9\nuplant\nxplant\nxj =\n, uj = \xef\xa3\xb0 c0j \xef\xa3\xbb\n(18)\nxt\nc1j\nIf a high-order control variation with continous slope is desired, it can be simply implemented by constructing a Hermite-type spline. Again de\xef\xac\x81ne a time state\nxj = nd, x(0) = 0, tj = xt \xe2\x88\x92 j\n\xcb\x99\nso that tj passes from 0 to 1 over each j\nfunction as\n\nth\n\n(19)\n\ninterval. With tj in hand, de\xef\xac\x81ne the control\n\n\xce\xb3j (tj ) = c0j + c1j tj + c2j t2\nj\n\n(20)\n\nand require\n\xce\xb3j (1) = \xce\xb3j+1 (0)\n\xce\xb3j (1) = \xce\xb3j+1\n\xcb\x99\n\xcb\x99\n\n\xe2\x86\x92 c0j + c1j + c2j \xe2\x88\x92 c0,j+1\n\xe2\x86\x92\nc1j + 2c2j \xe2\x88\x92 c1,j+1\n\n=\n=\n\n0\n0\n\n(21)\n\nThese dynamical constraints require that c1 and c2 be modelled as states added to the plant\nstate vector:\n(c1 )j\n\xcb\x99\n(c2 )j\n\xcb\x99\n\n= k1j\n= k2j\n\nand k1j and k2j are appended to the control vector uj , resulting in\n\xef\xa3\xae\n\xef\xa3\xb9\n\xef\xa3\xae\n\xef\xa3\xb9\nxplant\nuplant\n\xef\xa3\xaf xt \xef\xa3\xba\n\xef\xa3\xaf c0 \xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xaf\n\xef\xa3\xba\nx=\xef\xa3\xaf\n\xef\xa3\xb0 c1 \xef\xa3\xbb , u = \xef\xa3\xb0 k1 \xef\xa3\xbb\nc2\nk2\n\n(22)\n\n(23)\n\nThe discussion above has been presented primarily to whet the reader\xe2\x80\x99s imagination for\nposing MADS problems, and to provide assurance that it is not di\xef\xac\x83cult to set up problems\nthat fall outside the MADS defaults.\n\n2.2\n\nSubroutines To Be Provided By The User\n\nThe user\xe2\x80\x99s problem, as expressed by (1,4,5,6) is implemented in four user-supplied subroutines. These can be divided into two groups \xe2\x80\x93 subroutines that operate along trajectory arcs,\nand subroutines that operate on boundary values. Before providing individual details of the\nuser-supplied subroutines, we describe a SNOPT-related input common to all of them. That\ninput is an integer scalar, nstate, which is generated by SNOPT to provide the user with\nsignals for initialization operations \xe2\x80\x93 such as data initialization and memory allocation \xe2\x80\x93\nand post-run cleanup operations such as deallocation. The three most important conditions\nfor nstate are\n\n7\n\n\xe2\x80\xa2 nstate=0\nnormal subroutine call,\n\xe2\x80\xa2 nstate=1\n\xef\xac\x81rst call. If there are special operations to be performed on the \xef\xac\x81rst call, perform\nthem now, then proceed on to the operations performed for nstate = 0. Note that\nthere is only one nstate = 1 call to each of the user subroutines at the beginning of\na MADS run.\n\xe2\x80\xa2 nstate=2\n\xef\xac\x81nal call. If the user has cleanup operations to perform, they should be done now.\nMADS has \xef\xac\x81nished, and will not use the results of any computations performed during this call, so it would be best to simply return once user cleanup operations are\ncomplete. If the user has nothing to do for the nstate = 2 call in any of the four usersupplied subroutines, simply make the \xef\xac\x81rst executable line of each of the subroutines\n\xe2\x80\x9cif(nstate.GE.2)return.\xe2\x80\x9d\nThere are several other values that nstate can take on, none of which are recognized\nspeci\xef\xac\x81cally by MADS. Those values are explained in the SNOPT documentation [1]. The\nuser is recommended not use nstate, but rather to perform initialization and memory\noperations in code units separate from those implementing (1,4,5,6)\nThe subroutines that operate along trajectory arcs are\nxdot: This subroutine corresponds to (1), and provides the right-hand side of the system of\n\xef\xac\x81rst-order ordinary di\xef\xac\x80erential equations (ODEs) de\xef\xac\x81ning the trajectory for each of\nthe nph trajectory phases; that is to say, MADS calls one xdot, and that subroutine\nhas logic to return the state derivative for each k th phase, k = 1, . . . , nph. The calling\nsyntax for xdot is\nsubroutine xdot(nstate,kph,nk,jk,nx,x,nu,u,np,p,f)\ninteger,intent(in) :: nstate,kph,nk,jk,nx,nu,np\nreal(8),intent(in) :: x(nx),u(nu),p(np)\nreal(8),intent(out) :: f(nx)\nThe inputs are\nnstate: See the discussion at the beginning of this Subsection.\nkph: index of current trajectory phase, i.e. 1 \xe2\x89\xa4 kph \xe2\x89\xa4 nph\nnk: number of discretization intervals in this phase\njk: index number of current discretization interval, i.e. 1 \xe2\x89\xa4 jk \xe2\x89\xa4 nk\nnx: state dimension in current phase\nx: nx-element state vector\nnu: control dimension in current phase\nu: current value of nu-element control vector\nnp: dimension of vector of static free parameter\np: np-element static free parameter vector\nThe output is\nf: right-hand side of the state time derivative, for the current inputs.\n\n8\n\ncineq: This subroutine corresponds to (6), and provides the equality and inequality constraints that operate on the state and control trajectories in between boundary conditions. This routine di\xef\xac\x80ers from xdot in that it has access to the state at the discrete\ninstants at the beginning and end of the current discretization interval, whereas, xdot\nis simply called with whatever state argument is provided it by the user\xe2\x80\x99s chosen ME,\nRK2, or RK4 discretization logic. This routine also di\xef\xac\x80ers from xdot in that the user\nneeds to specify, for each element of the output vector, whether it is to be treated as\nan equality or inequality constraint. Recall that all inequality constraints in MADS,\nper (5, 6) are posed so that they are satis\xef\xac\x81ed by non-negative values. The calling\nsyntax for cineq is\nsubroutine cineq(nstate,kph,nk,jk,nx,xj,xjp1,nu,u,np,p, &\n&\nnc,c,iec,iecflag)\ninteger,intent(in) :: nstate,kph,nk,jk,nx,nu,np,nc,iecflag\ninteger,intent(out) :: iec(nc)\nreal(8),intent(in) :: xj(nx),xjp1(nx),u(nu),p(np)\nreal(8),intent(out) :: c(nc)\nThe inputs are\nnstate: See the discussion at the beginning of this Subsection.\nkph: index of current trajectory phase, i.e. 1 \xe2\x89\xa4 kph \xe2\x89\xa4 nph\nnk: number of discretization intervals in this phase\njk: index number of current discretization interval, i.e. 1 \xe2\x89\xa4 jk \xe2\x89\xa4 nk\nnx: state dimension in current phase\nxj: nx-element state vector at the beginning of discretization interval jk\nxjp1: nx-element state vector at the end of discretization interval jk\nnu: control dimension in current phase\nu: current value of nu-element control vector\nnp: dimension of vector of static free parameter\np: np-element static free parameter vector\nc: the dimension of the constraint vector c that is to be output by cineq\niecflag: integer scalar that signals cineq to output the iec vector. The values of iecflag\nthat MADS inputs are\n0: a normal call, in which cineq is to compute its constraint quantities.\n1: cineq is required to output iec and then exit. No other operations are\nwanted from cineq in this case. If the user does perform other operations,\nthey will be ignored.\nThe outputs are\nc: nc-dimensional constraint vector from (6)\niec: nc-dimensional integer vector of ones and zeros whose ith component signals\nMADS whether c(i) is an equality or inequality constraint. The values of iec are\niec(i)=0: c(i) = 0 is required for solution\niec(i)=1: c(i) \xe2\x89\xa5 0 is required for solutions\n\n9\n\nThe next two user subroutines operate on state boundary values and the p vector to implement (4) and 5). The boundary values are available to the routines as a vector, xbc,\nthat stacks the initial and terminal values, along with integer vectors k0 and kf such that\nk0(k) + 1 points to the \xef\xac\x81rst element of the initial state for the k th trajectory phase and\nkf(k) + 1 points to the \xef\xac\x81rst element of its terminal state, in turn. This is displayed in the\nfollowing equation, in which x0,k refers to the \xef\xac\x81rst (initial boundary value) state vector in\nthe k th phase and xf,k refers to the last (terminal boundary value) state vector in the k th\nphase. For a trajectory with nph phases, there will be nph state dimensions, which can be\ncollected in an integer vector nxv(k), k = 1, . . . , nph:\n\xef\xa3\xb9\n\xef\xa3\xae\n\xef\xa3\xae\n\xef\xa3\xb9\n(x0,k )1\n. . . k0(1) + 1\nx0,1\n\xef\xa3\xba\n\xef\xa3\xaf\n.\n\xef\xa3\xaf xf,1 \xef\xa3\xba . . . kf(1) + 1\n.\nx0,k = \xef\xa3\xb0\n\xef\xa3\xbb\n.\n\xef\xa3\xba\n\xef\xa3\xaf\n\xef\xa3\xaf x0,2 \xef\xa3\xba . . . k0(2) + 1\n(x0,k )nxv(k)\n\xef\xa3\xba\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xba\n(24)\nxbc = \xef\xa3\xaf xf,2 \xef\xa3\xba . . . kf(2) + 1\n\xef\xa3\xae\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xaf\n.\n.\n.\n.\n(xndk +1,k )1\n\xef\xa3\xba\n\xef\xa3\xaf\n.\n.\n\xef\xa3\xba\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xba\n.\n\xef\xa3\xb0 x0,nph \xef\xa3\xbb . . . k0(nph) + 1\n.\nxf,k = \xef\xa3\xb0\n\xef\xa3\xbb\n.\n. . . kf(nph) + 1\nxf,nph\n(xnd +1,k )\nk\n\nnxv(k)\n\nThe two user subroutines that operate on xbc and p are psibc for (5), and phiobj for the\ncost (4):\npsibc As noted above, this subroutine implements (5), operating on the trajectory\xe2\x80\x99s boundary values and the p vector to compute boundary conditions as equality or inequality\nconstraints, as speci\xef\xac\x81ed by the user. The calling syntax is:\nsubroutine psibc(nstate,nph,k0,kf,nxv,nxbc,xbc,np,p, &\n&\nnpsi,psi,iebc,iebcflag)\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph), &\n&\nnxbc,np,npsi,iebcflag\ninteger,intent(out) :: iebc(npsi)\nreal(8),intent(in) :: xbc(nxbc),p(np)\nreal(8),intent(out) :: psi(npsi)\nThe inputs are:\nnstate: See the discussion at the beginning of this Subsection.\nnph: the number of phases in the trajectory\nk0: explained in (24)\nkf: explained in (24)\nnxv: nph-element integer containing state dimension for each phase\nnxbc: dimension of xbc, that is 2*sum(nxv)\nnp: dimension of p vector\nnpsi: dimension of psi vector \xe2\x80\x93 number of boundary conditions\niebcflag integer scalar that signals psibc to output the iecbvec vector. The values of\niebcflag that MADS inputs are\n0: a normal call, in which psibc is to compute its constraint quantities.\n1: psibc is required to output iecbvec and then exit. No other operations are\nwanted from psibc in this case. If the user does perform other operations,\nthey will be ignored.\n\n10\n\nThe outputs are:\npsi: the npsi-element vector of boundary condition constraints\niebc: npsi-dimensional integer vector of ones and zeros whose ith component signals\nMADS whether \xcf\x88(i) is an equality or inequality constraint. The values of iebc\nare\niebc(i)=0: \xcf\x88(i) = 0 is required for solution\niebc(i)=1: \xcf\x88(i) \xe2\x89\xa5 0 is required for solutions\nphiobj: This routine implements (4), evaluating the cost function \xcf\x86. The calling syntax is\nsubroutine phiobj(nstate,nph,k0,kf,nxv,nxbc,xbc,np,p,phi)\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph), &\n&\nnxbc,np\nreal(8),intent(in) :: xbc(nxbc),p(np)\nreal(8),intent(out) :: phi\nThe, by now, familiar inputs are:\nnstate: See the discussion at the beginning of this Subsection.\nnph: the number of phases in the trajectory\nk0: explained in (24)\nkf: explained in (24)\nnxv: nph-element integer containing state dimension for each phase\nnxbc: dimension of xbc, that is 2*sum(nxv)\nnp: dimension of p vector\nand the subroutine outputs the cost:\nphi: the scalar cost function\n\n2.3\n\nProducing and Operating On A MADS Solution\n\nThis Subsection describes the organization of data in a MADS solution and describes software for operating on that data. The software is a mix of FORTRAN95 for the actual\noptimization calculations, and Matlab functions for data manipulation. This Subsection\ndoes not go into detail in formulating and coding trajectory optimization problems; that is\nprovided via solved examples in Section 2.\nThe steps in producing a MADS solution are as follows:\n1. Formulate a reasonable problem.\n2. Code the four user-supplied subroutines, per Subsection 1.2.\n3. Code routines to provide the derivatives of the four subroutines referred to in Step\n2. This is to be done using autodi\xef\xac\x80erentiation software; automatic, widely available,\nreliable, and (currently) free for noncommercial use.\n4. Assemble an initial guess.\n5. Run MADS.\n\n11\n\n6. Review the solution. Accept it, or modify the problem formulation and go to Step 2.\nSteps 1 and 2 are up to the user, with help and insight from this Tutorial. Step 3 can\nbe accomplished using scripts provided with the MADS package, provided that the user\ninstalls TAPANADE [2]. This Section will also provide generic comments on autodi\xef\xac\x80erentiation for MADS, should the user prefer to use a di\xef\xac\x80erent package. Before discussing\nautodi\xef\xac\x80erentiation, though, we will concentrate on Steps 4 through 6.\n2.3.1\n\nFormats for MADS Solution Data\n\nWe \xef\xac\x81rst consider the organization of data in MADS, and software for manipulating it. The\nproblem variables for optimization are stacked together in a vector:\n\xef\xa3\xae\n\nvM ADS\n\nv1\n\xef\xa3\xaf v2\n\xef\xa3\xaf\n\xef\xa3\xaf .\n=\xef\xa3\xaf .\n\xef\xa3\xaf .\n\xef\xa3\xb0 vnph\np\n\n\xef\xa3\xae\n\n\xef\xa3\xb9\n\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\nvk = \xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xb0\n\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\nx1,k\nu1,k\n.\n.\n.\nxndk ,k\nundk ,k\nxndk +1,k\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(25)\n\nIn order for MADS to operate on vM ADS , it requires dimensional and program option data.\nThis is supplied by a text \xef\xac\x81le with integers as follows:\nnph,\nnxv(1),\n.\n.\n.\n\nnpsi,\nnuv(1),\n.\n.\n.\n\nnp\nncv(1),\n.\n.\n.\n\nndv(1),\n.\n.\n.\n\nkodev(1)\n.\n.\n.\n\n(26)\n\nnxv(nph), nuv(nph), ncv(nph), ndv(nph), kodev(nph)\nThis will be referred to in the sequel as a \xe2\x80\x9cpremads\xe2\x80\x9d \xef\xac\x81le.\nBecause (25) and (26) comprise a miserably inconvenient format for operating on or visualizing a MADS solution, utility functions are provided for converting between vM ADS /premads\nand a Matlab structure \xe2\x80\x93 call it \xe2\x80\x9cS\xe2\x80\x9d \xe2\x80\x93 with the following \xef\xac\x81elds:\nS.nph: number of phases\nS.np: dimension of p\nS.nxv: nph-element array of state dimensions\nS.nuv: nph-element array of control dimensions\nS.ndv: nph-element array whose k th element is the number of discretization intervals in the\nk th phase.\nS.x: nph-element cell array containing whose k th element contains that phase\xe2\x80\x99s state trajectory.. Each x{k} is\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\nx{k} = \xef\xa3\xaf\n\xef\xa3\xb0\n\nx1,1\nx2,1\n.\n.\n.\n\nx1,2\nx2,2\n.\n.\n.\n\nx(ndv(k)+1),1\n\nx(ndv(k)+1),2\n\n12\n\n\xc2\xb7\xc2\xb7\xc2\xb7\n..\n\n.\n\xc2\xb7\xc2\xb7\xc2\xb7\n\nx1,nxv(k)\nx2,nxv(k)\n.\n.\n.\nx(ndv(k)+1),nxv(k)\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(27)\n\nS.tx: nph-element cell array containing time (independent variable) instants for plotting the\ntrajectory in S.x. These assume the use of (2) for time scaling, and that the \xef\xac\x81rst nph\nelements of the p vector are used for this purpose. The organization of S.tx{k} is\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\nS.tx{k} = \xef\xa3\xaf\n\xef\xa3\xb0\n\nt0 (k)\nt0 (k) + p(k)/ndv(k)\n.\n.\n.\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(28)\n\nt0 (k) + p(k)\n0, k = 1\nt0 (k \xe2\x88\x92 1) + p(k \xe2\x88\x92 1), k > 1\n\nt0 (k) =\n\nS.u: nph-element cell array whose k th element contains that phase\xe2\x80\x99s control trajectory.\nSimilarly to S.x, S.uk has the structure\n\xef\xa3\xae\n\nu1,2\nu2,2\n.\n.\n.\n\nundv(k),1\n\n\xef\xa3\xaf\n\xef\xa3\xaf\nu{k} = \xef\xa3\xaf\n\xef\xa3\xb0\n\nu1,1\nu2,1\n.\n.\n.\n\nundv(k),2\n\n\xc2\xb7\xc2\xb7\xc2\xb7\n..\n\n.\n\xc2\xb7\xc2\xb7\xc2\xb7\n\nu1,nuv(k)\nu2,nuv(k)\n.\n.\n.\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(29)\n\nundv(k),nuv(k)\n\nNote that there are ndv(k) instants in this array, rather than ndv(k)+1.\nS.tu: nph-element cell array containing time instants for plotting the control trajectory in\nS.u. Again, the assumption is made that (2) is used; but the control instants are\nindexed to the midpoints of the discretization intervals:\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\nS.tu{k} = \xef\xa3\xaf\n\xef\xa3\xb0\n\nt0 (k) + 1 p(k)/ndv(k)\n2\n1\nt0 (k) + (1 + 2 )p(k)/ndv(k)\n.\n.\n.\n1\nt0 (k) + (ndv(k) \xe2\x88\x92 2 )p(k)/ndv(k)\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(30)\n\nand t0 (k) is de\xef\xac\x81ned in (28).\nA nice feature of this structure is, of course, that the user can add additional \xef\xac\x81elds to S.\n2.3.2\n\nMatlab Functions for Operating On MADS Data\n\nThe MADS package includes several Matlab functions for\n\xe2\x80\xa2 importing of vM ADS data into the Matlab environment, and supporting its visualization,\n\xe2\x80\xa2 modifying MADS solution data for a given problem formulation, in support of constructing an initial guess for an alternate, but related, problem formulation,\n\xe2\x80\xa2 exporting S-format data to MADS input data.\nThe functions that import MADS data and support visualization are, primarily, plotmadsMADS,\nand dtplotMADS. Two additional functions, getMADS, readpremadsMADS are included to provide the user with a little more \xef\xac\x82exibility in programming style. The functions are\nimportMADS: This is the main import function for MADS, and is called as\nS=importMADS(premads,fdata,flag)\n\n13\n\nThe inputs are:\npremads: character string, the name of the premads \xef\xac\x81le for the MADS data to be imported.\nfdata: another character string, this the name of the MADS output data \xef\xac\x81le, whose\ndata is in vM ADS format.\nflag: scalar \xef\xac\x82ag to indicate whether or not the lagrange multipliers computed by\nSNOPT for the MADS problem should also be imported. The admissible values\nare\n0 . . . don\xe2\x80\x99t import\n1 . . . do\nThe importMADS output is S, which contains all of the data in Subsection 1.3.1 and,\nadditionally,\nS.up: nph-element cell array containing the control trajectory, formatted to plot as a\nsequence of zero-order hold values.\nS.tup: nph-element cell array containing the corresponding time values, again, assuming\nthat the \xef\xac\x81rst S.np element of the S.p vector are used in (2) for time scaling.\nS.lamx: cell array containing lagrange multiplier histories for the discretization constraints,\noutput if flag=1.\nS.lama: cell array containing lagrange multiplier histories for the constraints in (6), output\nif flag=1. lamak=[] for those phases where there are no (6) constraints.\nS.lampsi: lagrange multiplier vector for (5), output if flag=1. Note that lampsi=[] if there\nare no boundary conditions.\nIt should also be noted that, if S.np = 0, then S.p is returned as nan.\ndtplotMADS: This function produces time vectors for use in plotting S state and control trajectories\nfor the case where (3) is used for variable time steps. It is called as\n[tu,ux]=dtplotMADS(dtin)\nwith input\ndtin: nph-element cell array, the k th element of which contains the vector of u\xcf\x84 from\nthe MADS solution for that phase.\nThe outputs are\ntu: cell array containing the time values for plotting S.u.\ntx: cell array containing the time values for plotting S.x.\nThe user who has a solution with variable time steps should get the solution with\nimportMADS, then discard that S.tx, S.tu, and run [S.tu,S.tx]=dtplotMADS(dtin),\nhaving pulled dtin together from the S.u data.\ngetMADS: This function, called as\nS=getMADS(fdata,nxv,nuv,ndv,np)\noutputs an S data structure containing only x, u, tx, tu, p, nxv, nuv, ndv, and np.\n\n14\n\nreadpreMADS: This function, called as\nS=readpreMADS(name)\nreads a premads \xef\xac\x81le with name name and outputs a partially populated S structure,\nwhich contains the dimensional and discretization option information contained in the\npremads \xef\xac\x81le.\nThe Matlab functions that support modifying and exporting MADS data are adduxMADS,\nbreaktrajMADS, dtaunphMADS, and writepreMADS.\nadduxMADS: This function, called as\nvout=adduxMADS(x,u,nxout,nuout,randmag,(optional) outind)\npads or removes columns from S-format x and u, and collects them into a vM ADS format vector. The states and control may optionally be reordered before concatenating into vM ADS . The inputs are\nx: S-format state trajectory x(nd+1,nx)\nu: S-format control trajectory u(nd,nu). This may be empty if nu = 0.\nnxout: desired output state dimension. If nxout > nx, then the additional states are\nindexed as x(nx + 1) . . . x(nxout).\nnuout: desired output control dimension. Padding for u follows the same pattern as with\nx.\nrandmag: If nxout > nx or nuout > nu, the padded extra states or controls are populated with r=randmag*rand, where rand is the Matlab uniform random number\ngenerator.\noutind: (optional argument) structure containing desired ordering of states or controls\nin the output. The x indices are in outind.xind and the u indices are in\noutind.uind. If either xind or uind are not to rearrange state or control indices, they may be set empty; otherwise, the dimension of each must be nxout\nand nuout, respectively. As a concrete example, suppose that nx = 3, nxout = 5\nand outind.xind=[4 1:3 5]. In this case, the S-format organization of each\nrow of the expanded state is xk = [x(4) x(1)k x(2)k x(3)k x(5)], k = 1, . . . , nd.\nThe output is\nvout: x and u in vM ADS format.\nNote that, for multiphase problems, adduxMADS is simply called for each phase, and\nthe output vectors are stacked to make the full vM ADS . For example,\nrandmag=0;\nv=[];\nfor k=1:n\nv=[v;adduxMADS(S.x{k},S.u{k},nxout(k),nuout(k),randmag)];\nend\nv=[v;S.p];\n\n15\n\nbreaktrajMADS: This function is used to break a single xk, uk phase into subphases and, optionally,\nto resample one or more of the subphases with a di\xef\xac\x80erent number of discretization\nintervals. The function also assumes that the time scaling approach of (2) is used, and\nproduces a vector of phase durations for the output subphases. The function is called\nas\nbout=breaktrajMADS(x,u,bv,tau,(optional) ndin)\nThe inputs are\nx: S-format state trajectory x(nd+1,nx)\nu: S-format control trajectory u(nd,nu). This may be empty if nu = 0.\nbv: vector of breakpoints \xe2\x80\x93 time-wise indices comprising the initial points of the output subphases. Note, bv does not include the inital point of the input singlephase trajectory, i.e. bv = 1. The breakpoints bv are de\xef\xac\x81ned in terms of\nthe state discretization mesh points, with bv = k breaking the trajectory at\nmesh point k. Suppose, for simplicity, we have x scalar, nph=1, ndv=20, and\nbv=[3]. This breaks the trajectory into two output phases, with ndv=[2 18],\nand xbout (kf(1) + 1) = x(3) and xbout (k0(2) + 1) = x(3) , where xbout is informal\nnotation for the multiphase output of breaktrajMADS. This, and the fact that\ncontrols are de\xef\xac\x81ned on the interval between the k th and (k + 1)th instants means\nthat if the user uses the control trajectory to choose a breakpoint, the chosen\ncontrol instant will appear in the phase to the right of the breakpoint. Note that\nit is admissible to input bv=[]. This would correspond to the case of resampling\na single trajectory phase. In this case, ndin, detailed below, would have a single\nelement.\ntau: scalar \xe2\x80\x93 the duration of the input phase.\nndin: This is an optional input, but must be present if bv=[]. ndin is the number of\nintegration intervals desired for each of the output subphases. The resampling is\ndone using piecewise linear interpolation of input state and control trajectories.\nand the output is\nbout: structure contining the split trajectory and associated information:\nndv: nbv-element array containing the number of discretization intervals in each\nsubphase.\ntau: nbv-element array containing the duration of each subphase, based on the\ninput value of tau.\nx: nbv-element cell array containing state subphases. Assuming that ndin is\nnot input, we have (referring to bout.x as x and bout.nph as nph,\n\n\xef\xa3\xae\nxin\n\n\xef\xa3\xaf\n=\xef\xa3\xb0\n\nx1\n.\n.\n.\nxnd+1\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xbb\xe2\x86\x92\n\n\xef\xa3\xae\n\n\xef\xa3\xb1\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb2\n\nx{1}\n\nx{k}\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4 x{nph}\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb3\n\n16\n\n\xef\xa3\xaf\n= \xef\xa3\xb0\n\nx1\n.\n.\n.\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xbb\n\n\xef\xa3\xae xbv(1)\n\xef\xa3\xb9\nxbv(k\xe2\x88\x921)\n\xef\xa3\xaf\n\xef\xa3\xba\n.\n.\n= \xef\xa3\xb0\n\xef\xa3\xbb,\n.\nxbv(k)\nnph\n\xef\xa3\xae k = 2, . . . ,\xef\xa3\xb9 \xe2\x88\x92 1\nxbv(nph)\xe2\x88\x921\n\xef\xa3\xaf\n\xef\xa3\xba\n.\n.\n= \xef\xa3\xb0\n\xef\xa3\xbb\n.\nxnd+1\n\n(31)\n\nu: nbv-element cell array of control subphases. Here,\n\xef\xa3\xb9\n\xef\xa3\xae\n\xef\xa3\xb1\nu1\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xba\n\xef\xa3\xaf\n\xef\xa3\xb4\n.\n\xef\xa3\xb4\n.\nu{1} = \xef\xa3\xb0\n\xef\xa3\xbb\n\xef\xa3\xb4\n.\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\nubv(1)\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb9\n\xef\xa3\xae\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xae\n\xef\xa3\xb9\nubv(k\xe2\x88\x921)\n\xef\xa3\xb4\n\xef\xa3\xb4\nu1\n\xef\xa3\xb4\n\xef\xa3\xb2\n\xef\xa3\xba\n\xef\xa3\xaf\n.\n.\nu{k} = \xef\xa3\xb0\n\xef\xa3\xaf . \xef\xa3\xba\n\xef\xa3\xbb,\n.\n. \xef\xa3\xbb\xe2\x86\x92\nuin = \xef\xa3\xb0 .\n\xef\xa3\xb4\nubv(k)\n\xef\xa3\xb4\n\xef\xa3\xb4\nund\n\xef\xa3\xb4\n\xef\xa3\xb4\nk = 2, . . . ,\xef\xa3\xb9 \xe2\x88\x92 1\nnph\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xae\n\xef\xa3\xb4\n\xef\xa3\xb4\nubv(nph)\xe2\x88\x921\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xba\n.\n\xef\xa3\xb4 u{nph} = \xef\xa3\xaf\n.\n\xef\xa3\xb4\n\xef\xa3\xb0\n\xef\xa3\xbb\n\xef\xa3\xb4\n.\n\xef\xa3\xb4\n\xef\xa3\xb3\nund\n\n(32)\n\ndtaunphMADS: This function, called as\ndtout=dtaunphMADS(bv,dtin)\nbreaks the u\xcf\x84 trajectory from (3) into multiple subphases. It needs to be used in order\nto correctly scale the subphases\xe2\x80\x99 u\xcf\x84 s. The inputs are\nbv: vector of breakpoints, identical to that for breaktrajMADS, above.\ndtin: vector of u\xcf\x84 values taken from a MADS solution.\nand the output is\ndtout: cell array of with length(bv)+1 elements. Each k th cell contains the u\xcf\x84 trajectory\nfor the subphase of dtin that began with its element bv(k).\nwritepreMADS: This function is the twin of readpreMADS. It inputs an S structure and writes the\ncorresponding premads \xef\xac\x81le onto a \xef\xac\x81le with name name. It is called as\nwritepreMADS(S,name)\nFunction writepreMADS opens and closes \xef\xac\x81le \xe2\x80\x9cname.\xe2\x80\x9d\nThere are several other MADS support functions with very specialized applicability, and\nthey will be described in their contexts. Before leaving this topic, though, there is one\nadditional function to describe.\nfindIMADS: This function can be used to assist in debugging MADS problems. The function is\ncalled as\ntheI=findIMADS(S,row)\nwith S structure S and \xe2\x80\x9crow\xe2\x80\x9d as inputs. This function is used to help diagnose misbehavior in MADS solutions. The diagnostic output from SNOPT includes a check of\nthe correctness of the overall problem jacobian at the beginning of the run, comparing\nthe user-supplied analytic jacobian to one using numerical di\xef\xac\x80erentiation. If there\xe2\x80\x99s\nan error at a particular constraint element \xe2\x80\x93 \xe2\x80\x9crow\xe2\x80\x9d the comment \xe2\x80\x9cbad\xe2\x80\x9d is appended to\nthe right of the output for that row. At the end of the run, a summary of the \xef\xac\x81nal constraint activity is provided, labelled \xe2\x80\x9cSection 1 - Rows.\xe2\x80\x9d If there is an infeasibility\nfor a particular constraint (row), it will be \xef\xac\x82agged with an \xe2\x80\x9cI\xe2\x80\x9d in the column labelled\n\xe2\x80\x9cState.\xe2\x80\x9d To use findIMADS, the user supplies dimensional data in S, gotten either by\nusing importMADS or readpreMADS, and the o\xef\xac\x80ending row number. The output is\n\n17\n\ntheI: structure containing\nkph:\njk:\nxcp:\nind:\n\nthe phase number. theI.kph=[] if the constraint is in psibc.\nthe discretization interval. theI.jk=[] if the constraint is in psibc.\nthe \xe2\x80\x9ctype\xe2\x80\x9d of the constraint: \xe2\x80\x99c\xe2\x80\x99 if in cineq, \xe2\x80\x99x\xe2\x80\x99 if in xdot, or \xe2\x80\x99p\xe2\x80\x99 if in psibc.\nthe position of the constraint in the in the user-supplied routine\xe2\x80\x99s output.\nFor example, if theI.xcp=\xe2\x80\x99p\xe2\x80\x99 and theI.ind=2, the problem is with psi(2).\n\nWe hope that the user will never want to use this function, but we know better.\n\n2.4\n\nSetting Up and Executing a MADS Run\n\nThus far, we have described the general MADS problem formulation, the user-supplied\nsubroutines for realizing a given problem in MADS, and utilitiies for operating on MADS\xe2\x80\x99\ninput and output data. We now turn to the mechanics of actually making a MADS run.\nThere are three principal considerations to be kept in mind when setting up a problem\nfor MADS:\n1. Because the problem formulation resides in the four separate subroutines of Subsection\n1.2, it is generally in the user\xe2\x80\x99s best interest to treat those data that are common to two\nor more problem routines as global variables. We recommend use of the FORTRAN\n\xe2\x80\x9cMODULE\xe2\x80\x9d program unit as a means of safely sharing data across multiple local\nprogram units. Consider the following code fragment:\nmodule myprobMOD\nimplicit none\ninteger, parameter ::\n&\n& UsedByCineq = 1,\n&\n& UsedByAll = UsedByCineq + 2\nreal(8) ::\n&\n& xdotParam\nend module myprobMOD\nsubroutine cineq(nstate, kph, nk, jk, nx, xj, xjp1, &\n&\nnu, u, np, p, nc, c, iec, iecflag)\nuse myprobMOD, only : UsedByCineq, UsedByAll\nimplicit none\n.\n.\n.\nsubroutine xdot(nstate, kph, nk, jk, nx, x, nu, u, np, p, f)\nuse myprobMOD, only : UsedByAll, xdotParam\nimplicit none\n.\n.\n.\nprogram myprob\nuse myprobMOD, only xdotParam\nimplicit none\n.\n.\n.\nxdotParam = some number\n.\n.\n.\n\n18\n\n2. Typically, for a given physical plant model, several di\xef\xac\x80erent trajectory optimziation\nproblems may be posed for it. These may simply be di\xef\xac\x80erent missions that the plant\nis being called upon to perform, or it may be di\xef\xac\x80erent formulations of super\xef\xac\x81cially\nsimilar optimization problems that the user explores while seeking results that are\nnot only optimal but desirable. Each of the examples in the Tutorial Section 2 will\ncontain examples of this type of exploration. Because of this, it is highly desirable\nthat the user strictly separate plant model software from problem formulation software.\nFor example, suppose that a problem is posed with free terminal time using the (2)\nformulation. In that case, xdot should look like\nmodule FreeTimeMOD\n.\n.\n.\ninteger, parameter ::\n&\n& loctau = 1\n! location of terminal time in p\nend module FreeTimeMOD\nsubroutine xdot(nstate, kph, nk, jk, nx, x, nu, u, np, p, f)\nuse FreeTimeMOD, only : loctau\n.\n.\n.\n!\nMyPlant is a separate subroutine for plant ODEs\ncall MyPlant(x, u, f)\nf = p(loctau) \xe2\x88\x97 f ! Here is the time \xe2\x88\x92 scaling\nend subroutine xdot\n3. The instantiation of a given MADS problem will typically involve some 15-16 unique\n\xef\xac\x81les, not counting those pertaining to the plant model. These include \xe2\x80\x9cplain\xe2\x80\x9d and\nautodi\xef\xac\x80erentiated xdot, cineq, psibc and phiobj routines, main and MODULE program units, input and output data, and scripts for visualization and for assembling\nthe initial guess. Experience teaches that, unless the problem-unique \xef\xac\x81les for each\nMADS problem are kept separate from those of other MADS problems, confusion will\nensue. The authors strongly recommend devoting a directory or \xe2\x80\x9cfolder\xe2\x80\x9d to each such\nproblem and, further, to a\xef\xac\x83x a common character string to each of the names of each\nof the \xef\xac\x81les that associates them with their particular problem. This practice will be\nillustrated in the Tutorial.\nMADS execution is performed by the subroutine batchMADS, calling SNOPT. This subroutine is called by a main routine, and needs to be linked to the MADS subroutine library,\nthe problem subroutines cineq, xdot, psibc, phiobj, their derivatives cineq dv, xdot dv,\npsibc dv, phiobj dv, and any model-speci\xef\xac\x81c subroutines. Generation of the derivative routines\xe2\x80\x99 source code is described in the next Subsection, and the syntax of batchMADS is given\nbelow:\nbatchMADS: This subroutine,\nsubroutine batchMADS(findata,fpremads,foutdata,inform)\ninteger,intent(in) :: findata,fpremads,foutdata\ninteger,intent(out):: inform\nhas the following arguments:\nfindata: FORTRAN \xe2\x80\x9cunit number\xe2\x80\x9d for an opened \xef\xac\x81le containing the input guess.\n\n19\n\nfpremads: Unit number for an opened \xef\xac\x81le containing the premads \xef\xac\x81le for the given problem.\nfoutdata: Unit number for an opened \xef\xac\x81le into which batchMADS will write the solution\ndata at the conclusion of batchMADS execution. This \xef\xac\x81le contains a concatenation of the output value of vM ADS from (25) and the SNOPT-computed lagrange\nmultipliers for the constraints in the Z vector, de\xef\xac\x81ned in (8). Recall that extracting and organizing the lagrange multipliers from MADS output is handled\nby importMADS as an option. If SNOPT fails to converge, the output data in\nfoutdata corresponds to the state of the iterations at the end of the run.\ninfo: This is a batchMADS output, and is a pass-through from SNOPT, in whose documentation [1] info is fully documented. The most typical values that will be\nencountered by the MADS user are\n1:\n3:\n13:\n41:\n52:\n\n\xef\xac\x81nished successfully\ncouldn\xe2\x80\x99t achieve desired accuracy\ninfeasible constraint(s)\ncurrent point cannot be improved\nincorrect constraint derivatives\n\nIn batchMADS, several SNOPT parameters are set. These are Infinite Bound set to\n1020 , Verify Level, set to 3, Derivative Level, set to 3, and Linesearch Tolerance,\nset to 0.99. These values can be overridden, or other SNOPT options set by writing\nand linking a subroutine userset:\nsubroutine userset(fprt,fsumm,info,cw,lcw,iw,liw,rw,lrw)\ninteger,intent(in) :: fprt,fsumm,lcw,liw,lrw\ninteger,intent(out) :: info,iw(liw)\nreal(8),intent(out) :: rw(lrw)\ncharacter(8),intent(out) cw(lcw)\nIn the body of this subroutine, the user calls SNOPT routines snseti, or snsetr to\nset parameters as preferred. The user is not required to provide a userset, as the\nMADS library includes a dummy for linking.\n2.4.1\n\nAutodi\xef\xac\x80erentiation for MADS\n\nThis Subsection provides a short discussion of algorithmic di\xef\xac\x80erentiation (AD) in MADS.\nAlgorithmic, or \xe2\x80\x9cautomatic\xe2\x80\x9d di\xef\xac\x80erentiation [4] is the use of software techniques to numerically evaluate the derivative of a function calculated by a computer code. This is \xe2\x80\x93 very\nsuper\xef\xac\x81cially speaking \xe2\x80\x93 done by analytically di\xef\xac\x80erentiating the most primitive computations\nin the code, e.g., exponentiation, transcendental functions, and so on, and building up the\nfull evaluation of the derivative by repeatedly applying the chain rule. This technique has\na substantial advantage over the use of \xef\xac\x81nite di\xef\xac\x80erences in that the computed derivative is\naccurate to machine precision, with no degradation due to the truncation that is associated\nwith di\xef\xac\x80erence-based di\xef\xac\x80erentiation.\nMADS requires the derivatives of f (1), c (6), \xcf\x88 (5), and \xcf\x86 (4). If the user has\nTAPANADE [2] installed, the subroutines that provide these derivatives \xe2\x80\x93 xdot dv, cineq dv,\npsibc dv, phiobj dv \xe2\x80\x93 are simply obtained by executing the following Matlab script invocations from the command line:\ntapxdot(\xe2\x80\x99routines called by xdot, MODULES referenced by xdot\xe2\x80\x99)\ntapcineq(\xe2\x80\x99routines called by cineq, MODULES referenced by cineq\xe2\x80\x99)\ntappsibc(\xe2\x80\x99routines called by psibc, MODULES referenced by psibc\xe2\x80\x99)\n\n20\n\ntapphiobj(\xe2\x80\x99routines called by phiobj, MODULES referenced by phiobj\xe2\x80\x99)\ntapscript\nand then the user need not think any further about AD. In the code fragments above,\nincidentally, the arguments to each of the tapxxx functions are to be input as string variables.\nFor example, if xdot calls MyPlant.f90 and references variables from MyProbMOD.f90, then\nthe detailed call to tapxdot would be\ntapxdot(\xe2\x80\x99MyProbMOD.f90 MyPlant.f90\xe2\x80\x99)\nThe order of \xef\xac\x81les in the argument does not matter. Again, TAPANADE users can skip the\nrest of this section.\nIf the user wishes to use a di\xef\xac\x80erent AD package to generate the XXX dv subroutines, it will\nneed to be able to provide \xe2\x80\x9cmultidimensional\xe2\x80\x9d di\xef\xac\x80erentiation, and to do so in \xe2\x80\x9cforward,\xe2\x80\x9d or\nsynonymously, \xe2\x80\x9clinear tangent\xe2\x80\x9d mode. The \xef\xac\x81rst of these options will assure that the routines\nare di\xef\xac\x80erentiated over the entire span of their arguments: For a code that computes g(x),\nx \xe2\x88\x88 Rn , rather than generating a dv subroutine to compute v T gx , it will compute\n\xe2\x88\x82gk\n(33)\n\xe2\x88\x82xj\nRegarding \xe2\x80\x9cforward\xe2\x80\x9d versus the alternative \xe2\x80\x9cadjoint\xe2\x80\x9d or, synonymously, \xe2\x80\x9cbackward\xe2\x80\x9d modes\nof di\xef\xac\x80erentiation, \xe2\x80\x9cforward\xe2\x80\x9d is a di\xef\xac\x80erentiation mode that follows the order of execution in\nthe subroutine(s) being di\xef\xac\x80erentiated. This mode produces subroutines with the interface\nsyntax\n(gx )jk =\n\nsubroutine xdot_dv(nstate,kph,nk,jk,nx,x,xd,nu,u,ud,np,p,pd,f,fd,nb)\ninteger,intent(in) :: nstate,kph,nk,jk,nx,nu,np,nb\nreal(8),intent(in) :: x(nx),xd(nb,nx),u(nu),ud(nb,nu),p(np),pd(nb,np)\nreal(8),intent(out) :: f(nx),fd(nb,nx)\n! Note: nb=nx+nu+np\nsubroutine cineq_dv(nstate,kph,nk,jk,nx,xj,xjd,xjp1,xjp1d,\n&\nnu,u,ud,np,p,pd,nc,c,cd,iec,iecflag,nb)\ninteger,intent(in) :: nstate,kph,nk,jk,nx,nu,np,nc,iecflag,nb\ninteger,intent(out) :: iec(nc)\nreal(8),intent(in) :: xj(nx),xjd(nb,nx),xjp1(nx),xjp1d(nb,nx),\n&\nu(nu),ud(nb,nu),p(np),pd(nb,np)\nreal(8),intent(out) :: c(nc),cd(nb,nc)\n! Note: nb=2*nx+nu+np\n\n&\n\n&\n\nsubroutine psibc_dv(nstate,nph,k0,kf,nxv,nxbc,xbc,xbcd,np,p,pd, &\n&\nnpsi,psi,psid,iebc,iebcflag,nb)\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph),np,\n&\n&\nnpsi,iebcflag,nb\ninteger,intent(out) :: iebc(npsi)\nreal(8),intent(in) :: xbc(nxbc),xbcd(nb,nxbc),p(np),pd(nb,np)\nreal(8),intent(out) :: psi(npsi),psid(nb,npsi)\n! Note: nb=nxbc+np\nsubroutine phiobj_dv(nstate,nph,k0,kf,nxv,nxbc,xbc,xbcd,np,p,pd, &\n&\nphi,phid,nb)\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph),np,nb\nreal(8),intent(in) :: xbc(nxbc),xbcd(nb,nxbc),p(np),pd(nb,np)\nreal(8),intent(out) :: phi,phid(nb)\n! Note: nb=nxbc+np\n\n21\n\nThe dv subroutines above are autodi\xef\xac\x80erentiated with the following lists of dependent and\nindependent variables:\n\nxdot :\ncineq :\npsibc :\nphiobj :\n\ndependent\nf\nc\npsi\nphi\n\nindependent\nx u p\nxj xjp1 u p\nxbc p\nxbc p\n\nTAPANADE, and other AD programs within the author\xe2\x80\x99s experience, concatenates lists of\nmultiple independent variables, conceptually, into a column vector \xe2\x80\x9cb\xe2\x80\x9d:\nxdot :\ncineq :\npsibc :\nphiobj :\n\nb = [xT uT p],\nb = [xjT xjp1T uT pT ],\nb = [xbcT p],\nb = [xbcT p],\n\nnb = nx + nu + np\nnb = 2nx + nu + np\nnb = nxbc + np\nnb = nxbc + np\n\n(34)\n\nThe \xe2\x80\x9cd\xe2\x80\x9d-su\xef\xac\x83x variables in the subroutine input arguments, e.g., xd, ud, pd in the case of\nxdot dv, are column partitions of \xe2\x88\x82b/\xe2\x88\x82bT = I. Note the following:\n1. The orders of variables in (34) is not important. What is illustrated here is merely\nthe order in which the variables are stacked in the MADS code.\n2. It is critical that the AD user autodi\xef\xac\x80erentiates using the entire list of independent\nvariables at once. For example, if a user autodi\xef\xac\x80erentiates xdot \xef\xac\x81rst with dependent\nvariable x, then with u, then with p, he or she might get a di\xef\xac\x80erentiated subroutine\nwhose argument list looks super\xef\xac\x81cially similar to that displayed above; but attempting\nits use would almost certainly crash the program\xe2\x80\x99s execution or, worse yet, only provide\nerroneous results.\n3. It is not unusual for an AD code to presume that the dimensionality of b is actually\nlarger than that declared via the list of dependent variables declared to the AD software. In order to accomodate this presumption, they do things such as introducing a\nglobal variable into the dv code that contains the \xe2\x80\x9creal\xe2\x80\x9d row dimension of the d-su\xef\xac\x83x\nvariables. For example, TAPANADE inserts the line USE DIFFSIZES into the subroutine header, where DIFFSIZES is to be a user-supplied MODULE \xef\xac\x81le containing a\ndeclaration of the variable NBDIRSMAX. This NBDIRSMAX is then used as the row dimension for all of the d-su\xef\xac\x83x variables and certain intermediate variables. This behavior\nis unsuitable for MADS. The row dimensions of these variables should be nb, not\nNBDIRSMAX. This, and a few other annoyances are corrected for TAPANADE-based\nMADS users by executing the script tapscript.\n4. Some AD packages, by default, second-guess the user\xe2\x80\x99s declaration of dependent variables and fail to provide a d-su\xef\xac\x83x arguments in the dv routine\xe2\x80\x99s argument list for\na given dependent variable if the declared dependency doesn\xe2\x80\x99t actually exist for the\ngiven subroutine. For example, suppose that xdot didn\xe2\x80\x99t actually include any element\nof the p vector in its computation of f. In this case, the AD output would have \xef\xac\x81rst\nline\nsubroutine xdot_dv(nstate,kph,nk,jk,nx,x,xd,nu,u,ud, &\n&\nnp,p,f,fd,nb)\nThis example is missing \xe2\x80\x9cpd,\xe2\x80\x9d and attempting its use in a MADS execution would\nresult in, at best, a program crash, since MADS requires a particular, \xef\xac\x81xed, interface\n\n22\n\nto its dv subroutines. The user should be wary about this. This can happen; for\nexample, it is TAPANADE\xe2\x80\x99s default behavior, though that can be corrected by using\nthe command line option \xe2\x80\x9c-fixinterface.\xe2\x80\x9d\n\n23\n\n3\n\nTutorial Examples\n\nThis section is a tutorial for the use of MADS in solving numerical optimal control problems.\nThe exposition is cast in the form of a sequence of example problems. This sequence\nprogresses from very simple to fairly complicated, and each problem in the sequence features\none or more tricks that are generically useful in other problems that the user may face. Two\nexamples are considered:\n1. Linear System Minimum Time to Origin\nThe optimal solution of this classic problem, described in Chapter 3.9 of [5] in continuous time is a \xe2\x80\x9cbang-bang\xe2\x80\x9d control trajectory in which the control jumps discontinously\nbetween maximum and minimum constraint limits. Because MADS employs a \xef\xac\x81xed\ntime step in its discretization, it will be seen that the solution to the most straightforward MADS formulation di\xef\xac\x80ers from the continuous time solution by having an\n\xe2\x80\x9cexcrescence\xe2\x80\x9d in its control trajectory \xe2\x80\x93 a single time interval in which the control\ntakes on an intermediate value. Two approaches for capturing the structure of the\ncontinuous time problem are described:\n\xe2\x80\xa2 Break the problem into two phases.\n\xe2\x80\xa2 Introduce variable discretization step size.\nAlternatively, recognizing that true \xe2\x80\x9cbang-bang\xe2\x80\x9d control trajectories are not physically\nrealizable, we also demonstrate a technique that exploits the structure of the midpoint\neuler discretization to limit the bandwidth of the control solution by penalizing or\nconstraining its rate and acceleration. An alternative to this technique would be\nto introoduce a low-pass \xef\xac\x81lter for the control into the dynamics. In optimizing the\ntrajectory with such a \xef\xac\x81lter in place, however, there will be a tendency for the control\nsolution to attempt to cancel out the \xef\xac\x81lter dynamics. The approach given here has\nthe advantage of operating directly on the control.\n2. Goddard Problem\nIn the Goddard problem [8], the goal is to maximize the \xef\xac\x81nal altitude of a sounding\nrocket\xe2\x80\x99s ascent. In the problem treated here, it \xef\xac\x82ies through an exponentially decaying\natmosphere in an inverse-square gravitational \xef\xac\x81eld, and is subject to an inequality\nconstraint on dynamic pressure.\nThis problem is distinguished by having a \xe2\x80\x9csingular arc\xe2\x80\x9d as described in Chapter\n8 of [5]. A singular arc, in a variational optimal control problem, is a \xef\xac\x81nite portion of the optimal trajectory in which the control necessary condition for optimality\nvanishes identically; in other words, to \xef\xac\x81rst order, the optimal performance of the\nsystem is oblivious to the value of the control while it traverses the singular arc. It is\nstraightforward to obtain converged solutions to such problems using MADS, but this\ninsensitivity of performance to the control along singular arcs can a\xef\xac\x80ect the quality of\nthe converged solution in two ways:\n(a) The user is likely to get a messy-looking control trajectory where there is no\nnumerically unambiguous optimum.\n(b) The ambiguity in the control solution may also imply that the state trajectory\ndrifts some from the exact optimum.\nIn this example, a straightforward direct solution for the case without an active dynamic\npressure constraint displays the \xe2\x80\x9cmessy-looking\xe2\x80\x9d control trajectory warned of above, and a\npenalty function is applied to the jitter. The example concludes with imposition of a an\nactive dynamic pressure inequality constraint.\n\n24\n\n3.1\n3.1.1\n\nLinear System Minimum Time to Origin\nBaseline Problem\n\nIn this classic problem [5], a system of the form\nu \xe2\x88\x88 [\xe2\x88\x921, 1]\n\n(35)\n\nx(0) = b\n\xcb\x99\n\nx=u\n\xc2\xa8\n\n(36)\n\nis driven from\nx(0) = a\n\nto the origin in minimum time, \xcf\x84 \xe2\x88\x97 , resulting in an optimal trajectory in which the control,\nu(t), rides the saturation boundaries cited in (35), switching a maximum of one time from\n-1 to 1 or vice versa, depending on initial conditions. The problem is expressed for MADS\nby converting the expression x to \xef\xac\x81rst order ODEs:\n\xc2\xa8\nx1 = x2\n\xcb\x99\n\nx2 = u\n\xcb\x99\n\n(37)\n\nand time-scaling the the equations of motion, per (2), as\nx1\nx2\n\n=\xcf\x84\n\nx2\nu\n\n(38)\n\nThe cost function is\n\xcf\x86=\xcf\x84\n\n(39)\n\nthe control inequality constraints are\n1\xe2\x88\x92u\n1+u\n\nc(x, u) =\nand the boundary conditions are\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xcf\x88=\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xb0\n\nx1 (0) \xe2\x88\x92 a\nx2 (0) \xe2\x88\x92 b\nx1 (1)\nx2 (1)\n\xcf\x84\xe2\x88\x92 \xcf\x84\n\n\xe2\x89\xa50\n\n(40)\n\n\xef\xa3\xb9\n\n\xef\xa3\xae\n\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n\xef\xa3\xaf\n\xef\xa3\xaf\niebc = \xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xb0\n\n0\n0\n0\n0\n1\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(41)\n\nIn (41), recall that boundary conditions expressed with iebc = 0 are treated as equality\nconstraints. In the case where iebc = 1, above, the constraint is nonnegative:\n\xcf\x84\xe2\x88\x92\n\n\xcf\x84\n\n\xe2\x89\xa50\n\nwhere \xcf\x84 is a user-selected small positive number. A constraint of this kind is inexpensive to\ninclude, and can be quite valuable, since duration parameters in collocation-based trajectory\noptimization computations \xe2\x80\x93 at least in our experience \xe2\x80\x93 frequently exhibit unproductive\nbehavior during the iterative search for a solution, taking on zero or negative values unless\nrestrained. The parameter \xcf\x84 is placed in the pv partition of the vector of free variables:\nvin = [\xc2\xaf0 , u0 , x1 , u1 , \xc2\xb7 \xc2\xb7 \xc2\xb7 xnd , und , xnd+1 , \xcf\x84 ]\nx\n\xc2\xaf\n\xc2\xaf\n\xc2\xaf\nwhere xk = [(x1 )k , (x2 )k ] and nd is the number of discretization intervals selected. For this\n\xc2\xaf\nproblem, we choose nd = 50.\nThe subroutines below are reliably parsed by the version of TAPANADE [2] available at\nthe time of writing.\n\n25\n\nsubroutine xdot(nstate,kph,inst,xv,nx,uv,nu,pv,np,fv)\nimplicit none\ninteger,intent(in) :: nstate,kph,inst,nx,nu,np\nreal(8),intent(in) :: xv(nx),uv(nu),pv(np)\nreal(8),intent(out) :: fv(nx)\nreal(8) :: x2,u,p\nif(nstate.GT.1)return ! This is the last \xe2\x80\x98\xe2\x80\x98cleanup\xe2\x80\x99\xe2\x80\x99 call from SNOPT\nx2=xv(2) ! Calling out scalar variables aids in clarifying\nu=uv(1)\n! complicated nonlinear expressions. Pointers could be\np=pv(1)\n! substituted here if they were reliably supported.\nfv(1)=x2\nfv(2)=u\nfv=fv*p\nreturn\nend subroutine xdot\nsubroutine cineq(nstate,kph,nx,xj,xjp1,nu,uv,np,pv,nc,cv)\nimplicit none\ninteger,intent(in) :: nstate,kph,nx,nu,np,nc\nreal*8,intent(in) :: xj(nx),xjp1(nx),uv(nu),pv(np)\nreal*8,intent(out) :: cv(nc)\nif(nstate.GT.1)return\ncv(1)=1+uv(1)\ncv(2)=1-uv(1)\nreturn\nend subroutine cineq\nsubroutine psibc(nstate,nph,k0,kf,nxv,nxbc,xbc,np,pv,npsi, &\n& psi,iebc,iebcflag)\nimplicit none\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph), &\n& nxbc,np,npsi,iebcflag\ninteger,intent(out) :: iebc(npsi)\nreal(8),intent(in) :: xbc(nxbc),pv(np)\nreal(8),intent(out) :: psi(npsi)\nreal(8) :: x10,x20,x1f,x2f,tau\nif(nstate.GT.1)return\nif(iebcflag.EQ.1)then ! At the beginning of the run, tell MADS\niebc=0\n! which boundary conditions are\niebc(5)=1\n! equalities and which are inequalities,\nreturn\n! and RETURN!\nendif\nx10=xbc(k0(1)+1) ! x1(0)\nx20=xbc(k0(1)+2) ! x2(0)\nx1f=xbc(kf(1)+1) ! x1(t_f)\nx2f=xbc(kf(1)+2) ! x2(t_f)\ntf=pv(1)\npsi(1)=1-x10\npsi(2)=1-x20\npsi(3)=x1f\npsi(4)=x2f\npsi(5)=tau-1.D-6 !terminal time is positive\n\n26\n\nreturn\nend\nsubroutine phiobj(nstate,nph,k0,kf,nxv,nxbc,xbc,np,pv,phi)\nimplicit none\ninteger,intent(in) :: nstate,nph,k0(nph),kf(nph),nxv(nph),nxbc,np\nreal(8),intent(in) :: xbc(nxbc),pv(np)\nreal(8),intent(out) :: phi\nif(nstate.GT.1)return\nphi=pv(1)\nreturn\nend subroutine phiobj\nand, \xef\xac\x81nally, the premads \xef\xac\x81le is\n1,5,1\n2,1,50,2,0\nwhere the last element of the second line, recall, indicates that the midpoint Euler discretization is speci\xef\xac\x81ed.\nHaving assembled software for the cost function and modelling constraints, and ADprocessed the xdot, cineq, psibc, and phiobj routines, it remains to compute a converged\nsolution. The \xef\xac\x81rst two attempts to compute a solution for this very simple, nearly linear,\nproblem were unsuccessful. The initial guesses for vin were, respectively, all ones, and\nall random numbers generated by Matlab\xe2\x80\x99s rand() function. These attempts were both\nunsuccessful \xe2\x80\x93 SNOPT was unable to compute a feasible iterate.\nThe next attempt to generate an initial guess for this problem was to solve a similar,\nbut less stringent, problem. The changes were to eliminate the state boundary conditions,\nmoving them to the cost function. In other words,\n\xcf\x88\n\xcf\x86\n\n= \xcf\x84 \xe2\x88\x92 , iebc = 1\n= \xcf\x84 + \xce\xb1 \xe2\x88\x97 (x1 (0) \xe2\x88\x92 a)2 + (x2 (0) \xe2\x88\x92 b)2 + (x1 (1))2 + (x2 (1))2\n\nThis was also an unsuccessful problem, in that it did no better in leading to a feasible\nsolution. A successful initial guess was generated, however, by \xef\xac\x81xing \xcf\x84 , rather than letting\nit vary freely. This was done by setting setting iebc to zero for the psibc constraint\n\xcf\x84 \xe2\x88\x92 1 = 0, and using all ones as an initial guess.\nThis latter guess was passed on to the original problem formulation laid out above, and\nused successfully as an initial guess to obtain the time-optimal solution that satis\xef\xac\x81ed the\nstate boundary conditions. It will be seen that this pattern plays out generically in using\nMADS for solving OCPs. Initial guesses are most easily generated by relaxing path constraints, such as boundary conditions, instead getting a solution time history that satis\xef\xac\x81es\nthe discretization constraints, say (9). Final time should be treated warily in the search for\nthe initial guess.\nFigure 1 displays the solution for a minimum-time trajectory from initial conditions\nx(0) = 1, x(0) = 1. The plot on the right displays the actual control time history (piecewise\n\xcb\x99\nconstant) as dark red, and a continuous line drawn through the midpoints of the control\nincrements in lighter red. As mentioned in the tutorial\xe2\x80\x99s introduction, the control history\nis not perfectly \xe2\x80\x9cbang-bang,\xe2\x80\x9d having a little excrescence near the time t = 2.25s. Two\napproaches for \xef\xac\x81xing this are given below:\n\n27\n\n1.5\n\n1\n\n1\n0.5\n\n0\n\n0\n\nu\n\ndx/dt\n\n0.5\n\n\xe2\x88\x920.5\n\xe2\x88\x920.5\n\xe2\x88\x921\n\xe2\x88\x921.5\n0\n\n0.5\n\n1\n\n\xe2\x88\x921\n0\n\n1.5\n\n0.5\n\n1\n\n1.5\n\nx\n\n2\n\n2.5\n\n3\n\ntime\n\nFigure 1. Two-State Bang-Bang Problem with Constant Time Step\n3.1.2\n\nBreak the problem into two phases\n\nA cleaner control discontinuity can be obtained by breaking the problem into two phases\nat the point at which the solution \xe2\x80\x9cbangs\xe2\x80\x9d from its maximum to its minimum value. This\nis done by introducing continuity boundary conditions on the states, including separate\nduration parameters for each phase, and setting the control to its appropriate constrained\nvalue during each phase. Denoting the states as x11 , x21 during the \xef\xac\x81rst phase and x12 , x22\nduring the second, the revised formulation is\nx11 = x21 , x21 = u\n\xcb\x99\n\xcb\x99\nx12 = x22 , x22 = u\n\xcb\x99\n\xcb\x99\n\nPHASE 1\nPHASE 2\n\n(xdot)\n\n\xcf\x86 = \xcf\x841 + \xcf\x842\n\nc=\n\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xcf\x88=\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xb0\n\nu\xe2\x88\x921\n\xe2\x88\x92u + 1\nu+1\n\xe2\x88\x92u \xe2\x88\x92 1\n\n\xe2\x89\xa5\n\xe2\x89\xa5\n\xe2\x89\xa5\n\xe2\x89\xa5\n\nx11 (0) \xe2\x88\x92 a\nx21 (0) \xe2\x88\x92 b\nx11 (1) \xe2\x88\x92 x12 (0)\nx21 (1) \xe2\x88\x92 x22 (0)\nx12 (1)\nx22 (1)\n\xcf\x841 \xe2\x88\x92\n\xcf\x842 \xe2\x88\x92\n\n0\n0\n0\n0\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(42)\n(43)\n\nPHASE 1\n(cineq)\n\n(44)\n\nPHASE 2\n\xef\xa3\xae\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\niebc = \xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xaf\n\xef\xa3\xb0\n\n28\n\n0\n0\n0\n0\n0\n0\n1\n1\n\n\xef\xa3\xb9\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xba\n\xef\xa3\xbb\n\n(psibc)\n\n(45)\n\n3.5\n\nNote that the inequalities in (44) enforce u = 1 in phase 1 and u = 1 in phase 2. A\npsibc code fragment implementing the boundary conditions in (45) is\nx110=xbc(k0(1)+1)\nx210=xbc(k0(1)+2)\nx11f=xbc(kf(1)+1)\nx21f=xbc(kf(1)+2)\nx120=xbc(k0(2)+1)\nx220=xbc(k0(2)+2)\nx12f=xbc(kf(2)+1)\nx22f=xbc(kf(2)+2)\ntau1=pv(1)\ntau2=pv(2)\npsi(1)=x110-a\npsi(2)=x210-b\npsi(3)=x11f-x120 ! continuity across phases\npsi(4)=x21f-x220 ! continuity across phases\npsi(5)=x12f\npsi(6)=x22f\npsi(7)=tau1-epsilon\npsi(8)=tau2-epsilon\nThe initial guess for this problem is assembled from the solution of the single-phase problem by using the MADS Matlab data utilities. Assume that the single-phase output data \xef\xac\x81le\nis \xe2\x80\x9cbangbang1out.dat\xe2\x80\x9d and that the corresponding premads \xef\xac\x81le is \xe2\x80\x9cbangbang1premads.dat,\xe2\x80\x9d\nand that the trajectory\xe2\x80\x99s control discontinuity occurs near the 27th discretization interval.\nThe code fragment for generating the input data for the two-phase problem is\nS=importMADS(\xe2\x80\x99bangbang1premads.dat\xe2\x80\x99,\xe2\x80\x99bangbang1out.dat\xe2\x80\x99,0);\n% tau -- the duration of the single phase -- is needed to\n% compute durations of the two new phases. In this case, the\n% only element of S.p is tau. Note that, when there are\n% other static parameters than \xe2\x80\x98\xe2\x80\x98tau,\xe2\x80\x99\xe2\x80\x99 it is convenient to\n% place the trajectory duration(s) at one end of S.p or the\n% other.\ntau=p(length(S.p));\nbout=breaktrajMADS(S.x,S.u,27,tau);\n% Overwrite various fields of S with two-phase data and\n% write a new premads file.\nS.p=bout.tau;\nS.x=bout.x;\nS.ndv=bout.ndv;\nS.u=bout.u;\n% The user is required to supply the following information for\n% constructing the premads file for the new problem. Note that\n% the new state, control, and trajectory constraint dimensions\n% are identical with the old ones.\nS.nph=2;\nS.nxv=S.nxv*ones(2,1);\nS.nuv=S.nuv*ones(2,1);\nS.ncv=S.ncv*ones(2,1);\nS.kodev=[0;0];\n\n29\n\nS.npsi=8;\nwritepreMADS(S,\xe2\x80\x99bangbang2premads.dat\xe2\x80\x99);\n% Generate and write the input guess file for the two-phase\n% problem using adduxMADS, but without adding any additional\n% states or controls.\nv=[];\nfor k=1:S.nph\nv=[v;adduxMADS(S.x{k},S.u{k},S.nxv(k),S.nuv(k),0)];\nend\nv=[v;S.p];\nsave bangbang2in.dat v -ascii -double\n3.1.3\n\nIntroduce variable discretization step size\n\nIn order for the bang-bang control to be perfectly realized in the foregoing, it was necessary\nto break the problem into two phases, requiring an estimate of the point along the trajectory\nat which to position the break, and a substantial increase in the complexity of the psibc\nsubroutine.\nThis can be avoided by allowing the integration intervals in the discretization to vary\nalong the trajectory so that the duration of the subarc with max control will naturally be\n\xe2\x80\x9c\xcf\x841 \xe2\x80\x9d and that with minimum control will be \xe2\x80\x9c\xcf\x842 \xe2\x80\x9d. Despite the fact that MADS nominally\nuses a \xef\xac\x81xed-step discretization, this can be achieved posing the time step as a control\nvariable, rather than a scalar parameter:\nx = u\xcf\x84 (s)x(s),\n\xcb\x99\n\n0\xe2\x89\xa4s\xe2\x89\xa41\n\n(46)\n\nso that\n1\n\n\xcf\x84=\n\nu\xcf\x84 ds\n\n(47)\n\n0\n\nThe increments u\xcf\x84 are prevented from behaving irresponsibly by penalizing deviation of u\xcf\x84\nfrom its average value,\n1\n\n(u\xcf\x84 \xe2\x88\x92 \xcf\x84 )2 ds\n\n(48)\n\n0\n\nAdditionally, in cineq, impose\nu \xcf\x84 \xe2\x89\xa5 c\xcf\x84 > 0\n\n(49)\n\nwhere c\xcf\x84 is a user-selected constant. There are three things to be noted in this case:\n1. Although the plant dynamics are scaled by u\xcf\x84 , in this case the elapsed time and\npenalty computations must not be.\n2. The duration \xcf\x84 is the terminal boundary value of the di\xef\xac\x80erential equation for (47).\nThis can be made to appear in the integral by imposing a boundary condition on \xcf\x84\nand a free static parameter, say, p\xcf\x84 , in psibc:\np\xcf\x84 = \xcf\x84\n\n(50)\n\n\xcf\x86\xcb\x99\xcf\x84 = (u\xcf\x84 \xe2\x88\x92 p\xcf\x84 )2\n\n(51)\n\nso that (48) would be expressed\n\n30\n\nfor a total performance index of\n\xcf\x86 = \xcf\x84 + k \xcf\x84 \xcf\x86\xcf\x84 ,\n\nk\xcf\x84 > 0 user \xe2\x88\x92 selected\n\n(52)\n\n3. We generically deplore the use of penalty functions in trajectory optimization as being\nan unacceptably vague way of expressing performance goals and constraints. In this\ncase, a penalty is introduced only to prevent a nonunique solution for the additional\n(u\xcf\x84 )k and p\xcf\x84 degrees of freedom, rather than to compete with the principal goal of\nminimizing \xcf\x84 .\nWith the introduction of two additional states and one additional control, the problem\nelevates from being completely trivial to being fairly simple. Since these additional variables\nare being manipulated in four di\xef\xac\x80erent user routines, it behooves the user to take measures\nto avoid mistakenly picking o\xef\xac\x80 the wrong element of the xv or uv vectors in di\xef\xac\x80erent routines.\nDe\xef\xac\x81ne a FORTRAN Module:\nmodule bangMOD\nimplicit none\ninteger,parameter ::\n& locx2=2\n& locxtau=3\n& loctauint=4\n& locu=1\n& locutau=2\n& locptau=1\nreal(8),parameter ::\n& a=1\n& b=1\n& ctau=1d-6\n& ktau=1d-2\nend module bangMOD\n\n! enforce strong typing. Highly Recommended!\n& ! \xe2\x80\x98\xe2\x80\x98parameters\xe2\x80\x99\xe2\x80\x99 are compile-time fixed constants\n& ! elements of xv\n&\n&\n& ! elements of uv\n&\n! element of p\n&\n& ! initial value of x1\n& ! initial value of x2\n& ! value of c_tau in u_tau constraint\n! penalty weight on penalty integral\n\nThe relevant code fragments are shown below. Only the fragment for subroutine xdot\nshows the use of the module in the subroutine header, but similar \xe2\x80\x9cuse\xe2\x80\x9d statements appear\nin cineq, phiobj, and psibc.\nxdot use bangMOD,only : locx2,locxtau,loctauint,locu,locutau,locptau\nimplicit none\ninteger,intent(in) :: nstate,kph,nx,nu,np\nreal(8),intent(in) :: xv(nx),uv(nu),pv(np)\nreal(8),intent((out) :: fv(nx)\nreal(8) :: x2,xtau,tauint,u,utau,avetau\nx2=xv(locx2)\nxtau=xv(locxtau)\ntauint=xv(loctauint)\nu=uv(locu)\nutau=uv(locutau)\navetau=pv(locptau)\nfv(1)=utau*x2\nfv(locx2)=utau*u\nfv(locxtau)=utau\nfv(loctauint)=(utau-avetau)\n\n31\n\ncineq !use bangMOD,only : locu,locutau,ctau\nu=uv(locu)\nutau=uv(locutau)\nc(1)=u+1\nc(2)=1-u\nc(3)=utau-ctau\n\n-- info only; belongs in declarations\n\nphiobj !use bangMOD,only : loctauint,locxtau,ktau -- info only; goes in declarations\ntauint=xbc(kf(1)+loctauint)\ntaufinal=xbc(kf(1)+locxtau)\nphi=taufinal+ktau*tauint\npsibc !use bangMOD,only : locx2,loctau,loctauint,locptau -- info only\niebc=0\npsi(1)=xbc(k0(1)+1)-a\n! plant boundary conditions\npsi(2)=xbc(k0(1)+locx2)-b\npsi(3)=xbc(kf(1)+1)\npsi(4)=xbc(kf(1)+locx2)\npsi(5)=xbc(k0(1)+locxtau)\npsi(6)=xbc(k0(1)+loctauint)\npsi(7)=pv(locptau)-xbc(kf(1)+locxtau)\n\n4.2\n\n! zero IC for utau\n! zero IC for penalty integral\n! place terminal value of utau in ptau\n\n1\n\n4\n0.5\n\nvariable stepsize\nfixed setsize\n\n3.6\n\nu\n\nu\xcf\x84\n\n3.8\n0\n\n3.4\n\xe2\x88\x920.5\n3.2\n3\n0\n\n\xe2\x88\x921\n1\n\n2\n\n3\n\n2\n\ntime\n\n2.5\n\n3\n\n3.5\n\ntime\n\nFigure 2. Two-State Bang-Bang Problem with Variable Time Step\nThis problem was solved, as in the case of uniform time step (UTS), with 50 discretization\nintervals, i.e. nd = 50, and the penalty weight on variation in u\xcf\x84 was set to k\xcf\x84 = 1/100.\nThe initial guess for this problem was taken from the solution of the baseline case in\nSection 2.1.1, using the following script to add the additional two states and one control to\nthe input data:\n\n32\n\nS=importMADS(\xe2\x80\x99bangbang1premads.dat\xe2\x80\x99,\xe2\x80\x99bangbang1out.dat\xe2\x80\x99,0);\ntau=p(length(S.p));\nS.nuv=S.nuv+1;\n% more controls\nS.nxv=S.nxv+2;\n% more states\nS.npsi=7;\n% more boundary conditions\nS.ncv=3;\n% more trajectory constraints\nwritepreMADS(S,\xe2\x80\x99varsteppremads.dat\xe2\x80\x99);\nvout=adduxMADS(S.x,S.u,S.nxv,S.nuv,0)\nvout=[vout;tau];\nsave varstepin.dat vout -ascii -double\nFigure 2 displays details of the solution. The plot on the left displays u\xcf\x84 as a function\nof time. The plot on the right compares details of the control trajectory for the UTS case\nand the variable time step (VTS) case. The VTS does provide a clean \xe2\x80\x9cbang\xe2\x80\x9d and, in fact,\nreturns a very slight improvement in terminal time \xe2\x80\x93 3.4495s versus 3.4502s for the UTS\ncase. It\xe2\x80\x99s also interesting, but not surprising that the bang is initiated a little later for the\nVTS case.\n3.1.4\n\nEliminate the Bangs\n\nAs was pointed out in Section 2.1, various functions of state and control variables can be\nformulated to take the place of \xe2\x80\x9cu\xe2\x80\x9d in f (x, u, p), and these can be manipulated to control\ntheir temporal behavior; for example, limiting bandwidth. In this subsection, an alternate\napproach to enforcing limits on control accelerations is described \xe2\x80\x94 in order to illustrate a\nuseful trick available to the user with the ME discretization.\nThe ME discretization can be adapted to provide a multistep delay bu\xef\xac\x80er. Generally,\nthis can be used to implement a sliding temporal window along the trajectory on which the\nproblem formulation can impose conditions. For the current problem, we require three time\nsteps for building up a numerical estimate for u, and implement the following di\xef\xac\x80erential\n\xc2\xa8\nequations in xdot without time scaling:\nv1\n\xcb\x99\nv2\n\xcb\x99\n\n= 2nd(\xe2\x88\x92v1 + u)\n= 2nd(\xe2\x88\x92v2 + 2v1 \xe2\x88\x92 u)\n\n(53)\n\nwhere nd is the number of discretization intervals. These ODEs, when ME-discretized give,\nat the k th instant,\n(v1 )k = uk\xe2\x88\x921 ,\n\n(v2 )k = uk\xe2\x88\x922\n\n(54)\n\nAssuming a constant time step, u at the (k \xe2\x88\x92 1)th instant is approximately\n\xc2\xa8\nuk\xe2\x88\x921 \xe2\x89\x88\n\xc2\xa8\n\nnd\n\xcf\x84\n\n2\n\n(u \xe2\x88\x92 2v1 + v2 )k\n\n(55)\n\nwhere nd is the number of discretization intervals, and the expression for u is\n\xcb\x99\nuk \xe2\x89\x88\n\xcb\x99\n\nnd\n\xcf\x84\n\n(u \xe2\x88\x92 v1 )k\n\n(56)\n\nObviously, this trick can easily be adapted to the case of variable time steps by appropriately\nmodifying the numerical di\xef\xac\x80erentiation formulae.\n\n33\n\nWith these control derivatives in hand, the bandwidth of the optimal control solution\ncan be limited either through a slovenly penalty function approach, such as adding a term\nlike\n\xcf\x84\n\n(u \xe2\x88\x92 2v1 + v2 )2 d\xcf\x84\n\n\xcf\x86u =\n\xc2\xa8\n\n(57)\n\n0\n\nto the cost function, or by imposing a constraint on some function of the acceleration.\nAs an illustration of the latter approach, we consider the trade between |\xc2\xa8|max \xe2\x80\x93 rather\nu\nthan the rms-like acceleration measure in (57) \xe2\x80\x93 and system performance. This trade can\nbe explored either by \xef\xac\x81xing \xcf\x84 and minimizing |\xc2\xa8|max or vice versa. Pretend that our doubleu\nintegrator is actually a physical system, and that the value of |\xc2\xa8|max plays an important role\nu\nin its cost of manufacture. Pretend, further, that there is a range of potentially acceptable\n\xcf\x84 and that we want to \xef\xac\x81nd the \xe2\x80\x9cknee in the curve\xe2\x80\x9d in the relationship between |\xc2\xa8|max and\nu\n\xcf\x84 . Since we know what \xcf\x84 we can tolerate, constrain \xcf\x84 and minimize |\xc2\xa8|max by solving the\nu\nproblem of minimizing\n\xcf\x86 = pddmax\n\n(phiobj)\n\n(58)\n\nsubject to\n\xe2\x88\x92pddmax \xe2\x89\xa4\n\nnd 2\n\xcf\x84\n\n(u \xe2\x88\x92 2v1 + v2 )k \xe2\x89\xa4 pddmax\npddmax \xe2\x89\xa5 0\n\n0 = \xcf\x88\xcf\x84 = \xcf\x84 \xe2\x88\x92 \xcf\x84given\n\n(cineq)\n(psibc)\n\n(59)\n\n(psibc)\n\n(60)\n\nand, implemented in xdot and psibc,\nx1\n\xcb\x99\nx2\n\xcb\x99\nv1\n\xcb\x99\nv2\n\xcb\x99\n\nx1 (0) = a, x1 (1) = 0\nx2 (0) = b, x2 (1) = 0\nboundary values free\nboundary values free\n\n= \xcf\x84 x2 ,\n= \xcf\x84 u,\n= 2(\xe2\x88\x92v1 + u),\n= 2(\xe2\x88\x92v2 + 2v1 \xe2\x88\x92 u),\n\n\xef\xa3\xbc\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xbd\n\n(61)\n\n\xef\xa3\xb4\n\xef\xa3\xb4\n\xef\xa3\xbe\n\nNote that the acceleration constraints in (59) are indexed on the k th instant rather than the\n(k + 1)th . This is necessary in order to have u in its proper place in the u, v1 , v2 sequence\nof points.\nFinally, why specify \xcf\x84 via the constraint (60) rather than by merely using the constant\n\xcf\x84given as the duration parameter? The lagrange multiplier associated with \xcf\x88\xcf\x84given in (60) is\navailable from SNOPT (and hence, MADS) upon successfully converging a solution, and will\nsupply useful information in computing the trade between \xcf\x84given and |\xc2\xa8|max . In particular,\nu\nas is well-known, express a hypothetical cosntrained minimization problem as\nx\xe2\x88\x97\nL\n\n= arg minc(x)=0 L(x)\n= \xcf\x86(x) \xe2\x88\x92 \xce\xbb(c(x) \xe2\x88\x92 \xce\xb4)|\xce\xb4=0\n\n(62)\n\nwhere \xce\xb4 is a hypothetical small variation in the constraint setting. By di\xef\xac\x80erentating L by \xce\xb4\nit\xe2\x80\x99s easy to see that\nL\xe2\x88\x97 = \xce\xbb\xe2\x88\x97\n\xce\xb4\n\n(63)\n\nThus, for our trade, the sensitivity of minimum peak control acceleration with respect to\n\xef\xac\x81xed terminal time constraint setting is \xce\xbb\xe2\x88\x97 given .\n\xcf\x84\nFigure 3 displays solutions to this problem for several values of \xcf\x84given corresponding to\n0.5%, 1%, 2%, and 5% degradation in \xcf\x84 from the perfect \xe2\x80\x9cbang-bang\xe2\x80\x9d value of \xcf\x84 = 3.4495s.\nThe plot on the right displays the resulting control histories for each \xcf\x84given . The plot on the\nleft displays a hermite spline that uses the pddmax solution data and the associated lagrange\n\n34\n\n1\nhermite spline interpolation\nMADS solution points\n\n14\n\n0.5% degradation\n1% degradation\n0.5\n\n12\n\n2% degradation\n5% degradation\n\n10\n\nu\n\npeak control acceleration (1/s2)\n\n16\n\n8\n\n0\n\n6\n\xe2\x88\x920.5\n4\n2\n3.45\n\n3.5\n\n3.55\n\n\xcf\x84 (s)\n\n3.6\n\n3.65\n\n\xe2\x88\x921\n0\n\n0.5\n\n1\n\n1.5\n\n2\n\n2.5\n\n3\n\n3.5\n\ntime (s)\n\nFigure 3. Two-State Bang-Bang Problem with Variable Time Step\nmultipliers for (60) to provide an estimate of peak |\xc2\xa8| away from the MADS solutions. The\nu\nhermite spline used here is a cubic polynomial y(s) de\xef\xac\x81ned on the interval 0 \xe2\x89\xa4 s \xe2\x89\xa4 x that\nsatis\xef\xac\x81es the boundary conditions\ny(0) = y (0)\n\xc2\xaf\ny(x) = y (x)\n\xc2\xaf\n\ny (0) = y (x)\n\xc2\xaf\ny (x) = y (x)\n\xc2\xaf\n\n(64)\n\nwhere the barred quantities are data. Thus, the lagrange multpliers provide \xe2\x80\x9cfree\xe2\x80\x9d data that\npermit a cubic \xef\xac\x81t between pairs of solutions points, rather than the quartuples of solution\npoints that are needed with cubic splines that operate only on point values. In this case,\nthe y are the constrained system performance, i.e. the peak acceleration magnitudes, and\n\xc2\xaf\nthe y are the lagrange multipliers for the constraints (60). Table 3.1.4 displays the values\n\xc2\xaf\nof \xcf\x84given , pddmax , and the lagrange multiplier \xce\xbb\xcf\x88\xcf\x84 .\nTable 1. Data From MADS Solutions for Various Values of \xcf\x84given\n\xcf\x84given pddmax\n\xce\xbb\xcf\x84 given\n3.4668 15.598 \xe2\x88\x921.071(103 )\n3.4840 7.8212 \xe2\x88\x922.021(102 )\n3.5185 3.8812 \xe2\x88\x925.121(101 )\n3.6220 1.5223\n-9.8350\n\n3.1.5\n\nProblem Summary\n\nThis example has provided several things useful to the aspiring MADS user. They are listed\nbelow, associated with the subsection in which they appear:\n\n35\n\n1.1\n\n1. Code fragments shown for casting a simple problem in MADS format. In particular, treatment of boundary conditions and cost is demonstrated, and an informal\ndiscussion of measures to be taken in using an autodi\xef\xac\x80erentiation code for preparing the model for MADS is given.\n2. Description of obtaining an initial guess, including a warning that the user needs\nto be wary of allowing free terminal time problems to freely vary terminal time.\n3. The impact of \xef\xac\x81xed discretization stepsize on the \xef\xac\x81delity with which discontinuous phenomena are preserved from the continuous time problem is demonstrated.\n\n1.2\n\n1. Brief description of breaking the original problem into two subarcs in order to\nrecover the \xe2\x80\x9cbang-bang\xe2\x80\x9d control behavior is provided. Multiple-subarc problems\nwill be dealt with in more detail in the next example\n\n1.3\n\n1. Technique for allowing variable discretization time step in the context of a single\narc.\n2. Demonstrated use of psibc to make state boundary values available to the system\ndi\xef\xac\x80erential equations.\n\n1.4\n\n1. Demonstration of using the structure of the midpoint euler discretization (kode =\n0) to model time derivatives of the optimal control solution. This permits direct\nmanipulation of the temporal characteristics of the control without resorting to\nine\xef\xac\x80ective arti\xef\xac\x81ces such as placing \xef\xac\x81lters into the plant dynamics to bandlimit\nthe control.\n2. Code for changing the structure of a single-phase MADS run\xe2\x80\x99s output data to\nprovide an input guess for a MADS problem with that di\xef\xac\x80erent structure. A\nsubsequent problem will demonstrate breaking a run into multiple phases and\nchanging the discretization density.\n3. Demonstration of minimizing a variable\xe2\x80\x99s maximum value. The same approach\ncan be used for constraining the same.\n4. Demonstration and discussion of using lagrange multipliers that are output by\nSNOPT to provide better continuous realization of the variation of constrained\nsystem performance with constraint settings. This is of particular importance for\ngetting the best possible performnace surveys when it is not feasible to perform\na large number of MADS runs.\n\n3.2\n\nGoddard Problem\n\nThe Goddard problem [8] is a nonlinear optimal control problem in which a sounding rocket\ntravels vertically to maximize its peak altitude. For the version of the problem considered\nhere, the rocket \xef\xac\x82ies through an atmosphere whose density decays expontially with altitude,\nthe trajectory is terminated at its peak altitude, and an inequality constraint is imposed\non the maximum dynamic pressure to which the rocket is exposed. The dynamics, taken\nfrom [8], have nondimensionalized states r \xe2\x80\x93 radius from Earth\xe2\x80\x99s center, V \xe2\x80\x93 speed, and m\n\xe2\x80\x93 mass. The state equations are\nr=V\n\xcb\x99\n\n(65)\n\n1\nT \xe2\x88\x92D\n\xcb\x99\n\xe2\x88\x92 2\nV =\nm\nr\n\n(66)\n\nm = \xe2\x88\x92T /c,\n\xcb\x99\n\n36\n\nc = 1/2\n\n(67)\n\nwhere T is the control, thrust, satisfying\n0 \xe2\x89\xa4 T \xe2\x89\xa4 3.5\n\n(68)\n\nand D = KD q (r, V ) is drag, with KD = 620, and\n\xc2\xaf\nV2\nexp (\xce\xb2(1 \xe2\x88\x92 r)) , \xce\xb2 = 500\n2\nis dynamic pressure. The dynamic pressure constraint is simply\nq=\n\xc2\xaf\n\nqmax \xe2\x89\xa5 q (r, V )\n\xc2\xaf\n\xc2\xaf\n\n(69)\n\n(70)\n\nNote that this is a state inequality constraint; that is, the control, T , does not appear in\n(70). The boundary conditions for the trajectory are\nr(0)\n\n=\n\n1\n\nV (0) = 0\nV (tf ) = 0\n\nm(0) = 1\nm(tf ) = 0.6\n\n(71)\n\nThe problem is solved by determining the thrust history that maximizes the terminal altitude\nwhen the rocket runs out of fuel; that is,\n\xcf\x86 = \xe2\x88\x92r(tf )\n\n(72)\n\nAside from the nonlinearity of the plant and the presence of a state inequality constraint,\nthe problem introduces us to an additional complication in the form of a \xe2\x80\x9csingular arc,\xe2\x80\x9d\ndescribed in Chapter 8 of [5]. Loosely speaking, a singular arc is a \xef\xac\x81nite-length subinterval of\na continuous-time optimal trajectory during which the trajectory cost function\xe2\x80\x99s sensitivity\nto control vanishes to \xef\xac\x81rst order. In other words, to \xef\xac\x81rst order, the optimal control problem\nsimply doesn\xe2\x80\x99t care what the control does during a singular arc. There is, indeed, an optimal\nsolution for the control, but its computation typically requires recourse to the calculus\nof variations (COV) to obtain higher-order necessary conditions for optimality, which are\nsolved as a system of equations. The MADS user, on the other hand, uses \xef\xac\x81rst derivative\ninformation to directly minimize the cost function via NLP. In this case, it will be seen that\nthe singular arc exhibits itself by a tendency toward ugly, jittery, behavior in the control\nduring the singular arc.\nThis example will carry the user through solving the Goddard problem several di\xef\xac\x80erent\nways, and at several di\xef\xac\x80erent levels of complexity. Although the basic problem is nearly\ntrivial to solve, the user does have choices available in how to organize plant and inequality\nconstraints, whether to suppress numerical artifacts in the control during singular arcs, or\nwhether to optimze the distribution of discretization intervals to improve accuracy.\nBefore beginning the Goddard solutions, we propose guidelines for coding them \xe2\x80\x93 and\nthe user\xe2\x80\x99s own problems. There are three main considerations in setting up problems in\nMADS.\n\xe2\x80\xa2 Separate Plant Code:\nThere are typically more states and controls in the optimization problem than in the\nplant model. This was seen in the min-time linear problem of Subsection 3.1, and\nwill be particularly seen in the Goddard problem. Because of this, the plant-speci\xef\xac\x81c\nmodelling \xe2\x80\x93 particularly the plant dynamics \xe2\x80\x93 should be coded separately, to facilitate\nreliable re-use.\n\xe2\x80\xa2 Named Scalars from Vectors:\nNonlinear models are characterized by scalar computations. Therefore, readability of\ncode will be enhanced by separating these variables out from MADS state, control,\nand parameter vectors. For example, if xv = [r, V, m] is the state vector, then the\nplant dynamics will be more readable using scalars than vector references.\n\n37\n\nr=xv(1)\nV=xv(2)\nm=xv(3)\nT=uv(1)\nD=620*exp(500*(1-r))*V**2/2\nfv(1)=r\nfv(2)=(T-D)/m-1/r**2\nfv(3)=2*T\nThis is still seriously \xef\xac\x82awed, though. Consistent naming is needed throughout the\nproblem code, and hardwiring this variable name indexing scheme in each MADS user\nroutine would be horribly fragile; moreover, hardwiring plant dynamical parameters\nreduces code clarity and makes it di\xef\xac\x83cult to update the model.\n\xe2\x80\xa2 Use a MODULE to Set Indices and Parameters:\nMADS uses four user-supplied routines to instantiate any trajectory problem, and\nplant information is used by each of them, so that having a single location in the\nuser code for de\xef\xac\x81ning shared indices and parameters is essential. The FORTRAN\nMODULE provides an easy means to have such sharing. For our example,\nmodule rocketMOD\nimplicit none ! enforce strong typing (highly recommended!)\ninteger,parameter :: & ! \xe2\x80\x98\xe2\x80\x98parameters\xe2\x80\x99\xe2\x80\x99 are compile-time fixed constants\n& locr=1,\n& ! radius\n& locV=2,\n& ! speed\n& Locm=3,\n& ! mass\n& locT=1,\n& ! thrust (control)\n& nxp=3,\n& ! plant state dimension\n& nup=1,\n& ! plant control dimension\n& kxp=1,\n& ! index beginning plant state\n& kup=1\n! index beginning plant control\nreal(8),parameter ::\n& KD=620,\n& beta=500,\n& ISP=0.5D0,\n& mEmpty=0.6D0,\n& Tmin=0,\n& Tmax=3.5D0\nend module rocketMOD\n\n&\n&\n&\n&\n&\n&\n\n!\n!\n!\n!\n!\n!\n\ndrag coefficient\natmospheric density lapse rate\nspecific impulse\nrocket empty mass\nmin thrust\nmax thrust\n\nThis permits us to rewrite the plant dynamics as\nsubroutine rocket(xp,up,fp)\n! note that \xe2\x80\x98\xe2\x80\x98only\xe2\x80\x99\xe2\x80\x99 keyword prevents \xe2\x80\x98\xe2\x80\x98rocket\xe2\x80\x99\xe2\x80\x99\n! from seeing nxp, nup, mEmpty, Tmin, Tmax\nuse rocketMOD,only : locr,locV,locm,locT,KD,beta,ISP\nimplicit none\nreal(8),intent(in) :: xp(3),up(1) ! state and control\nreal(8),intent(out) :: fp(3)\n! state rate\nreal(8) :: r,V,m,T,D\nr=xp(locr)\n\n38\n\nV=xp(locV)\nm=xp(locm)\nT=up(locT)\nD=KD*exp(beta*(1-r))*V**2/2\nfp(locr)=V\nfp(locV)=(T-D)/m-1/r**2\nfp(locm)=T/ISP\nend subroutine rocket\nThis approach is used throughout the examples, described below. Note that the source\ncode for each example is located in Appendix GoddardAppx.\nThe organization of the remainder of this Section is as follows: In Subection 3.2.1, an\ninitial guess for the problem is generated. Next, (Subsection 3.2.2,) the problem is solved\ndirectly, with and without a dynamic pressure constraint. Subsection 3.2.3 introduces an\nadhoc but e\xef\xac\x80ective penalty function which can be used to correct singlarity-induced freaks\nin the direct solution.\n3.2.1\n\nObtaining an Initial Guess\n\nBecause the problem is substantially nonlinear, it will not do to simply choose random\nnumbers as the initial guess for the Goddard problem. Yet, at the same time, we would\nprefer to keep the initial guess workload as low as possible. Experience indicates that\nboundary conditions are frequently the most di\xef\xac\x83cult constraints to satisfy in generating a\nfeasible trajectory in MADS. If an optimal MADS trajectory can be obtained for boundary\nconditions that have been \xe2\x80\x9crelaxed\xe2\x80\x9d in some way by starting from a random initial guess,\nperhaps such a solution will be an adequate initial guess for the problem with boundary\nconditions enforced.\nIt is reasonable to initially try solving a trajectory problem with the rocket dynamics as\nper (65-67) and cost function (72), but with the boundary conditions relaxed. This is done\nby moving them over to cost as penalty terms:\n\xcf\x86 = \xe2\x88\x92r(tf ) + K \xe2\x88\x97 (r(0) \xe2\x88\x92 1)2 + V 2 (0) + V 2 (tf ) + (m(0) \xe2\x88\x92 1)2 + (m(tf ) \xe2\x88\x92 0.6)2\n\n(73)\n\nwhere K > 0.\nThe highlights of the code are summarized below. Since this is a problem with free terminal time, the trajectory duration is introduced as an element of the MADS pv vector, and\nused to scale the RHS of the plant di\xef\xac\x80erential equations. The code fragment in subroutine\nxdot is\ncall rocket(xv(kxp),uv(kup),fv(kxp))\ntau=pv(loctau)\nfv=tau*fv\nThe code implementing (68) in subroutine cineq is\nif(iecinflag.EQ.1)then\niecinv=1\n! all cineq constraints are inequalities\nreturn\nendif\nT=uv(locT)\ncv(1)=Tmax-T\ncv(2)=T-Tmin\n\n39\n\nand the implementation of the cost function (73) in subroutine phiobj is\nr0=xbc(k0(1)+locr)\nrf=xbc(kf(1)+locr)\nV0=xbc(k0(1)+locV)\nVf=xbc(kf(1)+locV)\nm0=xbc(k0(1)+locm)\nmf=xbc(kf(1)+locm)\nphi=-rf+K*((r0-1)**2+V0**2+Vf**2+(m0-1)**2+(mf-mEmpty)**2)\nFor this problem, psibc implements only a constraint ensuring that optimal duration \xcf\x84 \xe2\x88\x97 is\nnot zero or negative:\n\xcf\x88 = \xcf\x84 \xe2\x88\x92 \xcf\x84min > 0\n\n(74)\n\nThe parameters \xcf\x84min and mEmpty pertain to the problem de\xef\xac\x81nition, rather than the plant\ndescription. As such, they are placed in a separate module \xef\xac\x81le:\nsubroutine GGUESSMOD\nimplicit none\nreal(8) :: &\n& taumin,\n&\n& K\nend GGUESSMOD\nAn initial guess for this problem is generated from random numbers in makeGGUESS.m,\ngiven in the Appendix, is essentially\nrandmag=0.01\nP.nxv=3;\nP.nuv=1;\nP.nav=2;\nP.ndv=200;\nP.np=1;\nP.nph=1;\nP.kodev=0;\nP.nbc=1;\nvin=randguessMADS(P.nxv,P.nuv,P.ndv,P.np,randmag)+1;\nsave GGUESS_vin.dat vin -ascii -double\nname=\xe2\x80\x99GGUESS_premads.dat\xe2\x80\x99;\nwritepremadsMADS(P,name)\nThe \xef\xac\x81les generated by this code correspond to the main routine code\nprogram GGUESS\nuse GGUESSMOD,only : taumin,K\ntaumin=1D-4\nK=100\nFinput=13\nopen(13,file=\xe2\x80\x99GGUESS_vin.dat\xe2\x80\x99,status=\xe2\x80\x99old\xe2\x80\x99)\nFpremads=14\nopen(14,file=\xe2\x80\x99GGUESS_premads.dat\xe2\x80\x99,status=\xe2\x80\x99old\xe2\x80\x99)\nFoutput=15\nopen(15,file=\xe2\x80\x99GGUESS_vout.dat\xe2\x80\x99,status=\xe2\x80\x99unknown\xe2\x80\x99)\ncall batchMADS(Finput,Fpremads,Foutput,info)\nend program GGUESS\n\n40\n\nFinally, the solution is organized for plotting in Matlab by executing\nS=importMADS(\xe2\x80\x99GGUESS_premadst.dat\xe2\x80\x99,\xe2\x80\x99GGUESS_vout.dat\xe2\x80\x99,0)\nwhere S contains the solution data in a form suitable for graphics. The details of importMADS,\nrecall, are given in Section 1.3.2.\n\n3.5\n\n1.035\n\n3\n\n1.03\n\n2.5\n1.025\n\nT\n\nr\n\n2\n1.02\n\n1.5\n1.015\n\n1\n\n1.01\n\n0.5\n\n1.005\n0\n\n0.05\n\n0.1\n\n0.15\n\n0\n0\n\n0.2\n\nV\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\n0.25\n\ntime\n\nFigure 4. Initial Guess for Goddard Problem\nFigure 4 displays the solution to this problem. Note that the altitude boundary conditions are seriously violated, and that the thrust pro\xef\xac\x81le is substantially di\xef\xac\x80erent from that\nin Figure 5, lacking the intermediate thrust arc that appears in the optimal solution. Effectively, the solution has moved the starting point for the trajectory to a higher altitude,\nwhere the atmosphere is thinner, reducing drag, so that the \xe2\x80\x9cbang-bang\xe2\x80\x9d thrust solution\nproduces optimal altitude gain.\nThis section has provided the following:\n\xe2\x80\xa2 It has provided and illustrated advice on organizing a MADS problem. The key points\nare \xe2\x80\x93\n1. Separate plant-related code from the rest of the MADS problem code, because\nthe MADS formulation may introduce additional states, control, and parameters.\n2. Provide a consistent, globally available, index to identify each individual element\nof state, control, and parameter vectors.\n3. Place these in MODULEs, separating the MODULE or MODULEs dedicated to the plant\ndynamics from those that will carry values related only to the particular problem\nformulation.\n\xe2\x80\xa2 It has discussed a philosphy for starting MADS solutions from initial guesses that\nconsist only of random numbers. This was demonstrated by posing a problem with\nboundary conditions eliminated and replaced by a penalty function. While we do not\nclaim that it will always work, it\xe2\x80\x99s a good place to start.\n\n41\n\n3.2.2\n\nSimple Solution with Dynamic Pressure Constraint\n\nThis subsection provides the direct, unconstrained solution for the Goddard problem, and\ndemonstrates two approaches for imposing constraints that involve states in cineq. The\nunconstrained problem is posed by retaining xdot and cineq from Subsection 3.2.1, and\nmoving the boundary conditions from the penalty function (73) to psibc from phiobj. In\npsibc,\nif(iebcflag.EQ.1)then\niebcvec=0\n! The boundary conditions are equalities\niebcvec(6)=1\n! The constraint on tau versus taumin is inequality\nreturn\nendif\npsi(1)=xbc(k0(1)+locr)-1\npsi(2)=xbc(k0(1)+locV)\npsi(3)=xbc(k0(1)+locm)-1\npsi(4)=xbc(kf(1)+locV) ! Not theoretically necessary, but sharpens the problem\npsi(5)=xbc(kf(1)+locm)-mEmpty\npsi(6)=pv(loctau)-taumin\nand, in phiobj,\nphi=-xbc(kf(1)+locr)\nNote that for the very simple and unrepetitive expressions in psibc and phiobj, here,\nwe\xe2\x80\x99ve not bothered to break out individually named scalar variables. The code, as written,\nis perfectly readable.\nAssuming that the initial guess has been stored in GGUESS.mat as a importMADS structure \xe2\x80\x9cS,\xe2\x80\x9d the script for setting up the inputs for the MADS run will be\nload GGUESS\n\n% Assume this .mat file contains the structure S from using\n% importMADS on GGUESS_vout.dat and GGUESS_premads.dat\n\nrandmag=0.0;\nP=S;\n% Mostly, this problem is structured the same as GGUESS.\nP.nbc=6;\n% This problem has a different number of boundary conditions\nvin=adduxMADS(S.x{1},S.u{1},P.nxv,P.nuv,randmag); % This reorganizes S.x and\n% S.u back into a vector...\nvin=[vin;S.p];\n% and the duration parameter is tacked onto the end\nsave G1unc_vin.dat vin -ascii -double\nname=\xe2\x80\x99G1unc_premads.dat\xe2\x80\x99;\nwritepremads(P,name)\nWe now solve the problem, operate on the output and \xe2\x80\x9cpremads\xe2\x80\x9d \xef\xac\x81les with importMADS,\nand save the resulting structure in G1unc.mat. Figure 5 displays the resulting altitude/speed\nand thrust plots. The most noticeable feature of the displayed solution is the noisy appearance of the thrust history. Why is this? The optimal trajectory for this case is \xe2\x80\x9csingular\xe2\x80\x9d,\nand can be explained by informal appeal to variational optimal control theory.\nIn variational optimal control, the Minimum Principle [6], [7], states that the optimal\ntrajectory minimizes the problem\xe2\x80\x99s hamiltonian function, H, where, for x = f (x, u),\n\xcb\x99\nH = \xce\xbbT f (x, u),\n\n42\n\nT\n\xcb\x99\n\xce\xbb = \xe2\x88\x92fx \xce\xbb\n\n(75)\n\n1.015\n\n3.5\n3\n2.5\n\n1.01\n\nr\n\nT\n\n2\n1.5\n1.005\n\n1\n0.5\n\n1\n0\n\n0.05\n\n0.1\n\n0\n0\n\n0.15\n\nV\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 5. Goddard Solution Without Dynamic Pressure Constraint\n\nand \xce\xbb is a vector roughly analogous to the instantaneous value of trajectory of lagrange\nmultipliers. Because H is to be minimized by thrust T (t), its partial derivative trajectory\nHT provides a useful diagnostic. When HT = 0, optimality requires\n\nT\xe2\x88\x97 =\n\n\xef\xa3\xb1\n\xef\xa3\xb2\n\nTmin\nTmax\n\xef\xa3\xb3\nsome intermediate value\n\nfor HT > 0\nfor HT < 0\nfor HT = 0\n\n(76)\n\nThe \xe2\x80\x9csingularity\xe2\x80\x9d in this problem arises from the fact that, since T enters the dynamics\nlinearly in (66), T is absent from HT , so that it cannot be used to determine optimal T \xe2\x88\x97 .\nAdditionally, HT T is identically zero (hence singularity.) In practical terms, up to second\norder, the optimal trajectory simply \xe2\x80\x9cdoesn\xe2\x80\x99t care\xe2\x80\x9d about the particular value of T when\nH = 0. This, in turn, means that for our direct minimization solution process, the absence of\nperformance impact due to thrust deprives the solution iterations information necessary to\nsettle on a locally unique thrust trajctory, even though those iterations satisfy the solution\nalgorithm\xe2\x80\x99s convergence criteria.\nFigure 6 displays the optimal trajectory of HT for this problem, and the sequence of Tmax ,\nfollowed by some intermediate value, followed by Tmin is clear. This Figure, incidentally,\nwas generated by using MADS to emulate a variational solution to the Goddard problem,\nposing a discretization of the variational necessary conditions for optimal control as a penalty\nfunction to be minimized by meeting the boundary conditions and constraints.\nThis singular behavior is not a mere curiosity. It most frequently occurs in problems in\nwhich the dynamics are linear in one or more control variables \xe2\x80\x93 a category that includes\naerospace systems that involve propulsion. An extremely coarse cure for this issue would\nbe to introduce a nonlinearity in T into the problem dynamics, such as an integral thrust\n\n43\n\n0.2\n\n\xe2\x88\x82 H*/\xe2\x88\x82 T\n\n0.15\n\n0.1\n\n0.05\n\n0\n\n\xe2\x88\x920.05\n0\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 6. Hamiltonian Thrust Partial Derivative for Goddard Problem\npenalty,\n\xcf\x84\n\nT 2 dt\n\n\xcf\x86penalty = \xe2\x88\x92r(\xcf\x84 ) +\n\n(77)\n\n0\n\nSuch a penalty would cure the thrust jitters, since the additional state for the penalty\nintegral is nonlinear in T . The cure comes at the cost, however, of moving the performance\ngoal away from maximizing the terminal altitude, and toward minimizing thrust usage. We\nare no longer solving the original problem. Short of adopting a full variational solution,\nit is best to introduce the needed nonlinearity in a way that only neglibly a\xef\xac\x80ects optimal\nperformance, particularly during the nonsingular problem phases.\nLet\xe2\x80\x99s introduce a dynamic pressure constraint:\nqmax \xe2\x88\x92 q (r, V ) \xe2\x89\xa5 0\n\xc2\xaf\n\xc2\xaf\n2\nq = V2 exp(\xce\xb2(1 \xe2\x88\x92 r))\n\xc2\xaf\n\n(78)\n\nThis is the \xef\xac\x81rst instance, in this tutorial, of a state inequality constraint. Since, in MADS,\ncontrol is held constant across each discretization interval, expressing a control-only inequality is straightforward. What of the case where states are involved in the constraint\nexpression, as in (78)? States appear at di\xef\xac\x80erent instants in cineq, and in the discretization\nlogic that calls xdot. In cineq the state is available at the beginning (xj) and end (xjp1) of\neach discretization interval. Depending on the value of kode, xdot may be called with the\nmidpoint average (xj + xjp1)/2, for kode = 0, or with several extrapolated values, when\nusing the Runge Kutta (RK) discretizations, kode = 1, 2.\nIn the case.of the RK discretizations, there is no choice but to compute inequality constraint quantities in cineq using state values from xj or xjp1. In the mindpoint Euler\ncase, however, the user has the option of computing a constraint quantity, say \xe2\x80\x9cy,\xe2\x80\x9d in xdot,\nassigning a state, say xv(locy), to it and using an expression like\n\n44\n\nfv(locy) = 2 \xe2\x88\x97 nk \xe2\x88\x97 (y \xe2\x88\x92 xv(locy))\nto propagate it, so that the current value of y is available to cineq at xjp1(locy). Recall\nthat we introduced this trick in the Minimum-Time Double Integrator problem in Subsection\n2.1.4.\nWhy would one chose to compute y this way? The most direct motivation for doing\nthis would be when computation of y is tightly integrated with the software called in xdot\nfor computing the RHS of the plant ODEs. Extracting y from the existing plant dynamics\ncomputations might be preferable, from a software point of view, to redundantly coding the\nlogic for computing y. Furthermore, if the computation of y is not only tightly integrated\nwith the plant dynamics, but also expensive, the user has further incentive to compute y in\nxdot.\nIf the user chooses to set the problem up with cineq-related quantities computed in xdot,\nit must be remembered that they\xe2\x80\x99re being computed at the midpoint of the integration\ninterval, i.e. at (xj+xjp1)/2 in the notation of the cineq argument list. The practical\nimplications of this are explored in the remainder of this example.\nThe dynamic pressure constraint (78) is implemented in subroutine calcqbar:\nsubroutine calcqbar(xv,qbar)\nuse rocketMOD,only : c,kD,beta,locr,locV,nxp\nimplicit none\nreal(8),intent(in) :: xv(nxp)\nreal(8),intent(out) :: qbar\nreal(8) :: dexp\nreal(8),parameter :: ONE=1.D0\nreal(8) :: r,V\nr=xv(locr)\nV=xv(locV)\nqbar=dexp(beta*(ONE-r))*V**2/2\nend subroutine calcqbar\nFor the formulation in which qbar is computed in xdot with kodev=0, the relevant lines of\nxdot and cineq are\nreal(8) :: tau,qbar\ncall rocket(xv(kxp),uv(kup),fv(kxp))\ntau=pv(loctau)\nfv(kMain)=tau*fv(kMain)\ncall calcqbar(xv(kxp),qbar)\nfv(locqbarm)=2*nk*(qbar-xv(locqbarm))\nand\nif(iecflg.EQ.1)then\niecin=1\nreturn\nendif\ncv(1)=Tmax-uv(locT)\ncv(2)=uv(locT)-Tmin\ncv(3)=qbarmax-xjp1(locqbarm)\nrespectively. With qbar computed in cineq, the code in xdot is\n\n45\n\ncall rocket(xv(kxp),uv(kup),fv(kxp))\ntau=pv(loctau)\nfv=tau*fv\nand\nif(iecflg.EQ.1)then\niecin=1\nreturn\nendif\ncv(1)=Tmax-uv(locT)\ncv(2)=uv(locT)-Tmin\ncall calcqbar(xj(kxp),qbar)\ncv(3)=qbarmax-qbar\nNote the di\xef\xac\x80erences in xdot. For the kodev=0 case, (the former,) the time scaling is\nrestricted to fv(kMain), rather than to all of fv. The index vector is set in G1MOD.f90,\ngiven below:\nmodule G1MOD\nuse rocketMOD,only : nxp\nimplicit none\ninteger,parameter :: &\n& locqbarm=nxp+1\n\n! state for carrying qbar to cineq\n\ninteger,parameter ::\n& loctau=1\n\n&\n! time-scaling parameter in pv\n\nreal(8),parameter ::\n& mfinal=0.6D0\n\n&\n! empty mass\n\ninteger :: kmod\ninteger,parameter :: &\n\n! indices identifying states to be time-scaled.\n! lag state carrying qbar is *not* time-scaled.\n& kMain(nxp)=(/(kmod,kmod=1,nxp)/)\nreal(8) ::\n& taumin,\n& qbarmax\nend module G1MOD\\\n\nThe\n\n&\n& !\n!\n\nThe index vector kMain is initialized to kMain=[1,2,3], above, and the state variable for\npassing qbar is given the index locqbarm=nxp+1, appending it the plant state vector as a\nfourth state.\nBoth of the above versions of the qbar-constrained problem were started using the unconstrained solution as an initial guess. For the former case, the additional state xv(locqbarm)\nwas added to the input guess vector using the script\nS=importMADS(\xe2\x80\x99G1unc_premads.dat\xe2\x80\x99,\xe2\x80\x99G1unc_vout.dat\xe2\x80\x99,0);\nrandmag=0.0;\nP.nxv=4;\n% note additional state\nP.nuv=S.nuv;\n\n46\n\nP.nav=3;\n% additional inequality constraint\nP.ndv=S.ndv;\nP.np=S.np;\nP.nph=S.nph;\nP.kodev=S.kodev;\nP.nbc=S.nbc;\nvin=adduxMADS(S.x{1},S.u{1},P.nxv,P.nuv,randmag); % This will add a state\nvin=[vin;S.p];\nsave G1_vin.dat vin -ascii -double\nname=\xe2\x80\x99G1_premads.dat\xe2\x80\x99;\nwritepremads(P,name)\n\n5\n\n3\n\n2\n\n2\n\nT\n\n3\n\n10\n\nT\n\nqbar (X 10\xe2\x88\x924)\n\nThe script converts the \xe2\x80\x9cG1unc\xe2\x80\x9d output from a column vector to a importMADS structure,\nand then uses \xe2\x80\x9cadduxMADS\xe2\x80\x9d to create a new vector with the fourth state appended.\n\n1\n\n1\n\nqbar in xdot\n\n10\n\n3\n2\n\n2\n\n0\n\n0\n\n10\n\n3\n\n3\n\n2\n\n2\n\n5\n\nT\n\n1\n\nT\n\n1\n0\n\nqbar (X 10\xe2\x88\x924)\n\nqbar in cineq\n\n3\n\n5\n\n0\n\nT\n\n0\n\nT\n\nqbar (X 10\xe2\x88\x924)\n\n0\n\n1\n0\n0\n\n0.1\n\n0.2\n\ntime\n\n0\n0\n\n1\n0.1\n\ntime\n\n0.2\n\n0\n0\n\n0.1\n\n0.2\n\ntime\n\nFigure 7. Thrust Solution Behavior for Several Values of qbarmax\nFigure 7 compares the behavior of the optimized thrust for several values of qbarmax\n(unconstrained maximum q is roughly 1.2(10\xe2\x88\x923 ), and for q computed in xdot versus q com\xc2\xaf\n\xc2\xaf\n\xc2\xaf\nputed in cineq. Scanning from the left, the \xef\xac\x81rst column displays the q histories (taken from\n\xc2\xaf\nthe cases where q was computed in cineq). The middle column displays the corresponding\n\xc2\xaf\noptimized thrust histories where q was computed in xdot, and the third column shows the\n\xc2\xaf\ncorresponding thrust histories with q computed in cineq. All of these runs successfully\n\xc2\xaf\nconverged.\n\n47\n\nObviously, Figure 7 demonstrates that computing the state constraint quantity in xdot\nleaves the user vulnerable to misbehavior in the control solution. The reason for this is that\nsatisfying the constraint at the midpoint of each discretization interval does not guarantee\nthat the constraint rate is zeroed. At this point, Murphy\xe2\x80\x99s Law takes charge. This does not\nnecessarily mean that it never makes sense to compute the constraint quantity in xdot, but\nit certainly indicates that additional measures need to be taken in this case, before the user\ncan be con\xef\xac\x81dent of acceptable results.\nThere is more to be seen in this Figure. Observe how the q pro\xef\xac\x81le for qbarmax = 7(10\xe2\x88\x924 )\n\xc2\xaf\nfalls o\xef\xac\x80 at the end of the active constraint arc, signalling a probable singular arc. This\ntentative diagnosis is supported by the choppy behavior of the thrust solution in column\nthree. Alternatively, for qbarmax = 5(10\xe2\x88\x924 ), the active constraint arc completely eliminates\nthe singular arc, giving a very crisp Tmax \xe2\x88\x92 constrained \xe2\x88\x92 Tmin thrust pro\xef\xac\x81le. For qbarmax =\n7(10\xe2\x88\x924 ), however, close examination of the thrust pro\xef\xac\x81le shows a little rounding of the thrust\nhistory near the end of the active constraint arc. Is this a very short singular arc? The\nonly way to tell for sure is by solving the corrsponding variational optimal control problem,\nwhich can be quite intricate, per Chapter 8 of [5].\nThe user may very likely not care about the forensic details that are opened up by a full\nvariational analysis, but would just like to tame bad control behavior on singular arcs. One\nway of doing this is assign a penalty function designed to suppress jitter without interfering\nwith large control movements. This approach is described in the sequel. Before proceeding,\nquickly review what has been introduced in this Subsection:\n\xe2\x80\xa2 Two di\xef\xac\x80erent approaches for imposing a state inequality constraint were described\nand demonstrated, and pros and cons of each were discussed.\n\xe2\x80\xa2 One approach (computing constraint quantities in xdot) requires an additional state.\nLogic for adding states to an input guess was demonstrated.\n\xe2\x80\xa2 Logic for restricting time scaling of the state derivative to a subset of the states was\nshown.\n3.2.3\n\nA Penalty Function to Smooth Out Singular Jitter\n\nThe easiest, and least elegant, way to suppress singularity-induced control jitter is to penalize it. Looking at Figure 7, the reader will agree that control jitter is characterized by\npersistent, large, acceleration; so, it would make sense to penalize control acceleration. At\nthe same time, however, it would be best if the penalty did not suppress or distort the rapid\n\xe2\x80\x9cbang-bang\xe2\x80\x9d control shifts associated with leaving Tmax and moving to Tmin ; they are, after\nall, optimal. A compromise penalty would penalize control acceleration more heavily when\ncontrol rates are low, with the expectation that super\xef\xac\x82uous acceleration (jitter) would disappear, leaving necessary accleration (step changes) relatively intact. Such a penalty would\ntake the form\n1\n\nu2\n\xc2\xa8\ndt\n(79)\n\xcb\x992\npen + u\n0\nwhere it should be noted that we recommend that the penalty state be integrated from 0 to\n1, i.e., without time scaling. This could be implemented directly by rede\xef\xac\x81ning the control\n\xc2\xa8\nvariable to be thrust acceleration, i.e., u = T and appropriately introducing additional\nstates to realize (79) and T . MADS approximates (79) in subroutine ddpenMADS, which\ndi\xef\xac\x80erences across time steps to model acceleration and rates:\n\xef\xa3\xb1\n\xef\xa3\xb2 a = Tk \xe2\x88\x92 2Tk\xe2\x88\x921 + Tk\xe2\x88\x922\na2\nd\nv\xe2\x88\x92 = Tk\xe2\x88\x921 \xe2\x88\x92 Tk\xe2\x88\x922\nJddpen =\n,\n(80)\n2\n2\n\xef\xa3\xb3\ndt\npen + v\xe2\x88\x92 + v+\nv+ = Tk \xe2\x88\x92 Tk\xe2\x88\x921\nJpen =\n\n48\n\nwhere the (\xc2\xb7)k subscripts denote the time index in MADS. Implementing the time di\xef\xac\x80erencing in ddpenMADS requires three states, and the penalty integral introduces a fourth\nstate.\nThis penalty is applied to the problem of Subsection 3.2.2 by adding the states needed\nfor ddpenMADS and Jddpen , and including the penalty in the performance index:\n\xcf\x86 = \xe2\x88\x92r(\xcf\x84 ) + Kpen Jddpen (1)\n\n(81)\n\nwhere Kpen \xe2\x89\xa5 0 is user-speci\xef\xac\x81ed. The variables are organized in\nmodule SLO1MOD\nuse rocketMOD,only : nxp\nimplicit none\ninteger,parameter ::\n& locqbarm=nxp+1,\n& locddpv=locqbarm+1,\n& locddpint=locddpv+3\n\n&\n& ! carry qbar to cineq\n(4)\n& ! 3-element state for ddpen (5)\n! ddpen penalty integral\n(8)\n\ninteger,parameter ::\n& loctau=1\n\n&\n! time-scaling parameter in pv\n\ninteger :: kmod\ninteger,parameter :: &\n\n! indices identifying states to be time-scaled.\n! ddpen states not time-scaled.\n& kMain(nxp)=(/(kmod,kmod=1,nxp)/)\nreal(8) ::\n& taumin,\n& qbarmax,\n& epsvdd,\n& Kddp\nend module SLO1MOD\n\nThe\n\n&\n& !\n& !\n& ! denominator bias term in ddpen\n! weighting term for ddpen penalty\n\nand the logic in xdot becomes\ncall rocket(xv(kxp),uv(kup),fv(kxp))\ncall calcqbar(xv(kxp),qbar)\nfv(locqbarm)=2*nk*(qbar-xv(locqbarm))\n! Note that 4th argument of ddpenMADS is \xe2\x80\x98\xe2\x80\x983\xe2\x80\x99\xe2\x80\x99 That is the number of\n! states that the user needs to make available to ddpenMADS, and the\n! subroutine checks to see that the user has at least declared that he has\n! provided the right number of states.\ncall ddpenMADS(nk,uv(kxp),xv(locddpv),3,epsvdd,fv(locddpv),fv(locddpint))\ntau=pv(loctau)\nfv(kMain)=tau*fv(kMain)\nthere is no change in cineq, but the integral state Jddpen does require a zero initial condition,\nso that the logic becomes\npsi(1)=xbc(k0(1)+locr)-1\npsi(2)=xbc(k0(1)+locV)\n\n49\n\npsi(3)=xbc(k0(1)+locm)-1\npsi(4)=xbc(k0(1)+locddpint)\npsi(5)=xbc(kf(1)+locV)\npsi(6)=xbc(kf(1)+locm)-mfinal\npsi(7)=pv(loctau)-taumin\n\n! zero I.C. for penalty integral\n\nThe cost function is implemented in phiobj as\nrf=xbc(kf(1)+locr)\nphi=-rf + Kddp*xbc(kf(1)+locddpint)\nUnconstrained solutions for Kpen = {10\xe2\x88\x923 , 10\xe2\x88\x922 , 10\xe2\x88\x921 } and pen = 10\xe2\x88\x922 were obtained using\nthe solution from Figure 5 as an initial guess, and the results are displayed in Figure 8. The\nleft panel dispays the fallo\xef\xac\x80 in altitude performance as percentages for the several values of\nKpen . The right panel displays the T time histories for the Kpen = 10\xe2\x88\x923 and 10\xe2\x88\x921 cases.\nIf one enlarges the thrust pro\xef\xac\x81le for Kpen = 10\xe2\x88\x923 , small jitters are visible, but there is a\nsubstantial improvement from the behavior shown in Figure 5. The pro\xef\xac\x81le for Kpen = 10\xe2\x88\x921\nis smooth, but shows very little similarity to the optimal solution. Nonetheless, referring\nto the Figure\xe2\x80\x99s left panel, there is only 0.03% degradation in altitude performance. This is\na consequence of the presence of the singular arc \xe2\x80\x93 recall that the optimal performance is\nalmost entirely insensitive to the particular thrust pro\xef\xac\x81le over a signi\xef\xac\x81cant portion of the\ntrajectory.\n\n3.5\n\nKpen=1e\xe2\x88\x923\nKpen=1e\xe2\x88\x921\n\n3\n\n\xe2\x88\x920.005\n\n2.5\n\n\xe2\x88\x920.01\n\n2\n\xe2\x88\x920.015\n\nT\n\nPercent Altitude Degradation\n\n0\n\n1.5\n\xe2\x88\x920.02\n\n1\n\n\xe2\x88\x920.025\n\xe2\x88\x920.03\n\n0.5\n\n\xe2\x88\x923\n\n\xe2\x88\x922\n\nK pen exponent\n\n0\n0\n\n\xe2\x88\x921\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 8. Variation of Altitude Performance and Thrust Behavior with Kpen\nSolutions were next generated using the jitter penalty, for the same values of qbarmax\nas those displayed in Figure 7. Figure 9 displays the resulting thrust pro\xef\xac\x81les. In the left\ncolumn of the Figure, all runs used the solution for Kpen = 10\xe2\x88\x923 from Figure 8 as the\ninitial guess, and Kpen and pen were selected as displayed on each panel. The Figure\xe2\x80\x99s right\ncolumn display thrust for the case where the solutions were \xe2\x80\x9cwalked in,\xe2\x80\x9d i.e., the solution for\n\n50\n\nqbarmax = 9(10\xe2\x88\x924 ) is started from the unconstrained case, that for qbarmax = 7(10\xe2\x88\x924 ) is\nstarted from the solution for qbarmax = 9(10\xe2\x88\x924 ), and so on. We see that the latter approach\nprovides cleaner-looking solutions for less intrusive Kpen , pen settings.\n\nT\n\n3\n\n3\n\nKpen=10\xe2\x88\x922\n\xce\xb5pen=10\xe2\x88\x921\n\n2\n\nKpen=10\xe2\x88\x922\n\xce\xb5pen=10\xe2\x88\x921\n\n2\n\n1\n\n1\n\nqbarmax=9e\xe2\x88\x924\n0\n\n0\n\nT\n\n3\n\n3\n\nKpen=10\xe2\x88\x922\n\xe2\x88\x921\n\xce\xb5pen=10\n\n2\n\nKpen=10\xe2\x88\x923\n\xe2\x88\x921\n\xce\xb5pen=10\n\n2\n\n1\n\n1\n\nqbarmax=7e\xe2\x88\x924\n0\n\n0\n\nT\n\n3\n\n3\n\nKpen=1\n\xce\xb5pen=10\xe2\x88\x921\n\n2\n\nKpen=10\xe2\x88\x922\n\xce\xb5pen=10\xe2\x88\x921\n\n2\n\n1\n\n1\n\nqbarmax=5e\xe2\x88\x924\n0\n0\n\n0.05\n\n0.1\n\n0.15\n\n0\n0\n\n0.2\n\ntime\n\n0.05\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 9. Comparison of q -constrained Thrust Pro\xef\xac\x81les with Jitter Penalty\n\xc2\xaf\nWe most particularly note, however, that all of these q -constrained runs required heavier\n\xc2\xaf\njitter penalties than the unconstrained case from Figure 8. Recall that, in the unconstrained\ncase, the singular arc jitter exists because the optimization is largely oblivious to the value of\nT ; therefore, a very small penalty su\xef\xac\x83ces to correct the jitter. In the actively q -constrained\n\xc2\xaf\ncases, the optimization is taking advantage of the midpoint Euler discretization , settling\non a choppy T solution to maximize terminal altitude. A heavier penalty is required to\ncompete with this, and the overall T solution su\xef\xac\x80ers additional distortion.\nBefore proceeding further, let\xe2\x80\x99s review where we are in solving the Goddard problem.\nWe saw in Figure 8 that, using ddpenMADS, we could obtain a fairly clean, fairly undistorted\nunconstrained solution. We also saw that, even if we did penalize singularity-induced jitter\nso heavily that the thrust pro\xef\xac\x81le changed signi\xef\xac\x81cantly from the true optimal solution, it\nwouldn\xe2\x80\x99t matter have much impact on performance. In imposing an inequality constraint\non q , we saw, from Figure 7, that we had our best results computing the constraint in cineq\n\xc2\xaf\nrather than in xdot. The trajectory for qbarmax = 9(10\xe2\x88\x924 ), though, is marred by an untidy\nsingular arc that follows the active constraint arc.\nWhat can be done about this latter case? The simplest thing would be to apply a\nddpenMADS penalty to the problem, while using cineq to compute q . The result, for Kpen =\n\xc2\xaf\n10\xe2\x88\x924 , pen = 10\xe2\x88\x922 is shown in Figure 10. Like the lightly penalized unconstrained case\nin Figure 8, it provides a \xe2\x80\x9cpretty good\xe2\x80\x9d solution, probably good enough for any practical\napplication.\nWhat \xe2\x80\x93 in all of these singular cases \xe2\x80\x93 if we want cleaner results? Consider, again, the\nqbarmax = 9(10\xe2\x88\x924 ) case from Figure 7. It is easy to see that the optimal trajectory goes\nthrough four distinct phases: max thrust \xe2\x80\x93 max q \xe2\x80\x93 singular arc \xe2\x80\x93 min thrust. Conceptually,\n\xc2\xaf\nwe could partition the trajectory and apply each phase\xe2\x80\x99s appropriate constraints, one at a\n\n51\n\n\xe2\x88\x924\n\nx 10\n\n3.5\n3\n\n10\n\n2.5\n2\n\n6\n\nT\n\nqbar\n\n8\n\n1.5\n4\n\n1\n\n2\n\n0.5\n\n0\n0\n\n0.05\n\n0.1\n\n0.15\n\n0\n0\n\n0.2\n\n0.05\n\ntime\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 10. Comparison of q -constrained Thrust Pro\xef\xac\x81les with Jitter Penalty\n\xc2\xaf\ntime: Require:\nPhase 1 . . .\nPhase 2 . . .\n\nTmax = T,\nTmax \xe2\x89\xa5 T \xe2\x89\xa5 Tmin ,\n\nqbarmax \xe2\x89\xa5 q\n\xc2\xaf\nqbarmax = q\n\xc2\xaf\n\nPhase 3 . . .\n\nTmax \xe2\x89\xa5 T \xe2\x89\xa5 Tmin ,\n\nqbarmax \xe2\x89\xa5 q , ddpenMADS\n\xc2\xaf\n\nPhase 4 . . .\n\nT \xe2\x89\xa5 Tmin ,\n\nKpen = 10\xe2\x88\x924\n\xe2\x88\x921\npen = 10\n\nqbarmax \xe2\x89\xa5 q\n\xc2\xaf\n\nThe result is shown in the upper plots in Figure 11. The lower pair of plots in the Figure\nare the data from Figure 10. There are clearly some di\xef\xac\x80erences between the two problem\nformulations, but we will defer their discussion until after showing code fragments for setting\nup the four-phase problem.\nMulti-phase problems have several key di\xef\xac\x80erences from single-phase problems, that must\nbe kept in mind:\n1. Each phase will have its own duration. For this problem, the relevant lines of xdot\nare\ncall rocket(xv(kxp),uv(kup),fv(kxp))\ntau=pv(loctau0+kph)\nfv(kMain)=tau*fv(kMain)\n! time-scale only the rocket plant states\nif(kph.EQ.3)then\ncall ddpenMADS(nk,uv(locT),xv(locddpv),3,epsvdd,fv(locddpv),fv(locddpint))\nendif\nwhere loctau0 is set in the problem\xe2\x80\x99s MODULE \xef\xac\x81le as\n\n52\n\n3\n\n0.8\n0.6\n\nT\n\nqbar \xc3\x97 103\n\n1\n\n0.4\n\n2\n1\n\n0.2\n0\n\n1\n\n3\n\n0.8\n0.6\n\nT\n\nqbar \xc3\x97 103\n\n0\n\n0.4\n\n2\n1\n\n0.2\n0\n0\n\n0.05\n\n0.1\n\n0.15\n\n0\n0\n\n0.2\n\n0.05\n\ntime\n\n0.1\n\n0.15\n\n0.2\n\ntime\n\nFigure 11. Comparison of One- and Four-Phase q -constrained Cases with Jitter Penalty\n\xc2\xaf\ninteger,parameter ::\n& loctau0=0\n\n&\n! zero-base pointer for the taus for four phases\n\n2. Each phase may have a di\xef\xac\x80erent pattern of equality and inequality constraints in\ncineq. Here,\nif(iecflg.EQ.1)then\nselect case(kph)\ncase(1)\niecin=(/0,1/)\ncase(2)\niecin=(/1,1,0/)\ncase(3)\niecin=(/1,1,1/)\ncase(4)\niecin=(/0,1/)\nend select\nreturn\nendif\n\n! Tmax, q bounded\n! T bounded, qmax\n! T and q bounded (singular)\n! Tmin, q bounded\n\ncall calcqbar(xj(kxp),qbar)\nselect case(kph)\ncase(1)\ncv(1)=Tmax-uv(locT)\n! T=Tmax\ncv(2)=qbarmax-qbar\n! qbarmax >= qbar\ncase(2)\ncv(1)=Tmax-uv(locT)\n! Tmax>=T\n\n53\n\ncv(2)=uv(locT)-Tmin\ncv(3)=qbarmax-qbar\ncase(3)\ncv(1)=Tmax-uv(locT)\ncv(2)=uv(locT)-Tmin\ncv(3)=qbarmax-qbar\ncase(4)\ncv(1)=Tmin-uv(locT)\ncv(2)=qbarmax-qbar\nend select\n\n! T>=Tmin\n! qbarmax=qbar\n! Tmax>=T\n! T>=Tmin\n! qbarmax>=qbar\n! T=Tmin\n! qbarmax>=qbar\n\n3. If the user is constructing the multi-phase problem from a single-phase one, it is critical\nnot to forget that terminal boundary conditions no longer occur for xbc(kf(1)+ . . .).\nThis is very easy to forget. The best policy is to express terminal values in terms of\nxbc(kf(nph)+ . . .). This is always correct, regardless of changes to the problem code.\nFor phiobj, the code becomes\nrf=xbc(kf(nph)+locr)\nphi=-rf + Kddp*xbc(kf(3)+locddpint) ! ddpenMADS only on phase 3\nNote that because the ddpenMADS states only exist during phase three, the terminal\nvalue of the penalty integral is hard-wired to that phase.\n4. A multi-phase problem introduces boundary conditions at the intermediate phase\nboundaries. In this case, we require that the plant states be continuous, and we\nneed to initialize the penalty integral \xe2\x80\x93 xv(locddpint), referred to in phiobj, above\n\xe2\x80\x93 to zero at the beginning of the third phase. The easiest way to handle continuity\nboundary conditions is to set up an index vector. Suppose that states 1, 3, and 4 are\nto be continuous across the phase 1/2 boundary. De\xef\xac\x81ne\ninteger,parameter :: k134(3)=(/1,3,4/)\nand use it in psibc as follows:\npsi(kpsi+k134)=xbc(kf(1)+k134)-xbc(k0(2)+k134)\nkpsi=kpsi+3\nwhere kpsi at the beginning of the code fragment was the number of psi elements\nde\xef\xac\x81ned thus far. For our problem, the relevant lines of psibc are\nif(iebcflag.EQ.1)then\niebc=0\niebc(16:19)=1\nreturn\nendif\n! initial conditions\npsi(1)=xbc(k0(1)+locr)-1\npsi(2)=xbc(k0(1)+locV)\npsi(3)=xbc(k0(1)+locm)-1\nkpsi=3\n! 3\n! continuity of plant traj from Tmax to qmax arcs\n\n54\n\npsi(kpsi+kMain)=xbc(kf(1)+kMain)-xbc(k0(2)+kMain)\nkpsi=kpsi+nxp\n! 6\n! continuity from qmax to singular\npsi(kpsi+kMain)=xbc(kf(2)+kMain)-xbc(k0(3)+kMain)\nkpsi=kpsi+nxp\n! 9\n! initial condition for ddpenMADS integral\npsi(kpsi+1)=xbc(k0(3)+locddpint)\nkpsi=kpsi+1\n! 10\n! continuity from singular to Tmin\npsi(kpsi+kMain)=xbc(kf(3)+kMain)-xbc(k0(4)+kMain)\nkpsi=kpsi+nxp\n! 13\n! terminal conditions\npsi(kpsi+1)=xbc(kf(nph)+locV)\npsi(kpsi+2)=xbc(kf(nph)+locm)-mEmpty\nkpsi=kpsi+2\n! 15\n! bounds on taus\ndo k=1,nph\npsi(kpsi+k)=pv(loctau0+k)-taumin\nenddo\nkpsi=kpsi+nph\n! 19\nNote, in the fragment above, the initialization of the penalty integral as psi(10) and\nimposition of \xcf\x84j \xe2\x89\xa5 taumin, j = 1, nph. The index vector kMain has already been\nde\xef\xac\x81ned for use in time-scaling the plant equations of motion.\nAlthough this multi-phase problem has a substantially more complicated temporal structure than the corresponding single phase one, it is easy to create an initial guess, starting\nfrom a compatible single phase solution. Assume that we are starting from the solution for\nqbarmax = 9(10\xe2\x88\x924 ), from Figure 7, in the upper right corner. The \xef\xac\x81rst step in preparing\nthe initial guess for for the multi-phase problem is to plot whatever variable (frequently a\ncontrol) most clearly displays the switching structure, simply against index, e.g.,\nS=importMADS(\xe2\x80\x99SinglePhase_premads.dat\xe2\x80\x99,\xe2\x80\x99SinglePhase_vout.dat\xe2\x80\x99,0);\nplot(S.u{1});grid on;\nThe user then observes the index number(s) where the structure changes, and records them.\nFor this problem, we have bv=[19 62 77] for four phases. The \xe2\x80\x9cS\xe2\x80\x9d structure and bv are\nsaved together:\nsave SinglePhase S bv\nand that .mat \xef\xac\x81le is made available to a script like\nload SinglePhase % provide S and bv\ntau=S.p;\nbout=breaktrajMADS(S.x{1},S.u{1},bv,tau); % Note that\n% construct dimensions for four-phase initial guess\nP.nxv=[3 3 7 3];\n% extra states for ddpenMADS in singular arc\nP.nuv=[1 1 1 1];\nP.nav=[2 3 3 2];\n% see cineq...\nP.kodev=[0 0 0 0]; % kodev only *needs* to be 0 during phase 3\nP.nbc=19;\nP.nph=4;\n\n55\n\nP.ndv=bout.ndv;\nP.np=4;\n% p vector will hold four taus.\nrandmag=0;\nvin=[];\nfor k=1:P.nph\n% Note adding extra states in phase 3\nvin=[vin;adduxMADS(bout.x{k},bout.u{k},P.nxv(k),P.nuv(k),randmag)];\nend\nvin=[vin;bout.tau];\nsave FourPhase_vin.dat vin -ascii -double\nname=\xe2\x80\x99FourPhase_premads.dat\xe2\x80\x99;\nwritepremads(P,name)\nSubsection 2.3.2 describes how to use breaktrajMADS, andadduxMADS, and we have already\nused the latter in setting up the initial guess for the single-phase problem with ddpenMADS.\nThe function breaktrajMADS is used to partition the trajectory into subintervals delimited\nat the the integration intervals given in bv. The output of breaktrajMADS,\xe2\x80\x9dbout,\xe2\x80\x9d includes\nthe \xe2\x80\x9cndv\xe2\x80\x9d vector, bout.ndv, and the vector of subinterval durations, bout.tau, in addition\nto the state and control trajectories for each subinterval. Note that the input guess has\nthree states, so additional states are added only in the third phase, where P.nxv = 7.\nWe now return to Figure 11, to compare the single-phase and four-phase solutions.\nBefore that, though, a housekeeping comment is needed regarding the fallo\xef\xac\x80 in T in the\nfour-phase case (upper right plot) at the end of the max \xe2\x88\x92\xc2\xaf arc. The fallo\xef\xac\x80 in T lasts for\nq\none integration interval, and induces a corresponding violation of the q = qbarmax equality\n\xc2\xaf\nconstraint for that phase. Why did this happen? It is the result of computing q in cineq\n\xc2\xaf\nas a function of xj, the \xe2\x80\x9ccurrent\xe2\x80\x9d value of the state when cineq is called. Recall that for a\ntrajectory with nd integration intervals, the state appears at nd + 1 instants. By imposing\nthe q constraint on xj values, the terminal value of q was unconstrained. This situation can\n\xc2\xaf\n\xc2\xaf\nbe treated in several ways:\n\xe2\x80\xa2 Brute Force\nThe constraint could be doubled, imposed at both xj and at xjp1. This works, but\nis wasteful of computation, since it involves 2(nd \xe2\x88\x92 1) redundant evaluations of the\nconstraint.\n\xe2\x80\xa2 Additional Boundary Condition\nThe missing constraint could be imposed in psibc via\ncall calcqbar(xbc(kf(2)+kxp),qbar)\npsi(kpsi+1)=qbarmax-qbar ! This element has iebcvec(kpsi+1)=0\nThe is computationally e\xef\xac\x83cient, but has a downside in that it requires that q be\n\xc2\xaf\ncomputed separately in psibc.\n\xe2\x80\xa2 Compute the Constraint in xdot\nThis issue does not come up when q is computed in xdot, because it results in the con\xc2\xaf\nstraint being imposed at the midpoints of the integration intervals: All state instants\nparticipate in the constraint. The downside, here, is that there is a vulnerability to\ncontrol jitter on the active constraint arc. The jitter, as we\xe2\x80\x99ve seen, can be treated\nusing a penalty, as seen in this subsection. It is actually more e\xef\xac\x80ective, though, to\nconstrain the constraint rate \xe2\x80\x93 in this case d\xc2\xaf/dt to zero. This will be demonstrated\nq\nin the next subsection.\n\n56\n\n\xe2\x80\xa2 Set the Problem Up Cleverly\nWe observed the temporal pattern of active constraints in the single-phase case, before\nbreaking it up into the four-phase problem, so we knew that the \xef\xac\x81rst phase, for which\nqbarmax \xe2\x89\xa5 q , terminates with that constraint active, and that the state trajectory\n\xc2\xaf\nis continuous. Because of this, the \xef\xac\x81rst qbarmax = q constraint in the second phase\n\xc2\xaf\nis redundant, when q is computed using xj. We would do better in this case to use\n\xc2\xaf\nxjp1. The problem in Figure 11 can always be avoided by laying out the problem\nthoughtfully.\nHaving described how we set up the four-phase problem, and how we should have set it\nup, we return to Figure 11 to compare the single-phase and four-phase solutions. The most\nobvious di\xef\xac\x80erences appear in the thrust pro\xef\xac\x81les in the Figure\xe2\x80\x99s right column. The jittersuppressed \xe2\x80\x9csingular\xe2\x80\x9d arc in the four-phase case is nothing like that in the single-phase one.\nNot only is it, to say the least, di\xef\xac\x83cult to assign it a plausible physical interpretation, but\nit is very short. It follows an elongated max \xe2\x88\x92\xc2\xaf arc that carrys T all the way back to its\nq\nTmax boundary. This latter di\xef\xac\x80erence has a serious impact on the trajectory, increasing the\ntime spent on the max \xe2\x88\x92\xc2\xaf constraint boundary by roughly 20%. This is visually evident in\nq\nthe Figure\xe2\x80\x99s left column, in which the four-phase q history, at the top, essentially lacks the\n\xc2\xaf\nq dropo\xef\xac\x80 during the singular arc that was seen in the bottom, single-phase, plot.\n\xc2\xaf\nWhich of these trajectories is the (most) optimal one? It happens that the altitude gain\nfor the single-phase problem is slightly less than .01% better than that for the four-phase\none, but that\xe2\x80\x99s certainly not very signi\xef\xac\x81cant. If it is important to know what the optimal\nsolution is, without the distortions of jitter penalties, misbehaving singular arcs, or other\nnumerical artifacts, then it is necessary to formulate and solve the problem as a variational\noptimal control problem. While this can be quite di\xef\xac\x83cult \xe2\x80\x93 indeed, practically impractical\nfor practical problems - the next Subsection will use MADS COV support routines to lay\nout an approximate variational solution.\nBefore leaving this Subsection, review what has been introduced here. This Subsection\nhas focused on dealing with singular arcs using an heuristically motivated penalty function,\nimplemented in ddpenMADS that targets large control accelerations accompanied by relatively\nsmall control rates. New material introduced in this Subsection included\n1. application of ddpenMADS to problems with an active state constraint arc implemented\nby computing the constraint function in xdot. It was seen that, while the measure\nnowhere produces perfect results, it bene\xef\xac\x81ts from gradually \xe2\x80\x9cwalking the solution in;\xe2\x80\x9d\nthat is, solving a sequence of problems with increasingly stringent constraint settings,\nusing each solution as the initial guess for the next.\n2. The details of setting up a multiple-phase problem from a single-phase one were\ndemonstrated, and various subtleties were discussed for posing state constraints in\na multi-phase setting that uses cineq to compute the constraint function.\n\n57\n\nReferences\n1. Gill, P. E., Murray, W. M., and Saunders, M. A., \xe2\x80\x9cUser\xe2\x80\x99s Manual for SNOPT Version 7:\nSoftware for Large-Scale Nonlinear Programming,\xe2\x80\x9d University of California, San Diego,\nApril 2007.\n2. Hasco\xc2\xa8t, L. and Pascual, V., \xe2\x80\x9cThe Tapenade Automatic Di\xef\xac\x80erentiation tool: Principles,\ne\nModel, and Speci\xef\xac\x81cation,\xe2\x80\x9d ACM Transactions On Mathematical Software, Vol. 39, No.\n3, 2013.\n3. Huntington, G. T., Benson, D. A., and Rao, A. V., \xe2\x80\x9cA Comparison of Accuracy and\nComputational E\xef\xac\x83ciency of Three Pseudospectral Methods,\xe2\x80\x9d AIAA Paper 2007-6405,\n2007 AIAA Guidance, Navigation, and Control Conference, Hilton Head, SC, August\n2007.\n4. Neidinger, R., \xe2\x80\x9cIntroduction to Automatic Di\xef\xac\x80erentiation and MATLAB ObjectOriented Programming,\xe2\x80\x9d SIAM Review, Vol. 52, No. 3, 2010.\n5. Bryson, A. E., and Ho, Y.-C., Applied Optimal Control, Hemisphere Publishing, New\nYork, 1975.\n6. McShane, E., \xe2\x80\x9cOn Multipliers for Lagrange Problems,\xe2\x80\x9d American J. Math., 1939, Vol.\n61.\n7. Pontryagin, L., The Mathematical Theory of Optimal Processes, Wiley, New York, 1962.\n8. Seywald, H. and Cli\xef\xac\x80, E. M., \xe2\x80\x9cGoddard Problem in Presence of a Dynamic Pressure\nLimit,\xe2\x80\x9d AIAA Journal of Guidance, Control, and Dynamics, Vol. 16, No. 4, 1993, pp.\n776-781.\n\n58\n\nForm Approved\nOMB No. 0704-0188\n\nREPORT DOCUMENTATION PAGE\n\nThe public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources,\ngathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this\ncollection of information, including suggestions for reducing this burden, to Department of Defense, Washington Headquarters Services, Directorate for Information Operations and\nReports (0704-0188), 1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person\nshall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number.\nPLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.\n\n1. REPORT DATE (DD-MM-YYYY)\n\n2. REPORT TYPE\n\n01- 10 - 2014\n\n3. DATES COVERED (From - To)\n\nTechnical Memorandum\n\n4. TITLE AND SUBTITLE\n\n5a. CONTRACT NUMBER\n\nMADS Users' Guide\n\n5b. GRANT NUMBER\n5c. PROGRAM ELEMENT NUMBER\n5d. PROJECT NUMBER\n\n6. AUTHOR(S)\n\nMoerder, Daniel D.\n\n5e. TASK NUMBER\n5f. WORK UNIT NUMBER\n\n473452.02.07.03.02.01\n7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)\n\n8. PERFORMING ORGANIZATION\nREPORT NUMBER\n\nNASA Langley Research Center\nHampton, VA 23681-2199\n\nL-20256\n9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)\n\n10. SPONSOR/MONITOR'S ACRONYM(S)\n\nNational Aeronautics and Space Administration\nWashington, DC 20546-0001\n\nNASA\n11. SPONSOR/MONITOR'S REPORT\nNUMBER(S)\n\nNASA/TM-2014-218532\n12. DISTRIBUTION/AVAILABILITY STATEMENT\n\nUnclassified\nSubject Category 08\nAvailability: NASA CASI (443) 757-5802\n13. SUPPLEMENTARY NOTES\n\n14. ABSTRACT\n\nMADS (Minimization Assistant for Dynamical Systems) is a trajectory optimization code in which a user-specified\nperformance measure is directly minimized, subject to constraints placed on a low-order discretization of user-supplied plant\nordinary differential equations. This document describes the mathematical formulation of the set of trajectory optimization\nproblems for which MADS is suitable, and describes the user interface. Usage examples are provided.\n\n15. SUBJECT TERMS\n\nGuide; MADS; Users\n16. SECURITY CLASSIFICATION OF:\na. REPORT\n\nU\n\nb. ABSTRACT c. THIS PAGE\n\nU\n\nU\n\n17. LIMITATION OF\nABSTRACT\n\nUU\n\n18. NUMBER 19a. NAME OF RESPONSIBLE PERSON\nOF\nSTI Help Desk (email: help@sti.nasa.gov)\nPAGES\n19b. TELEPHONE NUMBER (Include area code)\n\n63\n\n(443) 757-5802\nStandard Form 298 (Rev. 8-98)\nPrescribed by ANSI Std. Z39.18\n\n"