b'SECOND ORDER ENDPOINT CONDITION\n\n\nBy Richard G. Brusch and Thomas L. Vincent\n\n\n;0\n\nO36\n(ACCESS ON\n\n2\n\n(T___________\n\nUMBER)\n\n(PAAE\n\nU(CODE)\n\n~I1\n(CATEGORY)\n\n(NASA CR OR TMX OR AD NUMBER)\n\nPrepared 2der Grant No. NGR 03-002-011 by\n\n-\'THE UNIVERSITY OF ARIZONA\nTucson, Arizona\n\nfor\n\nNATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n\nMarch ]970\nReproducod by\n\nNATIONAL TECHNICAL\n\nINFORMATION SERVICE\n\nk\n\nSpringild, Va.\n\n22151\n\nPMECEDING PAGE BLANK NOT FILMED.\n\nQABLE OF CONTENTS\n\nPage\n\nv\n\nLIST OF ILLUSTRATIONS\nABSTRACT\n\n\nI\nINTRODUCTION\n\n1\n\n1.1\n\nThe Problem of Bolza \n\n\n1.2\n\nSolutions\nThe Nature of Multiple Stationary\n\n4\n\nPath Sufficiency Conditions\n\nFixed Endpoint Problems and\nVariable Endpoint Problems\n\nSufficiency\n\nProblems Requiring Path and Endpoint\nConditions\n\nProblems with Periodic Solutions\n\nProblems with Singular Control\n\n14\n\nCONDITION \n\nA SECOND ORDER ENDPOINT\n\n2.1\n\nthe Problem of Bolza\nFunctional Relationships for\n\n2.2\n\nConditions \n\nDerivation of Transversality\n\n14\n22\n\n\nfor Endpoints\n\nTransversality Necessary Condition\ns\nEndpoint Condition\n2.3 Derivation of Second Order\n\n\n\n\n27\n\n\nSecond Order Endpoint Condition\n\n\n2.4 \nRelation to Classical Theory\n\n\n33\n\n35\n\n\n2.5\n\nGeodetic Example \n\n\nNecessary Path Conditions\n\nFunctional Relations\n\nNecessary Endpoint Conditions\n\n\nSecond Order Endpoint Condition\n\n\n46\n\n2.6 \nA Numerical Algoritln\n\n\n51\n\nCONCLUSIONS \n\n\niii\n\nTABLE OF CONTENTS - Cont\'d\n\n\nPage\n\nAPPENDIC A \t\n\nMINIMIZATION OF A FUNCTION OF SEVERAL\nVARIABLES\n\n\n52\n\n\nA.1\nA.2\n\n52\n\n\nMethod of Implicit Functions \t\nMethod of Lagrange Multipliers\n\n57\n\n60\n\n\nREFERENCES\n\niv\n\n\nLIST OF ILLUSTRATIONS\n\nPage\n\nFigure\n1.1\n\nA- Family oft Extremals and the Discriminant Locus\n\n5\n\n\n1.2\n\nMultiple Statibnary Solutions for the Brachistochrone\nProblem\n\n6\n\n\n1.3\n\nMultiple Stationary Solutions to a Geodetics Problem\n\n7\n\n\n1.4\n\nA Problem Requiring Second Order Conditions\n\n9\n\n\n1.5\n\nMultiple Solutions Due to A Periodic Cutoff Function\n\n10\n\n\n1.6\n\nMultiple Solutions Arising from Singular Control\n\n12\n\n\n2.1\n\nA Representation of yi as a Function of yif and tfl\n\n20\n\n\nv\n\n\nABSTRACT\n\n\nThe nature of multiple solutions\'to a.general Problem of\n\nBolza in the calculus of variations is investigated.\n\nThebe\n\n\nmultiple stationary solutions are of several distinct types,\n\neach of which is briefly discussed.\n\nMultiple stationary solutions often arise when only first\n\norder necessary conditions have been applied.\n\nA second order\n\n\n, test to eliminate some multiple solutions of this type is developed.\'\n\n\t\nIt is shown that second order tests can be broken down into path\n\ntests and endpoint tests and that once the first order necessary\n\nconditions of the calculus of variations have been applied, the\n\nsecond order path test and the endpoint test can be applied\n\nindependently.\n\nOnly the second order endpoint test is investigated.\n\nDirect\n\n\napplication of this condition requires the-analytical integration\n\nof a set of nonlinear differential equations subject to mixed\n\nboundary conditions.\n\nSince this is often difficult or impossible,\n\n\nan algorithm is developed for numerically implementing the second\n\norder endpoint condition.\n\nA geodetics problem is solved analytically\n\n\nto illustrate the theory and demonstrates that the second order condition\n\nis an effective computational tool, by eliminating certain classes of\n\nnon-optimal solutions from consideration.\n\n\nvi\n\n\nINTRODUCTION\xc2\xad\n\n1.1\n\nThe Problem of Bolza\n\nSince much of what is to follow depends upon an understanding\n\n\nof the -Problem of Bolza as formulated in- control notation (Vincent\n\nand Brusch, 1966, pp. 4-5), a brief statement of the problem in its\n\nsimplest form is appropriate.\n\nAmong the set of all continuous state functions,\n\n\nYi(t)\n\ni\n\n=\n\n1, 2,\n\n...\n\n,\n\nn; t o\n\n\n\n\nt\n\ntf\n\n(1.1.1)\n\nand continuous control variable functions\n\nuk(t)\n\nk = l, 2, ...,\'m < n\n\n(1.1.2)\n\n\nsatisfying differential equations and end-conditions of the form\n\n\nYi\n\n=\n\nfi(Yj, Uk\n\nt)\n\n=\n\n\'-, oYif\'-to\' tf) .0\n\n1, 2,\n\n...\n\n,\n\nn\n\n*g=.),,2,..., p _ 2r\n\n(1.1.3)\n\no\n\n(1.1.4)\n\n\nfind the set which will minimize a sum of the form:\n\nit = g(Yiol Yif, to, tf) +\n\ntfL(Yi(t), Uk(t), t) dt .(1.1.5)\n\n\nt\n\n0\n\n2\n\nHere it is assumed that the functions f., L, g, and VI\'are of class C\nIn the above and throughout this presentation, a dot above a variable\nwill be used to represent the derivative of the variable with respect\nto t, the independent variable.\n\nLikewise the subscripts o and f will\n\nindicate the evaluation of the variable or expression at the initial\n\nand final value of t, respectively.\n\nFor the sake of brevity, the\n\n\nrange of subscripts i, j, k, and I will be as given above and will\n\nnot be repeated in what follows.\n\nFollowing the conventional method of Lagrange multipliers\n\n(Bryson-and Ho, 1969), minimization of the augmented function\n\nJ\n\n= g + P1.e+\n\nf\n\nt\n\n\n[L-Xif i + "iYi I dt .(1.1.6)\n\n-0\n\n\nIn the above equation and throughout this report,\n\n\nis considered.\n\nrepeated subscripts iill be used to signify sumation. Equation (1.1.6)\n\nwas obtained by adjoining equations (1.1.3) and (1.1.4) to relation\n\n(1.1.5) as follows:\n\n3)by the variables Xi(t),\n\n(a) multiplying telations (I.l.\nrespectively, integrating from t\n\nto tf and by adding the\n\nsum of the integrals to expression (1.1.5),\n(b) multiplying equations (1.1.4) by the parameters p\n\nand\n\n\nadding the sum of the products to express-on (1.1.5).\n\n\nIt is convenient to define the following functions:\n\nG(yio\' Yif, to, if)-\n\ng + A\n\nHYi(t) , ,i(t),uk(t), t]\n\n(ltl.A\n\nX= \n\nkfi.-L(1.1.8)\n\nThe function.H is often referred to as the Hamiltonian.\n\nWith these\n\ndefinitions, equation (1.1.6) may.\'be written as\n\nJ=\n\n[-H + X\n\nG +\n\n] dt\n\nt\n0\n\nBy considering small variations in the path and eidpoints about a\n\nnominal path, it can be shown that if the functions uk(t) and y.(t)\n\n\n(1.1.9)\n\nare a solution to the Problem of Boiza, then they must satisfy th\n\nfollowing necessary conditions (Hestenes, 1966, pp. 346-351):\n\n\nCondition I.- There exist continuous multipliers X;(t) and\n\nHamiltonian function as defined by equation (1.1.8) such that:\n\n(1) the Euler-Lagrange equations,\n\n\nH \n\n\n(1.1.10)\n\n\nbyi\n\nbH\n\n=\n\no\n\n(1.1.11)\n\nbuk\nare satisfied at every point along the path and,\n\n(2) the transversality conditions\n\nbG\n\n+Ho = 0\n\nbt 0\n\n0\n\n(a.i. 12)\n\n=0o\nby\n\n(1.1.13)\n\nH\n\n0\n\n(i:\n\n+\n\nif\n\n\n0\n\nbG\n\nbtf\n\n\nbG\n\nbyif\n\n0\n\n)\n\n(1.1.15)\n\nare satisfied by the endpoints.\n\nCondition II.\n\nH[Y(t), ?i(t),\n\nThe inequality\n\n\nno(t), tI\n\nHE[y.i(t), X(t),\n\n)\n\n](1\n\n.\n\nmust be satisfied for all t\n\nOf\n\nt 5 tf and for all non-optimal\n\ncontrol functions un\n (Weierstrass Condition).\n\no\n\nCondition III.- The k by k matrix\n\n,s=l,2, ...\n\n\'2\nbH\n\n.\n\n, k\n\nUb~t(1.1.17\n\nmust be negative semi-definite for a minimum (Legendre-Clebsch\n\ncondition)..\n\n\nCondition IV.\n\nA fourth necessary condition is discussed by\n\n\nBliss (1946, pp. 226-228) in classical dependent variable notation.\n\nHe proves that the, second order variation of a sum similar to J\n\nmust be non-negative along a stationary arc, if that arc minimizes J\n\nHestenes (1966, pp. 283-286) verifies this conclusion in modern\n\ncontrol notation for the Problem of Bolza with fixed endpoints.\n\nAs\n\n\ndeveloped by Hestenes, the fourth necessary condition-represents\n\na necessary condition on the path alone; variations in the endpoints.\n\nare not considered.\n\nIf Condition III is satisfied, Condition IV is\n\n\nusually referred to as the Jacobi Condition.\n\nA further geometric\n\n\ninterpretation of this condition is presented in the following\n\nsection.\n\n\n1.2\n\nThe Nature of Multiple Stationary Solutions\n\nIt is helpful in understanding the nature of multiple stationary\n\n\nsolutions to classify them by the circumstances pertinent to thdir\n\noccurrence.\n\n\n4+\n\nFixed Endooint Problems - Multiple stationary solutions are\noften obtained for problems with fixed endpoints, because only the\nBliss (1946,\n\nfirst three necessary conditions have been applied.\n\np. 235) has shown in dependent variable notation that the fourth\nnecessary condition of Jacobi, taken together with the first three\nnecessary conditions, suitably strengthened\n\nforms a sufficient set\n\nof conditions for the Problem of Bolza.\nAlthough analytically complex\n\nthe Jacobi condition has a\n\n\nsimple geometric interpretation for-problems with one state variable.\nIn this case the set of all solutions forms a one dimensional family\nof extremal arcs, y = y(t, c), which all pass through the initial\npoint as shown in Figure (1.1).\n\nWith each arc is associated a\n\nparticular value of c. If arcs y(t, c) and y(t, c +\n\n)\n\nntersect in\n\nthe limit as e goes to 0, the point of intersection is called a\n\nconjugate point.\n\nThe locus of such intersections is called the\n\n\ndiscriminant locus, also shown in Figure (1.1)\n\ny\nDIS CRIMINANT\n\nSLOCUS\n\nFAMILY OF EXTRETLS\n0\n\nFig. 1.1 A Family of Extremals and the Discriminant Locus\n\n5\n\nIn terms of this geometry, the Jacobi condition requires that\n\nan optimal trajectory contain no conjugate point.\n\nAlternatively,\n\n\nthe condition requires that an optimal solution may not touch the\n\ndiscriminant locus.\' Figure (1.1) shows that there are two solutions\n\njoining points 0 and A, one of which touches the discriminant locus\n\nand is therefore non-optimal.\n\nIf the fourth necessary condition\n\n\nof Jacobi is applied in such cases of multiple stationary solutions,\n\nusually all but one of the trajectories will be shown to contain a\n\npoint conjugate to the initial point, thus rendering them non-optimal.\n\n-\n\nExamples of this occurrence are many:\n\nproblem with\n\nThe Brachistochrone\n\nfixed endpoints graphically illustrates the idea.\n\nConsider the problem of a bead sliding down a wire under the\n-\n\ninfluence of gravity alone.\n\nWhat should the shape of the wire be\n\nin order to minimize the time of transit between two points in a\nvertical plane?\ncycloids.\n\nIt is well known that the solution curves are\n\nHowever, as shown in Figure (1.2), there are several\n\ndifferent cycloids which satisfy the-necessary conditions of the\n\nDISCRIMINANT LOCUS\n\n\n2\n\n373\n\nFig. 1.2\n\n6\n\nMultiple Stationary Solutions for the Brachistochrone Problem\n\n\ncalculus of variations.\n\nIt\n\ncan be seen that the x-axis forms the\n\ndiscriminant locus and that the points where solutions 1 and 2 touch\n\nthe discriminant locus are conjugate-points.\nviolate the Jacobi condition,\n\nit\n\nis\n\nSince solutions 1 and 2\n\n\nevident that solution 3 is\n\nthe*\n\ntrue optimum.\nIn this cabe\n\n\xc2\xb1u\n\nuas uten pussiuwe uo\n\n-lflSTngUllsnl\n\ne True\n\noptimum from the candidates by applying a sufficiency condition\npertaining to the field of extremal paths.\n\nVariable Endooint Problems - Problems with variable endpoints\nr6quire that the endpoints of the trajectories, as well as the path,\n\nbe selected in an optimum fashion.\n\nConsider the geodesics problem\xc2\xad\n\nof trying to find the minimum distance from the origin to a given\n\nparabola as shown in Figure (1.3).\n\nIt will be shown in Chapter 2\n\n\nthat two stationery solutions exist, viz., OA and 0B.\n\nOnce an\n\n\nendpoint has been selected, the problem becomes one of fixed endpoints,\n\n\nA\n\nA\n\nT.B\n\n\nFig. 1.3\n\nMultiple Stationary Solutions to a Geodetics Problem\n\n\nand the path sufficiency conditions previously discussed can then\n\nbe applied.\n\nIn this case, with the endpoint, A or B, thought of\n\n\nas being fixed, it can be shown that both solutions satisfy the\nJacobi sufficiency condition (Boiza, 1961, pp., 84-86).- The\nendpoints shown satisfy first order necessary conditions only, it\nis apparent that a second order endpoint condition may be useful\nin distinguishing the true optimal.\n\nA second order condition will\n\nbe derived in Chapter 2. While the second order condition obtained\nis akin to the classical focal point condition (Bolza, 1961, pp. 104-10),\nthe result is new in form and is directly applicable to the optimal\ncontrol problem.\n\n-Problems-Requiring First and Second Order Conditions - In the\n\nlast two sections, the necessity of using fixed endpoint path\xc2\xad\nsufficiency conditions and second order endpoint conditions was\n\nillustrated separately.\n\nIt is not unusual, however, to encounter\n\n\nproblems requiring the application of both the Jacobi condition and\n\nsecond order endpoint conditions to distinguish the true optimum\n\nfrom the set-of multiple stationary solutions.\n\nTo illustrate this\n\n\nsituation, reconsider the Brachistrochrone problem where the\n\nfinal endpoint, instead of being fixed, is required to be on curve-E\n\nas shown in Figure (1.4).\n\nBoth trajectories OAB and OD satisfy\n\n\nsecond order endpoint conditions; that is, both solutions would\n\nrepresent a local minimum with respect to small variations of the\n\nendpoint along endpoint manifold E.\n\nAs discussed before, point A\n\n\nis a conjugate point, thus violating the Jacobi condition.\n\nTrajectory OC\n\n\nviolates a second order endpoint condition; it is in fact a local\n\nmaximum with respect to small variations of the endpoint along E.\n\n\nA\n\n0\n\nB\n\nC.\n\n\nFig. 1.4. A rroblem Requiring Second Order Conditions\n\n\nThus through the use of both the Jacobi condition and a second order\n\nendpoint condition, OB is selected as-the optimal candidate..\n\n\nProblems with Periodic Solutions - Consider a system of equations\n(1.1.3) which exhibit periodic oscillati6is when no 6ontrol effort\n\nis applied. -It is not unusual for the optimal controls and adjoint\n\nvariables of such\n\n.\n\nsystem to also demonstrate periodic motion with\n\n\n\'the same period, especially if\n\nthe magnitude of the control is small.\n\nThe criterion by which "the solution is terminated is also often\n-periodic\n\nfor problems exhibiting periodic oscillations.\n\nThe terminating\n\nor cutoff condition is obtained from the transversality conditions\n(1.1.12)-\n\n.(1.1.15) by eliminating the P\n\nparameters,\n\nto form a\n\nsingle relationship among the state and adjoint variables.\n\nThe\xc2\xad\n\nzeros of the cutoff function then represent the terminating condition.\n\nAs an example, consider the problem of getting the mass of a thrusting\n\n-harmonic oscillator to a specified height while minimizing \n the integral\nof the thrust with respect to time.\n\nA mass is\n\nconnected in\n\nby a spring and dashpot to an inertial reference.\n\na parallel\n\n\nThe mass is\n\ncapable\n\n\nof generating a bounded thrust in the upward direction.\nit\n\nis assumed that the mass is constant.\n\nFor simplicity\n\nFor small damping factors\n\nand null thrust, the state variables, position and velocity\n\nthe\n\n\nadjoint variables, and the cutoff function all exhibit damped.\n\nperiodic oscillations.\n\nAs shown in Figure (1.5) the cutoff condition\n\n\nis satisfied during each period. For sufficiently small thrnst\n\namplitudes the cutoff function will deviate only slightly from that\n\ngenerated for null thrust, and will be satisfied at several points.\n\n\nPOSSIBLE FINAL TIMES\n\nz\n\n0\n\nTIME\n\nFig. 1.5\n\nMultiple Solutions Due to a Periodic Cutoff Function\n\n\nEach" thne the cutoff condition is satisfied, a potential\n\noptimal endpoint and a corresponding stationary solution is obtained.\n\nThus in periodic systems with weak bounded control, multiple\n\nstationary solutions may be encountered.\n\n\n10\n\nProblems with Singular Control - In cases where the Hamiltonian\n\nis linear in a bounded control variable, the control cannot be\n\ndetermined from the Euler-Lagrange equation (1.1.11).\n\nIn this case\n\n\nthe Hamiltonian can be written as\n\n\n= S(yi,\n\nH\n\nXi,\n\nfor scalar control.\n\nt)u\n\n+\n\nQ(yi\n\nXi, t)\n\n(1.2.1)\n\nS is referred to as the switching function.\n\n\nThe well-known Maximum Principle for problems with bounded control\ndeveloped by Pontryagin et al. (1962) requires that\n\nu =u\n\nwhen S > 0\n\nmax\n\n(1.2.2)\n\n\nU = U.\n\nwhen S < 0\n\nHowever, for the case when S = 0 over a non-vanishing time interval,\nthe Maximum Principle is indeterminant, and u may take on intermediate\nvalues.\n\nThis is the case of singular control.\n\nLeitmann (1966, pp. 57-58)\n\nhas pointed out that,. "While it is possible in a particular problem....\nto rule out the p6ssibility of [singular control], this cannot be done\nin general."\nTo demonstrate the existence of multiple stationary solutions in\nthe case of singular control; examine the problem of minimizing\n\n2 dt\n1\n\n(1.2.3)\n\nsubject to the constraints:\n\nl= x2 + u\n=\n\nJul g1\n\nxl(0) = Xl0\n( 0)\n\n=x 20\n\nx()\n\n= 0\n\nx 2 ()\n\n= 0\n\n(1.2.)\n\nThis problem was first discussed by Johnson and Gibson (1963).\n\nThe Hamiltonian is\n\nH\n\n=\n\n.(X- X2 )u + Xx\n\nIn this case S = X1 - X2 .\n\n2 \n\n\nx,2 /2\n\n(1.2.5)\n\nIf S is identically zero for a non\xc2\xad\n\nvanishing time interval, the possibility of singular control exists;\n\nBy taking a suitable number of time derivatives, it can be shown\n\nthat the singular control is given by u = -Xl-x2 , and that the\n\nsingular arcs are two lines xl(t) = 0 and sl(t) + 2x2 (t) = 0.\n\nFigure (1.6) shows two possible stationarysolutions to the\n\nproblem starting at point A, one of which has a singular subarc.\n\nThe first arc AB is the same for both solutions.\n\nIn both solutions\n\n\nu = -1 along arc BC and then follow arc CO to the origin with\n\nu = +1. This is the so-called "bang-bang" solution.\nat point B one may elect singular control, n\n\n=\n\nAlternately,\n\nx2 , and proceed\n\nto the origin directly along arc BC.\n\nBANG-BANG SOLUTION\n\n0\n\n\nSINGULAR ARC x,\nOPTIMAL\nSOLUTION\n\nB\n0\n2\n\n-2\n\n2 SINGULAR ARC\nx I + 2x 2 = 0\n\nFig. 1.6\n\n12\n\nMultiple Solutions Arising from Singular Control\n\n\nUnfortunately, there is no guarantee that the solution with\n\nsingular control is minimizing or that it will always enter the\n\noptimal solution, even if the possibility of singular solutions\n\n-does exist.\n\nIn th s case the\n\nolution with ban.rbang cdntrol,\n\n\narc ABCO,.has -an index-.of performance almost 12 per cent larger\nthan-for the true optimal control which uses the singular control\n\narc B0;\nRecently, Kelly, Kopp and Moyer (1967) and Robbins (1965) have\n-\n\ndeveloped a new necessary condition-\'for testing the optimality of\n-singular\n\n\xc2\xad\n\nsubarcs.\n\n13\n\nA SECOND ORDER ENDPOINT CONDITION\n\n\nIn this section a second order condition is developed for\n\nvariational problems with-variable endpoints.\n\nAmong the multiple\n\n\nstationary solutions that may exist,. the conrditioh provides atest\n\nfor distinguishing those stationary solutionts which are local miniuns\nwith-respeqt to endpoint variations along the prescribed terminal\n\nmanifold.\n\nThe second order endpoint condition is related to\n\n\nsufficiency conditions of the classical calculus of variations in\n\nsection 2.4.\n\nIn section 2.5 the second order condition is illustrated\n\n\nwith- an example problem. Finally, a numerical algorithm is\n\ndeveloped\n\nf 6 r applying the endpoint sufficiency condition to problems with-no\nanalytic solution.\n\n\n2.1\n\nFunctional Relationships ror the Problem of Bolza\n\nArguments used in Section 1 have implied that the conditions\nfor the Problem of Bolza fall into two classes:\nthe path and those pertaining to the endpoints.\n\nthose pertaining to\n-It\n\nhas been\n\nfurther argued that conditions pertaining to the endpoints can be\nconsidered independently from those pertaining to path.\n\nConsider\n\nthe Problem of Bolza as expressed in Section 1.1, equations (1.1.1)\n(1.1.5).\n\nIn this formulation, and for the remainder of this section,\n\nthe controls "k are assumed to be unbounded functions of time.\n\nIn\n\naddition, it is now assumed that the Jacobian is not equal to zero\n\n\n,ulbu , "-"\n\n2\nb (ul u2 ,\n\nA"\n\nfor all points (Ul, u2 ,\n\n/ 0\n\n(2.1.1).\n\n\n,\n\nUk) in the control space.\n\nThE\n\nfunction H has been-previously defined in equation (1.i.8).\n\nIf\n\n\nequation (2.1.1) is valid,-the implicit function theorem (Buck,\n\n1965, pp. 283-286) assures the existence of the k functional\n\nrelations\n\nUk= uk[Yi(t),\n\nXi(t)J\n\n(2.1.2)\n\n\n-from the k control variable Euler-Lagrange equations (i.!.11).\nCondition (2.1.1) specifically eliminates from consideration those\xc2\xad\n-systems in which any state variable derivative, y as defined in\n\n\xc2\xad\n\nequation (1.1.3), is a linear function of any of the control variables.\nA solution to the Problem of Bolza is specified by solutions\nfor the state variables y., as well as the control variables uK , as\nfunctions of time.\n\nA selection of the initial time and the final\n\n\ntime completes the solution.\n\nTo obtain these solutions, the control\n\n\nvariable Euler-Lagrange equations are first\'solved.for the control\n\nvariables uk as functions of the state variables y1 and the adjoint\n\nvariables X..\n1\n\nThe functions f. (1.1.3) and the L function (1.1.5) are\n\n1\n\nnow explicitly dependent only on the state variables, the adjoint\n\nvariables, and time.\n\n\nf i = fi[y(t); uk(y (t)) X.(t)); t]\n\n(2.1.3)\n\n\n15\n\nL\n\nL[yj(t); uk(yj(t), Xj(t)); tJ\n\n(2.1.4)\n\n\nSimilarly the H function bedcmes an explicit function of the\nstate variables, the adjoint xariables, the adjoint variables,\nand time, alone:\n\nH0 = H[yi(t); i(t); Uk(Yi(tj; x.(t))y;\'t]\n\n(2-1.5)\n\nFinally, it is evident that a similar functionalrelationship exists\n\nfor the time derivatives of adjoint variables,\n\n\nX.\n\n=\nP[yi(t),\n\ni(t), tj\n\n(2.1.6)\n\nIn summary, once the optimal control is selected, the state\n\nvariable differential equations (1.1.3) and the adjoint variable\n\ndifferential-equations (1.1.10) comprise a set of 2n first order\n\nnonlinear differential equations in the 2n state and adjoint variables\n\nand time.\n\nThis set of differential equations can be integrated in\n\n\ntheory, yielding\n\n\nY= Y(t, c\n\nXi =-Xi(t\'\n\n)\n\nr\n\n=\n\n1, 2,\n\n...\n\n,\n\n2n\n\n(2.1.7Y\n\n(2.1.8)\n\nc).\n\nwhere.the cr\'S are constants of integration.\n\nThe p end conditions\n\n\n(1.1.4) and the 2n + 2 equations representing the transversality\nnecessary conditions (1.1.12)\n\n-\n\n(1.1.15) comprise a set of (2n + p + 2)\n\nnon-linear algebraic equations in the 2n constants c\nmeters ut\n\nthe initial time t,\n\nthe p para\xc2\xad\n\nand the final time t\n\nThe initial values (yio, Xif, tf) are specified.\n\nHence, the\n\nCr\'s may be determined as a function of these initial and/or final\n\n16\n\nvalues by evaluating equations (2.1.7) and (2.1.8) at either the\ninitial or final point.\n\nFor example, a solution for the cr\'s\n\nwould be-specified by the set (yio\n(yi-,\n\nthe set\n\nxio\' t0, tf\n\nXif, tf, to)"or the set (yio, Yif\n\nis\n\nWhile it\n\nt0 , tf).\n\ndifficult to attach any physical meaning to the initial or final\nvalues of the Lagrange multipliers, the initial and final values of\nthe state variables have an immediate physical significance.\n\nFor\n\nthis reason, the state variable endpoints have been selected to\nfunctionally represent.the cr constants of integration for the\nrest of this section.\n\nThus equations (.1.7) and (2.1.8) will be\n\nwritten as\n= yj(t, Yio, Yif, to, tf)\n\ny\n\n(2.1.9)\nt0\n\nand\n\naYio\n\nYifl tol\n\nt\n\ntf\n\nf)\n\n(2.1.10)\n\nBy substituting the functional relationships exhibited in\nequations (2.1.9) and (2.1.10) into relations (2.1\'.2)\n\n-\n\n(2.1.6), it\n\ncan be seen that the functions uk , L, fiH\xc2\xb0, and Pi can\'all be\nwritten as explicit functions of the set (t,\n\nyio\' Yif, to,\n\ntY.\n\nThese functional relations, together with that for the function G\nfrom equation (1.1.7) are summarized for reference below:\nuk = u\n\nL\n\n(t, Yio\' Yif\n\nto\' tf)(..)\n\n= L (t, y io, Yif, to, tf)\n\nyj = f(t, Yio\' Yif\nX =\n\nto\n\ntf)\n\n(t, Yiol Yif, to, tf\n\n(2.1.12)\n\n(21.13)\n\n(2.1.14)\n\n17\n\nH\xc2\xb0 [y\n\n(t\n\n, Yio\' Yif\' to, tf); ?,(t, Yio\' Yif, to, tf\n\nuk(t, Yio\' Yif\' to\'-tf); t]\n\nG =G(A, Yiol Yif\' to"\n\n(2.1.15)\n\n(2.1.16)\n\nf)\n\nSo that there will be no confusion as to the meaning oi zne subscripts,\nnote that\n\nYjo\n\no\n\nYjf\n\n(2117)\n\n-\n\n(2.1.18)\n\nYJt.tf\n\n(2.1.19)\n\nXf\n\n(2.1.20)\nSf\n\nUsing the functional relationships summarized above form the\naugmented function J\n\n= J + P\n\ni\n\nwhere\n\ng(Yio\'-Yi\'\nJ(Yio\' Yif\' to\' tf) --\n\n+-\n\n[-H\xc2\xb0(t, Yio\'\n\nft\n\nYif\' to0\n\nto, if)\n\ntf)\n\n-\n\n0\n\n+\n\nX(t, Y\n\nyift\n.io\n\ntf) Y(t, Yio\' Yif\' to\' tf)] dt\n\nBy requiring the trajectory to satisfy certain necessary conditions\nregarding path, equations (1.1.10) and (1.1.11), the Problem of Bolza\nhas been reduced to the problem of minimizing J, a function of end\xc2\xad\npoints, subject to the v\' algebraic constraints on the endpoints.\n\n18\n\n(2.1.2.1)\n\nBefore proceeding with the minimization of J,\'it is appropriate\n\nto consider a graphical interpretation of the functional relationship\n\nfor the state variables expressed in equation (2.1.9).\n\nFigure 2.1\n\n\nshows a general state function yi(t, Yiol Yf, to, tf) as a function\n\nof time.\n\nFrom the figure it can be-seen that a change in the final\n\n\nstate AYif while holding all of the other endpoints fixed causes\n\nLikewise a change in the\n\n\na change in yi for all values of t.\nfinal time At\n\nwhile holding all of the other endpoints fixed causes\n\n\nf\n\n\na change in the state yi for all-values of t.\n\nFormalizing this graphical interpretation in terms of differentials\n\nyields results which will be of value in the following sections.\n\nUsing\n\n\ndifferential of the state variables may be\n\nequation (2.1.9), the \t\nwritten as,\n\n\nYjo\n\ndyi(t\n\n\'\n\no \t f)\n-\n\n-Yi\ndto +\n\nyi -dt +\n\nbt 0_\n\nbt\n\ny\n\n2.1.\'22\n\ni\n- dtf\n\nbtf\'\n\nby.\nby.\n\ndy\n\ndy. +\n + \t\ni f i\n\nby.o -joby\ntf gives\n\n\nEvaluating this expression.at t\n\ndYi(tf\' yj,\n\nYjf.\'to\'-tf) = dyif\n\ndt\n\nbt\n\n+\n\nli \n\nt\n\no\n0\n\nbi\n\nbt f \t\n\ntf\nf\n\nbv\n\n=\n\ndtf \t\n\n~\n\n+fy \t\n\nby.\n\nbyjo\n\nI\n\n(2.1.23)\n\n\n30L\n\njo\n\nbyi.\n\nffby\n\n3y\n\n\n\nThe sum represented by the last term in the above equation can be\n\nseparated into those products for which i\ni = j.\n\n/\n\nj\n\nand that for which\n\nTransposing dyif to the right hand side, equation (2.1.23)\n\n\n19\n\n\nY\n\nYif +\n\nnYif\n\nL ff\n\nf\n\nYif\n\nII\nII\nII\n"J.1\n\n*1\nI\nI\nIII\n\nI\nI\n\nI\nFig. 2.1\n\nFig. 2.1\n\n20\n\n*1\n\nI\n\nYio\n\nA -RersnainoI\n\nII\nt\n\nsaFnto\n\nfyi\n\nn\n\no\n\nA Representation of y. as a Function of Yfand tf\n\n\nt\n\nbecomes\n\n\ni\n\n+ o\n\n1.\n\n1 t\n\ny\nf\n\nif\n\nbt\n\n-bt \n\n\n+4[i\n\ndy i\n\n+\nyjf f\n\n"\n\ndYT\xc2\xb0\n\n+ bYio\n1Yj\nby\n\n\n1}\n\nyjf\n\ndYjf\n\n(2.1.24)\n\n\ni=j\n\n.In the above\'equation the repeated subscripts on.the last term\ndo not imply summation.\n\nSince t, to\n\ntf\' yi, and yif have been\n\nassumed to be independent, equation (2.1.24) implies that\n\n\nby\nbt\n\n!\n\nby.\nf\n\nbtf\n\n\n1\n\n(2.1.25)\n\n0Yi\n\n(2.1.26)\n\n\nbt\n\n0\n\n\nby,\n\n=0\n\n(2.1.27)\n\n\n0\n\n(2.1.28)\n\n\nby. O \n\ni\n\n\nbyi\nby\n\n.\n\ni~j\n\n.\nbyJf\n\n= 1\n\n(2.1.29)\n\nf\ni=j\n\n\nBy evaluating equation (2.1.22) at t\n\nt\n\nand following arguments\n\n\n21\n\nsimilar to the ones above, it can be shown that\n\n\nbyi\n\n0\n\nbt\n\no2-.o\n\n\nbyf" I 0(2.1.30)\n\n\nSyif\n\nby..\n\no \n\n\n.bto\n\nf\n\n0\n\n\nby i_\n\nbyjf\n\n(2.1.3 )\n\n\n=\n\n0\n\n\n(912.32)\n\no\n\n(2.1.34)\n\nbyjo\n\ni=j\n\n\nThese identities will be useful in the proofs of necessary and\n\nsufficient conditions in the next section.\n\n\n2.2\n\nDerivation of Transversality Conditions\n\nIn determining the functional relationships in the last section,\n\n\nit was assumed that the control end adjoint variables were chosen so\n\nas to satisfy the Euler-Lagrange Equations (1.1.10) and (1.1.11).\n\nEquations (1.1.10) and (1.1.11) are referred to as the first path\n\nnecessary conditions.\n\nIn this section the endpoint necessary\n\n\nconditions (transversality conditions) are derived assuming that\n\nthe first necessary conditions for path are satisfied.\n\n\n22\n\nsolution to the path necessary conditions determines one\n\nThe \t\nor more trajectories (see section 1.3), any of which may be- expressed\nfunctionally as a set [y (t, Yio\nuk(t,\n\n10\no\n\nYif, to, tf), X.(t, Yio, Yif, to,-tf)!\n\nYif, to, tf)] as shown in section 2.1.\n\nOnce the functions\n\nrepresenting one of these trajectories is substituted into the integral\n-in equation-(2.1.21-), the integration can te performed.\n\nIt is there\xc2\xad\n\nfore \t lear that once .the trajectory is specified, J is a function of\n\nc\nonly \the p~rameters-yio\' Y\nt\n\nt\n\nhiftf.\n Specifying the path reduces\n\nd\n\nthe problem of minimizing J to the well-known problem -of finding the\n\nminimum of a function of several variables subject to algebraic\n\nequations of constraint (Bryson and Ho-, 1969).\n\nIt is shown in Appendix A that if the arguments of J in equation\n\n(2.1.21) are to satisfy the constraints and minimize J, then it is\nnecessary that the partial derivatives of the auxiliaiy function,\nshown below, with respect to yio, Yif\' to, and tf\'all be .equalto\nzero.\nThe J function is defined by J\nby equation (2.1.21).\n\n=\n\nJ + 1\n\nl where J is given\n\nUsing the definition of the function G from\n\n\nequation (1.2.8), J may be functionally represented as\n\nJ [Yio\n\nY\n\nif\n\n]\n\nto , tf\n\n=\n\ntf \t\n+\t\n\nYif, to, tf,\n\n]\n\nbyi\n\n\n[- (y:, X,\nto1\n\nG[yio\n\n0\n\nb\n\n]\n\ndt\n\n(2.2.1-)\n\n1\n\nIn the above equation it is understood that yi, X., and uk are all\xc2\xad\nfunctions of the set (t, yio) yif\' to, tf).\n\nIn writing the functional\n\n\nrelationship shown above, it has been assumed that the controls uk have\n\nbeen chosen in an optimal fashion in accordance with the control variable\n\n\n23\n\nindicated by the super\xc2\xad\n\nThis is\n\nEuler-Lagrange Equation (1.1.11).\n\nscript o on uk and on H. . The partial .derivative of J\n\nwith respec,\n\nto yio can now be written:\n\nbJ bo\nby\nby\n\nt\n\nbyjo=\n\nF- bu\n\nbX1\nbyjo\nby\n\njo\n\nf t0yjL\n0 [+\n\ny\n\nby.\n\nibjh\nXi byi\n\nb\nbt\n\n(2.2.2)\n\n] dt\n\no-o\n\nHere Leibnitz Rule (Hildebrand, 1948, p. 360) has been used for\ndifferentiation of an integral with respect to a parameter.\n\nUsing\n\nthe identity\n\n[Xx\ndt\n\nand expanding\n\nby.\n\nbi\nbyo\n\nbX\ni\n\nbyi\n\nbt\n\nby\n1\n= X.\nI byjobt\n\ni I\nbyjo\n\nbyjo\n\n(2.2.3)\n\n, equation (2.2.2) may be written as\nH\nbyjo\n\nbG +\nyo\n\n-b\n.f -y\nby. -by.\n\nfto\n\n_\n6H bu\n\nbH b~\ni\nbX by.\n1\n\n-_.\n\n7u ;\n\nby.\n\ni\n\nfi\n\n(2.2.4)\n\nb+ i\n\nbYi\n\nbyjo bt\n\n]\n\nb--i by\nbt\n\ndt\n\n+\n\nbyjo\n\nYjo\n\nt\n\nTerms under the integral sign may be combined to give\nbi\n\n._bG\n\nbyjo\n\nP\'[-(\n\n+ tf\n\n+ ?\'\ni\n\nbyjo\n\nby i\nitf\n\nby j\n\nX.\no\n\nit\n\n.\n\n"bYi\nI\nbyjo.\n\n(2.2.5)\nbH\n\nK\n\n- by 1TbX i\n.\nX.bt\n\n.by.\n\nbXi\n\nbH\n-y-o-y\xc2\xad\nby.\nbH\n+\n\n24+\n\ni\n\nbyi\n\nbt\ny\nbu,\n\no\n\ndt\n\nNote from equations (2.1.9) and (2.1.10) that once the optimal\n\nendpoints have been selected,\n\n\n1yi\n\nbt\n\ndyi\n1\n\nand\n\n\ni \n\n\ndt\n\n\nbt\n\ndt\n\ndki\n\n\nThe integral ,termvanishes, since equations (1.1.3), (1.1.10) and\n\n(1.1.11) were used to generate the functional relations (2.1.9) and\n(2\n\na\n\n*.io) \n\n\n.\n\nUsing equations (2.1.27), (2.1.33) and (2.1.34), it can be\n\nconcluded that the sums represented by the two remaining terms not\ncontaining G in equation (2.2.5) reduce to a single term, - Xj\n10\n\nWith these considerations, equation (2.2.5) reduces to\n\nb*\n\nW\n\n\n-x.\n\n\xc2\xad\nby o\n\nby.\njo\n\nI\n\n= 0\n\n(2.2.6)\n\nto\n\n\nBy taking the derivative of J\n\nwith respect to yjf and using arguments\n\n\nsimilar to those just presented (in this cas& equations (2.1.32),\n\n(2.1.28) and (2.1.29) must be taken into account), it can be shown\n\nthat\n\n:\nbyjf\n\n-\n\n+\n-byjf\n\nX.\n\n(2.2.7)\n\n0\nf\n\nTwo more necessary conditions remain to be derived.\nfrom taking the partial derivatives of J\ntwo variables, t\n\nand tf.\n\nThese result\n\n\nwith respect to the remaining\n\nPerforming.the first of these operations\n\nyields\n\n25\n\ntf\n\n* \t\n\nt \t\n\nbt\n\nbt\n.\n\no\n\n0\t\n\nX. b:]\nbt \n\n\n-[-H+\n\ni btbt\n\nbt\n\nat\n\n\nb__\n\n+\n\n+r--Oi1\n\n+4\n\nbto\n\nby-\n\n\n+\n\n\xc2\xad\n\n0\n\n(2.2.8)\n\nt,\n\n\n-Here again Leibnitz Rule has been- used; this time- the limits of\nintegration are functions of the differentiating variable.\n\n\xc2\xad\n\nUsing\n\n\n\'the identity\n\nbyi\nS_\n\nd\n\ni\n\n0\t\n\nand expanding\nbt\n\n\nbX.\n\nby,\n"\nbt\n\nby. \t\n\nt. \t\n\n0\n\n,\n\n22-.9\n\n9\n\nO"\n\nequation (2.2.8) may be written as\n\n0\n\nbE\n\n6J \t\nbt\xc2\xb0.\n\n""\n\n0t[\no\nby,\n\nby.1G\n\nbf bXi\n1\nb . bt\n\nbi 6t\n\nbH\nbuk bt\n\nby o\n\n\nl\n\nbb--by. dt + Xi 7K \t\ni ]\n\n+\n\nbt0 bt\n\nbt\n\n4-~\n\ni\n\n(2.2.10)\n\n0\n\nb. -i]\n0\n\nTerms outside the integral may be evaluated at the endpoints\n\nindicated and terms under the integral sign combined to give\n\n\nbJ*\n\n-- =\n\n26\n\nt\n\n+\t\n\nf\n\ni\n\nH\n\n-G\n\n26\n\nby\n\nX\n\ny.\n\no\n\n\n-b\n\n\t\n\nbt +~\n\ntf-~\n\n.\n\n-\n\naito\n\nO (2.2 .11)\n\n\nThe integral again vanishes identically for optimal paths.\n\nUsing\n\n\nequations (2.1.26) and (2.1.30), the three terms outside the integral\n\nrepresenting summations can also be equated to zero.\n\nWith these\n\n\nobservations, equation (2.2.11) reduces to\n\nbJ-\t\nNT\n\n- bG\n\no\n\n"+\n\nH\n\nI\n\n"(2.2.12)\n\n0(22.2\n= 0\n\no\n\nBy taking the derivative of J with respect to t,, following a\nline of-reasoning similar to that just given, and using equations\n(2.1.31) and (2.1.25), it can be shown that\n\nbtf\n\n=\n\nbtf\n\nH tf\n\n=\t\n\n(2.2-13)\n\n0\n\nThese results are summarized in the following statement:\n\nTransversality Necessary Condition for Endpoints - If a trajectory\n\nsatisfies the Euler-Lagrange and state variable differential equations,\n\nequations (1.1.10), (1.1.11), and (1.1.3), and if the set E = [yio\nto, tf, P\n\nyif,\n\n\nsatisfies endpoint equations of constraint (1.1.4) and\n\n\nprovides a local minimum of J with respect to small allowable variations\nin the endpoints, then the set E must satisfy equations (2.2.6),\n\n(2.2.7),\n\n(2.2.12) and (2.2.13).\n\nThese latter equations are referred to as the endpoint necessary\n\nconditions or, classically, as the transversality necessary conditions.\n\n\n2.3\n\nDerivation of Second Order EndDoint Conditions\n\n\nIn the last section the function J was shown to be a function of\n\nthe endpoint variables yio, Yif\n\nto , and tf when evaluated along an\n\n\n27\n\noptimal path.\n\nThe function J is constrained, however, through the\n\np equations of constraint\n\n4\n\nof equation (1.1,4).\n\nSecond order\n\nconditions for determining the minimumn- of a function whose arguments\nmust satisfy algebraic equations of constraint has recently been\n\ndiscussed by Vincent and Cliff (1970, pp. 171-173).\nwill be used here.\n\nTheir methods\n\n\nFor reference, a detailed discussion of the\n\n\nminimization of a function of several variables is included in\n\nAppendix A.\n\nBefore presenting a statement of the second order condition, a\n\nbrief discussion and definition of notation are in order.\n\nSince the\n\n\nalgebraic equations of constraint for the Problem of Bolza\'define\n\nrelationships among the endpoint variables, the endpoint variables are\n\nnot all independent.\n\nSince there are p equations of constraint and\n\n\n(2n + 2) endpoint variables, there are only (2n - p + 2) independent\nendpoint variables.\n\nThe p dependent -variables are determined by\n\nthe p-equations of constraint.\n\nAny p of the variables can be con\xc2\xad\n\nsidered to be- the dependent variables.\n\nThe choice is one of convenience\n\nLet the p dependent variables be denoted by the column vector w and\nthe remaining (2n - p + 2) independent variables be denoted by the\ncolumn vector v . Let the vector * represent a vector whose elements\nare the\n\nu\n\nconstraint functions.\n\nEquation (2.3.1) summarizes these\n\nrelations.\nWl\n\n2\n\n-v)\n\n*\n\nw\n\n413(O,\n\n)\n\nVl\n\n\nw2\n\nYEw, v)\n\nY2\n\nv\n\n=\n\np\n\nq = 2n - p + 2\n\n(2.3.1)\n\nVq\n\nThe identification of the elements of v and the elements of w\nwith the endpoints yio, yif, to , and tf is arbitrary except that\nthe set of i4 equations must contain every element of w and, in\naddition, every 1Y equation must contain at least one element of\nIt is convenient to define an additional column vector r, whose\n\n\nw.\n\nfirst elements are the dependent variables and last elements the\n\nindependent variables:\n\nwl\n\nw\nP\n\nr\n\n(2.3.2)\n\nv,\n\n\nV,\n\n\nq\n\n\n*\n\n]\n\n[ ibr\n\n\nWith these vectors define\n\n?r\n\nas a (2n + 2) by (2n + 2) matrix\n\n*\n\nwith elements a.. = br.br.\n\n\'3\n\n[\n\nwhere\n\ni\n\n[a]\n\n.\n\nLet the matrix - be defined by\n\n(2.3.3)\n\n\n~ILI,\n\nis a p by p matrix with elements a.j\n--\n\nL -- ]is\n\na p by q matrix with elements a\n\n.\n\nw\n\nand\n\nbD\nIt is\n\nshown in Appendix A that the a matrix is the linear transformation\n\nwhich transforms differential changes in the independent variables\n\n\n29\n\ninto differential changes in the dependent variables.\nhas p rows and q columns.\n\nThe 5 matrix\n\nFinally, define the (2n + 2) by q parti\xc2\xad\n\ntioned matrix 2 as\n\n[A~](2.3.4)\n\n=\n\nwhere I represents a q by q identity matrix.\n\nWith these definitions the second order endpoint condition may\n\nnow be stated:\n\n\nSecond Order Endpoint Condition.\nand multipliers [yio, Yif, to, tf,\n\nji\n\nIf E represents a set of endpoints\n\nI which satisfy the transversality\n\nnecessary condition for endpoints, and if the set E represents a local\ninterior minimum of the function J with respect to small allowable\nvariations in the endpoints then the quadratic form\n\ndvT01\n\nI\n\nu\']\n\n0\n\ndv(23.\n\nin \t the differentials dv is positive semi-definite when evaluated at\nthe stationary point E.\nTo implement this test, it is necessary to evaluate the elements\nof the matrix\n\nand the elements of the matrix F\n\nL\t\n\nJ\n\nbrbr\n\n.\n\nEvaluation\n\nof elements of @ represents no problem since the functional form of\n\n\t\nthe constraints is specified in the problem statement.\n\nHowever, the\n\n\nanalytic evaluation of the second partial derivatives of J\n\nwith\n\n\nrespect to the endpoints is not so simple.\n\nThe second partial derivatives of J\n\ncan be obtained by taking the\n\nt \t Conversely if the transversality conditions hold and if (2.3.5) is\npositive definite then the set E is a local interior minimum (sufficiency).\n\npartial derivatives of the transversality necessary conditions with\n\nrespect to the endpoints ri.\n\n\nb - (J-)\nbr.\n\nby\n\nI\n\n(2.3.6)\nbri by.\njo\n\njo\n\nb\n\nto\n\nbr.\ni\n\n(\',\nx\n\n-r Zf\n\nbr.\n\ni\n\ny\n\nio\nSr\ni - " --\n\n=\n\n(2.3.7)\n\nIto\n\n(23.8)\n\n(t\n\nbG\nf\n\n)\ntf\n\nbG\nr bto\n +\n\n-b_\n1-\n\ni\n\nbr.by.\n\ni f\n\n\'(2.3.9)\n\n1\n\n,\nwhere in the above equations i = 1, 2, ... 2n + 2.\n\nThe functional\n\nform of G as a function of the endpoints is specified bi the statement\nof the problem.\n\nHowever, the functions X. and H are not known functions\n3\n\nof the endpoints until the state variable and Euler-Lagrange differen\xc2\xad\ntial equations have been integrated analytically.\nSince analytical integration is often difficult 6r impossible,\nit would be desirable to evaluate the partial derivatives of X. and H\nwith respect to the endpoints in terms of functional forms specified\nin the statement of the problem.\n\nA complete set of relationships of\n\nthis type were not found. Unless future investigation establishes\nsuch relationships, analytic application of the second order condition\nrequires an analytic solution of the state variable and Euler-Lagrange\ndifferential equations.\n\nSome interesting relations of this type are easily obtained however.\n\nEach of the elements of the matrix\n\nI\n\nI\n\nis composed of a sum of\n\n\n31\n\nThe matrix can therefore.be expressed as the sum of\n\n\na-second term.\ntwo matrices,\n\n\nb_\n\nE\n[\'\n\nI\n\nbrbr\n\n+\n\nA\n\n(2.3.10)\n\n\xc2\xad\n\n(2.3.9)\n\nwhere the matrix A is determined from equations (2.3.6) _\'\nI\n\nSince J\n\n2-\n\n.-\n\nand G are of class C\n\nby hypothesis, both J\n\nThe obvious conclusion\n\n\nbe symmetric about their major diagonals.\nis that matrix A must also by symmetric.\n\nand Gmust\n\n\nBy equating symmetric elements\n\n\nof A, the following identities can be established:\n\n\nbxi\nio\nbyjo\n\n_o\nbyio\n\nbX\'i\nif\nbyjf\n\nbH\xc2\xb0\n-0\n\nU.\n.t10\n\nbHf\n- i\n\nbHf\n\nbkio\n\n6H\xc2\xb0\n0\n\nbYio\n\nbtf\n\nbyif\n\nif\n\n"bjo\n\nbxj\n\n\n\n\nbX.\n\n=\n\nbt 0\n\nbkif\n-(2.3.12)\n\n(..3\n\n\nbt\n\no\n\n\niHf\n\nbyi\n\n-\n\nWif\n\nbH\n\nfo\n\n1\n0\n\nby.o\n\n(2.3.11)\n\nbYif\n\n-\n\n(2.3.14)\n\nbt f\n\nIn addition, the .following relations can be established by considering\nthe functional relationships exhibited in section 2.1.\n\n6Hf\n\nbtf\n\nbH\n\n+ fjf.\n+\n\nbt\n\n-\n\n_\n\n\xc2\xad\n\nb \'f\n\nbH f\nbyif\n\n32\n\n+\n+\n\n--\n\nbtf\n\nUkif\n\nbt\n\n(2.3.16)\n\nf\n\nf\n\njf\n\n(2.3"15)\n\nby..\n\n\nSimilar equations exist for the initial point.\n\nUnfortunately, a sufficient number of these relationships have\n\nnot been found to determine the elements of A in terms of known\nfunctions in the problem statement.\n\nThe determination of further\n\nrelationsbips and the ultimate determination of the elements of A\nwithout resort to analytical integration of the state variable and\nEuler-Lagrange equations poses an interesting problem for future\ninvestigations.\n\n\n2.4\n\nRelation to Classical Theory\n\nBolza (1961, pp. 102-103) gives an excellent summary of the\n\n\nvarious classical approaches to the development of necessary and\n\nsufficient-conditions for variable endpoint problems.\n\nBecause of\n\n\nthe pertinence of his remarks to this presentation, his historical\n\nsynopsis is quoted in detail:\n\nThree essentially different methods have been proposed\n\nfor the discussion of problems with variable endpoints:\n\nt\n\n1. \nThe method of the Calculus of Variations proper:\n\nIt consists in computing 8J and 82J either by means of\nTaylor\'s formula or by the method of differentiation with\n\nrespect to\n, ...and discussing the conditions 8j=0 62j=0 ...\n2.\nThe method of Differential Calculus: This method\nis explained in general way in Dienger\'s Grundriss des\nVariationsrechnung (1867). It decomposes the problem into\ntwo problems by first considering variations which leave\nthe endpoints fixed, and then variations which vary the end\xc2\xad\npoints, the neighboring curves considered being themselves\nextremals. - The second part. of the problem reduces to a\nproblem of the theory of ordinary maxima and minima.\nThis\nmethod has been used by A. Mayer in an earlier paper on\nthe second variations in the case of variable endpoints\nfor the general type of integrals mentioned above (Leirziger\nBerichte (1884), page 99).\nt. The first and second order variation of the integral are written as\n\n8J and 82j, respectively.\n\nVariations in the endpoints and in the\n\npath are considered simultaneously in this method.\n\n\nit is superior to the first method not only on account of\n\nits greater simplicity and its more elementary character,\xc2\xad\nbut because by utilizing the well-known sufficient condi\xc2\xad\ntions for ordinary maxima and minima it leads, in a certain\n\nsense, to sufficient conditions it combined with Weier\xc2\xad\n.strauss\'s sufficient.conditions for the case of fixed end\xc2\xad\npoints....\n\n3. Kneser\'s method: This method, which has been\n\ndeveloped byKneser in his Lehrbucht, is based upon an\n\nextension of certain well-known theorems on geodesics.\n\nIt leads in the simplest way to-sufficient conditions,\n\nbut must be supplemented by one of the two preceding\n\nmethods-for an exhaustive treatment of the necessary\n\nconditions...\n\n\nWhile Bolza (1961, pp.\n\n104-109) used method 2 for investigating\n\n\nthe simplest classical problem with variable endpoints, and later\n\n\nBliss (1932, pp. 261-266) used the same method for the classical\n\nproblem of Bolza, more recent work, e.g. [Householder (1937,\n\n\npp. 485-526),-Bliss (pp. 147-184), and Hestenes (1966,,pp. 296-351)]\n\nhave utilized the first method quoted from Bolza.\n\nSufficiency conditions for the problem of Bolza can be obtained\n\nby employing either method.\n\nHowever, the type of normality assumptions\n\n\nused differ from one method to the other, and the first approach\n\napprently gained favor because it requires less stringent normality\n\nconditions.\n\n[As opposed to the second approach without modification,\n\n\nsee for example, Bliss and Hestenes (1933, pp. 305-326) for a modi\xc2\xad\nfication of method 21.\n\nIn this presentation, the second method was employed because\n\nof its simplicity.\n\nWe were not seeking a sufficiency condition for\n\n\nthe problem of Bolza in control notation per se.\nambitious project was investigated.\n\nInstead a less\n\n\nWe sought conditions to be\n\n\ntLehrbuch der Variationsrechnung Braunschweig (1900).\n\n\n34\n\nsatisfied for a given extremal to be a local minimum with respect to\n\nendpoint variations along a prescribed endpoint manifold.\n\n\n2.5\n\nGeodetic Examole\n\nAs an example of the application of the second order condition for\n\nendpoints, consider-the problem of determining the minimum distance\n\nfrom the origin to any point on a parabola of the form\n\n\n(2.5.1)\n\n2\n\nIn control notation the problem may be formulated as follows:\n\n\nMinimize\n\nsf\n\nJ\n\nJ\n\nds\n\n(2.5.2)\n\ns\n0\n\n\nsubject to the state-variable differential constraints,\xc2\xad\n\n(2.5.3)\n\ndx\n\n-s \n\n\nsin g,\n\n(2.5.4)\n\nand endpoint constraints,\n\nYo\n\nx0\n\nso\ny\n\n-\n\n2\n\nThe angle g is\n\n=\n\nb\n\no,\n\n(2.5.5)\n\n0,\n\n=\n\n(2.5.6)\n\n,\n\n(2.5.7)\n\n0.\n0\n\n(2.5.8)\n\nthe angle between the positive x axis and a tangent\n\n35\n\nto the curve.\n\nHere x and y are the state variables, g is the control\n\n\nvariable, and s is the independent variable analogous to t in the\nformulation of earlier sections.\nNecessary Path Conditions\n\n-\n\nThe H and G functions are\n\nH = Xx cos g + Xy sin g - 1\n\n(2.5.9)\n\n2\nG = Il(yf-xf -b) + P2x + P3x0 + NSo\n\n(2.5.10)\n\nThe adjoint-variable Euler-Lagrange equations are\n\nk\n\n=0\n\n(2.5.11)\n\nx\n\n- 0\n\n(2.5.12)\n\nand the control-variable Euler-Lagrange equation is\n- X x sin g + Xy cos g\n\n0\n\n=\n\n(2.5.13)\n\nEquations (2.5.11) and (2.5.12) imply that Xx and Xy are constants.\n\'Solving equation (2.5.13) for the control\nX\n\ntan g\n\nconstant\n\n- -\n\nXx\n\nwhich implies\n\n(2.5.14)\n\nX\nsin g\n\n(2.5.15)\n\n-\n\n24\n\n+\n\n2\n\nx\n\nCOS g 3\n\n36\n\n(2516)\n\nThe positive sign on the radical is a consequence of the Legendre-\n\nClebsh necessary condition (1.2.17).\n\nFunctional Relations - Integrating the state variable equations\n\n(2.5.3) and (2.5.4) with the optimal constant control g between the\n\ngeneral initial-point (xo, yo, s-) and general final point (xf, yf\n\ns.f)\n\n\nresults in\n\n\nXf - x\n\n=\n\n(sf - so) cos g\n\n-(2.5.17)\n\n\nYf - y\n\n=\n\n(sf - so ) sin g\n\n(2.5.18)\n\nSolving for the control\n\n\xc2\xb0\n\ntan g\n\nYf - Yo\n\n\n=\n\n-\n\n(2.5.19)\n\nSquaring both sides of equations (2.5.17) and (2.5.18) and adding\n\nyields the identity\n\n(sf - So)2\n\n(xf - 0)2\n\n=\n\n+\n\ny\n\n)\nyo)2\n\n\n(2.5.20)\n\n\nSolving equations (2.5.17) and (2.5.18) for the controls gives\n\nxf -x\n\nO\n\n\nsf \xc2\xad\n\n0 \n\no\n\ncosfg\n\n(2.5.21)\n\n\nand\nyf\nsin g\n\n-\n\n-\n\nY\n\n(2.5.22)\n\no\nsff - s\n\n\no\n\n\nSince the control is constant, the control is not a function of the\n\nindependent variable in this case.\n\nFor other problems the control may\n\n\nbe a function of the independent variable as well as the endpoints.\n\nIntegrating the state variable equations again between the general\n\n\n37\n\ninitial point (x0 , y0, So) and general intermediate point (x, y, s)\nand substituting the optimal control from equations (2.5.21) and\n(2.5.22),\n\nand rearranging yieils\n\nx\n\no\n\n\xc2\xb0\n\nx x\n\n+(s sf\n- so\n\n=\n\n+\n\n(2.5.23)\n\n(s-s)\n0\n\n\n(2.5.24)\n\n\no\n\nYf -\n\ny = Yo\n\n- s )\n\nf\nsf - so\n\nIt is seen from the above equations that the state variables are clearly\n\nfunctions of coordinates of the initial and final state variables and\nof the initial and final values of the dependent variable.\n\nThe first integral of the Euler-Lagrange equations is\n\n\nAx\nSolving this\n\nX\ny\n\ncos g\n\ngin g - 1=\n\n(2.5.25)\n\n0\n\nquatioh with equation (2.5.13) for X and" Xy and\n\nobserving equations (2.5.21) and (2.5.22) gives\n\nxf\n\nsf\n\n0\n\nXf\n\n-\n\n(xf\'xo0)2\n\nYf -Yo\n\n-X\n\n(2.5.26)\n\n+ (yf-Yo)2\n\n\n(2.5.27)\n\nYf - YO\n\nf- so\n\n(xf-x 0)\n\n+ (yf-yo)\n\n2\n\nTwo forms are given above for the Lagrange multipliers as functions of\n\nendpoints; either is correct.\n\nIf the second set is used, the J\n\nwill be independent of sf and s o.\n\nfunction\n\n\nIn either case it is clear that the\n\n\nLagrange multipliers can be written as explicit functions of the coordinates\n\nof the initial and final values of the dependent variables.\n\nEquations\n\n\n(2.5.19), (2.5.23), (2.5.24), (2.5.26), and (2.5.27) bear out the\n\nfunctional dependencies hypothesized for control, state, and adjoint\n\nvariables in section 2.1.\n\nNote that in deriving these equations,\n\n\nonly path necessary conditions have been used.\n\nThe transversality\n\n\nnecessary conditions for endpoints have not been used.\n\nNecessary Endpoint Conditions - The transversality conditions,\n\n(2.2.6), (2.2.7), (2.1.12), and (2.2.13) yield the following equations\n\n\n2 =o=\nb --- -2yo\n\n0\n\n\nbj*\n\n=\n\n(2.5.28)\n\n0\n\n(2.5.29)\n\n= 0\n\n(2.5.30)\n\n= 0\n\n(2.5.3.)\n\n-X\n\n=\n\nbx\n\n0\n\nxO\n\n3\n\n4\n\n+\n\no\n\nbyf\n\n+\n\n= 1\n1--\n\nyf\n\nbJ = _ 2lxlf + Xxf\n\nb\nbsf\n\n= _ X\nxf\n\ng\ngf\n\n(2.5.32)\n\n\n=0\n\nsin gf + 1\nyf\n\n=\n\n0\n\n(2.5-33)\n\nSince the initial point is fixed, the initial point transversality\n\n\nequations give no useful information.\n\nTo find the optimal endpoints, eliminate 1 between equations\n\n(2.5.31) and (2.5.32), yielding\n\n\n39\n\n2Ayfxf\n\n)xf\n\n(2.5.34)\n\n= 0\n\nSubstituting Xxf and Xyf from equations (2.5.26) and (2.5.27) into.\n\nequation (2.5..34) yields\n\n\n2(yf - yO)\n\nxf - xo\n\n2\nj(xf.-x0 )\n\n+ (yf-y)\n\n+\n2\n\nj(xf-x\n\nXf\n\no\n)2 + (yfy)2\n\n\n=\n\n0\n\n(2.5.35)\n\nFinally, multiplying through by the radical and imposing endpoint\n\nconstraints (2.5.5) and (2.5.6) gives\n\nxf(1 + 2yf)\n\n=\n\n(2.5.36)\n\n\n0\n\nThe necessary conditions are satisfied if either term in\'the above\n\nSolving equation (2.5.36) and equation\n\n\nequation is equal to zero.\n\n(2.5.8) simultaneously gives the two solutions\n\n\n\'1\nx\n\n-\n\nyf\n\n1\n\n-- (solution A)\n\n(2.5.37)\n\n\nand\nxf\n\n= 0\n\nyf\n\n= b\n\n(solution B)\n\n\nThese endpoints and the corresponding multiple solutions for\nb <\n\n-\n\n1\n\n2\n\n\nare shown in\'Figure 1.3 on page 11.\n\nFrom the symmetry of\n\nthe parabola, it is expected that either the plus or the minus sign\n\nin equation (2.5.37) will determine a solution giving the same value\n\nof distance.\nthe two.\n\nFor this reason a distinction has not been made between\n\n\nThe necessary conditions used so far have provided no\n\n\nmeans for determining under what circumstances solution A (or solution B)\n\nis the optimm.\n\nIn this case of multiple stationary solutions, the\n\n\nendpoint second order condition will provide a means for determining\n\n\nthe true optimum.\n\nBefore examining the second order conditions, the paramenter P1\nwill be evaluated in terms of the general endpoints for future\n\nreference.\n\nFrom equations (2.5.27) and (2.5.31) it is observed that\n\n\n(x0-x)\n\n2\n\n(2.5.38)\n\no\n\n"\n\nPYf\n\n+\n\n(yf-y)2\n\nSecond Order Endpoint Condition - To evaluate the endpoint\n\nsufficiency conditions, it is instructive to first determine the\n\n6 and 0 matrices of equations (2.3.3) and (2.3.4).\n\nThe constraints\n\n\nare\n\n\ni:\n\nYO\n\n=\n\n0 \t\n\n(2.5.39)\n\n\n2: \t\n\nx a\n =\n\n0 \t\n\n(2.5.4o)\n\n3\t\n3:\n\ns o\n = 0 \t\nYf-x2h -b\n\n(2.5.41)\n\n= \t0\n\n\n(2.5.42)\n\n\nSince there are four equations and six endpoints, there are two\xc2\xad\ndegrees of freedom.\n\nFor conveniency let xf and sf be the independent\n\n\nvariables and yo, x0 , so, and Yf be the dependent variables.\n\nThen in\n\n\no\nthe notation \t f section 2.3\n\nyo\n\n\nx \n\n\nYO\n\n0\n\nx0\n\nsf \t\n\nxCo\nso \n ,\n\n0o\n\nso\n\nYf \t\nx \t\n\nYf \t\n\nff \n\n\n(2.5.43)\n\n2\n\nxf -b\n\n\nSf\n\n41\n\nEvaluating the matrix of partial derivatives of yl with respect to\nthe independent variables gives\n\n0\n0\n\n0\n\n0\n-\n\n0\n\n0\n\n(2.5.44)\n\n0\n\n-2xf\n\nEvaluating the matrix-of partial derivatives of v with respect to\n\nthe dependent variables gives just the identity matrix\n\n\n1\n\n0\n1\n0 \n0\n\n0\n\n0\n\n0\n\n0\n\n0\n\n1\n\n0\n\n\n0\n\n6*\n\n0\n\n1\n\n0\n\n2.5.45)\n\nThe inverse of this matrix is obviously the identity matrix. From\n\nequations (2.5.44) and (2.4.45) the 6 matrix can be computed\n\n\n0.\n\n-\n\n0\n\n(2.5.46)\n\n0l 0\n\n2xf\n\n-\n\n0\n\nThe 0 matrix is formed by adjoining the - an identity matrix with the\n\ndimensions equal to the number of independent variables.\nThe 0 matrix is\n\n\nthere are two independent variables.\n\no\n\n0\n\n0\n\n0\n0l\n\n0\n0\n\n51\n11\n\n2xf00\n0\n\nWith the\n\nI\n\n0\n1\n\nnot yet evaluated, the endpoint sufficiency condition\n\n\nbrbr\n\n\n42\n\nIn this case\n\n\n(2.5.47)\n\nreduces to the condition that\n\n\nx2\n4\n\n2\n\n2*\n\n2*\n2xf\n\n+\n\nf7\n\nbyf\n\nhxf\n\nbJ\nbyfbxf\n\n+\n\nbyf bsf\n\n+\n\nbxfbsf\ne2i*\n\n[dxf dsf]\n\nds\n+\n\n2xf\n2*bsfbf \n\n\nb2 f\n\nbs bxf\n\nmust be positive definite.\n\nIf J\n\ncan be written so that is is not a function of sf, the\n\n\nsufficiency condition will be reduced to a simple inequality involving\n\ndxf only. From the transversality equations (2.5.31) - (2.5.33) and\n\nthe functional relations for X. and Xy, equations (2.5.26)\nand (2.5.27),\n\nit is seen that this can be done.\n\nTherefore, the sufficiency condition reduces to the condition that\n\n\nLf\nLbx\n\n+\n\n+Ivx\nf_Z1\n\n7]\n\ndx.\n\n>\n\n0\n\n(25.49)\n\n,\nbyf.bxf\n\nThis result is identical to the result that would have been\xc2\xad\nobtained if the fixed endpoint coordinates, y,\nexcluded from the G function.\n\nx0 , and so had been\n\n\nThis situation is similar to the trans\xc2\xad\n\nversality necessary conditions in that the initial points yield no\n\n\n43\n\ninformation.\n\nFrom this example and previous experience with endpoint\n\nconditions, the following conclusion is drawn:\n\nNo useful information\n\nconcerning,either necessary or sufficient conaitions results from\n\nincluding in G constraints which merely fix a given endpoint coordinate.\n\nSubstituting the functional forms for Xxf and X\n\nnot involving\n\nsf fran equations (2.5.26) and (2.5.27) into the first partial\nderivatives of J\n\nwith respect to yf and xf in equations (2.5.c31) and\n\n(2.5.32) gives\n\n\nbi*\n\nbyf\n\n*\n\n-Y\n\n-f\n\n=\n\nl\n\n+\n\nJ\n\nO\n\n\n(xf_0o)2 + (yf_yo)2\n\nxf - x\n\n\no\n\n+\n\nS = -2plxf + J (xf_x 0 )2+ (yf-yo) 2\n\n(2.5.51)\n\n\n(2.5.52)\n\nForming the required partial derivatives results in\n(xfxo)2 + (yf_yo)2 _.xf(xf_ 0)\n\n621*\n\n--f 2\n\nb2*\n\n-\n\n2p\n\nD.,\n\n(x-x) 2 + (yf-yo)2\n\nyf(yf-yo)\n\nD\n\nyf2\n\n21b\n\n(2.5.53)\n\n(xf-x0 ) (yf-Yo)\n\n\nbyfbx f\nb2 *\n\nf\n\n+\n\no)\n(Yf- YO (Xf-%) 0)\n\nbXf Jyf\n\n\n\n\n(2\n.5.56)\n\n\nD\n\n\nwhere\n\nD=\n\n44,\n\n2 3\n\n[(x -xo)2 + (yf-yo) ]2\n\n(2.5.57)\n\n\nComparing equations (2.5.54) and (2.5.56) verifies the symmetry of the\n\n[b.j_\nbrbr\n\n]\n\nmatrix.\n\nEvaluating these derivatives using initial point constraint\n\nfrom equation (2.5.38) and\n\n\nequations (2.5.5) and (2.5.6) and u\n\nsubstituting them into the endpoint sufficiency condition, equation\n\n\n(2.5.50) gives\n\n4xf 4\n\nr xf1f\n\n(x2+ Y2)3/2\n\nL (xI2+2\n\n+\n\n2\n\n+ y2)3/2\n\n(2.5.58)\n\nYf\nAxf2\n\n+ y2\n\n\n2\n\n+\n\nfor solution B (xf =\n\n(x2+\n\n0, yf\n\n1\n\n+\n\n2\n\nYf\n\nyj )3/2\n\n0\n\n\n>\n\n= b) this condition\'reduces to\n\n>\n\n0\n\n(2.5.59)\n\nFrom the geometry in Figure 1.3, it can be seen that b is negative.\n\nThe condition therefore requires that\n\n\n0 > b > -1 2\n\n(2.5.6o)\n\nThen solution B as shown in Figure 1.3 is optimum.\n\nFor solution A (xf\n\n1\n\n=-\n\n-\xc2\xad\n\nthe end sufficiency condition (2.5.58) becomes\n\n\n45\n\n4b2\n\n+ 2b +\nbb 2\n\n1\n\n4\n\n>\n\n0\n\n(2.5.61)\n\nCombining terms yields\n\n+ 3b 3/2\n+1\n\n\n4b2\n\n>\n\n(2.5.62)\n\n\n0\n\n3/2\n\n\n1\n\nIn order for the denominator to be real\n\n\nb\n\n(2.5.63)\n\n<\n\nUnder this condition inequality (2.5.62) is satisfied only if\n\n\nb\n\n(2.5.6k)\n\n\n-1\n2\n\n\n<\n\nTherefore solution A shown in Figure 1.3 is optimum for b less than\n\n1\n-\n\n-\n\n.\n\nThe optimal solution is summarized below.\nxf =\n\n,\n\nyf\nf\n\n> >-\n\n= b\n1Yf\n\n-\n\n2\n\nb <\n\n(25.65)\n(2.5.66)\n\nThis simple example has been analyzed in great detail to emphasize\n\nthe concepts developed in earlier sections and to reinforce and illus\xc2\xad\ntrate the notation.\n\n\n2.6\n\nA Nuerical Algorithm\n\nIn order to apply the second order endpoint condition, the matrix of\n\n\nsecond partial derivatives of J with respect to its arguments must be\n\n\ndetermined.\n\nFrom equations (2.3.6) - (2.3.9) it is seen that each of\n\n\nthese second partial derivatives is\n\ncomposed of two terms.\n\nThe first\n\nterms, in all cases, is a second partial derivative of the function G.\nThis derivative can be computed analytically from information given\nin the statement of the problem.\npartial derivative of J\n\nThe second term of each second\n\ncan be written in one of the following\n\nforms:\n\nfttf\n\n(2.6.1)\n\n10\n\n\n(2.6.2)\n\nt=to\nbrif\n\nf\n\n(2.6.3)\n\n\nbrif\n\nor\n\n(26.I)\n\n\nuIt=to\n\nwhere M represents any of the quantities H, Xl\n\nX2\n\n\'\n\nXn\n\nand r\n\n\nrepresents any of the state variables yi or the independent variable t.\n\nThese derivatives cannot be evaluated analytically without\n\nobtaining an analytic solution to the set of state variable and\n\nEuler-Lagrange differential equations.\n\nFor most problems of practical\n\n\n47\n\ninterest in the calculus of variations, the set of nonlinear state\n\nvariable and Euler-Lagraenge differential equations cannot be inte\xc2\xad\ngrated analytically.\n\nTherefore, the implementation of the endpoint\n\n\nsufficiency-condition in most cases requires the numerical computation\n\nof partial derivatives of the forms expressed in equations (2.6.1) \xc2\xad\n(2.6.4).\n\nFortunately, this is not conceptually difficult for most problems\nin engineering which have separated end constraints.\n\nEnd constraints\n\nare separated if none of the endpoint constraints involves both\ninitial values and final values; the constraints always related initial\nvalues to other initial values,\n\nor final values to other final values.\n\nThe function M evaluated at t = t\n=\n\nM\n\nwill be indicated by a subscript o:\nO\n\n(2.6.5)\n\n\nMo(yio \'yif\' to, t)\n\nThe function M evaluated at t = tf will be indicated by a subscript f:\n\n\nMf\n\n=\n\nMf(Yio\n\nYif\' to\' tf)\n\nBefore the second order condition test is applied, the problem is\nfirst solved using the necessary conditions yielding nominal endpoints\ny 10 \n\n\nf\n\nto\n\nand t f and nominal Lagrange multipliers X.and X..\nif\n10\n\nr\nFor brevity, let --o represent a vector with elements (ylo\' Y2\n0\nto), and rf represent a vector with elements (Ylf\' Y2 f\n"\'\n\n-Yno\'\n\ntf)\n\nand M\n\nbe a function evaluated with the nominal endpoints.\n\n\nNumerically the derivative (2.6.1) can be approximated as\n\nMf\n\nbr .i\n\n\n480\n\nM\n\nr2o\n*f(rlo\n\n..\n\n+\n\nA, ... ; rf)\nlo\n\n-\n\nMf\n(2.6.7)\n\n\n*\n\nwhere A is a small change in the nominal initial variable rio.\n\nIf\n\nthe state variable and Euler-Lagrange equations are then nuerically\n\nintegrated forward with the nominal Lagrange multipliers, the final\n\nnominal endpoint will not be reached.\n\nThe n initial Lagrange multi\xc2\xad\n\npliers must be adjusted in order to obtain the final nominal endpoint\n\nSince the n initial Lagrange multipliers give only n degrees\n\n\nagain.\n\nof freedom, the nominal endpoint can be reached only if M is a function\n\nThis will be true if\n\n\nof n or less then n independent final values.\n\nthere is at least one equation of constraint involving the final values.\n\nWith these new multipliers, the differential equations are integrated\n\nforward to the final point rf. Mf is then evaluated from the resulting\n\n*\n\nfinal Lagrange multipliers and rf. With Mf evaluated, the desired\n\npartial derivative can be evaluated using equation (2.6.7).\n\nThe derivative (2.6.2) can be approximated numerically\'as\n\n\no\n\nMo(-o \n rlf\'\n\nbr if \n\n\n2f\n\n"",rif\n\n+\n\n\n(2.6.8)\n\n\nA\n\n\nabove equation, M \xc2\xb0 is evaluated by making a small change in\n\nIn the ,0\n\nrif, while leaving all the other values unchahged.. A set of final\n\nLagrange multipliers is then determined so that a backward numerical\n\nr\nintegration in time will yield the nominal initial values -o\n.\nquantity M\n\n0\n\nThe\n\nis evaluated using the resulting initial Lagrange multi\xc2\xad\n\nrO\npliers and -- . With M o\n computed in this manner, the desired partial\n\nderivative can be evaluated using equation (2.6.8).\n\nThe derivative (2.7.3) can be approximated numerically as\n\n\nU_f\n\nrifA\n\nf\n\n-0 \'\n\n...\nlf, r2f\' -- ,r ri f\n\n+\n\nA,\n\n...\n\nf-\n\n(2.6.9)\n\nHere, Mf is evaluated by making a small change in the nominal final\npoint coordinate rif,\n\nwhile leaving all of the other final coordinates\n\nand the initial point -o unchanged.\nr\n\nA set of initial Lagrange\n\n\nmultipliers is then determined so that a forward integration from the\nnominal initial point will yield the varied final point (rlf, r 2 f,\nrf\n\n+\n\nA, ...).\n\n...\n\n,\n\nThe forward integration is then performed to the\n\n\nvaried final point, and Mf is evaluated using the resulting final\n\nLagrange multipliers and the coordinates of the varied final point.\n\nThe final derivative (2.6.4) can be approximated numerically as\n\n\nti0\n\nMo(r 1o , r2 ,\n\n..\n\nrio\n\n+\n\nA,\n\n...\n\nI)\n\n-\n\nM(2.6.1)\n\n\nA\n\n\nio\n\nHere, M0 is evaluated by making a small change in the nominal initial\n\nO\npoint r., while leaving all of the other initial coordinates and the\n\nfinal point r\n\nunchanged.\n\nA set of final Lagrange multipliers is then\n\n\ndetermined so that a backward integration in time from the nominal\n\nfinal point will yield the varied initial point (r10, r2o,\n\n-, rio\n\n\n+ A, ...). The backward integration is then performed to the varied\n\ninitial point, and M0 is evaluated using the resulting initial Lagrange\n\no\nmultipliers and the coordinates of the varied initial point.\n\nUsing the above techniques, the matrix of second partial derivatives\n\nof J\n\nwith respect to its arguments can be evaluated.\n\nBecause of the\n\n\nidentities (2.3.11) - (2.3.14), there is some choice as to which of\n\nthe above derivatives is used to evaluate the sufficiency condition.\n\nIt is a simple matter to numerically evaluate the matrix 0 from the\n\nnominal initial and final points and to test the matrix OT\nfor positive-definiteness.\n\n\n50\n\nb!J\n\n*\n\nCONCLUSIONS\n\n\nIt has been shown that once the first necessary path conditions\n\nhave been applied, a calculus of variations problem with variable\n\nendpoints is reduced to a problem of the minimization of a function\n\nof several variables.\n\nAnalytical application of the second order endpoint condition\nrequires the analytical integration of the set of state variable and\nEuler-Lagrange differential equations.\n\nSince in most cases this is\n\ndifficult or impossible, the algoritbm developed for the numerical\nimplementation of the second order endpoint test should be an\neffective computational tool in complex applications.\n\nFor example,\n\nthrough the use of the second order endpoint test, a complete class\nof nonoptimal solutions can be discarded immediately upon encounter.\nWithout the aid of the second order endpoint test an investigator\n\xc2\xad\n\nwould have no indication that solutions he is generating are non\xc2\xad\noptimal whether he encounters multiple solutions or not.\nIt could be argued, when multiple stationary solutions are obtained,\n\nthat a comparison of solutions would quickly yield which one was\n\noptimal.\n\nHowever such a comparison technique fails if it is not known\n\n\napriori exactly how many multiple solutions exist.\n\nOne has no criteria\n\n\nin general\' for determining in advance just how many multiple stationary\nsolutions a problem may have, so that a direct comparison technique is\n\nunreliable unless every multiple solution is somehow found.\n\n51\n\nAPPENDIX A\n\n\nINM4IZATION OF A FiUNCTION OF SEVERAL VARIABLES\n\nIn the proof that follows, free use will be made of the notation\n\nand conventions established at the beginning of section 2.3.\n\nFollowing\n\n\nthe methods of Vincent and Cliff (1970), consider the problem of\n\nminimizing a function-of several variables\n\n\nJ\n\n=\n\n(A.1)\n\n\nJ(w, v)\n\nsubject to the constraints\n\n\nU, (w, _V)\n\n(A.2)\n\n\n=0 \n\n\nwhere both J and ulare functions of class C2 and the constraints are\n\nsuch that the determinant of the Jacobian\n\n\nL" I\nis nonsingular.\n\n(A.3)\n\nThe dimension of i1and w is assumed to be p and the\n\ndimension of v is assumed to be q.\n\n\nA.1\n\nMethod of Implicit Functions\n\nSince ! is of C2 and condition (A.3) has been postulated, the\n\n\nimplicit function theorem (Buck, 1965, pp. 283-286) states that equation\n\n(A.2) implicitly assures the existence of the vector function W explicitly\n\nrelating the dependent variables w to the independent variables v\n\n\nw(X)\nw = W(v) =\n\nw (v)\n2\nW5(v)\n\n52\n\n(A.4)\n\nBy substituting (A.4) into (A.l), J becomes a function of v only\n\n(A.5)\n\n=" j(W(v), v)\n\nj\n\nDefine the general value of independent variables v in a small\n\n0\n\n\nneighborhood of an optional point v\n\nv\n\n0\n\n(A.6)\n\nc\n\n+\n\nbut non-zero,\n\nwhere c is a vector of arbitrarily chosen smallP,\nconstants and e is a scalar multiplier.\n\nJ [W(O + C c),\n\n3\n\ni\n\n7o\n\n\xc2\xb0\n +e0\n\n_\n[W(v 0 + e c),v\n\nThen, from (A.1) and (A.2)\n\n(A.7)\n\n+ C c.\n\nci\n\n(A.8)\n\n0\n\nNow J is a function of e only, and the necessary condition for\nan ordinary local extremum is\n\ndJ\n\n-Z\n\nde\n\nhT\n\nb\n\n\n(A.9)\n\nI\n\n-\n\nbW.\n\nwhere h is the vector with elements hi\n\ne\n\n=\n\n.\n\nThe vector h\n\nrepresents changes in the dependent-variables wcorresponding to\nthe changes c in the independent variables.\n\nDifferentiating equation\n\n(A.8) with respect to e yields\n\nh\n\n+\n+-\n\n0\n\nc=\n\n(A. 10)\n\nSolving for h yields\n\n\nl\n\n[\n\nC\n\n(A.11)\n\n\n53\n\nSubstituting (A.ll) into (A.9) and rearranging giver\n\n\ndJ=\n\n[E\n\nTbI]lb\n\n]\n\nc\n\n=\n\n0\t\n\n(A.12)\n\nSince c is an arbitrary nonzero vector, each of the elements of the\n\nvector in parenthesis must be equal to 0 at the optimal point.\n\n\nbj\n\nTp\n\nbj\n\nP\xc2\xb11=o \t\n\n(A.13)\n\nIf equation (A.13) is satisfied, then a further necessary condition\n\nfor a local interior minimum is that\n\nd2 J \t\nde 2\n\n(A.l)\n\n*\n\nv\xc2\xb0\n\nmust be positive semi-definite for arbitrary values of h and c\n\nsatisfying equation (A.11).\n\nBefore evaluating this expression, an identity for taking the\n\npartial derivative of the inverse of a matrix must be developed.\n\nLet A.. represent a general element of the\n\nmatrix:\n\ne-1\n\n\naiJ\n-\t\n\nwA ij\t\n\n(A.135)\n\nThen in indicial notation the definition of inverse may be\n\nexpressed as\n8qj\n\n-\n\nA \t\nm\n\nt \t\nEquation (A.13) and (A.14) positive definite is sufficient for a\n\nlocal interior minimum.\n\n\n(A.16)\n\n\nPremultiplying by Aiq gives\n\nqj is the Kroniker delta.\n\nwhere\n\nA\n\nA..\n\na\n\n(A.i7)\n\n\'-q A\nma\niq w\nm\n\nTaking the partial derivative of both sides yields\n\n\n-\n\nn\n\n(q\n\n+A q\n\n(Aq)8q\n\n(A..)=\n\nn\n\nn\n\nA\n\n\n.\n\n(A.18)\n\n+\n\n(A.)\n\n8\n\nSince 6ij represents a constant, equation (A.18) reduces to\n\n-\n\nb\n(Aj)\n\n-\n\n(A.j)\n)\nbr nbr\nn\n\nnr\nn\n\n+\n\n_b\n\nA.\nAq\n\n/biJ\'q\\\n\nn\nn\n\ni\n\n--\n\n(A+b)\n\n.)\nAmj\n\n+\n\nn\n\nnl\n\n(A.19)\n\n3\xc2\xad\n\nwhich gives the desired identity:\n\n\n(A\n\n=\n\n(A.20)\n\nA.\n\n-Ai\nm ,\n\nFrom this point-on results must ,beexpressed in indicial notation\n\n\nsince\n\nb\n\nq\nn\n\nis a tensor.\n\nIn indicial notation equation (A.12)\n\nra\n\nbecomes\n\ndj\nde\n\n[\n\nbj\n\nbvk\n\n-L\nb\n\nbw,\n\nA.."\'\n1\n\n\'VJ\n\nc\n\nk\n\n\n(A.21)\n\nUsing equations (A.20) and (A.21) the second order condition (A.14)\n\nbecomes\n\n\n55\n\n2\n\nd\n\n~\n\nj\n2 \t-\n\nA\ni\n\n%\n\nbwb\n\nrw-- Aiq\n\n.+\ni\n\nkkmn\n\nn \t\n\n,bii\n\nbwn6vt\n\nAmj\n\nb\n\nk\n\nCkhn \t\n\n(A.22)\n\nnmk\n\n\nk \t\n\nm \tv m \n\n2\n\nb j\n\n1\n\nb2\nbw\n\nA\n\nc\t\n\ne.\t\n\nbJ\n+\n\nli.\n\nAij\n\nn\n\nk n\n\nThe indieial notation representation of equation (A.11)\n\nkmC\n\nj v\n\n\'e.2\n\n22,\n\nA\t\n\nk\n\n-\n\n(A.23)\n\nov\n\n\nappears in four terms of equation (A.22).\ncan be written\n\nd2j\n\nRegrouping te-rms, (A.23)\n\n\n2\n\n2j\n\nbi\n\nAi__\neke\n\nn\n\n(A.24)\n\n\n56\n\n2\n\n+\n\n(\n\nS\n_\n\n__j\n\n+\n\n___\n\n22\n\nbw\nbJ\n\nA\n\nbvQ. )I\nAPQ S\nq )\n\nA\n\n-_\n\nin\n\n(A.24)\n\nh.h.\n\np\n\n312\n\nh.c(\n\nI3\n\nEquation (A.24) and equation (A.13) provide a set of first and\n\nsecond order conditions for J(w, v) to be minimumn subject to the\n\nconstraints Lit\n\nA.2\n\nV)\n\n= 0.\n\nMethod of Lagrange Multipliers\n\nThe first and second order conditions can be put in a form which\n\n\nis more convenient to-use by defining the augmented function\n\n\nv , P) = J(w, v) + E i(w, V)\n\nJ (\n\n(A.25)\n\nwhere P is a vector of constant multipliers called Lagrange multipliers.\n\nIf the Lagrange multipliers are given by the identity\n\n\niA ij\n\n=\n\n(A.26)\n\n1\n\nor in matrix notation\n\n\njT\n\nL\n\n-i(A.27)\n\n\nseveral observations can be made.\n\nThus necessary conditions for J\n\n\nto be a minimum (A.13) become\n\n\n0\n\n(A.28)\n\n57\n\nThe second order conditions (A.24) may be written as\n\nb21\nJ\n\n+ j -b22c.c\n.\nn\n\n! .kn\n\nk\n\nb2\n\n+ Pi\n2~\nn\n\nbib.\n\n+ P\n1\n\nbibk\n\nV1-b2\n\n21b2\n+\\-n"\n\n+\n\nh\nckh\n\n2 * ,\'\niw\n\nk\n\ni\n(A29\n\n1b2\nhVb~\nC\n\n+\n\n( h\n\nk\n\n-i\'j\n+\n\nI\n\n(A29\n\nDefine the vectors r and d as\n\n\nw2\nr\n\nh2\n\nh\n\n\nwp\n\nd =\n\nh\n\n(A.30)\n\nV,\n\n\nv2\n\nc2\n\n\nv\n\nC\n\nThe second order condition (A.29) may now be put in compact matrix\n\nnotation by using equation (A.25) and definitions (A.30):\n\n\nAT[ b\n\n]a\nljr\n\n(A.31)\n\nTo guarantee that c and h in vector d satisfy equation (A.11), elements\n\nof d may be expressed as functions of the independent constants c only.\n\nIn matrix notation this may be expressed as\n\n\nd\n\n58\n\nc =\n\nc\n\n(A.32)\n\n\nwhere\n\nand I is a q by q indentity matrix.\n\nThe second order condition (A.32)\n\n\nmay then be written as\n\n\n-C-\n\nba\n\n1 c\n\n(A.34)\n\nThe advantage of the Lagrange multiplier technique is that the\n\nfirst .and second order conditions can be expressed in a compact\n\nmatrix notation.\n\n\n59\n\nREFERENCES\n\n\nBliss, G. A., Lectures on the Calculus of Variations, University of\n\n. Chicago Press, Chicago (1946).-\n\nBliss, G. A. and Hestenes, M. R., Sufficient Conditions for a Problem\n\n\t\nof Mayer in the Calculus of Variations, Transactions of the\n\nAm. Math. Soc., Vol. 35, 1933.\n\nBliss, G. A., The Problem of Bolza in the Calculus of Variations,\n\nAnnals of Mathematics, Vol. 33., 1932.\n\nBolza, 0., Lectures on the Calculus of Variations, Dover Publications,\n\nNew York (1961); also, University of Chicago Press, Chicago\n\n\n(1904).\n\nBryson, A. E., and Ho, Y. C., Optimization Estimation, and Control,\n\nBlaisdell, New York\n\n(1969).\n\n\nBuck, R. C., Advanced Calculus, McGraw-Hill Book Co., New York (1965).\n\nHestenes, M. R., Calculus of Variations and Optimal Control Theory,\n\nWiley and Sons, New York (1966).\n\nHildebrand, F. B., Advanced Calculus for Applications, Prentice-Hall,\nEnglewood Cliffs, N. J. (1948).\nHouseholder, A. S., "The Dependency of a Focal Point Upon Curvature\nin the Calculus of Variations," Contributions to the Calculus\nof Variations, University of Chicago Press, Chicago (1937),\n\npp. 485-526.\nJohnson, D. C., and Gibson, J. E., "Singular Solutions in Problems\nof Optimal Control," IEEE Transactions on Automatic Control,\n\nVol. AC-8 \t (1963), pp. -14.\nKelly, H. J., Kopp, R. E., and Moyer, H. G., "Singular Extremals,"\nTopics in Optimization, edited by Leitmann, G., Academic\n\'Press, New York (1967).\n\nLeitmann, G., An Introduction to Optimal Control, McGraw-Hill Book Co.,\n\nNew York (1966), pP. 57-8.\n\nPontryagin, 1.S., Boltyanskii, V. G., Gamkrelidze, R.V., and Mischenko,\n\nE:F., The Mathematical Theory of Optimal Processes, edited by\n\nNeustadt, L. W., translated by Trirogoff, K. M., Wiley and Sons,\n\nNew York (1962).\n\n\nRobbins, H. M., "Optimality of Intermediate Thrust Arcs of Rocket-\n\nTrajectories," American Institute of Aeronautics and\n\nAstronautics Journal, Vol. 3, No. 6 (1965), pp. 1094-8.\n\nVincent, T. L.4, and Brusch, R. G., "Minimum Time Aircraft TrajectoriU.\n\nbetween Two Points in Range Altitude Space," NASA CR-631,\n\nNational Aeronautics and Space Administration, Washington,\n\nD. C. (1966).\n\nVincent, T. L. and Cliff, E. M., "Maximum-Minimum Sufficiency and\n\nLagrange Multipliers," AIAA Journal, January 1970.\n\n61\n\n'