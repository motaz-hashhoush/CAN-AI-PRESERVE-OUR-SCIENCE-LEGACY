b'NASA/TM-2011-217089\nNESC-RP-10-00619\n\nReadiness for First Crewed Flight\nDawn M. Schaible/NESC\nLangley Research Center, Hampton, Virginia\n\nApril 2011\n\nNASA STI Program . . . in Profile\n\nSince its founding, NASA has been dedicated to\nthe advancement of aeronautics and space science.\nThe NASA scientific and technical information (STI)\nprogram plays a key part in helping NASA maintain\nthis important role.\n\n\xe2\x80\xa2\n\nCONFERENCE PUBLICATION. Collected\npapers from scientific and technical\nconferences, symposia, seminars, or other\nmeetings sponsored or co-sponsored by NASA.\n\n\xe2\x80\xa2 SPECIAL PUBLICATION. Scientific,\nThe NASA STI program operates under the\ntechnical, or historical information from NASA\nauspices of the Agency Chief Information Officer. It\nprograms, projects, and missions, often\ncollects, organizes, provides for archiving, and\nconcerned with subjects having substantial\ndisseminates NASA\xe2\x80\x99s STI. The NASA STI program\npublic interest.\nprovides access to the NASA Aeronautics and Space\nDatabase and its public interface, the NASA Technical\n\xe2\x80\xa2 TECHNICAL TRANSLATION. EnglishReport Server, thus providing one of the largest\nlanguage translations of foreign scientific and\ncollections of aeronautical and space science STI in\ntechnical material pertinent to NASA\xe2\x80\x99s mission.\nthe world. Results are published in both non-NASA\nchannels and by NASA in the NASA STI Report\nSpecialized services also include creating custom\nSeries, which includes the following report types:\nthesauri, building customized databases, and\norganizing and publishing research results.\n\xe2\x80\xa2 TECHNICAL PUBLICATION. Reports of\ncompleted research or a major significant phase\nFor more information about the NASA STI\nof research that present the results of NASA\nprogram, see the following:\nprograms and include extensive data or\ntheoretical analysis. Includes compilations of\n\xe2\x80\xa2 Access the NASA STI program home page at\nsignificant scientific and technical data and\nhttp://www.sti.nasa.gov\ninformation deemed to be of continuing\nreference value. NASA counterpart of peer\xe2\x80\xa2 E-mail your question via the Internet to\nreviewed formal professional papers, but having\nhelp@sti.nasa.gov\nless stringent limitations on manuscript length\nand extent of graphic presentations.\n\xe2\x80\xa2 Fax your question to the NASA STI Help Desk\nat 443-757-5803\n\xe2\x80\xa2 TECHNICAL MEMORANDUM. Scientific\nand technical findings that are preliminary or of\n\xe2\x80\xa2 Phone the NASA STI Help Desk at\nspecialized interest, e.g., quick release reports,\n443-757-5802\nworking papers, and bibliographies that contain\nminimal annotation. Does not contain extensive\n\xe2\x80\xa2 Write to:\nanalysis.\nNASA STI Help Desk\n\xe2\x80\xa2\n\nCONTRACTOR REPORT. Scientific and\ntechnical findings by NASA-sponsored\ncontractors and grantees.\n\nNASA Center for AeroSpace Information\n7115 Standard Drive\nHanover, MD 21076-1320\n\nNASA/TM-2011-217089\nNESC-RP-10-00619\n\nReadiness for First Crewed Flight\nDawn M. Schaible/NESC\nLangley Research Center, Hampton, Virginia\n\nNational Aeronautics and\nSpace Administration\nLangley Research Center\nHampton, Virginia 23681-2199\n\nApril 2011\n\nThe use of trademarks or names of manufacturers in the report is for accurate reporting and does not\nconstitute an official endorsement, either expressed or implied, of such products or manufacturers by the\nNational Aeronautics and Space Administration.\n\nAvailable from:\nNASA Center for AeroSpace Information\n7115 Standard Drive\nHanover, MD 21076-1320\n443-757-5802\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\nReadiness for First Crewed Flight\n\nApril 12, 2011\n\nNESC Request No.: TI-10-00619\n\n1 of 58\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n2 of 58\n\nApproval and Document Revision History\nNOTE: This document was approved at the April 12, 2011, NRB. This document was\nsubmitted to the NESC Director on April 15, 2011, for configuration control.\n\nApproved:\n\nOriginal Signature on File\nNESC Director\n\nVersion\n1.0\n\nDescription of Revision\nInitial Release\n\nNESC Request No.: TI-10-00619\n\nOffice of Primary\nResponsibility\nMs. Dawn Schaible,\nManager, NESC\nSystems Engineering\nOffice\n\n4/15/11\nDate\n\nEffective Date\n04/12/11\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n3 of 58\n\nTable of Contents\n1.0\n2.0\n3.0\n3.1\n4.0\n4.1\n4.2\n4.3\n4.4\n\n4.5\n\n4.6\n5.0\n\nNotification and Authorization ........................................................................................ 5\nSignature Page................................................................................................................... 6\nTeam List ........................................................................................................................... 7\nAcknowledgements ............................................................................................................. 7\nEvaluation of Readiness for First Crewed Flight........................................................... 8\nPreface................................................................................................................................. 8\nIntroduction ......................................................................................................................... 9\nNeed for First Crewed Flight ............................................................................................ 10\nUnderstanding and Mitigating Residual Risk ................................................................... 10\n4.4.1 Focus on Crew Safety ........................................................................................... 10\n4.4.2 System Knowledge and Uncertainty Reduction ................................................... 12\n4.4.3 Proven Means of Return to Earth.......................................................................... 17\nConfidence ........................................................................................................................ 17\n4.5.1 Design Maturity and Simplicity ............................................................................ 18\n4.5.2 Verification and Validation................................................................................... 18\n4.5.3 Program Team ....................................................................................................... 18\n4.5.4 Program Processes ................................................................................................ 19\n4.5.5 Demonstrated Record of Success.......................................................................... 20\n4.5.6 Independent Input and Perspective ....................................................................... 20\nSummary ........................................................................................................................... 21\nAcronyms List ................................................................................................................. 23\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n4 of 58\n\nList of Figures\nFigure 4.4-1. Focus on Safety-related Items and Risks ................................................................ 11\nFigure 4.4-2. Major Contributors to Understanding Residual Risk for First Crewed Flight ........ 13\nFigure 4.4-3. Understanding Margins and Incremental System Capability Validation ................ 15\nFigure A.1-1. Progression of Testing to Build Up Evidence for Safe System Operation ............ 24\nFigure E.1-1. Mercury Redstone and Atlas Critical Path for Return to Earth .............................. 41\nFigure E.1-2. Gemini Critical Path for Return to Earth ................................................................ 44\nFigure E.1-3. Apollo Critical Path for Return to Earth ................................................................. 45\nFigure E.1-4. Space Shuttle Critical Path for Return to Earth ...................................................... 48\nFigure E.1-5. U.S. Human Spaceflight Development ................................................................... 52\nAppendices\nAppendix A.\nAppendix B.\nAppendix C.\nAppendix D.\nAppendix E.\nAppendix F.\nAppendix G.\n\nThe Role of Testing ................................................................................................ 24\nTechniques for Risk Identification ......................................................................... 29\nDiscussion of Risk Contributors............................................................................. 33\nEvaluation of Risk Analysis Tools ......................................................................... 35\nHistorical Perspective on First Crewed Flights ...................................................... 39\nBenchmarking with U.S. Navy and Air Force Flight Test Center .......................... 54\nSelected References................................................................................................ 57\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n5 of 58\n\n1.0 Notification and Authorization\nOn March 11, 2010, the Constellation Program (CxP) Manager, Mr. Jeff Hanley, requested the\nNASA Engineering and Safety Center (NESC) to \xe2\x80\x9cdevelop a framework for evaluating whether a\nprogram has sufficiently complete and balanced plans in place to allow crewmembers to fly\nsafely on newly developed human spaceflight systems for the first time: including technical, risk,\nand programmatic considerations.\xe2\x80\x9d The CxP Manager then asked that the framework be applied\nto current CxP plans. In addition, the NASA Chief Engineer and Chief Safety and Mission\nAssurance (S&MA) Officer requested the framework also encompass future human spaceflight\nsystems that may be developed by government and/or commercial providers.\nAn NESC out-of-board (OOB) activity was approved on March 11, 2010. An OOB summary\nwas presented at the NESC Review Board (NRB) on March 30, 2010. The assessment plan was\napproved by the NRB on April 29, 2010. A status briefing was presented to the NRB on\nJuly 16, 2010.\nThe key stakeholders for this assessment are CxP, Office of Chief Engineer, Office of S&MA,\nand Commercial Crew Transportation Planning Office.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n6 of 58\n\n2.0 Signature Page\nSubmitted by:\nTeam Signature Page on File -4/25/11\nMs. Dawn M. Schaible\n\nDate\n\nSignificant contributors:\n\nMr. P. Michael Bay\n\nDate\n\nMr. Michael P. Blythe\n\nDate\n\nMr. Patrick G. Forrester\n\nDate\n\nMr. David A. Hamilton\n\nDate\n\nMr. Benjamin G. Jimenea\n\nDate\n\nMr. T. K. Mattingly\n\nDate\n\nMs. Victoria A. Regenie\n\nDate\n\nMr. Charles W. Shaw\n\nDate\n\nMr. J. Phillip Sumrall\n\nDate\n\nSignatories declare the findings and observations compiled in the report are factually based from\ndata extracted from Program documents, contractor reports, and open literature, and/or generated\nfrom independently conducted tests, analysis, and inspections, as well as individual opinions and\nexperience.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n7 of 58\n\n3.0 Team List\nName\nDiscipline\nCore Team and Consultants\nDawn Schaible\nNESC Team Lead\nMichael Bay\nSystem Engineering\nMichael Blythe\nNESC Deputy Director for Safety\nPatrick Forrester\nNESC Chief Astronaut\nDavid Hamilton\nSpacecraft Development/Consultant\nBenjamin Jimenea\nNESC Systems Engineer\nT.K. Mattingly\nFormer Astronaut/Consultant\nCynthia Null\nNASA Technical Fellow for Human Factors\nVictoria Regenie\nNESC Systems Engineer\nCharles Shaw\nMissions Operations/Consultant\nJ. Phillip Sumrall\nLaunch Vehicle Development\nTricia Johnson\nMTSO Program Analyst\nProject Liaison\nCxP Special Assistant for System Integration and\nWilliam Arceneaux Verification\nAdministrative Support\nTerri Derby\nProject Coordinator\nLinda Burgess\nPlanning and Control Analyst\nCarolyn Snare\nTechnical Writer\n\n3.1\n\nOrganization\nLaRC\nGSFC\nJSC\nJSC\nJSC - retired\nKSC\nSPA\nARC\nDFRC\nJSC \xe2\x80\x93 retired\nMSFC\nLaRC\n\nJSC\nLaRC/ATK\nLaRC/ATK\nLaRC/ATK\n\nAcknowledgements\n\nThe NESC team would like to thank Mr. Kenneth Johnson and Dr. William Vesely for their\ncontributions to the development of the appendix on the evaluation of risk analysis tools.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n8 of 58\n\n4.0 Evaluation of Readiness for First Crewed Flight\n4.1\n\nPreface\n\nThe NASA Engineering and Safety Center (NESC) was requested to develop a generic\nframework for evaluating whether any given program has sufficiently complete and balanced\nplans in place to allow crewmembers to fly safely on a human spaceflight system for the first\ntime (i.e., first crewed flight). The NESC assembled a small team which included experts with\nexperience developing robotic and human spaceflight and aviation systems through first crewed\ntest flight and into operational capability. The NESC team conducted a historical review of the\nsteps leading up to the first crewed flights of Mercury through the Space Shuttle. Benchmarking\nwas also conducted with the United States (U.S.) Air Force and U.S. Navy.\nHistorical data shows that there are multiple approaches which have been successful for\ndetermining readiness for the first crewed flight. Every approach has to be tailored to the\nspecific system design and situation of that particular system and mission objectives. Because\nspecific approaches may vary significantly between different system designs, the NESC team\ndetermined prescriptive instructions or thorough checklists could not be developed to apply to all\npossible human spacecraft systems. In the course of the team\xe2\x80\x99s deliberations, however, it\nbecame evident that there are certain guiding principles that should be applied when developing\nthe first crewed flight decision. A general framework for evaluating whether a program has\nsufficiently complete and balanced plans for the first crewed flight is documented in the narrative\nthat follows. In the appendices that follow, a more in-depth discussion of testing, risk\nidentification, risk contributors, risk analysis tools, and a historical perspective are covered.\nThe NESC framework presented here includes important factors to consider when developing a\nnew system or evaluating an existing system for the first crewed flight. The NESC team believes\nthat documenting these concepts in one place will help to focus on the critical areas for\nconsideration and additional scrutiny. By applying the following framework to a specific design,\ntest program, and intended mission objectives, decision makers will have better information with\nwhich to make the decision for first crewed flight. To focus the NESC team\xe2\x80\x99s discussion, only\nspace transportation to and from low Earth orbit was considered, because these stages represent\nthe most relevant and significant risks to a first crewed flight. For considerations beyond low\nEarth orbit, the framework described in this report can be extended to encompass all mission\nrisks.\nThe question of when to fly crew for the first time is evaluated at many stages through the\ndevelopment of the human spaceflight system\xe2\x80\x94first during the planning stages and then\nthroughout development and testing and at major milestones. While the NESC team was\nrequested to look at the planning decision, the concepts described in this report are applicable\nthroughout the lifecycle of the program. Determining readiness for a first crewed flight is\ndependent on the specific system and its mission. In general terms, the system is ready to fly\nwhen residual risk has been mitigated to the point where it is outweighed by the need to fly the\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n9 of 58\n\nfirst crew. This decision is ultimately the judgment of the program and Agency management in\nconjunction with the design and operations team.\n\n4.2\n\nIntroduction\n\nDetermining readiness for a human spaceflight system\xe2\x80\x99s first crewed flight, especially when the\ntest flight is part of the overall system certification process, has been a challenge for program\ndecision makers. In addition, this question is not limited to human space flight; it is also\ncommon in aeronautic and naval applications. Most aircraft and terrestrial systems, however, are\ndesigned to have relatively large performance envelopes that allow incremental and reversible\nenvelope expansion techniques during development and testing. In a human spaceflight system,\nonce a ground test program is complete, an incremental test approach is difficult. Many space\nsystems events, especially launch vehicle liftoff, de-orbit, and re-entry, are irreversible events\nthat require using essentially the entire performance envelope to achieve a safe outcome\xe2\x80\x94\nmaking this decision process even more difficult.\nThe decision on first flight is ultimately the judgment of the program and Agency management\nin conjunction with the design and operations team. There is, however, some general guidance\nthat can be used in making these judgments. Close involvement of the technical and\nmanagement teams throughout the design and development process is essential. Verification and\nvalidation (V&V) of safety-critical systems and survival functions are required. Based on\nprevious experience, historical perspectives, and best practices, this report will illustrate a toplevel thought process for making a first flight decision and will help focus the debate and\ndiscussion on critical areas for consideration and additional scrutiny.\nIn the simplest terms, it is time to fly a crew for the first time when it is safe to do so and the\nbenefit of flying a crew is greater than the residual risk (see Section 4.3). This is rarely a\nstraight-forward, clear-cut trade off so experience, sound judgment, and established (and clearly\ndocumented) decision-making processes are essential (see Section 4.4). In addition, the\nunderlying level of confidence the manager has in making the decision must be considered (see\nSection 4.5). The remainder of this report will describe this concept in greater detail.\nThis report focuses on ways to understand the residual risk1 and gain confidence in the decisionmaking processes. Based on the NESC team\xe2\x80\x99s deliberations and collective experiences,\nchallenges were identified that are likely to be encountered and examples provided of techniques\nthat have been proven (or may now be available) to manage risk to acceptable levels, as thought\nprovokers (see Appendices).\n\n1\n\nIn this report, residual risk is defined as the risk remaining after other known risks have been eliminated, managed,\nmitigated, or accepted\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n4.3\n\nDocument #:\n\n10 of 58\n\nNeed for First Crewed Flight\n\nGiven that the human spaceflight system is designed for human spaceflight, it is accepted that the\nobjective is to fly humans when risks to crew safety have been mitigated to the point where the\nneed or benefit is worth the residual risks. The effort then shifts to deciding WHEN it is safe to\nfly crew, not IF a crew should fly.\nSenior leaders and decision makers must evaluate the specific test objectives for the mission to\ndetermine the need for a crew. Once this need has been established, the focus then shifts to\nensuring that the necessary safety-related crew interface, safety, and survivability requirements\nare met. A prerequisite for a first crewed flight is confidence gained through understanding of\nthe system design, development, analysis, and testing.\nIt should be noted that the decision that crew is needed for a particular test or mission is\nprimarily a programmatic decision (program and Agency management). For the technical team,\nthe focus must be on ensuring a safe and technically sound system.\n\n4.4\n\nUnderstanding and Mitigating Residual Risk\n\n4.4.1\n\nFocus on Crew Safety\n\nThe process of designing, developing, and testing a new launch system is very complex and\ninvolves the spacecraft, launch vehicle, ground systems, mission systems, recovery systems,\nground crews, and flight test crews. The program teams have a wide-ranging responsibility to\nensure the system is adequately assessed, tested, and deemed safe for human flight. It is\nrecognized that, despite the best efforts of the vehicle team, early flights of new systems will\nentail some degree of residual risk. Therefore, the focus should be on reducing and managing\nsafety-related risk to the greatest extent practical. Initial crewed missions must be conducted\nwith a minimum of onboard personnel (either active or passive participants). Such flights may\nwarrant unique contingency procedures/capabilities that will preserve a safe return capability\n(i.e., above and beyond that required for the nominal design mission) utilizing specially trained\ncrews.\nIn order to focus to those items that are unique to the initial crew participation, it is assumed the\nsystem/operations design must preserve a safe return to Earth capability in the presence of any\nsingle failure in any critical functional capability to the maximum extent practical. Safety issues,\nincluding providing for a safe crew return, should be separated from those needed only to\nenhance the mission. Mission enhancement functions of the crew are only considered to the\nextent that they affect safety. Figure 4.4-1 illustrates this concept. Safety and crew survival\n(such as abort capability) functions are non-negotiable and must be fully tested, verified, and\nvalidated prior to the first crewed flight. For each specific test or mission, additional functions\nwill be required to meet objectives that have been defined. Each subsequent test and mission\nmay require additional capabilities.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n11 of 58\n\nFigure 4.4-1. Focus on Safety-related Items and Risks\n\nFunctions that are critical for crew safety and survival must be established early in the design and\ndevelopment process. These crew safety and survival functions should be formed into a set of\nnon-negotiable, first crewed flight requirements that form the basis for required design,\ndevelopment, testing, and V&V. The following criterion is assumed as the basis for determining\nthe minimum requirements that must be satisfied in allowing crew participation:\nSystem/operations design must preserve a safe return to Earth capability in the\npresence of any single credible failure in any critical functional path for the\nintended mission.\nThe focus then shifts to determining what these safety-critical functions are and the degree to\nwhich they can be validated2.\n\n2\n\nVerification of a product shows proof of compliance with requirements. Validation of a product shows that the\nproduct accomplishes the intended purpose\xe2\x80\x94and in the case of models/analysis, that models adequately predict the\nenvironment and match actual vehicle performance.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n4.4.2\n\nDocument #:\n\n12 of 58\n\nSystem Knowledge and Uncertainty Reduction\n\nSafety must be an inherent part of the design. Programs must establish requirements for each\nsystem\xe2\x80\x99s specific design that will address safety-related items (e.g., failure tolerance, risk of loss\nof crew and mission, overall system reliability). A system-level focus on selection of simple and\nsafe solutions to meet critical functions necessary to\naccomplish the mission is required. These safetyKey elements of common aerospace design\ncritical design requirements must be addressed prior\npractices instrumental in the path to first flight\nto the first crewed flight. Sound aerospaceinclude:\nengineering practices for design, testing, and\nx Implementation of applicable technical\nanalysis must include all disciplines that affect any\nrequirements\naspect of a safe design. Examples include:\nx Utilization of safety analyses in system\npropulsion; environmental control and life support;\ndevelopment\nstructures; mechanisms; materials; active/passive\nx Verification, validation, and testing of\nthermal; pyrotechnics; aerodynamics; flight\ncritical system performance\nmechanics; loads and dynamics; guidance,\nx Technical authority involvement\nnavigation, and control; electrical systems; avionics;\nx Hazard identification and control\nsoftware; thermal protection; crew systems; human\nfactors; communication; space environments;\nx Integration of human-in-the-system and\nhuman-error management (both ground\nground operations; and flight operations. In\nand flight test crews)\naddition, design guidelines and standards associated\nwith each technical and operational discipline must\nx Analyses, tests, demonstrations, and\ninspections in ground tests and previous\nbe considered relative to their effect on crew safety\nflight tests\n(e.g., margins, structural strength, and factors of\nsafety). Including representation from those\norganizations that will operate the system (in flight and on the ground) is also important in the\ndesign of active systems and user interfaces, as well as during system-level testing.\nGaining understanding of system design, operation, and performance (hence reducing risk) is\ntraditionally accomplished through many factors that have been established as part of sound\nengineering practices. Figure 4.4-2 highlights areas that warrant particular attention when\ndetermining first crewed flight readiness. Specific details and examples are described in\nAppendices A\xe2\x80\x93D.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n13 of 58\n\nFigure 4.4-2. Major Contributors to Understanding Residual Risk for First Crewed Flight\n\nGiven that the first crewed flight is likely to occur as part of the development process, extra\nconsideration for crew safety must be given to the specific mission plan and vehicle\nconfiguration. The flight test environment must be compared to previous test\nconditions/parameters and analysis assumptions. Understanding the environment in which the\nsystem will operate and how it will vary for different phases of the mission allows the system to\nbe tested in relevant conditions and thus reduces uncertainty. Design and analysis should\naddress full flight envelope operation of the spaceflight system\xe2\x80\x99s design capability (including\ninduced and natural environments) and failure/abort conditions. Examples: loads analyses for\nlaunch, ascent, orbit, entry, and landing (coupled loads analyses); strength/stress/margin\nassessments for critical load conditions; entry heating and thermal protection system\nperformance; crew life support; propulsion systems; and trajectories.\nThe flight hardware/software for test flights may, however, be in a different configuration than\nfor operational flights, or may not be fully qualified. It is imperative that these differences be\nidentified and thoroughly evaluated to fully understand the residual risk. The key areas that\nrequire specific attention and scrutiny include:\nx\n\nConfiguration of the vehicle for flight test versus previous tests\n\nx\n\nFidelity, assumptions, and validation of models versus flight configuration\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\nx\n\nAnalyzed configuration versus flight configuration\n\nx\n\n14 of 58\n\nCertification level and fidelity of hardware/software installed for flight test\n\nA review of the specific flight configuration should be conducted, along with the implications of\ntest results and anomaly resolutions from previous testing and analyses. Specific analyses may\nbe performed for the mission, to include any potential\n\xe2\x80\x9cDuring the second Gemini Launch\ncontingencies. It is critical, however, to understand the\nVehicle Test (GT-2), the launch\nassumptions and fidelity of the models being used, and\nvehicle lost hydraulic pressure in its\nwhere the results are valid for that particular flight\nprimary control system and had\nconfiguration. Accepting data from models that are not\nswitched over from primary to\nvalidated within the range of operation can be\nsecondary guidance and control. The\nproblematic.\nsystem had detected its own hydraulic\nAnother area that poses a potential problem for a first\ncrewed flight is the certification level or fidelity of\nhardware/software installed on the vehicle for that flight\n(and of the ground systems used to support and operate the\nvehicle/mission). Due to timing and the requirements for\nthe specific mission, engineering and/or prototype\nequipment may be used. Additional test instrumentation\nmay also be part of the mission configuration. A decision\nto use an uncertified or off-nominal configuration requires\na thorough review, including an assessment of any\npossible unintended interactions.\nManaging margins is critical to the vehicle design and\ndevelopment. In this case, a margin is the difference\nbetween the design requirements (including factors of\nsafety) and the system\xe2\x80\x99s actual performance capability in\nthe worst-case environment and operating states.\nExamples of areas where margins are important include\npower, mass, delta-velocity, structure, and many others.\nDecision makers must understand the margins of each\nsystem before making a first flight decision. Planned\noperations are often placarded to stay within system\ncapabilities, especially in the early development flights (in\nsome cases, such as launch, it is difficult to gain margin\nvia placards; propulsion systems may operate near\nmaximum levels on every mission). Through effective\ntesting and proper processing, the actual system capability\ncan be determined. Each development flight test provides\nincreased knowledge and reduces uncertainty within the\ncleared envelope of operation\xe2\x80\x94allowing for incremental\nNESC Request No.: TI-10-00619\n\nfailure, responded by switching over\nto its secondary system, and then,\nbecause it was still on the ground,\ncommanded its engine to shut off.\nSubsequent investigation revealed that\nunexpectedly high pressure in one of\nthe hydraulic lines had burst the\naluminum housing of a servovalve.\nDuring development, someone had\ndecided that the walls of the housing\nwere twice as thick as they needed to\nbe; a third of a centimeter of\naluminum was ample to meet design\npressures. No one, however, thought\nto test the actual pressure the housing\nwould have to withstand, nor was any\nimpulse test, as such, included in\nsystem qualification. More likely than\nnot, one or another Titan II had\nsuffered the same sort of hard start,\nbut the stouter housings that remained\nstandard in the missile could survive\nsuch a pulse while the lighter\nstructural shell in the Gemini booster\ncould not.\xe2\x80\x9d\nFrom On the Shoulders of Titans: A\nHistory of Project Gemini by Barton C.\nHacker and James M. Grimwood, NASA\nSpecial Publication-4203 in the NASA\nHistory Series, 1977.\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n15 of 58\n\nenvelope expansion as more measurements are obtained and analytical tools are validated.\nFigure 4.4-3 illustrates this concept. The outer oval represents the operational system capability\nor \xe2\x80\x9cdesigned to\xe2\x80\x9d envelope, as built up/validated over the course of the test program. A robust,\nreliable, and safe design incorporates the ability to test specific points of the design where lower\nmargins, high risk, etc., occur due to new technology, use of previous technology in an untested\nenvironment, or other factors. As in most systems, the amount of margin varies. In some cases\nthe system is quite robust (i.e., large positive margin), in other areas there is little margin (see\nFigure 4.4-3). Greater margins are required where there is large uncertainty in the design and\nenvironments. Understanding the margins, to the maximum extent practical, is vital in\ndetermining the safety of first crewed flight.\n\nFigure 4.4-3. Understanding Margins and Incremental System Capability Validation\n\nMinimizing risk goes beyond meeting requirements and adhering to established standards. It\nrequires exploring what can go wrong and developing mitigations that either eliminate or reduce\nthe ensuing residual risk to acceptable levels in the as-built system, including where uncertainties\nmight reduce margins to unsafe levels along the flight envelope. Providing sufficient margin is\nan essential part of mitigating uncertainty and performing a safe mission.\nPrior to crewed flight, the system\xe2\x80\x99s performance and operating margin relative to the natural and\ninduced environments must be anchored by validated analysis/modeling and/or testing.\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n16 of 58\n\nKnowledge of the design process improves understanding of the limitations of analysis\ntechniques\xe2\x80\x94as it is these limitations that are critical to understanding the risk and ultimately the\nsafety of the system. The results from analytical tools are dependent on the accuracy of the\nmodels and the methods of calculation. While most results can be calculated to multiple\nsignificant figures, most models do not have that level of accuracy of the actual\nsystem/hardware. Many of the models may be approximations due to limited knowledge of the\nphysics, external environment, systems, or limited resources. These tools have enormous\npotential for improving the development process once their results are validated by\nexperimentation in each specific application. Furthermore, since these model formulations can\nbe manipulated to match experimental data at a given condition, they cannot be considered\naccurate until the same formulation is used under multiple plausible conditions. Such validation\ncan, to a large degree, be accomplished through ground testing, but there are several classes of\nmeasurements that can only be obtained with accuracy in flight (acoustics, aero-thermal, induced\nenvironments, etc.).\nA critical test list is a key tool for determining when a vehicle is ready for flight. This list\ncontains the tests, along with success criteria, that must be completed to reduce the system risk to\nan acceptable level and would cover the non-negotiable items, as discussed in Section 4.4.1.\nThis list should be created early in the development process. While the overall test requirements\nwill be fluid over the course of the program, changes to this critical test list should be rare and\nonly done after much debate and agreement among the team. Adhering to the list will help guard\nagainst the pressures of limited resources (time and budget) that programs often face during\ndevelopment.\nThe progression from analysis to ground test and then to flight test (uncrewed and then crewed)\nis also the progression of the fidelity of data that can be generated. Ideally, safety-critical and\nsurvival functions would be tested and verified through ground tests. This is not always\npossible, as flight environments and potential interactions cannot always be anticipated and\nreplicated on the ground. Any safety-critical function that must operate (or must not operate)\nduring a crewed mission must be verified and validated to an accepted confidence level prior to\nthe first crewed flight. Flight and ground tests must have similar instrumentation and be in the\nsame locations, as much as is practical, to compare data and allow the flight test to validate the\nground test and the analysis. A single measurement in any of the testing may not be sufficient to\nvalidate the system or model. (See Appendix A for a more detailed discussion of testing.)\nTo understand the uncertainty, and for the flight risk to be accepted, sufficient test measurements\nare needed to verify the environment, confirm the analysis, and confirm location of flight\nmeasurements. Flight tests should include: definition of flight test reference missions,\nobjectives, flight-specific functions, performance, and verification requirements; and assessment\nof all waivers, deviations, and exceptions. Finally, the program should ensure the resolution of\nanomalies from previous ground and flight tests and identify deviations from previous tests and\nbaseline design.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n4.4.3\n\nDocument #:\n\n17 of 58\n\nProven Means of Return to Earth\n\nA safe return to Earth from any stage of a mission, including launch, must be ensured through\ncontingency capabilities and procedures to the maximum practical extent. Careful thought must\nbe given to the entire mission with the goal of always being able to return the crew safely to\nEarth. In addition, it must be verified that the intended mission can be controlled, with\nuncertainties, to remain within the flight envelope validated for that mission.\nLaunch through the atmosphere inherently poses a tightly constrained flight envelope due to the\nrapid release of large amounts of energy by the propulsion system, significant aerodynamic\nloading, and the fact that structural loads may be at their maximum for the launch vehicle and\nsome spacecraft components. Therefore, early human spaceflight designs provided some form of\n\xe2\x80\x9clast resort\xe2\x80\x9d escape from the launch vehicle during the period from liftoff through maximum\ndynamic pressure (max q-bar), transonic transition, stage separation, and the establishment of a\nfunctioning upper stage. Because the range of unacceptable conditions is impossible to define\nwith complete confidence, emergency system designs cannot ensure success in every\nconceivable case, but portions of the envelope can and must be verified and validated to be safe\nfor supporting human flight. If a launch escape capability is available, it should not be factored\ninto reliability considerations but serve as a last resort to preserve the life of the crew.\nThe Space Shuttle configuration, unlike the small crew capsules used in the early programs,\nprecluded reliance on escape systems while its solid rocket boosters (SRBs) were burning.\nBecause SRB thrust termination designs introduced additional safety risks, the design team\nelected to invest the resources necessary to provide assurance that the entire launch system could\nbe treated, like primary structure, as having a reliability of 1.0 from ignition through SRB\nseparation. The fact that an unrecognized combination of environments subsequently resulted in\na catastrophe does not, by itself, invalidate the selected design approach. Rather, this tragic\nevent reinforced the importance of meticulously monitoring flight and test data relentlessly\npursuing, understanding, and resolving every out-of-family (not just out-of-specification)\nmeasurement.\nKnowledge of the system and understanding of the residual risks are gained as a system evolves.\nEach step of the design, development, assembly, integration, and test process builds the body of\nevidence the decision makers can use to determine the acceptability of the residual risks.\nTherefore, the decision of first flight must be considered, planned, and assessed at each step of\nthe process. An important part of this overall process is maintaining and encouraging the open\ndiscussions and debates within the entire program team\xe2\x80\x94and maintaining a healthy tension\nbetween the program and technical authorities, operations and design, systems and disciplines,\netc.\n\n4.5\n\nConfidence\n\nAn important consideration in determining when it is safe to put crews in a human spaceflight\nsystem is the overall level of confidence that the decision makers have in the system. For this\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n18 of 58\n\nreport, the NESC team is referring to subjective confidence based on engineering judgment, not\nstatistical projections. Decision makers gain confidence through a combination of several\ntangible and intangible means. Some examples and descriptions of contributing factors are\nprovided in the following sections.\n4.5.1\n\nDesign Maturity and Simplicity\n\nThe use of \xe2\x80\x98proven\xe2\x80\x99 hardware/software and designs can provide increased confidence, assuming\nsimilar environments, conditions, applications, etc. However, the design team should be\ncautious in using \xe2\x80\x98heritage\xe2\x80\x99 and \xe2\x80\x98off the shelf\xe2\x80\x99 hardware and software. The use of these proven\nsystems must be analyzed and verified for use in new environments and applications. Designs\nthat have additional safety margins at the component, system, or operations levels (as discussed\nin Section 4.4.2) may also merit increased confidence.\nSystems that employ inherently simpler designs, fewer interfaces, and large margins to meet\ntheir needs will likely increase confidence in their ability to perform safely and reliably. For\nexample, the Space Shuttle drops its landing gear by releasing retention hooks and allowing\ngravity and air loads to deploy the landing gear, avoiding hydraulic or other actuating power\ndevices. Complexity should only be added when there is benefit such as in weight, volume,\nperformance, or operations.\n4.5.2\n\nVerification and Validation\n\nV&V are essential for developing a safe human spaceflight system. When determining if a\nvehicle is ready for crewed flight, a review of the V&V program should be conducted (as\ndiscussed in Section 4.4.2 and Appendix A). A complete and thorough test program will\nincrease confidence in mission success. When a vehicle or system has a significant history of\ntesting prior to the current program and the configuration, operational environment, and\nperformance parameters are similar enough, the applicable historical test data and analyses may\nbe used for verification and can also increase confidence in the system. Analytical design tools,\nvalidated with experimental data over a range of conditions, provide the most confidence.\nThe test program should always include end-to-end testing and integrate humans, hardware, and\nsoftware to the degree needed to sufficiently understand the dynamics of interaction, control risk,\nand gain confidence in the integrated system.\n4.5.3\n\nProgram Team\n\nThe experience and longevity of the program team are significant confidence builders in\ndevelopment of a successful human spaceflight system.\nConfidence is enhanced when program management and supporting members of the program\nteam (including safety and mission assurance (S&MA) and medical) are responsible for ensuring\nan appropriate emphasis on safety during the design, development, and testing of the launch\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n19 of 58\n\nvehicle, spacecraft, launch-abort system, mission operations, ground operations, manufacturing,\nand other areas.\nTeams consisting of members with significant design/development experience in the fields they\ncurrently support and who have already been through major design, development, and testing\ncampaigns provide increased confidence. A strong systems engineering focus is also important\nin understanding and managing the interfaces and interactions\xe2\x80\x94of both the design and the team.\nConfidence increases when decision makers insist on personal accountability (ownership) for the\nend results; good communication between team members; and operation in an open, positive\nenvironment. As stated in Section 4.4.3, maintaining and\nIt is important for the entire team to\nencouraging open discussions and debates within the entire\nremain focused on building up evidence\nteam\xe2\x80\x94and maintaining a healthy tension between the program\nto prove that the system is safe for first\nand technical authorities, operations and design, systems and\ncrewed flight. When this focus is lost, the\ndisciplines, etc., is an important part of developing confidence.\nteam becomes vulnerable to error,\nIdeally, the team should be organized so that the decision-making oversights, and poor judgment. For\nauthority is delegated to the hardware/system design level,\nexample:\nthereby allowing timely decisions to be made. However, final\n\xe2\x80\x9cThe engineers found themselves in the\naccountability remains with the program and Agency managers.\nAll decisions must consider safety first and be based on a balance unusual position of having to prove that\nthe situation was unsafe \xe2\x80\x93 a reversal of\nof sound technical and programmatic rationale. It is important to\nthe usual requirement to prove that a\nnote that organizations should have an alternate reporting path or\nsituation is safe.\xe2\x80\x9d Columbia Accident\ngovernance structure that ensures safety and technical concerns\nInvestigation Board Report.\nare addressed.\nIt should be emphasized that hardware/software and system\ncontractors are an essential part of the program team. The contract should allow open\ncommunication and individual responsibility. Since most hardware and software elements are\nprovided by prime and sub-tier contractors, careful attention must be paid to the applicable\nstatements of work, terms, and conditions to make sure that they motivate all parties to ensure\nsafety and reliability. Some contract incentives may drive behavior contrary to what is desired.\nA simplified example would be if all award fees are based on simply meeting milestones\xe2\x80\x94\nschedule pressure could take precedence over technical matters.\n4.5.4\n\nProgram Processes\n\nFor any complex program, established, efficient, effective, and documented processes are\nessential to define how the program functions. Understanding and ensuring proper program\nprocesses and outcomes will help determine the level of confidence.\nExamples of processes to be analyzed include technical reporting/authority, technical checks and\nbalances, S&MA practices, integration, and documentation. For instance, decision makers may\ngain confidence when the team has clearly defined and understood roles and responsibilities; a\nstrategy for independent reviews and reporting; well-established risk management practices that\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n20 of 58\n\nidentify and eliminate, reduce, or mitigate risks; readily available and up-to-date documentation;\nand documented rationale of major decisions.\n4.5.5\n\nDemonstrated Record of Success\n\nHuman spaceflight systems typically have well-documented design processes, with thorough\nengineering standards and processes. Some systems, however, may offer limited access to\ndetailed design information. These systems may have different design and verification\napproaches, as well as differing processes, documentation, or quality-control plans. From a\nconfidence-building standpoint, these kinds of differences and potential shortcomings may well\nbe offset, in part, by a demonstrated launch performance record. This concept may apply to\ncomplete human spaceflight systems, such as the Russian Soyuz, or components or subsystems,\nsuch as the RD-180 rocket engine.\nAn existing system or subsystem may add to the confidence of decision makers if it has\nestablished a sound flight record in a similar configuration or operation, or if it has undergone\nrelated systems testing. Successful components or systems may function or operate within\nspecific parameters but if those components or systems are introduced into new parameters, their\ncontinued success cannot be assumed unless appropriate testing using these new parameters is\nperformed. Decision makers should be cautious if components or systems that were successful\nin previous programs are now used in environments for which they were not designed or tested.\nIn addition, understanding of all past anomalies is essential.\nIt is important to note that decision makers must remember that past success does not\nautomatically translate to future success. Previous flight history is only one factor in building\nconfidence\xe2\x80\x94it is not sufficient by itself to determine readiness for a first crewed flight. When\nusing these previously flown systems or components, it is vital that the technical team has a\nsound basis for confidence in their continued success. Every system will present its own unique\nset of circumstances that must be thoughtfully considered in a manner consistent with the\nprinciples described in this report. In the end, the technical team will be accountable for the final\nresults.\n4.5.6\n\nIndependent Input and Perspective\n\nThroughout the process, program and Agency management should seek out and integrate input\nfrom competent, current, and independent review teams. It is important that they review the\nprogram throughout its life cycle and have relevant insight into and knowledge of the design in\norder to make sound observations and recommendations. However, care should be taken that the\nreview team retains their independence and maintains a balance between close participation and\nindependence. In addition, independent technical assessments of new technologies, new\ndevelopments, and expected high-risk areas should be performed throughout the life cycle.\nConfidence is not a number or a data point. Decision makers must develop confidence to safely\nlaunch humans by working closely with the entire program team throughout the process of\ndesigning, building, and testing the vehicle.\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n21 of 58\n\nThe factors outlined above, along with others, contribute to building confidence in the human\nspaceflight system\xe2\x80\x99s ability to fly a crew safely. Overall confidence is a combination of many\nconsiderations and it is important that the contributing factors chosen encompass the entire\nsystem, including the launch vehicle and ground/mission systems. Readiness for crewed flight\noperations will always be an integrated judgment call based on the decision makers\xe2\x80\x99 experience,\nknowledge, and level of confidence in the system.\n\n4.6\n\nSummary\n\nThe key points in this report can be viewed as questions that a decision maker may ask\nthroughout the process of designing, building, and testing a new crewed vehicle. These\nquestions include (but are not limited to):\nx\n\nAre adequate safety features inherent in the design?\n\nx\n\nDoes the design preserve a safe return to Earth in the event of a single credible failure?\n\nx\n\nAre the design requirements of the entire system understood and implemented?\n\nx\n\nDoes the team thoroughly understand the design and configuration?\n\nx\n\nHas sufficient knowledge been gained through adequate design, analysis, and testing?\n\nx\n\nHave models been thoroughly validated with physical data?\n\nx\n\nAre hazards adequately identified and controlled, including across systems and interfaces,\nto the maximum extent practical?\n\nx\n\nHave the safety-critical and survival functions been identified, verified, and validated\nprior to the first crewed flight (including test flights)?\n\nx\n\nHave the program management and technical teams worked together and has there been\nopen communication of issues throughout the lifecycle?\n\nx\n\nHas the first crewed flight decision been considered at each step of the lifecycle?\n\nx\n\nHas confidence been developed throughout the lifecycle and used in making an informed\njudgment?\n\nx\n\nWhen decisions were made, did the team focus on showing how those decisions affect\noverall safety and risk?\n\nx\n\nAre the program, engineering, S&MA, and operations teams in agreement for system\nreadiness of a first crewed flight?\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n22 of 58\n\nThe process of determining readiness for a first crewed flight is dependent on the specific system\nand mission. In general terms, the vehicle is ready to fly when it has been deemed safe and when\nany residual risk has been mitigated to the point that it is outweighed by the need for a crew.\nThis decision is ultimately the judgment of the program and Agency management in conjunction\nwith the design and operations team.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n5.0 Acronyms List\nARC\nATK\nCAD\nCAM\nCxP\nDFRC\nFEA\nFMEA\nFPGA\nGSFC\nISS\nJSC\nKSC\nLaRC\nLEO\nMA\nMC\nMCO\nMEIT\nMR\nMSFC\nMTSO\nNESC\nNEST\nNRB\nOOB\nPRA\nS&MA\nSCA\nSEO\nSPA\nSRB\nSRM\nSSME\nV&V\nWIRE\n\nDocument #:\n\nAmes Research Center\nAlliant Techsystems, Inc.\nComputer-Aided Design\nComputer-Aided Manufacturing\nConstellation Program\nDryden Flight Research Center\nFinite Element Analysis\nFailure Modes and Effects Analysis\nField-Programmable Gate Array\nGoddard Space Flight Center\nInternational Space Station\nJohnson Space Center\nKennedy Space Center\nLangley Research Center\nLow Earth Orbit\nMercury Atlas\nMonte Carlo\nMars Climate Orbiter\nMulti-Element Integrated Tests\nMercury Redstone\nMarshall Space Flight Center\nManagement and Technical Support Office\nNASA Engineering and Safety Center\nNESC Engineering Statistics Team\nNESC Review Board\nOut of Board\nProbabilistic Risk Assessment\nSafety and Mission Assurance\nShuttle Carrier Aircraft\nSystems Engineering Office\nSystems Planning and Analysis\nSolid Rocket Booster\nSolid Rocket Motor\nSpace Shuttle Main Engine\nVerification and Validation\nWide Field Infrared Explorer\n\nNESC Request No.: TI-10-00619\n\n23 of 58\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n24 of 58\n\nAppendix A. The Role of Testing\nTesting is often the most reliable and costly method of V&V. Unless there is an extensive and\navailable body of knowledge about the new vehicle operating in its operational environment,\ntesting is often the only way to generate the knowledge needed to buy down risk to an acceptable\nlevel. The importance of validating the models and analysis cannot be stressed highly enough.\nA common thread throughout testing and this discussion is the need to validate the models and\nanalysis, both those used for design and those used for verification. In order to understand the\nuncertainty and for the risk to be accepted, sufficient test measurements are needed to verify the\nenvironment and confirm the analysis. Models, especially complex models, are often not linear\nand if linear, can include multiple interactions. Therefore attempting to validate a model\nutilizing a single measurement is not likely to be possible. The number of measurements will\ndepend on the complexity, size of the system envelope, and the model uncertainty.\nTesting demonstrates that the system, hardware, software, and interactions operate safely and as\nexpected. Testing builds on each previous test to generate the body of knowledge necessary to\ndetermine when it is acceptable to fly a crew for the first time. Testing progresses from ground\ntest to uncrewed flight test and finally to crewed flight tests (see Figure A.1-1).\n\nFigure A.1-1. Progression of Testing to Build Up Evidence for Safe System Operation\n\nDetermining what tests must be done to ensure that safety-critical items are fully understood is a\njudgment call. Such a determination is based on model and analysis fidelity and credibility, as\nwell as system complexity, technology maturity, heritage systems, design margins, and previous\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n25 of 58\n\nexperience. Important factors to be taken into account when designing a test program include an\nunderstanding of the test environments and their limitations, what system interfaces and\ninteractions are critical to safety, the weak points in the analysis and modeling, and how much\ndata are needed to reasonably verify the system. Repeatability (the ability to demonstrate that\nthe vehicle operates the same way more than once) is another important aspect of a test program.\nThe severe thrust oscillations (often referred to as pogo) during the Apollo Program illustrate\nhow results can be different for the same test. The first Saturn V launch vehicle carrying the\nuncrewed Apollo 4 spacecraft was thought to have performed nearly flawlessly. The second\nuncrewed Saturn V unexpectedly experienced pogo greater in amplitude than that tolerated for\nMercury or allowed for crew exposure during Gemini.\nThe definition of the instrumentation and data to be collected from ground and flight testing is\ncritical to reducing the uncertainty of the model. Matching the instrumentation to the models and\nanalysis is essential to validate both model and analysis. While many systems can be mostly\nvalidated on the ground, few can be fully validated until flight. Some systems such as\npropulsion, structures, vibration, and acoustics cannot be fully validated by ground tests, so flight\ntesting is essential. Determining what systems can only be validated through flight testing and\nconcentrating attention and instrumentation on those elements for the test flights are essential.\nGround Test\nGround testing of hardware/systems is necessary before any flight test. Ground tests are the\nprimary method for ensuring that the models and analyses are valid, and the systems meet the\nrequirements and operate safely and as desired. During the developmental cycle, ground tests\nare necessary to understanding and trading the core technology that will be used in the new\nvehicle. Typical tests include material properties, avionics architecture, structural strength,\npropulsion systems performance, thermal protection system concepts, aerodynamics, and many\nothers. The next set of needed ground tests are used to verify that the design meets the\nrequirements and to validate analysis and models. The discipline/component ground tests\ndemonstrate lower-level requirements and, when combined with integrated tests and the other\ncomponent/discipline tests, help validate the system. The first time many flight interfaces and\ninteractions are demonstrated and verified is in integrated system tests. Therefore the analysis\nhas, at best, limited ability to predict what the interactions will be. Integrated systems tests start\nat the subsystem level and progress to system-level tests on the vehicle. The requirements are\nverified and a critical evaluation is made of the subsystem operation. During the integrated\ntesting, it is essential to test at the edges of the performance envelope. In structures this may\ninvolve testing at higher load conditions or inducing loads through unexpected paths. Often a\nfull structural test will discover that the load paths are different than expected. The same is true\nfor avionics, propulsion, and other subsystems.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n26 of 58\n\nThe majority of the integrated testing generally requires complex test environments.\nUnderstanding the differences and capabilities of the test system is important for understanding\nthe test results, especially when evaluating whether the system is operating as expected.\nIntegrated systems testing for many systems (avionics, power, propulsion feed and cooling,\nenvironmental control and life support, and active/passive thermal control) requires a highfidelity simulation to produce realistic data for the systems\nunder test. All items that can be tested on the ground should\nMulti-Element Integrated Tests (MEIT)\nbe, including the integration testing of major elements. The\nwere performed on International Space\nbehaviors of the integrated major elements are difficult, if\nStation (ISS) elements during ground\nnot impossible to predict and often adversely affect safety.\nprocessing at Kennedy Space Center\nAs with all complex systems, the vehicle\xe2\x80\x99s behavior and\n(KSC). MEIT was conducted to validate\nreactions may change over time based on interactions with\nthe operation of flight elements and\nassociated systems in an environment\nthe environment and between elements\xe2\x80\x94often with\nthat was as flight-like as possible\xe2\x80\x94\nunintended consequences. Many of these behaviors will\nwhere practical, actual flight\nrequire design and/or implementation changes. As a\nconnections, flight hardware\nconsequence, integrating the essential elements, especially\ncomponents, and flight software were\nthose that are related to safety, reduces the uncertainty and\nused. If available, actual on-orbit\nsubsequently the risk. As a rule, it is difficult if not\noperators (astronauts), ground\nimpossible to fully test an integrated system on the full-up\ncontrollers, and on-orbit procedures\nvehicle. Therefore, care should be taken to assess the\nwere also used. MEIT found problems\nimpact on safety when integrated element testing is moved\nsuch as an electrical component underto the vehicle. It is critical to ensure that the fidelity of the\nvoltage condition that would have\ntest set-ups is at the level needed to understand the\nprevented start up of an element; an\nactivation sequence that was nearly\nvulnerabilities of the systems.\ntwenty times longer than specified;\n\nPrior to any flight test, a set of integration tests must be\nrequirements that would have led to\nperformed on the vehicle to ensure that the vehicle matches\nthermal loading and a loss of an\nthe systems tested on the ground and the analysis result.\nelement; and swapped video signals that\nThese tests encompass ground assets as well as the flight\nwould have required an additional\nextravehicular activity (EVA) which\nvehicle. Subsets of those tests run on the ground are often\nwould have increased risk to the crew.\nused, as well as additional tests that can only be performed\nMEIT found several significant issues\non the vehicle. Environmental qualification testing, another\nthat were corrected prior to launch,\nmajor part of ground testing, takes flight or preflight\nwhereas resolution of those problems on\ncomponents, sub-systems, and systems and exercises them\norbit would have been more difficult or\nin an environment as similar to the actual flight environment\nimpossible to accomplish.\nas can be created on the ground. Typically, components are\nqualified separately and, depending on the maturity, validity\nof the analysis, and heritage of the component, the environmental testing will be extended to the\nsystem. It is important to understand the differences between the test and the flight\nenvironments. The tests should be testing the system at the extremes as well as in the \xe2\x80\x9cnominal\xe2\x80\x9d\noperating range. Typically environmental qualification tests include loads, thermal, pressure\n(internal and external), electromagnetic interface/electromagnetic control, vibration, and\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n27 of 58\n\nacoustics. Qualification testing and analyses should verify the design for all of the expected\nenvironments, performances, and life (cycle, shelf, and operating times) of each level of\nhardware (part, component, subsystem, and system). Acceptance testing should screen for\nworkmanship, all testable failure modes, and performances at each level of hardware. The\nacceptance test should ensure that each following hardware copy was manufactured, processed,\nand assembled as the qualification test hardware.\nUncrewed Flight Test\nWhile knowledge of the vehicle and its systems is increased through ground testing, it is still\nnecessary to further understand the uncertainty for the safety-critical elements. The main goal of\nmost uncrewed flight tests is to verify those elements that can only be verified in the flight\nenvironment and to validate the full system. It is not possible for ground tests to fully match the\nflight environment, nor can all the system interactions and interfaces be fully tested on the\nground. The induced environments are one set of environments that cannot be matched on the\nground. Determining which systems can only be validated through flight tests and concentrating\nattention and instrumentation on those elements for the flight tests is essential. Capturing\nemergent behavior of the system prior to a crewed flight is another goal of the uncrewed flight\ntest. Defining test conditions and instrumentation to capture the behavior of the system is\ncritical.\nUncrewed flight tests can be conducted during any of the program phases: design and\ndevelopment, qualification and acceptance, and integration. Typically, the uncrewed flight tests\nperformed during design and development are technologyfeasibility tests, model, analysis, and process validation, and\nThe NASA Launch Services\nrisk-reduction tests. During the development phase, an\nProgram launches unmanned\nvehicles with high-value, one-of-auncrewed flight test is added to verify and validate changes\nkind payloads. Based upon desired\nwhose risk is considered too high for a crewed flight.\nrisk levels and classes of payloads,\nUncrewed flight tests have unique challenges. Without\nNPD 8610.7D requires a minimum\nonboard observers, the only way to gain knowledge of how\nnumber of successful launch\nthe system operated and identify any stress points is through\nvehicle flights before a payload can\ndata collected from extensive instrumentation systems. The\nbe flown.\ndefinition of the instrumentation and data to be collected is\ncritical to reducing the uncertainty and must be carefully chosen to ensure that the areas of\nuncertainty and those areas vital to model validation are adequately addressed. Flight and\nground tests must have similar instrumentation and in the same locations, as much as reasonable,\nto be able to compare data and enable the flight test to validate the ground test and the analysis.\nHaving enough instrumentation to define the system performance is a necessary and difficult\ntask. There is always the push for more instrumentation against the limits of mass, time, and\nmoney. The impact of the added instrumentation on the test environment must be understood\n(i.e., wiring through insulation is a heat transfer path). Uncrewed testing covers all portions of\nthe system, including the launch vehicle, spacecraft, and ground/mission operations. Special\nattention to a launch-abort system, when launch is part of the mission, is also essential prior to\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n28 of 58\n\nthe first crewed flight. Because it is a \xe2\x80\x9clast chance\xe2\x80\x9d escape, additional ground and uncrewed\nflight testing will be necessary. Understanding the envelope and capability of the system\nthrough well-validated models and analysis is essential. Since a launch-abort system is complex\nand there are many unique interactions and interfaces with the launch system, a substantial\nportion of the validation needs to be done with flight testing.\nCrewed Flight Test\nValidation testing may continue on crewed flights when the benefit of the crewed flight is greater\nthan the residual risk. There will be systems that cannot be fully validated without a crew and\nthere may be elements of the testing that can be safely delayed, if necessary. The introduction of\na crew adds another set of interfaces and interactions that potentially change the performance of\nthe system, often in unexpected ways. These flights, as with the uncrewed flights, will be used\nto gather important test data to verify and validate the vehicle and its systems. The test flights\nwill also be used to gather data necessary to further validate the analysis and models. As the\nflight program progresses, the analyses and models will be relied on to plan future flights and\nassist in resolving any anomalies or understanding emergent behavior. While instrumentation\nmay be reduced for crewed flight tests, it cannot be eliminated. Ensuring that sufficient data is\ngathered to continue validation of the system started during ground testing is essential.\nPrior to a crewed flight, the system must be determined to be at an acceptable risk level. It is at\nthis point that an understanding of the differences in ground and uncrewed flight environments is\ncritical. All items required for safe flight should be tested prior to flight to provide sufficient\nsafety margin to allow for unexpected events. Even those items that are not directly related to\nsafety must be evaluated before flight to ensure they do not cause degradation in crew safety.\nThe mission of the crewed flight test must be clearly defined and well understood to increase\nsafety and reduce risk. Each flight mission should be limited to essentials and, as much as\npractical, incremental missions utilized to clear the vehicle for its full operational mission. The\nfirst crewed flight should not try to clear the system as fully operational for all its missions. At\nthe same time, the crew should be focused on only those objectives essential to safely completing\nthe mission.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n29 of 58\n\nAppendix B. Techniques for Risk Identification\nThe details of NPR 8705.2 (Human Rating Requirements Document) and other NASA Standards\nsuch as 8715.3 (Safety and Mission Assurance Plan) and 8000.4 (Risk Management Plan)\nprovide guidance in risk management. It is essential to have the proactive mindset needed to\nassess what could go wrong, whether in the design phase (including model development and\nvalidation), testing phase, or operational phase. The purpose of the documentation on risk\nmanagement is to be more than just a \xe2\x80\x9cchecklist\xe2\x80\x9d to determine that all risks are eliminated.\nImportantly, the purpose is to help focus that proactive mindset in such a way that things do not\n\xe2\x80\x98slip through the cracks.\xe2\x80\x99 It is vitally important to maintain a balance between the \xe2\x80\x98process\xe2\x80\x99 and\nmaintain an awareness of what the process is trying to help the team accomplish, namely, to\nensure thorough risk identification and preclude either eliminating or reducing attention to items\nthat could result in an undesirable outcome.\nOver the years, several techniques for identifying risk have been developed. Because a single\nstrategy that works in every situation has not been identified, multiple paths are pursued in\nparallel in an attempt to maximize the opportunity to identify risks at the earliest time.\nRisk identification (and assessment) can be approached from a number of different perspectives.\nFor instance, either a bottom-up or top-down perspective could be used. It is important to choose\ncomplementary approaches to achieve a more complete understanding of the risks. Top-down\nand bottom-up approaches each have their advantages and disadvantages. The biggest\ndisadvantage of a top-down perspective is that the person doing the assessment may not have a\nsufficiently detailed knowledge of the systems. However, the top-down approach allows \xe2\x80\x98out of\nthe box\xe2\x80\x99 ideas and perspectives that a person submerged in the details of the system may not\nhave. One of the bottom-up approach\xe2\x80\x99s biggest drawbacks is the lack of a wider perspective,\nwhich can miss critical interactions across subsystems. The strength of a bottom-up approach is\nthat perspective is based on a solid knowledge of the details of the system which may not be\nevident to an outside reviewer. It is for these reasons that a variety of approaches and\nperspectives should be implemented.\nThe following information addresses some of the pros, cons, and comments for some of the more\npopular risk identification techniques.\nSimplify what must be assessed. There are things that MUST work. So, what are they and\nwhat can go wrong? The objective of this mission is (fill in the blank), and what MUST happen\nto achieve that objective? Where can these few critical things go wrong and then how can I\nprevent those things from going wrong? This mindset can also be used to simplify the mission\nobjectives and what has to be certified before flying a crew for the first time (see Figure 4.4.1).\nDesign reviews. In addition to a program representative, these reviews should include the\nengineering and S&MA community and representatives of the manufacturing, assembly, test and\ncheckout, and operations teams. Independent reviewers should also be included. It is imperative\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n30 of 58\n\nthat designs be fully integrated across systems and interfaces in order to achieve the desired level\nof confidence in risk identification.\nFailure modes and effects analysis (FMEA). The FMEA was developed as a methodical way\nto examine each component to determine its failure modes and corresponding signatures and\nimplications. This is a valuable technique but relies on judgment and can be labor intensive.\nThis is a bottom-up approach.\nFish bone diagrams. These have proven to be extremely powerful tools, especially in\nconducting accident investigations. This technique starts with a symptom (e.g., an engine\nignition failed). The analysis works backward to identify every step in the functional sequence\nthat might cause such an outcome. It has helped find relationships that were overlooked during\nthe FMEA process, but it can be labor intensive. An ideal approach would be to perform both\nFMEA and fish bone analyses on critical functional paths. This is a top-down approach.\nMission simulations. Simulations have been used for decades to prepare operational teams and\nvalidate mission rules. Their effectiveness is contingent on having the simulation supervisors\naggressively search for unusual combinations of actions and events that would challenge the\nteam\xe2\x80\x99s knowledge. The cost of such high-fidelity simulations has been reduced over time and\nprovides a powerful technique for identifying unrecognized interactions. If such capabilities can\nbe implemented in the early design stage, such simulations will help identify problems early and\nimprove the utility of the operational inputs to the design team. In general, mission simulations\nare a bottom-up approach implemented by the operations community (fail a subsystem\ncomponent and see how it affects overall operations), but can also be a powerful top-down\napproach to assess system interactions and dependencies (a lack of cooling requires powering\ndown, but critical operations require staying powered up).\nConfiguration management. Most human spaceflight programs involve many people and\norganizations dispersed across the country. This decentralized approach can make the programs\nmore vulnerable to miscommunication, oversights, and omissions. The importance of\nconfiguration management (control what is supposed to be there), configuration accounting\n(awareness of what IS there), materials and parts traceability, and the ability to ensure everyone\nis using the same data sets cannot be overemphasized as a front line risk reduction activity. In\ngeneral this is a bottom-up approach.\nChecklists and surveys. Checklists and surveys are probably the most common form of risk\nidentification. They are used to systematically search and identify as many exposures, perils,\nand hazards as possible. Many people like them because they are standardized, they can be used\nby non-risk management personnel with minimal training, information can be easily categorized,\nand they can be used to create a history. On the down side, they cannot cover all areas or\noperations and provide limited, if any, financial impact effect. They also do not prioritize the\nrisk exposures that they identify and may not identify new exposures. This is usually considered\nto be a top-down approach.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n31 of 58\n\nPolicy and procedure reviews. These are used to identify how an organization functions. They\ncan be done either internally or externally or both. While there is an opportunity to identify\nexposures, organizational politics may prevent this from being effective. This is usually\nconsidered a top-down approach.\nContract reviews. This is a broad category and often there is the misconception that because an\nattorney or contract specialist wrote or blessed it, it is acceptable. Contract review includes a\nwide variety of material, including but not limited to: leases, hold harmless and indemnification\nagreements, purchase orders and sales contracts, bills of lading, warranties, advertising materials,\nemployment contracts, service contracts, and insurance certificates. If a full contract review has\nnot been conducted (regardless of the size of the program), it is safe to say there is unidentified\n(passive) risk in that program.\nExperts. Experts bring additional technical depth, experience, and perspective to the risk\nidentification process that may not exist internally. It may be difficult to find qualified experts in\nsome disciplines and they could be expensive.\nCommon-risk checking. In most systems disciplines, lists of known risks unique to that type of\nsystem are available. Each risk on the list can be checked for application to a particular\nsituation. Depending on the level of technical detail, this can be either top down or bottom up,\nbut since it employs a generic type of approach, it is usually considered a top-down strategy.\nEvent-based risk identification. This refers to events that, when triggered, cause problems.\nHence, risk identification can also start with the source of problems or with the problem itself.\nThe chosen method of identifying risks may depend on culture, industry practice, and\ncompliance to requirements. The identification methods are formed by templates or the\ndevelopment of templates for identifying the source, problem, or event. Three common\nperspectives of event-based risk identification are:\nObjectives-based risk identification. Organizations and programs teams have\nobjectives. Any event that may endanger partly or completely achieving an objective is\nidentified as a risk.\nScenario-based risk identification. In scenario analysis, a functional decomposition is\nperformed to identify and list each step required to be performed to achieve an objective\nor perform a task (similar to a fishbone diagram). However, then different scenarios that\nillustrate potential issues that may arise in performing that step are explicitly listed\n(e.g., a message must be received and acted upon. Scenarios are that the message was\ngarbled, or not received, or not understood, etc.). The scenarios may be the alternative\nways to achieve an objective or step, or an analysis of the interaction of systems that\ncauses an issue. Any event or scenario that triggers a subsequent undesired scenario\nalternative is identified as a risk.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n32 of 58\n\nTaxonomy-based risk identification. The taxonomy in taxonomy-based risk\nidentification is a breakdown of possible risk sources. Based on the taxonomy and\nknowledge of best practices, a questionnaire is compiled. The answers to the questions\nreveal risks [CMU/SEI-93-TR-6 Taxonomy-based risk identification in software industry\nhttp://www.sei.cmu.edu/library/abstracts/reports/93tr006.cfm].\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n33 of 58\n\nAppendix C. Discussion of Risk Contributors\nThere are many different sources of technical risk to a system\xe2\x80\x94some are known and understood\nand many are not. These unknown risks are often referred to as epistemic or systemic\nuncertainties. Some of the most important sources of uncertainty include: variability in the\nprocesses (materials, manufacturing, measurements, etc.), complexity of the system, maturity of\nthe hardware/software, reuse of hardware/software, and emergent behavior or unintended\ninteractions. These factors are recognized and understood by the decision makers but may not be\nconsciously considered during the decision-making process. In order to achieve the best possible\nresults, decision makers should think through each of the sources of uncertainty before making a\nfinal decision.\nTypically, concerns with variability, complexity, and maturity are addressed upfront in the\ndesign phase through conservative margins and requirements. For example, structural engineers\nmay apply knock-down factors or electrical engineers will ensure larger power margins. This\ncan accommodate some of the uncertainty. As development progresses, extensive testing at each\nstage will also help to identify any weaknesses or unexpected interactions. Testing of systems is\nmore than just verifying requirements, it is also essential for understanding the true operation and\nlimitations of a system. This is also addressed in Appendix A.\nMost managers and decision makers recognize that new designs, technology, and interfaces\ncreate additional uncertainty, while previous testing increases confidence for the program.\nHowever, reuse of existing components in new applications may increase uncertainty. Decision\nmakers may assume that reuse of a component of hardware or software will reduce the\nuncertainty level of the system. Unfortunately this is often not the case. The new application\nand new interfaces may in fact increase the uncertainty, unless enough time and effort are\ninvested in a thorough review and analysis of the particular application. One example of the\nperils of software reuse without a thorough understanding of the implications was experienced\nby NASA\xe2\x80\x99s Mars Climate Orbiter (MCO). The MCO reused software code originally developed\nfor another spacecraft for the thruster trajectory equation. The conversion code was in British\nunits but the specification called for metric. The code was obscure and the specification was not\nwell understood or reviewed with the reuse application. The subsequent mismatch of units\nresulted in the loss of the MCO.\nAn example that specifically relates to heritage hardware in a different application is Landsat 7.\nThe instrument on Landsat 7 was the Enhanced Thematic Mapper Plus, which had many heritage\ncomponents and a few new ones. One of the heritage components was the main power supply\nbox which converted the spacecraft 28-V direct current power into the secondary voltages\nrequired for the instrument electronics systems. The power supply had an input filter that had\nfairly large inductors and capacitors and therefore large complex impedance. This was not an\nissue for previous Landsats that used this power supply design because these spacecraft had\nunregulated 28-V power supply buses. However, Landsat 7 had a regulated bus and when the\ninstrument was powered, the bus would ring due to the large complex impedance at the\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n34 of 58\n\ninstrument power supply input. The least expensive way to fix this problem at that point in the\nprogram was to develop and integrate a damping circuit in a separate box on the spacecraft.\nThese examples demonstrate a possible downside of reuse: decision makers may be lulled into a\nfalse sense of security due to successes in the past. Sometimes such reductions may be the\nappropriate action but a thorough review and analysis must take place first. Appropriate decision\nmaking must take into account that similar components will not necessarily behave identically.\nThe process of identifying emergent properties and unintended operations of human-rated\nspacecraft must begin at an early stage in the development process to ensure that as many issues\nas possible are recognized and addressed. Analytical methods can be applied to early systems to\nfind and correct possible interactions before the design is complete. Analysis alone will not\nidentify all unexpected emergent behaviors; testing is necessary to ensure that those interactions\nthat do present themselves will not create an unsafe situation for the spacecraft or crew.\nAn example of this kind of unexpected behavior occurred during the Wide-Field Infrared\nExplorer (WIRE) experiment launch in March 1999. After the launch, a system anomaly\noccurred in which the telescope aperture cover was opened prematurely, resulting in the release\nof the spacecraft\xe2\x80\x99s cryogenic hydrogen. The subsequent report on the incident traces the\nbehavior to a field-programmable gate array (FPGA) that was used in a circuit for which it was\nnot well suited. The mishap investigation determined that a transient signal occurred after start\nup of the FPGA. The WIRE report indicated that the testing method used for the spacecraft was\nperformed at the hardware-box level only, a method that would not have identified the transient.\nThe report also stressed that the spacecraft should have been tested in its flight configuration to\nidentify these types of behaviors.\nMost engineers and managers recognize unexpected emergent behavior as a source of\nuncertainty in the system\xe2\x80\x99s operation yet few are able to describe a standard process for driving\nout such behavior. Most system and test engineers suggest additional testing in off-nominal and\nmaximum-use conditions as a means of discovering unexpected behavior. Consciously\naddressing any potential unexpected emergent properties is important and the test program\nshould be designed to uncover as much of this behavior as possible.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n35 of 58\n\nAppendix D. Evaluation of Risk Analysis Tools\nJust as a proactive mindset is important for the risk identification process, so is an awareness of\nanalysis tool limitations and personal accountability and responsibility for the outputs of\n\xe2\x80\x98accepted\xe2\x80\x99 analysis tools. Any tool will give an incorrect answer if fed incomplete or inaccurate\ninputs, so any tool used must be given input based on real data whenever possible. Assumptions\nshould only be used when clearly understood and accepted rationale exists for using them. One\nmust always apply a common-sense litmus test to any result. This can be difficult because good\njudgment often comes from experience, but valuable experience often includes remembering the\nresults of poor judgment. In addition, one must always remember that statistical results can be\nmanipulated to tell any story, especially if someone is trying to justify an answer.\nThe following information addresses a number of different tools that can be powerful aids for\nmaking informed decisions about risk.\nSystem Modeling and Analysis. This includes a broad variety of methods, including:\nx\n\nSolid physical and computer-aided design (CAD)-based models of hardware\n\nx\n\nConcept and flow evaluation tools such as network and event sequence diagrams\n\nx\n\nModels describing physical processes such as stress models or flow dynamics\nmodels\n\nx\n\nProbabilistic models that build on many of these tools by quantifying uncertainty\n\nTechniques of varying effectiveness are available to model at almost any complexity level, from\nstresses on small regions of a single bolt hole through complex environmental effects on highly\ncomplex structures. Perhaps the most important strength of system modeling lies in the\ndevelopment of the models: the mere effort of putting the model together will reveal risk\ncontributors, consequences, and mitigations during early design stages when changes are\nrelatively inexpensive. Problems of modeling often stem from the fact that they are models, not\nthe actual physical system or process. Assumptions, simplifications, design changes, interactions\nwith unmodeled factors, and misunderstanding of the system can be significant, unquantified risk\ncontributors.\nNASA-STD-7009 (Standard for Models and Simulations) is a valuable reference that can help\nanalysts design, use, and communicate results from many types of computer-based models.\nWhile adherence to this standard does not guarantee avoidance of the problems mentioned\nabove, it can be effective in addressing problems, especially when used with other risk analysis\nmethods. Other excellent tools can be drawn from other disciplines, such as systems\nengineering, operations research, human factors engineering, reliability, maintainability, and\nquality engineering.\nTwo important types of probabilistic modeling tools are Monte Carlo (MC) simulation and\nprobabilistic risk assessment (PRA).\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n36 of 58\n\nMonte Carlo (MC) Simulation. This technique gains its name from the city famous for its\ngames of chance. Initially, a system model is constructed. Instead of deterministic inputs\n(simple point estimates, means, medians, allowables, etc.), important variable or uncertain inputs\nare modeled by probability distributions intended to explicitly reflect the variability or\nuncertainty of each of these inputs. The model is run (exercised) a number of times (trials).\nEach trial uses a different set of input values, chosen randomly from each input\xe2\x80\x99s assigned\nprobability distribution. The output, then, is itself a distribution of values rather than a single\nnumber. If the model and inputs sufficiently reflect reality, the distribution from exercising the\nMC model will be the same as one would expect from operating actual hardware. For example,\na drive to work might be modeled using an event sequence diagram. The model can then be\nperturbed by varying the speed of traffic, number of red lights, etc., according to appropriate\nprobability distributions. Running the model a number of times using different traffic speeds\nweighted by how likely they are to occur will give an idea of not only how long it takes to make\nthe drive, but also the range of drive times that might be expected.\nStrengths of MC analyses include generally greatly reduced cost over physical testing and\nimproved risk quantification due to gaining estimates of not only means, but also variability in\nresponses and insight into drivers of variability of output (sensitivity analysis). Experienced\npractitioners can construct useful models early in the design process, even with extremely limited\ndata. MC models are particularly useful in modeling stochastic processes, when there is a time\ncomponent in the process or variability. Potential weaknesses need to be recognized and include\nunmodeled contributors to risk, sensitivity to incorrect assumptions and to probability\ndistributions used, plus the significant resources and time that can be needed to assemble and\nexercise models of complex structures, physics, and processes.\nProbabilistic Risk Assessment (PRA). A PRA is a structured analysis that presents a set of\nscenarios, frequencies, and associated consequences. A scenario contains an initiating event and\none or more pivotal events leading to an end state, generally an undesired consequence such as\nloss of mission or loss of crew. The initiating event is typically an energetic event, failure, or\nother perturbation that requires response from one or more systems, or operators, (e.g., an\nexplosion of a hydrogen tank). Pivotal events generally include failures of these responses,\nwhich enable the end state to occur when the initiating event occurs; an example might be the\npuncture of an oxygen tank due to debris from the initiating event at the hydrogen tank.\nThe logic of possible scenarios leading from the initiating event is shown using event trees or\nfault trees. Scenarios are classified into end states according to the kind and severity of\nconsequences. Physics-based models are used for phenomena and dynamic events. The\nprobabilities of the initiating event and the pivotal events are estimated\xe2\x80\x94along with their\nuncertainties\xe2\x80\x94to obtain the probability and associated uncertainty for the scenario. The scenario\nprobabilities are then combined to obtain the total probabilities and associated uncertainties for\nthe end states.\nThe technique is generally used for highly complex systems; however, smaller-scale applications\ncan be carried out using simpler models. PRA on a highly complex system can be time- and\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n37 of 58\n\nresource-intensive, thus expensive; however, it can be more efficient than many other methods\nfor modeling highly complex systems, particularly early in the design process when uncertainties\nare greater. The results of the tool will be no better than the accuracy of the input data and\nassumptions. For systems early in their design phase, extra care must be taken when assessing\nthe inputs to the tool for their validity and applicability\nA method known as Bayesian updating is often used in PRA analysis. This mathematical\ntechnique is a quantitative formalization of techniques used in engineering judgment. Bayesian\nupdating is used to reconcile conflicts in data sources and explicitly quantify uncertainties related\nto the lack of credibility, strength, and/or similarity of sources in the analysis results.\nThe models and inputs can be drawn from many sources, including raw physics, test and\nhistorical data, experience from similar systems, and/or expert opinion. For models that reflect\nhigh complexity there is often a dearth of directly applicable data, low design maturity of the\nmodeled system, and uncertainties about physics and other issues. In those instances, uncertainty\nanalysis is an important part of the PRA and a healthy skepticism is needed when assessing the\nvalidity of the assumptions and data feeding into the model.\nThis leads to both its most important strengths and weakness. A PRA includes significant\nsources of uncertainty stemming from possibly more assumptions than are used in other\nmodeling techniques. Assembling highly complex models using large numbers of assumptions,\nincluding uncertain inputs and quantification of their \xe2\x80\x98goodness,\xe2\x80\x99 is bound to cause disagreement.\nDisagreements between experts on assumptions and inputs can also be significant. However,\nexplicit evaluations of the risk impacts of the uncertainties and disagreements can be made via\nuncertainty and sensitivity analyses. This is an important feature of a PRA.\nFor applications involving complex systems and new design, it is most likely true that PRA\nresults do not exactly reflect accurate \xe2\x80\x98absolute\xe2\x80\x99 risk values because of the sheer complexity and\nuncertainties. In addition, the time needed to construct a PRA can mean the analysis lags design,\nso the \xe2\x80\x98current\xe2\x80\x99 design\xe2\x80\x99s actual risk status can be different than the tool\xe2\x80\x99s results. This said, PRA\ncan be tremendously useful, especially as a comparative risk assessment tool for these particular\napplications. A well-constructed PRA can provide key information on:\nx\n\nQuantification of uncertainty levels on risk estimates (example: 5th, mean, and\n95th percentile estimates)\n\nx\n\nQuantitative assessment of system risk contributors and measures of risk and\nreliability effects in trades between different system designs\n\nx\n\nSensitivities to problems, environments, stressors, age, etc.\n\nx\n\nQuantitative importance and rank orders of contributors to risk\n\nx\n\nIdentification and relative importance of knowledge gaps for prioritization of test\nand design choices\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n38 of 58\n\nPRAs can also be tremendously useful for organizing thinking and suggesting priorities in the\ncase of actual system problems, especially when the system is complex. A good starting\nresource on PRA containing further references is PRA Procedures Guide for Managers and\nPractitioners, currently in version 1.1 (NASA Office of S&MA, March 2002).\nDemonstrated Reliability Estimate and Associated Confidence. A quick, useful, often\nmisused, and frequently misunderstood summary quantitative method is the demonstrated\nreliability estimate. It would seem to make sense that if there have been 100 flights and no\nfailures, then that program must have demonstrated high reliability. But there are important\nmisconceptions in that short statement. First, a firm definition of \xe2\x80\x98high reliability\xe2\x80\x99 must be\ndeveloped from the program\xe2\x80\x99s acceptable risk posture a\xe2\x80\x99 priori. For this example, suppose an\nacceptable mission failure rate of 1/200 was stated in the program\xe2\x80\x99s risk-planning documents.\nSecond, it must be remembered that each mission is a sample from a population of all possible\nmissions. As such, the current collection of 100 missions is a collection of samples that\nestimates the failure rate in the population of all missions. It is quite possible to achieve\n100 missions without a failure given a population failure rate of 1 in 70; in fact, the program\ncould expect to get this result about \xc2\xbc of the time. Obviously, optimism regarding proof of\nacceptable risk is unwarranted.\nBecause the set of successful flights can only be used to obtain an estimate of the true risk, a\nrequired confidence level must be decided upon a\xe2\x80\x99 priori and published along with the program\xe2\x80\x99s\nacceptable risk document to bound the limit of acceptable estimation error on the value. The\nconcept of statistical confidence will not be covered here. As a rule-of-thumb, a value between\n70 and 95 percent confidence is recommended (closer to 95 percent for easy-to-estimate or\nhigh-risk values; the closer to 70 percent, the more derating by use of larger safety factors is\nnecessary). Many specialized statistics software tools are available to calculate demonstrated\nreliability. An excellent and free tool for calculating not only true demonstrated reliability\nvalues but also sample sizes required to prove a reliability risk given a desired confidence level is\nGary Pryor\xe2\x80\x99s Reliability Test Planner3.\n\n3\n\nAvailable at www.midmozark.com\\rtp.html. A tutorial is available through NASA\xe2\x80\x99s NESC\nEngineering Statistics Team (NEST) by contacting the NESC at www.nesc.nasa.gov.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n39 of 58\n\nAppendix E. Historical Perspective on First Crewed Flights\nThe purpose of this appendix is to provide a general discussion of the steps leading to the first\nhuman flights of all NASA crewed launch systems from Mercury through the Space Shuttle.\nThe material in this appendix was synthesized from a survey of readily available public\ndocuments (listed in Appendix G) and personal experiences related to:\nx\nx\nx\nx\n\nPreparing for the first crewed flights of the Space Shuttle, Apollo spacecraft, and Saturn\nlaunch vehicles\nWorking with those responsible for developing and flying Mercury and Gemini\nDeveloping and committing one-of-a-kind robotic systems to flight\nExecuting experimental and developmental flight tests of aircraft and rockets\n\nTeam members used personal experience along with information published in applicable NASA\nspecial publications (SP) to infer the basis for management confidence in committing crews to\nflight during the Mercury, Gemini, Apollo, and Space Shuttle Programs. The material contained\nin this appendix reflects these observations but should not be taken as total evidence of the actual\nthought processes and logic that were used in making these historic decisions. Nevertheless, the\nteam believes that the observations in this appendix are consistent with history and warrant\nconsideration in planning for initial crewed missions for future human-rated systems.\nA space launch/transportation system for the purposes of this discussion includes the launch\nvehicle, spacecraft, and components required to return humans safely to Earth from any point in\na low Earth orbit (LEO) mission. The scope of this overview is limited to identifying the basis\nfor confidence in the ability to execute functions that must be performed in order to send humans\ninto space and return them to Earth with reasonable assurance.\nEarly Human Spaceflight Programs\nThe three early human spaceflight programs (Mercury, Gemini, and Apollo) are reviewed as a\nsingle series of missions. While the mission and vehicle designs for each program were\ndifferent, the management processes and technical approaches were very similar. This similarity\nlikely reflects the fact that the same core government teams that led development of the Mercury\nspacecraft and Redstone launch vehicle also led development of Saturn, Gemini, and Apollo. In\naddition, following Mercury, each program leveraged the design and data from the previous\nprogram. The development and preparation for human flight was guided by experience gained\nalong the way. Ultimately all three programs were focused on the same eventual Apollo goal of\nlanding men on the Moon and returning them safely to Earth.\nThe \xe2\x80\x9cman in space\xe2\x80\x9d Program was introduced just 6 days after NASA was formed on\nOctober 1, 1958. The Program was renamed Project Mercury on November 26, 1958. Project\nMercury involved three distinct systems: the Mercury spacecraft (capsule), the launch vehicles\n(Redstone and Atlas), and the launch escape system. The Mercury spacecraft (capsule) was a\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n40 of 58\n\ncone-shaped, one-man capsule with a cylinder mounted on top. It was 2 m (6 ft, 10 in) long and\n1.9 m (6 ft, 2.5 in) in diameter. A 5.8-m (19-ft, 2-in) escape tower was fastened to the cylinder\nof the capsule. Project Mercury\xe2\x80\x99s design philosophy was based on practicality and relatively\nsimple requirements. Basic guidelines and criteria were established and observed in the design\nand development of the Mercury spacecraft and further extended to the modification and\naccommodation of the two Mercury launch vehicles, the Redstone and Atlas. The Mercury\nRedstone (MR) and Mercury Atlas (MA) critical paths for a safe return to Earth are shown in\nFigure E-1.1.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n41 of 58\n\nFigure E.1-1. Mercury Redstone and Atlas Critical Path for Return to Earth\n\nWith critical functions identified and a development strategy defined, the program prepared a\nflight test sequence that would validate all critical functions required for each manned mission at\nthe earliest time. The first missions collected data needed to complete spacecraft and launch\nescape system (LES) designs. Boilerplate spacecraft were used to show that each launch vehicle\nwas compatible with the spacecraft. Finally a series of envelope expansion flights was made\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n42 of 58\n\nwith \xe2\x80\x9cproduction\xe2\x80\x9d spacecraft. A series of 18 uncrewed test flights of the Mercury spacecraft was\nconducted on various launch vehicles (Little Joe, Big Joe, Mercury, Atlas) to check out the\nperformance of critical spacecraft systems. A primate named Ham was launched on Mercury\nRedstone 2 (MR-2) on January 31, 1961, prior to flying humans for the first time on\nMay 5, 1961.\nIt should be noted that the Mercury launch vehicle development heavily leveraged previous\nsystems and testing by the Army Ballistic Missile Agency. Mercury used classic flight envelope\nexpansion techniques to demonstrate human compatibility with launch and entry environments\nbefore evaluating human utility in orbit. The build-up sequence began with qualifying Redstone\nfor suborbital flight with the Mercury spacecraft, demonstrated compatibility with a primate, and\nconcluded with crewed missions. The Atlas launch vehicle was qualified for orbital flight in\nparallel with the Redstone missions and then used a primate to validate the life support systems\nand compatibility with increased time in zero gravity. Human compatibility and utility were\nevaluated by a series of flights with increasing time in zero gravity. Qualification of the launch\nescape system and procedures for launch, flight operations, and recovery were pre-requisites for\nall human missions. Satisfactory completion of the flight-test sequence, hardware qualification,\nand validation of critical function fault tolerance was expected to provide sufficient evidence of\nreadiness for first crewed flight.\nFollowing the successful test of MR-2, consideration was given to launching a human on a\nsuborbital trajectory on the next Mercury-Redstone launch. Dr. Wernher von Braun met with his\nleadership team at MSFC to develop a recommendation on how to proceed. The team, with one\nexception, was prepared to fly a human on the next launch. Typically, Dr. von Braun attempted\nto arrive at team consensus, but frequently decisions were made without unanimous agreement\namong the team members. The lone dissenter in this meeting believed that it would be wise to\nfly one more test that, if nearly perfect, would provide confidence to man the next flight.\nDr. von Braun decided that the historical nature of launching the first American into space,\ndictated that his team agree unanimously on the recommendation. As a result, one additional\nflight test (MR-BD) with a boilerplate spacecraft was flown on March 24, 1961. The flight was\nfully successful. On May 5, 1961, a Redstone rocket launched astronaut Alan Shepard into space\nin a Mercury spacecraft designated Freedom 7. Just 15 days later, on May 20, 1961, President\nKennedy announced the Apollo Program to a joint session of the U.S. Congress.\nBecause it was the first U.S. human spaceflight program, the first crewed flight decision for\nMercury was arguably the most difficult\xe2\x80\x94with the most unknowns. The man-rating program for\nthe Redstone, Atlas, and Titan launch vehicles was characterized as follows: \xe2\x80\x9cThe total manrating program fell into the general categories of minimum redesign, an extensive quality\nprogram, the development of an abort sensing and implementation system, and a program\ndiscipline which insisted through meticulous attention to detail that we not fly when there were\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n43 of 58\n\nany unanswered problems concerning the status of any of the hardware.\xe2\x80\x9d 4 Only those changes\nnecessary to adapt the vehicle to the requirements of the mission and those necessary for the\nimprovement of safety were authorized.\nGemini was the next human spacecraft after Mercury. The spacecraft was an enlargement of the\nfamiliar Mercury capsule\xe2\x80\x945.8 m (19 ft) long, 3 m (10 ft) in diameter, and weighing about\n3,810 kg (8,400 lb). Engineering changes simplified maintenance and made it more\nmaneuverable for the pilots. The Titan II rocket, more powerful than the Redstone or Atlas\nrockets, placed the larger spacecraft into orbit. Sometimes referred to as Gemini-Titan for the\ncraft and its launch vehicle, each flight was designated by a Roman numeral. The Gemini\nspacecraft had approximately 50 percent more volume than the Mercury for twice as many\ncrewmembers. Aircraft-type ejection seats replaced the Mercury Project\xe2\x80\x99s escape rocket. The\nGemini spacecraft was designed with essentially the same type of redundancy features that had\nbeen employed in Mercury. One significant departure from Mercury was that the Gemini crew\nwas given the capability to make the decision to abort based on inputs from selected sensors.\nThe launch vehicle for the Gemini missions was the Titan II. As with the Atlas, an intensive\ninvestigation of Titan performance and all past failures was undertaken in order to pinpoint the\nvehicle areas that needed to be modified, redesigned, or made redundant. As a result of these\nstudies, it was determined that the flight control, propulsion, electrical systems, and hydraulic\nsystems were the areas that needed reliability improvement and possible redundancy.\nThe first human Gemini launch occurred on March 2, 1965, after two successful test flights of\nGemini I and Gemini II were conducted and all primary test objects achieved. The Gemini\ncritical path for a safe return to Earth is shown in Figure E.1-2.\n\n4\n\nCulbertson, \xe2\x80\x9cMan-rating the Atlas as a Mercury Booster,\xe2\x80\x9d America Institute of Aeronautics, paper No. 65-252,\nWAFLUASD Support for Manned Flight Conference, Dayton, OH, April 21\xe2\x80\x9323, 1965.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n44 of 58\n\nFigure E.1-2. Gemini Critical Path for Return to Earth\n\nThe 10 crewed Gemini flights demonstrated the capability to subject two men and supporting\nsystems for the challenges of longer duration flights as required for the later trips to the Moon; to\neffect the rendezvous and docking with other orbiting vehicles for Apollo; to perfect methods of\nreentry and landing at a pre-selected landing point; and to gain additional information on the\neffects of weightlessness on crew members and to record the physiological reactions of the crew\nduring long-duration flights.\nThe Apollo Saturn IB was the first launch vehicle developed specifically to carry humans into\nspace. The Redstone, Atlas, and Titan systems all had their origins as ballistic missiles. In order\nto launch humans, a process called \xe2\x80\x9cman-rating\xe2\x80\x9d was followed that included various\nmodifications which were subsequently validated through a combination of ground and flight\ntesting. Although the Saturn IB would also be used to launch uncrewed payloads, it was\ndesigned from the outset to be able to safely launch crews into orbit. The Saturn IB flew four\nuncrewed flight tests, all considered fully successful. Based on the success of these 5 S-IB test\nflights and the 10 successful flights in the Saturn I test series, the decision was made that the\nSaturn IB was ready for its first crewed orbital flight test in October 1968. The Apollo critical\npath to a safe return to Earth is shown in Figure E.1-3.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n45 of 58\n\nFigure E.1-3. Apollo Critical Path for Return to Earth\n\nIn reviewing the previous human spaceflight programs, common traits became evident. First,\nclear definitions of the end result (objectives), the method by which they were to be achieved\n(guidelines), and development and verification that was required prior to flight (development\ntasks) were established at the outset. For all the early programs, the decision makers determined\nthat the following conditions were met:\n1. The development team was confident that the evidence of task completion was\ncompelling.\n2. There were no uncorrected, not understood, or unverified corrections to design-related\nanomalies.\n3. The development team was confident that (a) the mission could be executed as planned\nand (b) no single credible failure could prevent returning the crew safely to Earth (as\ndepicted in Figures E.1-1 through E.1-3).\n4. Flight and mission systems replicated the certified design configuration and\nspecifications.\nThe history of the early human spaceflight programs includes numerous developmental tests,\nboth ground and flight. The development process focused on building and ground testing\nsystems at the highest level of assembly and flying test articles at the earliest possible time to\ngather data needed for design refinement. As part of this build, test, and \xe2\x80\x9cfix what doesn\xe2\x80\x99t work\xe2\x80\x9d\napproach, failure to fully achieve specific test objectives was not a showstopper unless the data\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n46 of 58\n\nwere deemed insufficient for design and validation purposes. Hence, the development process\nincluded a robust ground test program that emphasized critical functionalities. A few examples\ninclude:\nx\n\nStructural test article tests to demonstrate full design capabilities with appropriate\nmargins\n\nx\n\nWater-landing tests to demonstrate structural integrity and performance in worstcase scenarios\n\nx\n\nFull-scale parachute deployment tests to demonstrate chute operation, strength, and\nthe ability to reliably deploy and inflate the drogue and main parachutes\n\nx\n\nPost landing flotation\n\nx\n\nWater-drop tests to demonstrate effectiveness of air bags in reducing crew landing\nloads\n\nx\n\nCrew couch tests to demonstrate non-injurious crew loads\n\nx\n\nMission simulated timelines with production spacecraft (and crew) in vacuum\nchambers\n\nx\n\nSeries of special space mission testing to exercise planned and contingency scenarios\nwith all systems running\n\nx\n\n1,730 J-2 engine tests before Apollo 8\n\nx\n\nGround vibration tests for launch vehicle and spacecraft combinations\n\nAs part of the development cycle, classic flight envelope expansion techniques with prioritized\nbuilding blocks were used to demonstrate human compatibility with launch and entry\nenvironments before evaluating human utility in orbit. The first missions collected the data\nneeded to complete spacecraft and launch systems design/ratings using boilerplate spacecraft.\nBoilerplate spacecraft were initially used to show that each launch vehicle was compatible with\nthe spacecraft. Finally a series of envelope expansion flights was made with \xe2\x80\x98production\xe2\x80\x99\nspacecraft building up to a primate and then a human flight. The need to repeat or re-fly a test if\na targeted test condition or component was modified was based on engineering judgment.\nA significant, yet unquantifiable factor that led to the overall success of the early human\nspaceflight programs was the strong, well-established technical and management teams.\nWorking together so closely, for so long, and in such a fast-paced, pressure-filled environment\nbuilt strong relationships and understanding. Each team member was accountable for their own\nsystem/components and related decisions. The senior managers were technically proficient and\nremained personally involved from inception through flight, continuously asking \xe2\x80\x9cwhat if\xe2\x80\x9d and\n\xe2\x80\x9chow do you know\xe2\x80\x9d questions.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n47 of 58\n\nThe Space Shuttle Program\nThe Space Shuttle represented a significantly more complex system than the early human\nspaceflight programs. George Low, leader of the Apollo Spacecraft Program Office, noted after\na Moon landing that only 100 wires linked the Saturn rocket to the Apollo spacecraft. He wrote.\n"The main point is that a single man can fully understand this interface and can cope with all the\neffects of a change on either side of the interface. If there had been 10 times as many wires, it\nprobably would have taken a hundred (or a thousand?) times as many people to handle the\ninterface."5 This also meant that, in the preceding programs, contractors and NASA Centers\ncould develop hardware in relative isolation from one another, which enabled work on multiple\nparts of the system to progress in parallel. The Space Shuttle, on the other hand, had to be highly\nintegrated because of its requirements for re-usability and the ability to land like an aircraft on\nany 10,000-ft runway, among other reasons. The tight integration of the Space Shuttle also\nrequired intensive communication and good working relationships among the different\norganizations involved in its development. The aerodynamic shapes of the Orbiter and launch\nconfigurations were much different than the Mercury, Gemini, and Apollo spacecraft, which\nmeant a significant set of new development challenges for even the experienced workforce\ninvolved in its design and development. The Space Shuttle critical path to Earth is shown in\nFigure E.1-4.\n\n5\n\nSP-287, "What Made Apollo a Success." George M. Low, introduction. Accessed on 10/12/10 at:\nhttp://klabs.org/history/reports/sp287/ch1.htm; SP-4219, \xe2\x80\x9cThe Space Shuttle\xe2\x80\x99s First Flight, STS-1,\xe2\x80\x9d Henry C.\nDethloff; SP-6104, \xe2\x80\x9cA perspective on the Human-Rating Process of U.S. Spacecraft: Both Past and Present,\xe2\x80\x9d\nGeorge Zupp, Editor, February 1995.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n48 of 58\n\nFigure E.1-4. Space Shuttle Critical Path for Return to Earth\n\nConsiderations for crew safety were a tremendous challenge over previous programs due to the\nvehicle\xe2\x80\x99s complex launch and reentry configuration. One of the most significant challenges was\nhow to address the issue of first-stage aborts (while the SRBs were thrusting). The unique Space\nShuttle system design took the Program down a different solution path than previous programs.\nSeveral first-stage abort concepts were considered for the Space Shuttle but each introduced its\nown significant safety risks and complexities. As a result, the decision was made that these\nadditional risks and complexities were of greater concern than the presumed low failure rates of\nthe solid motors. For those areas deemed \xe2\x80\x98high risk\xe2\x80\x99 more stringent design requirements were\nderived to build in greater reliability. For example, simultaneous ignition, simultaneous thrust\ntail off, and similar thrust profiles were absolutely critical and received extraordinary attention\nand ground testing. Previous human spacecraft included additional safety through escape\ncapsules or crew ejection in order to accept the less than desired launch vehicle reliability. The\nSpace Shuttle, alternatively, used an historical solid rocket motor (SRM) performance database\nand extensive testing to minimize risk and deemed the vehicle acceptable for crewed flight\nwithout first-stage abort capability.6\n\n6\n\nSP-6104, \xe2\x80\x9cA perspective on the Human-Rating Process of U.S. Spacecraft: Both Past and Present,\xe2\x80\x9d George Zupp,\nEditor, February 1995.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n49 of 58\n\nThe Space Shuttle Program\xe2\x80\x99s significant emphasis on the approach of focusing on reliability\nand/or redundancy of high-risk areas relied on extensive testing and quality control processes\nbeing successfully implemented as part of the decision considerations to fly a crew on the first\n(or any) launch. The effective and appropriate use of test articles and test results was vital. The\nSpace Shuttle Enterprise played a large role in supporting this approach.\nThe Enterprise was not designed to be capable of spaceflight. It was designed and built as a test\nbed for conducting the horizontal ground vibration tests (HGVTs) at the manufacturing plant.\nThe HGVT activity was designed to test the structural integrity of Space Shuttle Orbiters with\nparticular emphasis on launch and landing conditions.\nLater, Enterprise was modified to support the approach and landing tests at Edwards Air Force\nBase in California. Many systems that would be required for an actual flight into space were\neither simpler versions or were not even aboard Enterprise for these tests. The Enterprise\napproach and landing tests included four categories (this is also an example of how to do\nincremental test build ups with aircraft):\n1. Three Taxi Tests, intended to verify the taxi characteristics of the 747 Shuttle Carrier\nAircraft (SCA) while carrying a Space Shuttle. These were runway taxi tests only and\ndid not involve flight. No crew flew aboard Enterprise for these tests.\n2. Five Captive-Inactive Flights, intended to verify the performance, stability, and control of\nthe SCA while carrying a Space Shuttle in flight. No crew flew aboard Enterprise for\nthese tests.\n3. Three Captive-Active Flights, intended to determine the best separation profile that\nEnterprise could utilize as it separated from the SCA during upcoming Free Flights,\nrefine crew procedures, and evaluate Enterprise flight systems. A two-man crew flew\naboard Enterprise for these tests.\n4. Five Free Flights, intended to verify the airworthiness, integrated system operations,\npilot-guided landing systems, and automated landing systems of the Space Shuttle. A\ntwo-man crew flew aboard Enterprise for these tests. The first four glides to the Rogers\nDry Lake runway provided real envelope expansion. The first three drops were\nconducted on the lake bed with a drag-reducing tail cone over the boat tail. Flight 4\nremoved the tail cone but used the long lake bed so that there was no pressure to try to\nland on the spot. Finally, flight 5 was targeted for the concrete runway without a tail\ncone to evaluate the braking and roll out control that would be representative of an\noperational return.\nAt the conclusion of the Enterprise approach and landing tests, NASA certified the Space Shuttle\nOrbiter as aerodynamically sound for subsonic flight and determined that no additional flight\ntests would be necessary. Enterprise, as a high-fidelity pathfinder, was then extensively used to\ntest Kennedy Space Center (KSC) equipment and procedures that would be necessary to support\nprocessing operations of a Space Shuttle.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n50 of 58\n\nThe use of the Enterprise in testing is only one example of the extensive hardware, avionics,\nsoftware, and operations development and testing that were done in preparation for getting the\nSpace Shuttle ready for its first launch. The complexity of the Space Shuttle introduced\nnumerous additional interactions and dependencies (such as thermal and power management,\nGN&C and mechanical system dependencies, and complex software integration and\nmanagement) and required much more integration and testing to ensure proper coordinated\nfunctionality.\nThe baseline plan in 1973 was to fly the first Space Shuttle mission with a crew, yet preserve an\noption to launch without a crew. However, at the Program Director\xe2\x80\x99s Review in June of that\nyear, two key issues were raised: Should the first flight be baselined with a crew, and if so,\nshould ejection seats be used? The Program wanted to avoid dual mode vehicle design and focus\nthe Program along a single path.7\nPart of the rationale for deleting the uncrewed flight test options was that the successful return of\nthe Orbiter was critical to the continuation of the vertical flight test program (one of a kind\nspacecraft), and the crew would significantly increase the probability of this success. There was\na recognized risk to the crew, but the Space Shuttle design effort and test program was geared to\nestablish confidence in the system. It was postulated that maintaining a dual path would detract\nfrom or compound the development effort of the baseline crewed system, thus reducing its\nreliability and robustness.\nThe major points discussed at this key review were the necessity of recovering the Orbiter, past\nexperiences of crew members saving a mission from failure, confidence in ground-test programs,\ncrew ability to deal with contingencies (i.e., landing at alternate sites), preventing hazards to over\nflight of population, capabilities of abort and ejection systems, and the impact of an uncrewed\noption on crewed design effort (uncrewed capability requires a successful auto land program).\nThe decision from that review was to proceed with design, development, and testing of the Space\nShuttle considering only a crewed first flight and to discontinue development of the uncrewed\noption. It was also stated that the decision would be reviewed again 18 months before the first\norbital flight. The rationale was that as the benefits of crewed flight (greater probability of\nsuccess, less risk to fly over populated areas, lower cost, and better operational system) far\noutweighed the crew and program risks involved.\nIn 1977, at the planned review 18 months prior to launch, the conclusion remained that the\ncrewed first flight test was superior for reasons of mission success and avoidance of diluted\nprogram effort, and the crew risk was acceptable. The reasons supporting the original decision\nwere essentially unchanged and the maturing of the Space Shuttle design and the test program\nexperience increased the overall confidence.\n\n7\n\n\xe2\x80\x9cChronology of Decision, Manned versus Unmanned Vertical Flight Test for the Space Shuttle,\xe2\x80\x9d compiled by\nCode Q, NASA HQ, August 15, 2002.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n51 of 58\n\nAlthough program and Agency management decided that the first Space Shuttle flight would\ninclude crew, they had to ensure a safe and successful first flight. As a result, the team pushed\nthe envelope in design analysis and ground testing. For example:\nx\n\nMany wind tunnel years were devoted to building an aerodynamic database for each\nconfiguration over the entire range of Mach numbers\n\nx\n\nThousands of hours of super-computer time evaluating structural models combining\nthermal and dynamic loads\n\nx\n\nValidation of redundant data systems involved years of hardware and software\ncompatibility tests in dedicated facilities\n\nx\n\nDevelopment and validation of the stand-alone backup flight computer to protect against\nloss of the tightly synchronized redundant computer set\n\nx\n\nYears of development testing for thermal protection systems\n\nx\n\nYears of system operation simulations to develop and test flight procedures and rules\n\nx\n\nDeveloped Shuttle training aircraft to support development of approach and landing\ntechniques and crew training\n\nx\n\nSpace Shuttle Main Engines (SSME) had 726 starts and 110,000 seconds of testing\nbefore STS-1\n\nx\n\nSSME certification tests demonstrated boundary of performance on ground before first\nflight\n\nx\n\nExternal Tank structural test article with over 1,000 strain gauges\n\nx\n\nMated ground vibration test provided design information for guidance and control\nsystems\n\nx\n\nSRM underwent full-scale static tests before first flight that included four development\nmotors and three qualification motors\n\nThe first four Space Shuttle missions using Columbia were deemed to be orbital flight test (OFT)\nmissions. The OFT configuration included thousands of pounds of development flight\ninstrumentation. Each of the OFT missions included a minimum crew of two and employed\nejection seats (which were later removed). The first crewed Space Shuttle launch occurred on\nApril 12, 1981.\nGeneral Observations\nOn the surface, it may appear that each of the four programs discussed did not follow the same\napproach to determining the first crewed flight, as each occurred at a seemingly different time in\nthe test program. This is due, however, mainly to the differences in system design and mission.\nThough each decision was not reconstructed, it was evident that each program followed similar\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n52 of 58\n\nthought processes outlined in the body of this report. Each event on the critical path to a safe\nreturn to Earth was thoroughly tested and the programs were continually questioning the results,\ndata, and previous assumptions. The residual risks were discussed at all levels of management\nand open deliberations and communications were evident throughout the program teams.\nWhile Mercury, Gemini, and Apollo were formally separate programs, in practice they\nfunctioned as one decade-long program leading up to the accomplishment of the mission set\nforth by President Kennedy in 1961 to send a man to the Moon and return him safely to Earth.\nThe knowledge gained in each program informed all of the subsequent programs. The same held\ntrue for the workforce, which transferred relatively seamlessly from one program to the other. In\none decade, for example, a group of engineers that had never before built a spacecraft went on to\ndevelop four (Mercury, Gemini, Apollo Lunar Module, and Apollo Command Module) (See\nFigure E.1-5).\n\nFigure E.1-5. U.S. Human Spaceflight Development\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n53 of 58\n\nThis previous workforce experience carried over beyond Apollo and Skylab to the development\nof the Space Shuttle and was invaluable in that development. Though the Space Shuttle posed\naltogether different technical challenges than the earlier programs, there was strong continuity of\nengineering design and operations personnel from the early programs to the design and\ndevelopment of the Space Shuttle. Few of these experienced engineers and managers have been\na part of the development of the newer human spaceflight programs.\nThe second-generation workforce, on the other hand, did not have the benefit of developing and\noperating a new human-rated launch system for more than two decades between the first launch\nof the Space Shuttle and the establishment of CxP. It can be noted that there was some\ncontinuity in the design of human-rated spacecraft and significant upgrades within the launch\nvehicle. There were also other programs initiated, but not fully developed, tested, and put into\noperation. Another change that shaped the second-generation workforce was the growing role\nthat information technology played in the work of engineering. The primary computational tools\nfor the first-generation workforce that developed Mercury, Gemini, and Apollo were slide rules,\npencils, and paper. NASTRAN, a finite element analysis (FEA) program, was introduced in the\nlate 1960s, by which time the design and development of the Apollo Program was complete.\nSome of those tools were later used in an assessment of Apollo performance and flight data. By\nthe mid-1980s, the use of modeling tools such as CAD and computer-aided manufacturing\n(CAM) had become standard practice and these tools grew increasingly sophisticated over the\nnext decades. While modeling tools revolutionized the practice of aerospace engineering, they\nalso distanced practitioners from fundamental calculations, making them dependent on the\nassumptions embedded in the software. The earlier work methods, while arduous, aided in the\nrapid development of engineering judgment by ensuring that practitioners understood the\nnumbers that informed their designs.\nWhile the technical and technological issues faced by previous and future human-rated space\nprograms may be different, the same fundamental factors that are essential to mission success\nremain the same: sound engineering judgment, attention to detail, continuous questioning,\ntechnically competent engineers and managers, and constant vigilance.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n54 of 58\n\nAppendix F. Benchmarking with U.S. Navy and Air Force Flight Test Center\nIn assessing when to fly a crew on a new vehicle for the first time, the inputs and experiences\nfrom other organizations with similar crew implementation requirements were sought. Personnel\nfrom the Air Force Flight Test Center (AFFTC) at Edwards Air Force Base in California and the\nU.S. Navy\xe2\x80\x99s Virginia-class Program Office (for submarines) were consulted on their respective\nprocesses and practices for putting into service first-in-class crewed vehicles. Both of these\norganizations have a history of developing and testing high-risk vehicles in severe environments:\nthe U.S. Navy\xe2\x80\x99s nuclear submarines and the U.S. Air Force\xe2\x80\x99s advanced aircraft. Nuclear\nsubmarines operate in an extreme depth under high water pressure and at the edge of\nperformance, and advanced aircraft operate in the extreme conditions of the atmosphere at the\nedge of performance. Both organizations develop and test new systems on a regular basis; the\nlast new submarine class was in 2000 and the latest advanced aircraft is the F-35 (December\n2006). While the advanced systems are developed primarily by industry, both government\norganizations are involved in the development process and have the final safety review and\nacceptance prior to a first use of the new systems. Therefore their experience and processes were\nconsidered relevant to this study.\nBoth organizations were asked to address the following questions:\nx\n\nHow is it determined when in the test program to add the crew for the first time? Can\nrequirements be reduced if the configuration is similar to a previous vehicle? What\ntradeoffs, if any, are considered?\n\nx\n\nHow is it determined that the benefit of having a crew is greater than the risk to the crew?\n\nx\n\nHave the processes been documented (such as standards or policies, etc.) that specifically\noutline what is required before a crew can be put on board to operate the vehicle? If so,\nwhat is the documentation and does it change for differing environments?\n\nAir Force Flight Test Center Experience\nThe AFFTC\xe2\x80\x99s mission is to developmental flight test a system to determine if it meets\nspecifications, uncover any problem areas, and ultimately recommend whether the system is\nready to proceed to operational testing. Their approach is based on the diversity of systems,\nfrom new state-of-the-art fighter aircraft to a fuselage tank on 50-yr-old aircraft, for which they\nare responsible for establishing flight safety. This broad spectrum of systems requires processes\nand requirements that can be tailored to meet the needs of each system. Rarely have there been\nvehicles that are flown first without a crew and then with a crew, therefore the decision process\nfor adding a crew is in place for the first flight. A broad combination of ground analysis and test\nis required before a first crewed flight, with each unique program or system evaluated\nindividually.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n55 of 58\n\nThe AFFTC utilizes multiple reviews, including those for the developmental flight test,\noperational flight test, and operational use. There is a distinct difference in what level of risk and\nuncertainty may be acceptable prior to proceeding with a flight test program versus sending the\nsystem to an operational unit for routine use. For readiness to proceed to operational testing or\ndeployment, the results from the flight test program are added to the results from the ground test\nand analysis to assess an overall risk. The AFFTC may decide the risk is acceptable to proceed\nwith flight testing, but that the risk is not yet sufficiently low to proceed with operational\ndeployment, including operational testing. A risk matrix is utilized, which attempts to identify\nspecific risks along with the probability of occurrence and the consequences if they do occur.\nMany of the risks may be based on computed probabilities of occurrence, but many others are\nqualitative estimates of the probability of occurrence based on experience and engineering\njudgment. An extensive flight test and safety planning process is included to reduce the risk\nfurther by putting forethought into what needs to be tested. The testing addresses the most\neffective and safest approach, and what additional risk mitigation can be applied such as\nincremental testing (starting at the most benign conditions first), procedures, monitoring, etc.\nThe flight test safety planning process is critical to ensuring all that is practical is done in order\nto safely proceed with flight test. The AFFTC has process documentation that outlines what is\nrequired prior to a first flight but can be tailored to a specific situation or system. The process\ntends to be very detailed and often utilizes standards but allows for some flexibility to account\nfor varying systems requirements. Alternatively, the criteria for Air Worthiness Certification\n(MIL-HDBK--516B) for operational status is usually significantly more rigorous than the\nrequirements to proceed with flight test.\nU.S. Navy Nuclear Submarine Experience\nThe U.S. Navy submarine development approach is an incremental process; each new\nsubmarine\xe2\x80\x99s specifications are built on the previous submarine\xe2\x80\x99s specifications. A three-tiered\norganization and process of program management, technical authority, and safety and quality, is\nused to determine when the ship is ready for its first sea trial. A combined complement of\ncontractor and government, from these listed organizations, goes on the first sea trials where\nhull, propulsion systems, and safety systems are tested together as a system for the first time.\nA combination of contractor and Navy personnel operates the ship but nuclear power plant\noperations can only be operated by Navy nuclear personnel. The Navy\xe2\x80\x99s development process\nfor submarines includes locating the ship\xe2\x80\x99s crew and Navy civilians at the contractor site\nthroughout manufacture and testing. Prior to the sea trials, a \xe2\x80\x9cmaximum reasonable assurance\xe2\x80\x9d\nthat the ship is safe to go to sea is determined, based on the experience and judgment of the\nprogram management, technical authority, and safety and quality. The crew lives on-board\nduring the initial testing, followed by dock trials and Fast Cruise. Fast Cruise is the operation of\nthe ship as if it was at sea, concentrating on operations and safety systems. Once the primary\nsystems required to return the crew safely to land are tested and the vehicle/ship is determined to\nbe safe, the remainder of the ship is tested. Incremental testing and operation of systems is\nperformed during sea trials that allow the crew to incrementally test up to operating capability.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n56 of 58\n\nAn independent assessment is performed prior to delivery that evaluates the ship to ensure it\nmeets the needs of the Navy. The independent assessment includes a review of paperwork and\nunderway trials. Once the review is completed at the end of testing, the ship testing results are\npresented to a board. The board evaluates two elements for unrestricted operations: Is the\nmaterial sound and is the ship force trained? All mandatory deficiencies, as defined by the\nboard, must be corrected prior to acceptance.\nThe team observed several commonalities between AFFTC and U.S. Navy approaches. Those\ncommonalities and a brief discussion of how they might apply to a human spaceflight program\nare as follows:\n1. Both AFFTC and the U.S. Navy are able to do incremental expansion of development,\ntesting, and operational capability, and thus do not initially operate at full capability of\nthe vehicle. It is more difficult for a crewed space system to do incremental expansion.\nTo some extent, incremental testing of various components can be performed, however,\nincremental testing of an integrated vehicle is typically prohibitive due to cost and\navailability of one-of-a-kind hardware (unless features allowing for upgrades are part of\nthe initial design).\n2. Both AFFTC and the U.S. Navy have new development programs on a regular basis.\nThis on-going development allows the organizations to consistently maintain their\nknowledge and experience base, building on lessons from program to program, rather\nthan having to relearn. NASA may create a new crewed space system in multiple decade\nincrements. It is much more difficult to maintain a knowledge and experience base and\nmany lessons are lost.\n3. Both AFFTC and the U.S. Navy stressed that the final evaluation was a judgment call and\nthat the extensive design activities and testing that occurred prior to the first flight/sea\ntrial provided information for that judgment. As noted in #2 above, that judgment is also\nbased on experience in developing new systems.\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n57 of 58\n\nAppendix G. Selected References\nThe following selected references were deemed by the team to be informative and beneficial in\naddressing the question of first crewed flight.\nHuman Rating:\nNPR 8705.2B, Human-Rating Requirements for Space Systems\nNASA-STD-3000, Man-Systems Integration Standards, July 1995\nSSP 50808, ISS Commercial Orbital Transportation Services (COTS) Interface\nRequirements Document, Revision A, April 2008\nT98-10212, A Review of Man Rating in past and Current Manned Space Flight Programs,\nA. Bond, 1998\nHistorical:\nMercury Chronology, http://history.nasa.gov/SP-4001/contents.htm\nGemini Chronology, http://history.nasa.gov/SP-4002/contents.htm\nApollo Chronology, http://www.hq.nasa.gov/office/pao/History/SP-4009/contents.htm\nSaturn Chronology (MSFC), http://history.nasa.gov/MHR-5/contents.htm\nMSFC internal letter, Apollo 502 Anomaly Resolution and AS 503 Flight with Crew\nDecision, 1968\nAIAA paper 3812, ELV Human Rating, Atlas Heritage and Future Potential, author\nHolguin, tracking number 33343\nNASA TMX 57497, Pilot Safety Program for Mercury-Atlas Launch Vehicle, B A\nHohmann, 1963\nHistory of Rocketry and Space Travel, W. von Braun and F. I. Ordway III, (Thomas Y.\nCrowell, New York, 1969).\nApollo Program Summary Report, http://history.nasa.gov/apsr/apsr.htm\nApollo-Saturn 205 Mission, MSFC 70-30, 215 C.1, Jan 1966\nApollo links (KSC), http://www-pao.ksc.nasa.gov/kscpao/history/apollo/apollo.htm\nNASA SP Series on Space Exploration, http://history.nasa.gov/series95.html\n\nNESC Request No.: TI-10-00619\n\nNASA Engineering and Safety Center\nTechnical Assessment Report\n\nDocument #:\n\nVersion:\n\nNESC-RP10-00619\n\n1.0\nPage #:\n\nTitle:\n\nReadiness for First Crewed Flight\n\n58 of 58\n\nSafety/Risk:\nSSP 30309E, Safety Analysis and Risk Assessment Requirements, July 2009\nNPR8000.4, Agency Risk Management Procedural Requirements, December 2008\nNPR8715.3, Safety and Mission Assurance Plan\nNPD 8610.7D, Launch Services Risk Mitigation Policy for NASA-Owned and/or NASASponsored Payloads/Missions, January 2008\nProbabilistic Risk Assessment Procedures Guide for NASA Managers and Practitioners,\nVersion 1.1, Dr. Michael Stamatelatos, NASA OSMA, August 2002.\nNASA/SP-2010-576, NASA Risk-Informed Decision Making Handbook, April 2010\nJS-2010-017, Significant Incidents Human Spaceflight, Rev A\nDesign, Test, and Verification:\nNESC RP-06-108, Design, Development, Test and Evaluation Considerations for Safe and\nReliable Human Rated Spacecraft Systems\nScience Applications International Corporation, A Study Of Commercial Industry Best\nPractices In Test & Evaluation Which are Potentially Applicable to DoD Developmental\nTest And Evaluation, 2002\nNASA-STD-7009, Standard for Models and Simulations, August 2008\nProgram/Project Management:\n7120.5D NASA Space Flight Program and Project Management Requirements\nAerospace Report TOR-2005(8617)-4204, 100 Questions for Technical Review, September\n2005\nSystems Engineering and Integration:\nNASA SP-2007-6105, NASA Systems Engineering Handbook\nNPR 7123.1A, NASA Systems Engineering Processes and Requirements\n\nNESC Request No.: TI-10-00619\n\nForm Approved\nOMB No. 0704-0188\n\nREPORT DOCUMENTATION PAGE\n\nThe public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions, searching existing data sources,\ngathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this\ncollection of information, including suggestions for reducing this burden, to Department of Defense, Washington Headquarters Services, Directorate for Information Operations and\nReports (0704-0188), 1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202-4302. Respondents should be aware that notwithstanding any other provision of law, no person\nshall be subject to any penalty for failing to comply with a collection of information if it does not display a currently valid OMB control number.\nPLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.\n\n1. REPORT DATE (DD-MM-YYYY)\n\n2. REPORT TYPE\n\n01- 04 - 2011\n\n3. DATES COVERED (From - To)\n\nTechnical Memorandum\n\nMarch 2010 - April 2011\n\n4. TITLE AND SUBTITLE\n\n5a. CONTRACT NUMBER\n\nReadiness for First Crewed Flight\n5b. GRANT NUMBER\n5c. PROGRAM ELEMENT NUMBER\n5d. PROJECT NUMBER\n\n6. AUTHOR(S)\n\nSchaible, Dawn M.\n5e. TASK NUMBER\n5f. WORK UNIT NUMBER\n\n869021.05.07.07.25\n7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES)\n\n8. PERFORMING ORGANIZATION\nREPORT NUMBER\n\nNASA Langley Research Center\nHampton, VA 23681-2199\n\nL-20026 NESC-RP-10-00619\n9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS(ES)\n\n10. SPONSOR/MONITOR\'S ACRONYM(S)\n\nNational Aeronautics and Space Administration\nWashington, DC 20546-0001\n\nNASA\n11. SPONSOR/MONITOR\'S REPORT\nNUMBER(S)\n\nNASA/TM-2011-217089\n12. DISTRIBUTION/AVAILABILITY STATEMENT\n\nUnclassified - Unlimited\nSubject Category 16-Space Transportation and Safety\nAvailability: NASA CASI (443) 757-5802\n13. SUPPLEMENTARY NOTES\n\n14. ABSTRACT\n\nThe NASA Engineering and Safety Center (NESC) was requested to develop a generic framework for evaluating whether any\ngiven program has sufficiently complete and balanced plans in place to allow crewmembers to fly safely on a human\nspaceflight system for the first time (i.e., first crewed flight). The NESC assembled a small team which included experts with\nexperience developing robotic and human spaceflight and aviation systems through first crewed test flight and into operational\ncapability. The NESC team conducted a historical review of the steps leading up to the first crewed flights of Mercury through\nthe Space Shuttle. Benchmarking was also conducted with the United States (U.S.) Air Force and U.S. Navy. This report\ncontains documentation of that review.\n\n15. SUBJECT TERMS\n\nNASA Engineering and Safety Center; Human spaceflight; Low Earth orbit; First crewed flight\n\n16. SECURITY CLASSIFICATION OF:\na. REPORT\n\nU\n\nb. ABSTRACT c. THIS PAGE\n\nU\n\nU\n\n17. LIMITATION OF\nABSTRACT\n\nUU\n\n18. NUMBER 19a. NAME OF RESPONSIBLE PERSON\nOF\nSTI Help Desk (email: help@sti.nasa.gov)\nPAGES\n19b. TELEPHONE NUMBER (Include area code)\n\n63\n\n(443) 757-5802\nStandard Form 298 (Rev. 8-98)\nPrescribed by ANSI Std. Z39.18\n\n'