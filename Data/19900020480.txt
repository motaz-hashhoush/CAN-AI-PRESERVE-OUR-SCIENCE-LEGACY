b'N 9 0 - 2 2)\nROBOTIC\n\nSusumu Tachi,\n\n98\n\nTELE-EXISTENCE\n\nHirohiko\n\nArai\n\nand Taro\n\nMaeda\n\nMechanical Engineering Laboratory, MITI\nI-2, Namiki, Tsukuba\n305 JAPAN\n\nAbstract\nTele-existence\nis an advanced type of teleoperation\nsystem that\nenables a human operator at the controls to perform remote manipulation\ntasks dexterously with the feeling that he or she exists in the remote\nanthropomorphic\nrobot in the remote environment.\nIn this report the concept\nof the tele-existence\nis shown, the principle of the tele-existence\ndisplay\nmethod is explained, some of the prototype systems are described, and its\nspace application\nis discussed.\nI. Introduction\nTele-existence\n\naims at a natural\n\nand efficient\n\nremote\n\ncontrol\n\nof\n\nrobots by providing an operator a real time sensation of presence. It is an\nadvanced type of teleoperation system that enables a human operator at the\ncontrols to perform remote manipulation tasks dexterously with the feeling\nthat he or she exists in one of the remote anthropomorphic\nrobots in the\nseveral remote environments\n[I,2]. Similar concept is called artificial\nreality\n\n[3] or telepresence\n\n[4].\n\nFundamental\n\nfor the realization\n\nstudies\n\nof the tele-existence\n\nsystem are now being conducted in the authors\' division of the Mechanical\nEngineering Laboratory (MEL) as part of the National Large Scale Project\ncalled JUPITER (JUvenescent PIoneeing TEchnology for Robots), which is a\nresearch and development program of advanced robot technology for a system\nthat avoids the need for humans to work in potentially hazardous working\nenvironments,\nsuch as nuclear power plants, under sea, and disaster areas.\nIn previous papers [I,2], the principle of the tele-existence\ndisplay method was proposed. Its design procedure was explicitly defined.\nExperimental display hardware was made, and the feasibility of the visual\ndisplay with a sensation of presence was demonstrated\nby psychophysical\nexperiments using the test hardware. In the latest paper [5], a method was\nproposed to realize a mobile tele-existence\nsystem, which can be remotely\ndriven with the auditory and visual sensation of presence. A prototype\nsystem was constructed and the feasibility of the method was evaluated. The\neffectiveness\nof the proposed system was evaluated by navigation\nexperiments of the mobile robot through an obstructed space. Several\ndisplay and operation methods were compared quantitatively\nusing the time\nelapsed, smoothness of the travelled path and the number of collisions as\nthe criteria for comparison.\n\n171\n\nIn this report the concept of the tele-existence\nis shown, the\nprinciple of the tele-existence display method is explained, some of the\nprototype systems are described including an anthropomorphic\nrobot with\nseven degrees of freedom arm, which is designed and developed as a slave\nrobot for feasibility experiments of teleoperation\nusing tele-existence\nmethod.\n2. Tele-existence\n\na remote\n\nIn tele-existence,\nan autonomous anthropomorphic\nrobot is placed at\nsite and an information transmission communication channel is\n\nestablished between human and robot. The operator\'s movements and physical\nstatus are sensed and transmitted to the robot via this communication\nchannel. The transmitted signals override the autonomy of the robot and\ndirectly control the robot\'s motor system to reproduce the exact movements\nof the operator in its artificial eyes, neck, hands, legs, and feet.\nInformation picked up by the artificial sensory organs of the robot are\ntransmitted back to the operator via the communication channel to the\noperator\'s sensory organs.\nTake vision for example. Whichever direction the operator looks,\nthe robot will look in the exact same spot. The operator will see on his\nretinae the image seen by the robot, in exactly the same manner as it would\nbe seen by a human in the same position. If the operator were to bring his\narm in front of his eyes, he would see the robot\'s arm being brought into\nhis field of view in exactly the same relative position as his own arm.\nThus the operator is able to maintain his or her visual sensation and\nproprioceptive\nsensation coherent. The operator can perform tasks via a\nrobot at a distance yet maintain the same spacial relation among the\nobjects, the arms and the environment as that by direct observation.\nAuditory and tactile sensations are also transmitted to the operator.\nObjects touched by the robot are also felt by the operator as tactile\nstimuli.\nTele-existence\ntechnology also goes beyond the scope of the human\nsenses. Radiation, ultra-violet rays, infrared, micro waves, ultrasonic\nwaves, and ultra low frequency sound information sensed by the robot\nsensors can also be utilized to augment the human operator. For example\ninfrared information picked up by the robot sensors can be converted into\nvisible light on the operator\'s display. As the display gives a realistic\nsensation of presence, tasks can be performed in the dark yet with the\nillusion that it is light. These pieces of information can also be\nsuperimposed on the visual display as three dimentional superimposition.\nFor example, by adding distance information at the location of an object.\nIt is also possible to display human like solid model arms instead of the\nmechanical robot\'s arms, which enhances the operator\'s sensation of\npresence.\nThe final version of the tele-existence\nsystem will be consisted of\nintelligent mobile robots, their supervisory subsystem, a remote-presence\nsubsystem and a sensory augmentation subsystem, which allows an operator\nto use robot\'s ultrasonic, infrared and other, otherwise invisible, sensory\ninformation with the computorgraphics-generated\npseudorealistic\nsensation\nof presence. In the remote-presence\nsubsystem realistic visual, auditory,\n\n172\n\ntactile,\n3.\n\nkinesthetic\n\nPrinciple\n\nof\n\nand vibratory\n\nTele-Existence\n\ndisplays\nand Means of\n\nmust\n\nbe realized\n\n[I].\n\nRealization\n\nThe basic\nconfiguration\nof the tele-existence\nsystem is shown in\nFig.\nI. Take vision\nas an example\nto explain\nthe principle\nof the display\nwhich gives\na sensation\nof presence\n[I]o\nThe system is based on the principle\nthat\nthe world we see is\nreconstructed\nby the human brain\nusing\nonly two real\ntime\nimages on the two\nretinae\nof a human. What we get from the environment\nare only\ntwo-dimensional\npictures\non the retina\nchanging\nin real\ntime according\nto\nthe movement of the eyeballs\nand the head. We reconstruct\nthe\nthree-dimensional\nworld\nin the brain\nand project\nthe reconstructed\nworld\nto\nthe real\nthree-dimensional\nworld\n[I].\nIn our new type of robotic\ndisplay;\n(a) human movements including\na head and/or\neyeballs\nare precisely\nmeasured\nin real\ntime,\n(b) robot\nsensors\nand effectors\nare constructed\nanthropomorphically\nin\nfunction\nand size,\n(c) movements of the robot\nsensors\nare controlled\nprecisely\nto follow\nthe\nhuman operator\'s\nmovement,\nand\n(d) the pictures\ntaken\nby the robot\nsensors\nare displayed\ndirectly\nto the\nhuman eyes in a manner which assures\nthe the same visual\nspace as is\nobserved\ndirectly\nat the robot\'s\nlocation.\nThis display\nenables\nan operator\nto see the robot\'s\nupper\nextremities,\nwhich are contrlled\nto track\nin real\ntime precisely\nthe same\nmovement of the operator\'s,\ninstead\nof his/hers\nat the position\nhis/her\nupper extremities\nshould\nbe.\n4.\n\nDesign\n\nof\n\nthe\n\nVisual\n\nDisplay\n\nwith\n\nSensation\n\nof\n\nPresence\n\nEssential\nparameters\nfor human three\ndimensional\nperception\nof\nobject\nare:\n(I)\nthe size of the retinal\nimage of the object,\nor visual\nangle,\n(2) convergence\nof the two eyes,\nor equivalent\ndisparity\nof the\nretinal\nimages,\nand (3) accomodation\nof the crystalline\nlenses.\nAdding\nthe above monochromatic\nparameters,\nfidelity\nin color\nis important\nfor\nrealistic\ndisplay\n[5].\n\nan\ntwo\nto\na\n\nFigure\n2 (a) shows a schematic\ndiagram\nof the direct\nobservation\nof\nan object\nin three\ndimensional\nspace.\nThe human observer\nmeasures\nthe\nconvergence\nangle\n((_.) and the size of the object\non the retina\n(Im).\nSince\nthe distance\nbetween the two eyes (Wm) and the distance\nbetween\nthe\ncrystalline\nlens and the retina\n(am) are known, a human observer\ncan\nestimate\nthe distance\nto the object\n(dobj)\nand the size\nof the object\n(lobj)\nas follow\n[5]:\ndobj\nlobj=\nIf we think\nto the direction\nof\nas shown in Fig.\n5,\n\n(la)\n(Ib)\n\n= Wm/2tan(O_/2)\ndobj*Im/am\nof a virtual\nplane at\nthe head; and project\nand the human observer\n\n173\n\na distance\nthe object\nobserves\n\nof dvir\nperpendicular\nimage onto the plane\nthe projected\nimages by\n\nusing\nthe corresponding\neyes, then the observed\nparameters,\ni.e.,\no_ and\nlobj,\nare the same and the human observer\ngets the same lobj\nand dobj.\nThe\nlobj\nand dobj can be derived\nby using\nthe equivalent\ndisparity\n(ed) on the\nvirtual\nplane\nand the projected\nimage size\non the virtual\nplane\n(Ivir)\nas\nfollows:\ndobj\nlobj\nwhere\n\ndvir\n\nsituation\nproduce\ndistance\n\nis\n\nthe\n\n= Wm*dvir/(Wm-ed)\n= dobj*Ivir/dvir\n\ndistance\n\nto\n\nthe\n\n(2a)\n(2b)\n\nvirtual\n\nplane.\n\nFigure\n2(b)\nshows the display\nsystem which\nreproduces\nthe same\nas the direct\nobservation.\nTwo TV displays\nand lens systems\nthe virtual\nimages of the size\nIvir\non the virtual\nplane\nat the\nof dvir\nwith\nthe equivalent\ndisparity\nof ed.\n\nFigure\n2(c)\nshows the slave\nrobot\'s\ncamera system,\nwhere\ndistance\nbetween\nlenses\nWs is set to be equal\nto Wm. The distance\ntwo CCD devices\n(wcam) is usually\n,but\nnot necessarily,\nset as\nWcam=Wdis=Ws, where Wdis is the distance\nbetween the two centers\ndisplays.\n\nthe\nbetween\nof\n\nthe\n\nTV\n\nUnder these\nconditions,\nwe define\na magnification\nfactor\n_ =\nIdis/Is.\nThen by arranging\nam:_*as,\nwe have the condition\nof Fig.6,\nwhich\nis the same condition\nas for a direct\nobservation.\nPractically,\nam can be\ndetermined\nby measuring\nthe size\nof the image on the diplay\n(Idis)\nwhen\nmonitored\nthrough\nthe TV camera for a known size\nobject\nlobj\nat the known\ndistance\n\ncondition\n\ndobj\n\nas:\n\nam =\n\n_\n\nThe focal\nlength\nthat\nthe virtual\n\n*dobj,\nof\n\nwhere\n\n_=\n\nIdis/lobj.\n\nthe lens (fm) must be selected\nto meet\nimage of the TV display\nis on the virtual\n\nIdeally\nthe distance\nto the virtual\nplane\n(dvir)\ncontrolled\nto coincide\nwith\nthe dobj controlling\nboth fm\nexperiments\nrevealed\nthat\nif 200 mm _dobj\n<oo,\ndvir\ncan\nmm, and if\n145 mm_dobj_2OOOmm,\ndvir\ncan be fixed\nto 500\nthe design\nand realization\nof the system more practical.\n\nthe\nplane.\n\nshould\nbe\nand am. However,\nbe fixed\nto I000\nmm. This makes\n\nIf these\nconditions\nare satisfied\nand the cameras and the display\nsystem follow\nthe head movement of the operator,\nthe ideal\ncondition\nof the\ndirect\nobservation\nis always maintained\n[5].\nIn order\nto have a wide view\nwithout\nmoving the operator\'s\nhead, a short\nfocal\nlength\nof the camera (fs)\nmust be selected\nand the appropriate\nvalues\nfor as and am must be set.\n5.\n5.1.\n\nDesign\n\nand Control\n\nMaster-Slave\n\nof\n\nControlled\n\nDisplay\n\nMechanisms\n\nActive\n\nDisplay\n\nMechanism\n\n[2]\n\nFigure\n3 shows the experimental\nhardware\nsystem for the evaluation\nstudy.\nThe movement of the head of the human subject\nis measured\nin real\ntime\nby the light\nweight\ngoniometer\nwith\nsix degrees\nof freedom.\nThree\ntranslational\ncoordinates\n(x,y,z)\nand three\nrotational\nangles\n(roll,pitch,\nyaw) are calculated\nby a microprocessor,\nand both the camera position/\n\n174\n\norientation and the display\nfollow the head movement.\n\nposition/orientation\n\nare servo-controlled\n\nto\n\nAs the number of degrees of freedom of the allowed head movement is\nlarge, it is impossible to use the torque produced by the operator\'s head\nmovement as the energy source of the movement of the display device. Even\nif the weight is removed by a counter balance mechanism, the inertia can\nnot be eliminated. Therefore, it is necessary to servo-control\nthe display\ndevice.\nThe active display mechanism shown in Fig. 3 has five degrees of\nfreedom. Each degree of freedom is actuated by a direct drive torque motor\n(Inland Rare Earth D.D.Torque Motor). The dispaly follows the goniometer\'s\nmovement like a master-slave manipulator system with the goniometer as a\nmaster and the display as a slave.\nVisual displays were designed according to the procedure proposed\nin section 4 using two 1.5 inch color CRTs. The visual tele-existence\nsystem with these displays were experienced by several subjects. All\nsubjects had an impression that this type of display produces very\nrealistic feeling of remote presence. Adding to the qualitative evaluation,\nobjective and quntitative experiments were also conducted [2].\nExperiments with this hardware revealed, however, that the\nposition/ orientation control is not enough. Subjects usually want a\ncompliant motion which follows their head movement. Therefore, force\ncontrol based on the measurement of the head movement and/or force\ncondition\n\nbecomes\n\n5.2. Impedance\n\nnecessary.\n\nControlled\n\nActive\n\nDisplay\n\nMechanism\n\nFigure 4 shows a general view of the impedance controlled headcoupled display with two degrees of freedom. It has an active power\nassistance mechanism and its impedance can be controlled by internal\nfeedback loop. We used direct drive motors to attain this mechanisms,\nand\nthe dedicated computer controls the impedance of the display mechanisms so\nthat the human operator feels only quite low inertia compared with the\nphysical inertia of the system.\nThe dynamic equation\nexpressed as follows:\n\nof a system with\n\nKtl + To = J_s _\n\n+ Fb_\n\ns\n\n+\n\none degree of freedom\n\nFc,\n\ncan be\n\n(3)\n\nwhere e is the motor rotary angle, I is the motor current, Kt is the\nsensitivity of the motor torque, To is the torque caused by the manual\nforce, J is the moment of inertia, Fb is the viscous friction coefficient,\nand Fc is Coulomb\'s friction torque.\nBy substituting\nI : (oLJ(_s\'+_Fb(_s\ninto equation\n\n+_rFc)/Kt,\n\n(3), we find that\n\n175\n\n(O<W,_,_\'<l)\n\n(4)\n\nTo = (l-#C)J_s\nwhich\n\nexhibits\n\nthe\n\neffects\n\nz + (l-@)FbOs\n\nattainable\n\n+ (l-_\')Fc,\n\nby multiplying\n\nthe\n\n(5)\ninertia\n\nforce,\n\nviscous times\nfriction as high,\nforce, respectively.\nand Coulomb\'s In friction\nforce it (I-_), possi\n(l-#)\'oandb_e\nt\n(I-_)\nother\nwords,\nis\nredesign\nthe motion\nequations\nof the system\n(or impedance\nof the system)\ninto\nan arbitrary\nform through\ninternal\nfeedback\n[6,7].\nAn extention\nof\nthe method to the multiple\ndegrees\nof freedom\nsystem\nis shown in [6].\nFigure\n4(a)\nshows the impedance\ncontrolled\ndisplay\nusing two 3 inch\ncolor\nLCDs, and Fig.\n4(b)\nshows the anthropomorphically\narranged\nslave\ncamera system with\ntwo degrees\nof freedom.\nWhen operators\nactually\nwore the\ndisplay\nand moved it by neck force,\nthe reaction\nforce\ncaused by inertia\nappeared\nto be lighter,\nand they\nreported\nthat\nthe difference\nwas\nparticularly\nnoticeable\nwhen the display\nwas moved swiftly.\nOperators\nfelt\nthat\nthe system\nis quite\nsimilar\nto a passive\nmechanism\nof lighter\nweight.\n5.3.\n\nHead Mounted\n\nDisplay\n\nA Head mounted display is also a promising design approach. The\nmerit of the head mounted display is that an operator can move around quite\neasily, while that the human operator must support all the weight by\nhimself becomes its demerit. Since gravitational\nforce and the inertia of\nthe system can not be compensated\nin this system, the design of light\nweight display is quite important.\nFigure\n5 shows the head-mounted\ndisplay\nMk. I. It weighs\n1.7 Kg,\nincluding\na helmet\n( 620 g for the display).\nIt uses two 4 inch color\nliquid\ncrystal\nTV displays\n(resolution:\nH320 x V220).\nEye lenses\nwhich are\nused to attain\nthe effect\nof Fig.\n2(b)\nare\nmounted on a spectacles\'\nframe.\nLighter\nversion\nof the head mounted display\nMk. II has been made. Its total\nweight\nis 600 g.\n6.\n6.1.\n\nTele-Existence\nMobile\n\nExperimental\n\nTele-Existence\n\nSystems\nSystem\n\n[5]\n\nA prototype\nsystem with\nfundamental\nmobile\nhas been assembled\nfor experimentation.\nThe system\nindependent\nmobile\nrobot\nwith\ntwo TV color\ncameras,\nstation\nwith\nthe visual\nand auditory\ndisplays\nwith\nand a communication\nlink\nbetween\nthe human operator\nDuring\nroutine\nnavigation\ntasks,\nthe robot\nusing\nthe environmental\nmap and the environmental\nthe visual\nsensors\n(two TV cameras and an ultrasonic\nsensors\n(two odometers\non the rear wheels).\n\ntele-existence\nfunctions\nconsists\nof an\na remote\ncontrol\na sensation\nof presence,\nand the mobile\nrobot.\ntravels\nautonomously\ninformation\ngathered\nby\nsensor)\nand internal\n\nThe navigation\nprocess\ncan be monitored\nby the operator.\nWhen the\nrobot\nencounters\na task which the robot\nis not able to manage by itself,\nit\nstops\nand asks the operator\nfor help.\nAt that\ntime the operator\ncontrols\nthe robot\nusing\njoysticks\nas though\nhe were driving\nthat\nrobot\nlike\nan\nautomobile,\ni.e.,\nas if he were on board the robot\nat the position\nwhere\nthe robot\'s\nTV cameras are located.\n\n176\n\nFigure\npresence\nused\ntele-existence\n6.2.\n\n6(a)\nshows the head-linked\nin the system,\nwhile\nFig.\nmobile\nrobot\nconstructed.\n\nTele-existence\n\nManipulation\n\ndisplay\nwith\n6(b)\nshows the\n\na sensation\nprototype\n\nof\n\nSystem\n\nFigure\n7 shows a general\nview of the anthropomorphic\nslave\nrobot\nwith\nan operator\nwearing\nhead-mounted\ndisplay\nexplained\nin Section\n5.3.\nFigure\n8 shows an operator\nusing the impedance\ncontrolled\ndisplay\nexplained\nin Section\n5.2.\nIn the latter\nsystem electromagnetic\nsensor\nis used for the\ncontrol\nof the manipulator.\nThe slave\nrobot\nhas a three\ndegrees\nof freedom\nneck mechanism\non\nwhich stereo\ncamera is mounted.\nThe robot\'s\nstructural\ndimensions\nare set\nvery close\nto those of human\'s,\nand it\nis controlled\nto follow\nthe human\nmovement.\nThe human operator\'s\nelectromagnetic\nsensor\nand\nthe master\'s\nmovement.\nThe\noperator\nand displayed\nas\ndirection\nand size of the\n7.\n\nTele-Existence\n\nhead movement is measured\nin real\ntime using\nthe slave\nrobot\'s\nneck is controlled\nto follow\nstreo\ncolor\nvideo\nsignals\nare sent to the human\na fused\nimage,\nwhich keeps the distance,\nobject\nas those\nof the direct\nobservation.\n\nSimulator\n\nExtension\nof the tele-existence\nto the artificially\nconstructed\nenvironmental\ninformation\nhas been sought,\nthe visual\ntele-existence\nsimulator\nhas designed,\npseudo-real-time\nbinocular\nsolid\nmodel robot\nsimulator\nhas been made, and its\nfeasibility\nhas been experimentally\nevaluated\n[8],\nTwo main\n\nsituations\n\nfor\n\nthe\n\nsimulator\n\nusages\n\nare:\n\n(I)\nTo provide\nthe operator\ninformation\nof the remote\nenvironment\nwhich\nhuman senses do not work but the robot\'s\nsensors\ndo. For example,\nat night\ninfrared\nsensor\ninformation\nis converted\nto visible\nlight\nto see an object\nin the dark.\nIt is also possible\nto superimpose\nrange information\ngathered\nby the robot\'s\nultrasonic\nand/or\nlaser\nrange sensors\nto the three\ndimensional\nvisual\ndisplay.\nThe operator\ncan effectively\nuse this\npiece of\ninformation\nto augment human ability.\n(2) To provide\ntotally\nartificial\nbut realistic\nenvironmental\ninformation\nto the operator,\ne.g.,\nrealization\nof virtual\nterminal\nor virtual\nconsole\nfor the operator\n[3].\nThe operator\ncan enjoy\nvariety\nof consoles\nwithout\nchanging\nthem physically.\nThis can also be used for the simulation\nstudy\nfor training\nand also for optimal\nparameter\nselection\nand evaluation\nof\nman-machine\nsystem.\nThe usage of the system as scientific\ntools\nfor the\nanalysis\nof human visual\nsensation,\nmotion\ncontrol\nand sensor-motor\ncoordination\nis also possible.\nAs the first\nstep toward\nthe goal,\na sol_d\nmodel robot\nmanipulator\nwith\npseudo-real-time\nshading\ncapability\nwas constructed.\nBy using\nthe\nspecially\ndesigned\nbinocular\noptical\nsystem,\nthree\ndimensional\nobservation,\nwhich can exactly\nassign\nthe distance\nand the size\nof the manipulator\nand\nan object,\nbecame possible.\n\n177\n\n8. Space Applications\nWide variety of application of tele-existence\ntechnology\ncan be conceived, including tele-observation,\ntele-maintenance,\ntele-construction,\ntele-experiment,\nand tele-experience.\n\nto space\n\nIn Japan the Space Robot Resarch Planning Committee for the\nMinistry of International Trade and Industry has been organized. In the\ncommittee a space robot which replace some of the human extravehicular\nactivities is being planned. Tele-existence will be intensively applied for\nthe design of the space tele-robot.\nIn order to apply tele-existence technology to a tele-robotic\nsystem whose slave robot is located far away and the time delay for\ncommunication\ncan not be neglected, it is important for a slave robot to be\nautonomous.\nFoundamental study for the realization of tele-existence using\nautonomous robots as slaves under the circumstances\nis now being conducted\nin the authors\' laboratory.\n\nReferences\n[I]\n\n[2]\n\nS. Tachi\net al.,"Tele-existence\n(I)\n-Design\nand evaluation\nof a visual\ndisplay\nwith\nsensation\nof presence-,"\nProceedings\nof the 5th Symposium\non Theory\nand Practice\nof Robots and Manipulators\n(RoManSy 84),\npp.245-254,\nClSM-IFToMM,\nUdine,\nItaly,\nJune 1984.\nS.Tachi\nand H.Arai,"Study\non tele-existence\n(II)\n-Three\ndimensional\ncolor\ndisplay\nwith\nsensation\nof presence-,\nProceedings\nof the \'85\nInternational\nConference\non Advanced\nRobotics\n(ICAR),\npp.345-352,\nTokyo,\nJapan,\nSept.\n1985.\n\n[3]\n\nS.S. Fisher\net al.,"Virtual\nWorkshop on Interactive\nCarolina,\nOctober\n1986.\n\n[4]\n\nJ.D. Hightower,\nE.H.Spain\net al.,"Telepresence:\nA hybrid\napproach\nhigh-performance\nrobots,"\nProceedings\nof the \'87 International\nConference\non Advanced\nRobotics\n(ICAR),\npp.563-573,\nVersailles\nOctober\n1987.\n\n[5]\n\n[6]\n\n[7]\n\n[8]\n\nenvironment\n3D Graphics,\n\ndisplay\npp.l-ll,\n\nsystem,"\nACM 1986\nChapel Hill,\nNorth\nto\nFrance,\n\nS.Tachi,\nH.Arai,\nl. Morimoto\nand G.Seet,"Feasibility\nexperiments\non a\nmobile\ntele-existence\nsystem,"\nThe International\nSymposium and\nExposition\non Robots (19th\nISIR),\nSydney,\nAustralia,\nNovember 1988.\nH.Arai\nand S.Tachi,"Force\ndetection\nand active\npower assistance\nof a\ndirect-drive\nmanipulator,"\nAdvanced\nRobotics,\nvol.2,\nno.3,\npp.241-257\n1987.\nH.Arai\nand S.Tachi,"Development\nof\ndisplay\nsystem using\na direct-drive\n1989 (to be published).\nS. Tachi,\n\nH.Arai\n\na power-assisted\nhead-coupled\nmotor,"\nAdvanced\nRobotics,\n\nand T.Maeda,"Tele-existence\n\nsimulator\n\nreality\n(I),\n-Design\nand evaluation\nof a binocular\nsolid\nmodels-,"\nProceedings\nof the IEEE International\nIntelligent\nRobots and Systems,\npp.719-724,\n1988.\n\n178\n\nwith\n\nvol.3,\n\nartificial\n\nvisual\ndisplay\nusing\nWorkshop on\n\nMEASUREMENT\nOF\nWHOLE BODY MOVEMENT\n==_DISPLAY\n\nOF SENSORY\n\nAUDITORY,\n1\n\n_N\nINFORMATION_---"_\'_\n\nTAOTII"E,\n\n"")--i"\n\n(vISUAL\'\n\n__._,__\nCONTROL\n\nOF\n\nwM\nTRANSMISSION\n(HEAD,\n\nMANIPULATORS,\nVEHICLE,\n"")\n\nOF MOVEMENT\nINFORMATION\nEYES, ARMS, BODY, "")\nFig.\n\n1\n\nConcept\n\nof\n\nthe\n\ntele-existence.\nVirluol\nPlone\n\nVirluol\nPlone\n\ni\n\nI\n\n. ,\n!lenslm\nTV dispmoy\nL..,._,,= ,\'_ ,-,\n_Rm\n\n.\n\nLm\nI\nI\nI\n\n_ucb\n\nL\n[\n\nII\n\n.......\n\nd\xc2\xa5ir\n\n_dobj\nd,i,\n\n\xe2\x80\xa2 -_\n\nJ\n\nr\'.....\n\no : convergence ongle\n\na : convergence on(jle\ned : equivolenl di_ority\n\ned : equivolenl dispo(ily\n\nFig. 2(a)\n\nVisual\n\nP"ed\n\nI\n\nI\n\n_m\n\nparameters\n\nof\n\ndirect\n\nFig. 2(b)\n\nobservation.\n\nParameters through the display.\n\nl_tl s ../_1 Is\nR\nV_\'--"\n\n,\n\nL, 1.2:\nz: dobj\n\n,\n\nl,w:\n\n,\n\n}--\xc2\xa3\'-,.4\'\n-_/Wcom\n\nFig.\n\nFig.\n\n3\n\n,"_\'\'\n\nBLACK\n\nMaster-slave\n\ncontrolled\n\nactive\n\nFig. 4(a)\n\ndisplay.\n\n?it:I P_,t._C\n\n" ......\n,-_i,4_ WH;iL\n\nP;\'.OiOGRAPH\n\n2(c)\n\n179\n\nParameters\n\nImpedance\n\nof\n\nthe\n\ncontrolled\n\nslave\n\nactive\n\nrobot.\n\ndisplay.\n\ni _, ..._,_o_\n\n_\n\nb_..<,.,_,, A_\'_\',._....\n\nFig.\n\n4(b)\n\nSlave\n\ncamera\n\nE i_r--,Oi-OGRAPH\n\nsystem.\nFig.\n\nFig.\n\nFig.\n\nFig.\n\n6(a)\n\n7\n\nHead-coupled\n\nAnthropomorphic\n\n6(b)\n\n5\n\nTele-existence\n\nHead\n\nmounted\n\nmobile\n\ndisplay.\n\nrobot.\n\ndisplay.\n\nslave\n\nrobot.\n\nFig.\n\n180\n\n8\n\nOperation\n\nusing\n\nimpedance\n\ncontrolled\n\ndisplay.\n\n'